{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestions = pd.read_csv('Questions.csv', delimiter=\"|\", names=[\"qID\", \"qHeader\", \"qvote\", \"question\", \"qCodePart\", \"qPostTime\", \"qAuthor\", \"qAuthorRep\", \"numAnswers\"])\n",
    "dfAnswers = pd.read_csv('Answers.csv', delimiter=\"|\", names=[\"qid\", \"acceptFlag\", \"ansId\", \"ansVote\", \"ans\", \"ansCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23133\n",
      "22235\n"
     ]
    }
   ],
   "source": [
    "# Number of Questions\n",
    "print(len(dfQuestions))\n",
    "# Number of Answers\n",
    "print(len(dfAnswers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19995\n",
      "19059\n"
     ]
    }
   ],
   "source": [
    "# Number of Unique Questions\n",
    "print(len(dfQuestions['qID'].unique()))\n",
    "# Number of Unique Answers\n",
    "print(len(dfAnswers['ansId'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuestions = dfQuestions.drop_duplicates(\"qID\", ignore_index=True)\n",
    "dfAnswers = dfAnswers.drop_duplicates(\"ansId\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19995\n",
      "19059\n"
     ]
    }
   ],
   "source": [
    "# Number of Questions\n",
    "print(len(dfQuestions))\n",
    "# Number of Answers\n",
    "print(len(dfAnswers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>qHeader</th>\n",
       "      <th>qvote</th>\n",
       "      <th>question</th>\n",
       "      <th>qCodePart</th>\n",
       "      <th>qPostTime</th>\n",
       "      <th>qAuthor</th>\n",
       "      <th>qAuthorRep</th>\n",
       "      <th>numAnswers</th>\n",
       "      <th>qid</th>\n",
       "      <th>acceptFlag</th>\n",
       "      <th>ansId</th>\n",
       "      <th>ansVote</th>\n",
       "      <th>ans</th>\n",
       "      <th>ansCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74250490</td>\n",
       "      <td>How to calculate mAP on test dataset using pyt...</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nI am new to AI. I am working on VisDrone d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-10-30 04:27:15Z</td>\n",
       "      <td>ShehjadK</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74249708</td>\n",
       "      <td>Pytorch least squares residuals computation</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nThe pytorch implementation of least square...</td>\n",
       "      <td>[&lt;code&gt;# data to work with\\r\\n    targets = t_...</td>\n",
       "      <td>2022-10-30 00:07:09Z</td>\n",
       "      <td>Feillen</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74249550</td>\n",
       "      <td>How does one find the name of a local variable...</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nI have lambda function that is screwing up...</td>\n",
       "      <td>[&lt;code&gt;Traceback (most recent call last):\\r\\n ...</td>\n",
       "      <td>2022-10-29 23:24:55Z</td>\n",
       "      <td>Charlie Parker</td>\n",
       "      <td>9,917</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74248377</td>\n",
       "      <td>What is an efficient way to make a dataset and...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI'm trying to forecast high frequency time...</td>\n",
       "      <td>[&lt;code&gt;class TSDataset(Dataset):\\r\\n  \\r\\n  de...</td>\n",
       "      <td>2022-10-29 19:53:07Z</td>\n",
       "      <td>Toshi Mint</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74248099</td>\n",
       "      <td>Tensor repeat for image patches</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI have a batch of 20 flattened tensors rep...</td>\n",
       "      <td>[&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; imgs.shape\\r\\n(20, 65536)\\...</td>\n",
       "      <td>2022-10-29 19:10:06Z</td>\n",
       "      <td>Tamir</td>\n",
       "      <td>1,019</td>\n",
       "      <td>1</td>\n",
       "      <td>74248099.0</td>\n",
       "      <td>True</td>\n",
       "      <td>74248275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\r\\nI would suggest reshaping your scores arra...</td>\n",
       "      <td>[&lt;code&gt;import torch\\r\\nimg_size = 4\\r\\npatch_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24787</th>\n",
       "      <td>71108331</td>\n",
       "      <td>torchaudio load audio with specific sampling rate</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nFrom documentation, https://pytorch.org/au...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-14 07:20:34Z</td>\n",
       "      <td>Zabir Al Nazi</td>\n",
       "      <td>9,565</td>\n",
       "      <td>2</td>\n",
       "      <td>71108331.0</td>\n",
       "      <td>True</td>\n",
       "      <td>73463011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nYou can resample with torchaudio.functiona...</td>\n",
       "      <td>[&lt;code&gt;torchaudio.functional.resample&lt;/code&gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24788</th>\n",
       "      <td>71108331</td>\n",
       "      <td>torchaudio load audio with specific sampling rate</td>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\nFrom documentation, https://pytorch.org/au...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-14 07:20:34Z</td>\n",
       "      <td>Zabir Al Nazi</td>\n",
       "      <td>9,565</td>\n",
       "      <td>2</td>\n",
       "      <td>71108331.0</td>\n",
       "      <td>True</td>\n",
       "      <td>71108407.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\r\\nResample can be used from transforms.\\r\\nw...</td>\n",
       "      <td>[&lt;code&gt;Resample&lt;/code&gt;, &lt;code&gt;waveform, sample...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24789</th>\n",
       "      <td>70733004</td>\n",
       "      <td>Python pitch modulation (not shifting)</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI want to augment my audio data for a mach...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-01-16 18:33:50Z</td>\n",
       "      <td>stanislax</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>70733004.0</td>\n",
       "      <td>False</td>\n",
       "      <td>70734375.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nPedalboard is a library for audio data aug...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24790</th>\n",
       "      <td>70733004</td>\n",
       "      <td>Python pitch modulation (not shifting)</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI want to augment my audio data for a mach...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-01-16 18:33:50Z</td>\n",
       "      <td>stanislax</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>70733004.0</td>\n",
       "      <td>False</td>\n",
       "      <td>70747404.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nAre any of the libraries that are listed i...</td>\n",
       "      <td>[&lt;code&gt;pcmOut[1] = pcmIn[1] * (0.9) + pcmIn[2]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24791</th>\n",
       "      <td>69241010</td>\n",
       "      <td>how do I correct dc offset with torchaudio hig...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI am segmenting drum audio files at each t...</td>\n",
       "      <td>[&lt;code&gt;from torchaudio.functional import highp...</td>\n",
       "      <td>2021-09-19 06:55:15Z</td>\n",
       "      <td>cbhower</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>69241010.0</td>\n",
       "      <td>False</td>\n",
       "      <td>69248232.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\r\\nIt turns out the dc offset was produced by...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24792 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qID                                            qHeader  qvote  \\\n",
       "0      74250490  How to calculate mAP on test dataset using pyt...     -1   \n",
       "1      74249708        Pytorch least squares residuals computation     -1   \n",
       "2      74249550  How does one find the name of a local variable...     -1   \n",
       "3      74248377  What is an efficient way to make a dataset and...      0   \n",
       "4      74248099                    Tensor repeat for image patches      0   \n",
       "...         ...                                                ...    ...   \n",
       "24787  71108331  torchaudio load audio with specific sampling rate      1   \n",
       "24788  71108331  torchaudio load audio with specific sampling rate      1   \n",
       "24789  70733004             Python pitch modulation (not shifting)      0   \n",
       "24790  70733004             Python pitch modulation (not shifting)      0   \n",
       "24791  69241010  how do I correct dc offset with torchaudio hig...      0   \n",
       "\n",
       "                                                question  \\\n",
       "0      \\r\\nI am new to AI. I am working on VisDrone d...   \n",
       "1      \\r\\nThe pytorch implementation of least square...   \n",
       "2      \\r\\nI have lambda function that is screwing up...   \n",
       "3      \\r\\nI'm trying to forecast high frequency time...   \n",
       "4      \\r\\nI have a batch of 20 flattened tensors rep...   \n",
       "...                                                  ...   \n",
       "24787  \\r\\nFrom documentation, https://pytorch.org/au...   \n",
       "24788  \\r\\nFrom documentation, https://pytorch.org/au...   \n",
       "24789  \\r\\nI want to augment my audio data for a mach...   \n",
       "24790  \\r\\nI want to augment my audio data for a mach...   \n",
       "24791  \\r\\nI am segmenting drum audio files at each t...   \n",
       "\n",
       "                                               qCodePart  \\\n",
       "0                                                     []   \n",
       "1      [<code># data to work with\\r\\n    targets = t_...   \n",
       "2      [<code>Traceback (most recent call last):\\r\\n ...   \n",
       "3      [<code>class TSDataset(Dataset):\\r\\n  \\r\\n  de...   \n",
       "4      [<code>&gt;&gt;&gt; imgs.shape\\r\\n(20, 65536)\\...   \n",
       "...                                                  ...   \n",
       "24787                                                 []   \n",
       "24788                                                 []   \n",
       "24789                                                 []   \n",
       "24790                                                 []   \n",
       "24791  [<code>from torchaudio.functional import highp...   \n",
       "\n",
       "                  qPostTime         qAuthor qAuthorRep  numAnswers  \\\n",
       "0      2022-10-30 04:27:15Z        ShehjadK         19           0   \n",
       "1      2022-10-30 00:07:09Z         Feillen         97           0   \n",
       "2      2022-10-29 23:24:55Z  Charlie Parker      9,917           0   \n",
       "3      2022-10-29 19:53:07Z      Toshi Mint          1           0   \n",
       "4      2022-10-29 19:10:06Z           Tamir      1,019           1   \n",
       "...                     ...             ...        ...         ...   \n",
       "24787  2022-02-14 07:20:34Z   Zabir Al Nazi      9,565           2   \n",
       "24788  2022-02-14 07:20:34Z   Zabir Al Nazi      9,565           2   \n",
       "24789  2022-01-16 18:33:50Z       stanislax          3           2   \n",
       "24790  2022-01-16 18:33:50Z       stanislax          3           2   \n",
       "24791  2021-09-19 06:55:15Z         cbhower         59           1   \n",
       "\n",
       "              qid acceptFlag       ansId  ansVote  \\\n",
       "0             NaN        NaN         NaN      NaN   \n",
       "1             NaN        NaN         NaN      NaN   \n",
       "2             NaN        NaN         NaN      NaN   \n",
       "3             NaN        NaN         NaN      NaN   \n",
       "4      74248099.0       True  74248275.0      1.0   \n",
       "...           ...        ...         ...      ...   \n",
       "24787  71108331.0       True  73463011.0      0.0   \n",
       "24788  71108331.0       True  71108407.0      1.0   \n",
       "24789  70733004.0      False  70734375.0      0.0   \n",
       "24790  70733004.0      False  70747404.0      0.0   \n",
       "24791  69241010.0      False  69248232.0      1.0   \n",
       "\n",
       "                                                     ans  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4      \\r\\nI would suggest reshaping your scores arra...   \n",
       "...                                                  ...   \n",
       "24787  \\r\\nYou can resample with torchaudio.functiona...   \n",
       "24788  \\r\\nResample can be used from transforms.\\r\\nw...   \n",
       "24789  \\r\\nPedalboard is a library for audio data aug...   \n",
       "24790  \\r\\nAre any of the libraries that are listed i...   \n",
       "24791  \\r\\nIt turns out the dc offset was produced by...   \n",
       "\n",
       "                                                 ansCode  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4      [<code>import torch\\r\\nimg_size = 4\\r\\npatch_s...  \n",
       "...                                                  ...  \n",
       "24787  [<code>torchaudio.functional.resample</code>, ...  \n",
       "24788  [<code>Resample</code>, <code>waveform, sample...  \n",
       "24789                                                 []  \n",
       "24790  [<code>pcmOut[1] = pcmIn[1] * (0.9) + pcmIn[2]...  \n",
       "24791                                                 []  \n",
       "\n",
       "[24792 rows x 15 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnAMerged = pd.merge(left = dfQuestions, right= dfAnswers, how='outer', left_on='qID', right_on='qid')\n",
    "QnAMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>qHeader</th>\n",
       "      <th>qvote</th>\n",
       "      <th>question</th>\n",
       "      <th>qCodePart</th>\n",
       "      <th>qPostTime</th>\n",
       "      <th>qAuthor</th>\n",
       "      <th>qAuthorRep</th>\n",
       "      <th>numAnswers</th>\n",
       "      <th>qid</th>\n",
       "      <th>acceptFlag</th>\n",
       "      <th>ansId</th>\n",
       "      <th>ansVote</th>\n",
       "      <th>ans</th>\n",
       "      <th>ansCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74249708</td>\n",
       "      <td>Pytorch least squares residuals computation</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nThe pytorch implementation of least square...</td>\n",
       "      <td>[&lt;code&gt;# data to work with\\r\\n    targets = t_...</td>\n",
       "      <td>2022-10-30 00:07:09Z</td>\n",
       "      <td>Feillen</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74249550</td>\n",
       "      <td>How does one find the name of a local variable...</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nI have lambda function that is screwing up...</td>\n",
       "      <td>[&lt;code&gt;Traceback (most recent call last):\\r\\n ...</td>\n",
       "      <td>2022-10-29 23:24:55Z</td>\n",
       "      <td>Charlie Parker</td>\n",
       "      <td>9,917</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74248377</td>\n",
       "      <td>What is an efficient way to make a dataset and...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI'm trying to forecast high frequency time...</td>\n",
       "      <td>[&lt;code&gt;class TSDataset(Dataset):\\r\\n  \\r\\n  de...</td>\n",
       "      <td>2022-10-29 19:53:07Z</td>\n",
       "      <td>Toshi Mint</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74248099</td>\n",
       "      <td>Tensor repeat for image patches</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI have a batch of 20 flattened tensors rep...</td>\n",
       "      <td>[&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; imgs.shape\\r\\n(20, 65536)\\...</td>\n",
       "      <td>2022-10-29 19:10:06Z</td>\n",
       "      <td>Tamir</td>\n",
       "      <td>1,019</td>\n",
       "      <td>1</td>\n",
       "      <td>74248099.0</td>\n",
       "      <td>True</td>\n",
       "      <td>74248275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\r\\nI would suggest reshaping your scores arra...</td>\n",
       "      <td>[&lt;code&gt;import torch\\r\\nimg_size = 4\\r\\npatch_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74247049</td>\n",
       "      <td>Round Tensor in Python but preserve the decima...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI am relatively new to pytorch and working...</td>\n",
       "      <td>[&lt;code&gt;[[[-0.9969, -0.9993, -0.9994,  ..., -0....</td>\n",
       "      <td>2022-10-29 16:42:18Z</td>\n",
       "      <td>Mish</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24774</th>\n",
       "      <td>65580989</td>\n",
       "      <td>Problem reproducing the predicted covariance o...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI need to build a function that gives the ...</td>\n",
       "      <td>[&lt;code&gt;        from gpytorch.mlls import Exact...</td>\n",
       "      <td>2021-01-05 14:39:36Z</td>\n",
       "      <td>Bruno Morabito</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>65580989.0</td>\n",
       "      <td>False</td>\n",
       "      <td>65594220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nI found the errors:\\r\\n\\r\\nThe noise is no...</td>\n",
       "      <td>[&lt;code&gt;K += noise  * np.eye(n_datapoints)&lt;/cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>60363286</td>\n",
       "      <td>Sklearn Gaussian Process and GPytorch give dif...</td>\n",
       "      <td>3</td>\n",
       "      <td>\\r\\nI try to replicate a solution for a GP reg...</td>\n",
       "      <td>[&lt;code&gt;from sklearn.model_selection import tra...</td>\n",
       "      <td>2020-02-23 14:37:22Z</td>\n",
       "      <td>AJK</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>74032126</td>\n",
       "      <td>Torchaudio.load returning attribute, not tensor</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI'm using torchaudio.load() to load an aud...</td>\n",
       "      <td>[&lt;code&gt;torchaudio.load()&lt;/code&gt;, &lt;code&gt;tensor(...</td>\n",
       "      <td>2022-10-11 17:44:43Z</td>\n",
       "      <td>mehsheenman</td>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24784</th>\n",
       "      <td>73379250</td>\n",
       "      <td>\"RunTime Error: Failed to load audio\" for mp3 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>\\r\\nNo matter how I import my audio file (thro...</td>\n",
       "      <td>[&lt;code&gt;waveform, sample_rate = torchaudio.load...</td>\n",
       "      <td>2022-08-16 19:18:35Z</td>\n",
       "      <td>ihavenoidea</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>73379250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>74141435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nAt the time of the question is posted, Goo...</td>\n",
       "      <td>[&lt;code&gt;!add-apt-repository -y ppa:savoury1/ffm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24785</th>\n",
       "      <td>73364960</td>\n",
       "      <td>Unable to use TorchAudio</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nGood morning, for some reason I cannot get...</td>\n",
       "      <td>[&lt;code&gt;pip3 install torchaudio&lt;/code&gt;, &lt;code&gt;c...</td>\n",
       "      <td>2022-08-15 18:21:13Z</td>\n",
       "      <td>Novous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18845 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qID                                            qHeader  qvote  \\\n",
       "1      74249708        Pytorch least squares residuals computation     -1   \n",
       "2      74249550  How does one find the name of a local variable...     -1   \n",
       "3      74248377  What is an efficient way to make a dataset and...      0   \n",
       "4      74248099                    Tensor repeat for image patches      0   \n",
       "5      74247049  Round Tensor in Python but preserve the decima...      0   \n",
       "...         ...                                                ...    ...   \n",
       "24774  65580989  Problem reproducing the predicted covariance o...      0   \n",
       "24779  60363286  Sklearn Gaussian Process and GPytorch give dif...      3   \n",
       "24780  74032126    Torchaudio.load returning attribute, not tensor      0   \n",
       "24784  73379250  \"RunTime Error: Failed to load audio\" for mp3 ...      2   \n",
       "24785  73364960                           Unable to use TorchAudio      0   \n",
       "\n",
       "                                                question  \\\n",
       "1      \\r\\nThe pytorch implementation of least square...   \n",
       "2      \\r\\nI have lambda function that is screwing up...   \n",
       "3      \\r\\nI'm trying to forecast high frequency time...   \n",
       "4      \\r\\nI have a batch of 20 flattened tensors rep...   \n",
       "5      \\r\\nI am relatively new to pytorch and working...   \n",
       "...                                                  ...   \n",
       "24774  \\r\\nI need to build a function that gives the ...   \n",
       "24779  \\r\\nI try to replicate a solution for a GP reg...   \n",
       "24780  \\r\\nI'm using torchaudio.load() to load an aud...   \n",
       "24784  \\r\\nNo matter how I import my audio file (thro...   \n",
       "24785  \\r\\nGood morning, for some reason I cannot get...   \n",
       "\n",
       "                                               qCodePart  \\\n",
       "1      [<code># data to work with\\r\\n    targets = t_...   \n",
       "2      [<code>Traceback (most recent call last):\\r\\n ...   \n",
       "3      [<code>class TSDataset(Dataset):\\r\\n  \\r\\n  de...   \n",
       "4      [<code>&gt;&gt;&gt; imgs.shape\\r\\n(20, 65536)\\...   \n",
       "5      [<code>[[[-0.9969, -0.9993, -0.9994,  ..., -0....   \n",
       "...                                                  ...   \n",
       "24774  [<code>        from gpytorch.mlls import Exact...   \n",
       "24779  [<code>from sklearn.model_selection import tra...   \n",
       "24780  [<code>torchaudio.load()</code>, <code>tensor(...   \n",
       "24784  [<code>waveform, sample_rate = torchaudio.load...   \n",
       "24785  [<code>pip3 install torchaudio</code>, <code>c...   \n",
       "\n",
       "                  qPostTime         qAuthor qAuthorRep  numAnswers  \\\n",
       "1      2022-10-30 00:07:09Z         Feillen         97           0   \n",
       "2      2022-10-29 23:24:55Z  Charlie Parker      9,917           0   \n",
       "3      2022-10-29 19:53:07Z      Toshi Mint          1           0   \n",
       "4      2022-10-29 19:10:06Z           Tamir      1,019           1   \n",
       "5      2022-10-29 16:42:18Z            Mish          1           0   \n",
       "...                     ...             ...        ...         ...   \n",
       "24774  2021-01-05 14:39:36Z  Bruno Morabito        552           1   \n",
       "24779  2020-02-23 14:37:22Z             AJK         97           0   \n",
       "24780  2022-10-11 17:44:43Z     mehsheenman        397           0   \n",
       "24784  2022-08-16 19:18:35Z     ihavenoidea         31           2   \n",
       "24785  2022-08-15 18:21:13Z          Novous          1           0   \n",
       "\n",
       "              qid acceptFlag       ansId  ansVote  \\\n",
       "1             NaN        NaN         NaN      NaN   \n",
       "2             NaN        NaN         NaN      NaN   \n",
       "3             NaN        NaN         NaN      NaN   \n",
       "4      74248099.0       True  74248275.0      1.0   \n",
       "5             NaN        NaN         NaN      NaN   \n",
       "...           ...        ...         ...      ...   \n",
       "24774  65580989.0      False  65594220.0      0.0   \n",
       "24779         NaN        NaN         NaN      NaN   \n",
       "24780         NaN        NaN         NaN      NaN   \n",
       "24784  73379250.0      False  74141435.0      0.0   \n",
       "24785         NaN        NaN         NaN      NaN   \n",
       "\n",
       "                                                     ans  \\\n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4      \\r\\nI would suggest reshaping your scores arra...   \n",
       "5                                                    NaN   \n",
       "...                                                  ...   \n",
       "24774  \\r\\nI found the errors:\\r\\n\\r\\nThe noise is no...   \n",
       "24779                                                NaN   \n",
       "24780                                                NaN   \n",
       "24784  \\r\\nAt the time of the question is posted, Goo...   \n",
       "24785                                                NaN   \n",
       "\n",
       "                                                 ansCode  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3                                                    NaN  \n",
       "4      [<code>import torch\\r\\nimg_size = 4\\r\\npatch_s...  \n",
       "5                                                    NaN  \n",
       "...                                                  ...  \n",
       "24774  [<code>K += noise  * np.eye(n_datapoints)</cod...  \n",
       "24779                                                NaN  \n",
       "24780                                                NaN  \n",
       "24784  [<code>!add-apt-repository -y ppa:savoury1/ffm...  \n",
       "24785                                                NaN  \n",
       "\n",
       "[18845 rows x 15 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnAMerged = QnAMerged[(QnAMerged['qCodePart'] != \"[]\") & (QnAMerged['ansCode'] != \"[]\")]\n",
    "#QnAMerged.drop(QnAMerged.loc[QnAMerged['qCodePart'] == \"[]\" & QnAMerged['ansCode'] == \"[]\"].index, inplace=True)\n",
    "QnAMerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qID</th>\n",
       "      <th>qHeader</th>\n",
       "      <th>qvote</th>\n",
       "      <th>question</th>\n",
       "      <th>qCodePart</th>\n",
       "      <th>qPostTime</th>\n",
       "      <th>qAuthor</th>\n",
       "      <th>qAuthorRep</th>\n",
       "      <th>numAnswers</th>\n",
       "      <th>qid</th>\n",
       "      <th>acceptFlag</th>\n",
       "      <th>ansId</th>\n",
       "      <th>ansVote</th>\n",
       "      <th>ans</th>\n",
       "      <th>ansCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74249708</td>\n",
       "      <td>Pytorch least squares residuals computation</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nThe pytorch implementation of least square...</td>\n",
       "      <td>[&lt;code&gt;# data to work with\\r\\n    targets = t_...</td>\n",
       "      <td>2022-10-30 00:07:09Z</td>\n",
       "      <td>Feillen</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74249550</td>\n",
       "      <td>How does one find the name of a local variable...</td>\n",
       "      <td>-1</td>\n",
       "      <td>\\r\\nI have lambda function that is screwing up...</td>\n",
       "      <td>[&lt;code&gt;Traceback (most recent call last):\\r\\n ...</td>\n",
       "      <td>2022-10-29 23:24:55Z</td>\n",
       "      <td>Charlie Parker</td>\n",
       "      <td>9,917</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74248377</td>\n",
       "      <td>What is an efficient way to make a dataset and...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI'm trying to forecast high frequency time...</td>\n",
       "      <td>[&lt;code&gt;class TSDataset(Dataset):\\r\\n  \\r\\n  de...</td>\n",
       "      <td>2022-10-29 19:53:07Z</td>\n",
       "      <td>Toshi Mint</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74248099</td>\n",
       "      <td>Tensor repeat for image patches</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI have a batch of 20 flattened tensors rep...</td>\n",
       "      <td>[&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; imgs.shape\\r\\n(20, 65536)\\...</td>\n",
       "      <td>2022-10-29 19:10:06Z</td>\n",
       "      <td>Tamir</td>\n",
       "      <td>1,019</td>\n",
       "      <td>1</td>\n",
       "      <td>74248099.0</td>\n",
       "      <td>True</td>\n",
       "      <td>74248275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>\\r\\nI would suggest reshaping your scores arra...</td>\n",
       "      <td>[&lt;code&gt;import torch\\r\\nimg_size = 4\\r\\npatch_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74247049</td>\n",
       "      <td>Round Tensor in Python but preserve the decima...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI am relatively new to pytorch and working...</td>\n",
       "      <td>[&lt;code&gt;[[[-0.9969, -0.9993, -0.9994,  ..., -0....</td>\n",
       "      <td>2022-10-29 16:42:18Z</td>\n",
       "      <td>Mish</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18840</th>\n",
       "      <td>65580989</td>\n",
       "      <td>Problem reproducing the predicted covariance o...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI need to build a function that gives the ...</td>\n",
       "      <td>[&lt;code&gt;        from gpytorch.mlls import Exact...</td>\n",
       "      <td>2021-01-05 14:39:36Z</td>\n",
       "      <td>Bruno Morabito</td>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>65580989.0</td>\n",
       "      <td>False</td>\n",
       "      <td>65594220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nI found the errors:\\r\\n\\r\\nThe noise is no...</td>\n",
       "      <td>[&lt;code&gt;K += noise  * np.eye(n_datapoints)&lt;/cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>60363286</td>\n",
       "      <td>Sklearn Gaussian Process and GPytorch give dif...</td>\n",
       "      <td>3</td>\n",
       "      <td>\\r\\nI try to replicate a solution for a GP reg...</td>\n",
       "      <td>[&lt;code&gt;from sklearn.model_selection import tra...</td>\n",
       "      <td>2020-02-23 14:37:22Z</td>\n",
       "      <td>AJK</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>74032126</td>\n",
       "      <td>Torchaudio.load returning attribute, not tensor</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nI'm using torchaudio.load() to load an aud...</td>\n",
       "      <td>[&lt;code&gt;torchaudio.load()&lt;/code&gt;, &lt;code&gt;tensor(...</td>\n",
       "      <td>2022-10-11 17:44:43Z</td>\n",
       "      <td>mehsheenman</td>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>73379250</td>\n",
       "      <td>\"RunTime Error: Failed to load audio\" for mp3 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>\\r\\nNo matter how I import my audio file (thro...</td>\n",
       "      <td>[&lt;code&gt;waveform, sample_rate = torchaudio.load...</td>\n",
       "      <td>2022-08-16 19:18:35Z</td>\n",
       "      <td>ihavenoidea</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>73379250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>74141435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\\r\\nAt the time of the question is posted, Goo...</td>\n",
       "      <td>[&lt;code&gt;!add-apt-repository -y ppa:savoury1/ffm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>73364960</td>\n",
       "      <td>Unable to use TorchAudio</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nGood morning, for some reason I cannot get...</td>\n",
       "      <td>[&lt;code&gt;pip3 install torchaudio&lt;/code&gt;, &lt;code&gt;c...</td>\n",
       "      <td>2022-08-15 18:21:13Z</td>\n",
       "      <td>Novous</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18845 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            qID                                            qHeader  qvote  \\\n",
       "0      74249708        Pytorch least squares residuals computation     -1   \n",
       "1      74249550  How does one find the name of a local variable...     -1   \n",
       "2      74248377  What is an efficient way to make a dataset and...      0   \n",
       "3      74248099                    Tensor repeat for image patches      0   \n",
       "4      74247049  Round Tensor in Python but preserve the decima...      0   \n",
       "...         ...                                                ...    ...   \n",
       "18840  65580989  Problem reproducing the predicted covariance o...      0   \n",
       "18841  60363286  Sklearn Gaussian Process and GPytorch give dif...      3   \n",
       "18842  74032126    Torchaudio.load returning attribute, not tensor      0   \n",
       "18843  73379250  \"RunTime Error: Failed to load audio\" for mp3 ...      2   \n",
       "18844  73364960                           Unable to use TorchAudio      0   \n",
       "\n",
       "                                                question  \\\n",
       "0      \\r\\nThe pytorch implementation of least square...   \n",
       "1      \\r\\nI have lambda function that is screwing up...   \n",
       "2      \\r\\nI'm trying to forecast high frequency time...   \n",
       "3      \\r\\nI have a batch of 20 flattened tensors rep...   \n",
       "4      \\r\\nI am relatively new to pytorch and working...   \n",
       "...                                                  ...   \n",
       "18840  \\r\\nI need to build a function that gives the ...   \n",
       "18841  \\r\\nI try to replicate a solution for a GP reg...   \n",
       "18842  \\r\\nI'm using torchaudio.load() to load an aud...   \n",
       "18843  \\r\\nNo matter how I import my audio file (thro...   \n",
       "18844  \\r\\nGood morning, for some reason I cannot get...   \n",
       "\n",
       "                                               qCodePart  \\\n",
       "0      [<code># data to work with\\r\\n    targets = t_...   \n",
       "1      [<code>Traceback (most recent call last):\\r\\n ...   \n",
       "2      [<code>class TSDataset(Dataset):\\r\\n  \\r\\n  de...   \n",
       "3      [<code>&gt;&gt;&gt; imgs.shape\\r\\n(20, 65536)\\...   \n",
       "4      [<code>[[[-0.9969, -0.9993, -0.9994,  ..., -0....   \n",
       "...                                                  ...   \n",
       "18840  [<code>        from gpytorch.mlls import Exact...   \n",
       "18841  [<code>from sklearn.model_selection import tra...   \n",
       "18842  [<code>torchaudio.load()</code>, <code>tensor(...   \n",
       "18843  [<code>waveform, sample_rate = torchaudio.load...   \n",
       "18844  [<code>pip3 install torchaudio</code>, <code>c...   \n",
       "\n",
       "                  qPostTime         qAuthor qAuthorRep  numAnswers  \\\n",
       "0      2022-10-30 00:07:09Z         Feillen         97           0   \n",
       "1      2022-10-29 23:24:55Z  Charlie Parker      9,917           0   \n",
       "2      2022-10-29 19:53:07Z      Toshi Mint          1           0   \n",
       "3      2022-10-29 19:10:06Z           Tamir      1,019           1   \n",
       "4      2022-10-29 16:42:18Z            Mish          1           0   \n",
       "...                     ...             ...        ...         ...   \n",
       "18840  2021-01-05 14:39:36Z  Bruno Morabito        552           1   \n",
       "18841  2020-02-23 14:37:22Z             AJK         97           0   \n",
       "18842  2022-10-11 17:44:43Z     mehsheenman        397           0   \n",
       "18843  2022-08-16 19:18:35Z     ihavenoidea         31           2   \n",
       "18844  2022-08-15 18:21:13Z          Novous          1           0   \n",
       "\n",
       "              qid acceptFlag       ansId  ansVote  \\\n",
       "0             NaN        NaN         NaN      NaN   \n",
       "1             NaN        NaN         NaN      NaN   \n",
       "2             NaN        NaN         NaN      NaN   \n",
       "3      74248099.0       True  74248275.0      1.0   \n",
       "4             NaN        NaN         NaN      NaN   \n",
       "...           ...        ...         ...      ...   \n",
       "18840  65580989.0      False  65594220.0      0.0   \n",
       "18841         NaN        NaN         NaN      NaN   \n",
       "18842         NaN        NaN         NaN      NaN   \n",
       "18843  73379250.0      False  74141435.0      0.0   \n",
       "18844         NaN        NaN         NaN      NaN   \n",
       "\n",
       "                                                     ans  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3      \\r\\nI would suggest reshaping your scores arra...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "18840  \\r\\nI found the errors:\\r\\n\\r\\nThe noise is no...   \n",
       "18841                                                NaN   \n",
       "18842                                                NaN   \n",
       "18843  \\r\\nAt the time of the question is posted, Goo...   \n",
       "18844                                                NaN   \n",
       "\n",
       "                                                 ansCode  \n",
       "0                                                    NaN  \n",
       "1                                                    NaN  \n",
       "2                                                    NaN  \n",
       "3      [<code>import torch\\r\\nimg_size = 4\\r\\npatch_s...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "18840  [<code>K += noise  * np.eye(n_datapoints)</cod...  \n",
       "18841                                                NaN  \n",
       "18842                                                NaN  \n",
       "18843  [<code>!add-apt-repository -y ppa:savoury1/ffm...  \n",
       "18844                                                NaN  \n",
       "\n",
       "[18845 rows x 15 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnAMerged.reset_index(drop = True, inplace=True)\n",
    "QnAMerged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "QnAMerged.to_csv(\"CleanednMerged.csv\", sep = \"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "QnAMerged = pd.read_csv('CleanednMerged.csv', delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [<code># data to work with\\r\\n    targets = t_...\n",
       "1        [<code>Traceback (most recent call last):\\r\\n ...\n",
       "2        [<code>class TSDataset(Dataset):\\r\\n  \\r\\n  de...\n",
       "3        [<code>&gt;&gt;&gt; imgs.shape\\r\\n(20, 65536)\\...\n",
       "4        [<code>[[[-0.9969, -0.9993, -0.9994,  ..., -0....\n",
       "                               ...                        \n",
       "18840    [<code>        from gpytorch.mlls import Exact...\n",
       "18841    [<code>from sklearn.model_selection import tra...\n",
       "18842    [<code>torchaudio.load()</code>, <code>tensor(...\n",
       "18843    [<code>waveform, sample_rate = torchaudio.load...\n",
       "18844    [<code>pip3 install torchaudio</code>, <code>c...\n",
       "Name: qCodePart, Length: 18845, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QnAMerged['qCodePart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = QnAMerged[(QnAMerged['qCodePart'].str.split().str.len() > 20) | (QnAMerged['ansCode'].str.split().str.len() > 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[<code># data to work with\\r\\n    targets = t_betas_roi         # shape = [750,4313]\\r\\n    data = t_predictions2         # shape = [60,750,2] we have 2 predictors\\r\\n    n_betas = targets.shape[0]    # 750\\r\\n    n_voxels = targets.shape[1]   # 4313\\r\\n    n_samples = data.shape[0]     # 6340\\r\\n\\r\\n# solution to the least squares problem: data * sols = targets\\r\\n    sols = torch.linalg.lstsq(data, torch.reshape(targets.repeat(n_samples,1,1), [n_samples,n_betas,n_voxels]), rcond=-1)[0] \\r\\n    # sols.shape = [n_samples, 2, n_voxels]\\r\\n\\r\\n# working out the residuals as \\r\\n    resids = targets.repeat(n_samples,1,1) # resids.shape = [60, 750, 4313]\\r\\n    resids = resids - (\\r\\n                  torch.permute(data[:,:,0].repeat(n_voxels,1,1), [1,2,0]).mul(sols[:,0,:].repeat([n_betas,1,1]).permute(1,0,2)) +\\r\\n                  sols[:,1,:].repeat([n_betas,1,1]).permute(1,0,2) # maybe can reduce to scalar?\\r\\n    ) # measure errors\\r\\n    resids = resids.mul(resids) / 748 # square and over degrees of freedom of the residuals\\r\\n    resids.sum(dim=1)\\r\\n</code>, <code>data</code>, <code>target</code>]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['qCodePart'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp['qCodePart'] = temp['qCodePart'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp['qCodePart'] = temp['qCodePart'].str.replace('\\r', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-a4fa3e38accb>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['qCodePart'] = temp['qCodePart'].str.replace('<code>', '')\n"
     ]
    }
   ],
   "source": [
    "temp['qCodePart'] = temp['qCodePart'].str.replace('<code>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-9ff44ef186d5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['qCodePart'] = temp['qCodePart'].str.replace('</code>', '')\n"
     ]
    }
   ],
   "source": [
    "temp['qCodePart'] = temp['qCodePart'].str.replace('</code>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-44-216129a7a689>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['qCodePart'] = temp['qCodePart'].str.replace('&gt;&gt;&gt;', '')\n"
     ]
    }
   ],
   "source": [
    "temp['qCodePart'] = temp['qCodePart'].str.replace('&gt;&gt;&gt;', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ imgs.shape\\r\\n(20, 65536)\\r\\n, (20,64), imgs * score, score.repeat(1,1,64), import torch\\r\\nimg_size = 4\\r\\npatch_size = 2\\r\\nimg = torch.rand((2,img_size,img_size)) # (2,4,4)\\r\\nscore = torch.tensor([[1,2,3,4],[5,6,7,8]]) # (2,4)\\r\\n, score = [[1,1,3,3],[2,2,4,4],[5,5,6,6][7,7,8,8]]\\r\\n]'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['qCodePart'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [# data to work with\\r\\n    targets = t_betas_...\n",
       "1        [Traceback (most recent call last):\\r\\n  File ...\n",
       "2        [class TSDataset(Dataset):\\r\\n  \\r\\n  def __in...\n",
       "3        [ imgs.shape\\r\\n(20, 65536)\\r\\n, (20,64), imgs...\n",
       "4        [[[[-0.9969, -0.9993, -0.9994,  ..., -0.9975, ...\n",
       "5        [class ResNet(nn.Module):\\r\\n\\r\\n    def __ini...\n",
       "6        [import torch\\r\\nfrom torch.utils.data import ...\n",
       "7        [def train_loop(model, opt, loss_fn, X_dataloa...\n",
       "8        [import cv2\\r\\nimport torch\\r\\nimport lietorch...\n",
       "9        [https://github.com/hjxwhy/mipnerf_pl, htop, c...\n",
       "11       [def normalize(img, mean, std):\\r\\n    \"\"\" Nor...\n",
       "13       [import torch.onnx\\r\\n# Standard ImageNet inpu...\n",
       "14       [# Prepare data palatable to DataLoader\\r\\ncla...\n",
       "15       [KeyError: 'eval_loss', args = TrainingArgumen...\n",
       "16       [TypeError: 'Adam' object is not callable\\r\\n,...\n",
       "17       [from summarizer import Summarizer\\r\\n\\r\\nbody...\n",
       "18       [patch_dim = in_channels * patch_size ** 2\\r\\n...\n",
       "20       [torchivision, nn.Identity(), [batch, ch*w*h],...\n",
       "21       [mamba install pytorch torchvision torchaudio ...\n",
       "22       [---------------------------------------------...\n",
       "23       [RuntimeError: CUDA out of memory., !export 'P...\n",
       "24       [RuntimeError                              Tra...\n",
       "25       [pts = [[160, 160], [280, 280]]\\r\\nmask = np.z...\n",
       "26       [x = torch.tensor([1,2,3,4])\\r\\n, tensor([[1, ...\n",
       "27       [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "28       [File \"&lt;MY PROJECT PATH&gt;\\src\\main.py\", l...\n",
       "29       [class NBV_Net(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "30       [run_clm.py, .json, ...\\r\\n{\"text\": \"some text...\n",
       "31       [conda install pytorch==1.11.0 torchvision==0....\n",
       "32       [def train(model, data_in, loss, optim, max_ep...\n",
       "33       [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "34       [Rearrange , from einops.layers.torch import R...\n",
       "35       [Traceback (most recent call last):\\r\\n  File ...\n",
       "36       [WeightedRandomSampler, (bs x 8), total_datase...\n",
       "37       [   inv_mask = ~mask\\r\\n--&gt; 224         loo...\n",
       "39       [trainer.tuner.lr_find, OSError: [Errno 30] Re...\n",
       "40       [class musterModel(nn.Module):\\r\\n    def __in...\n",
       "41       [(grid_search pid=18285) == Status ==\\r\\n(grid...\n",
       "42       [make: /scratch/gpuhost7/rklokov/libs/cuda-10....\n",
       "43       [---------------------------------------------...\n",
       "44       [#r \"nuget: DiffSharp.Core\"\\r\\n#r \"nuget: Diff...\n",
       "45       [    Traceback (most recent call last):\\r\\n   ...\n",
       "47       [from accelerate import notebook_launcher\\r\\n\\...\n",
       "49       [  File \"/home/miranda9/miniconda3/envs/metale...\n",
       "51       [trainer.evaluate()\\r\\n, Evaluation results:  ...\n",
       "53       [std = std_est_network(noisy_img)\\r\\nstage_1_o...\n",
       "54       [python detect.py --weights runs/train/yolo/we...\n",
       "55       [x_train\\r\\ntensor([[68.0000,  2.0000, 27.5000...\n",
       "57       [Precision-recall curve, summarize, print(\"IoU...\n",
       "58       [class GCAN(nn.Module):\\r\\n\\r\\n  def __init__(...\n",
       "60       [cv2.error: OpenCV(4.5.1) C:\\Users\\appveyor\\Ap...\n",
       "61       [feature = self.m_resnet(input), print('featur...\n",
       "62       [Windows 10\\r\\nCUDA Version: 11.3  (according ...\n",
       "63       [def train_model(model, train_loader, test_loa...\n",
       "64       [200x200, x,y, theta, s_x, s_y, x,y, theta, s_...\n",
       "65       [\\r\\nmodel_conv = torchvision.models.resnet18(...\n",
       "66       [class GCN_AISUMMER(nn.Module):\\r\\n\"\"\"\\r\\n\"\"\"\\...\n",
       "67       [def drawMatrix(self,root_name,epoch):\\r\\n    ...\n",
       "70       [chunksize= 100\\r\\nfilename = 'dataset.csv'\\r\\...\n",
       "71       [custom_sort(torch.Tensor([2, 3, 1, 2, 3, 4]))...\n",
       "72       [import torch\\r\\nstart_value, end_value = 4,9\\...\n",
       "74       [class TinyYoloNet(nn.Module):\\r\\n    \\r\\n    ...\n",
       "75       [loss1_grads = torch.autograd.grad(loss1, mode...\n",
       "76                                       [[1, 1, 80, 120]]\n",
       "77       [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "80       [\\r\\nimport torch\\r\\nfrom fastapi import FastA...\n",
       "81       [import torch\\r\\ntensor = torch.rand(1,64,44)\\...\n",
       "82       [import hiddenlayer as hl\\r\\n\\r\\nx_train = np....\n",
       "83       [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "84       [res = torch.clamp(res_not_clamp, 0.0, 1.0)\\r\\...\n",
       "85       [(1, 4, 128, 128), (1, 3, 256, 256), (1, 4, 25...\n",
       "86       [import torch\\r\\n\\r\\nprint(torch.cuda.is_avail...\n",
       "88       [dataLoad=load_breast_cancer()\\r\\nX_train,X_te...\n",
       "90       [\"categories\": [\\r\\n{\\r\\n    \"supercategory\": ...\n",
       "91       [class FashionMNISTModelV2(nn.Module):\\r\\n    ...\n",
       "92       [A, B x 4, B, H x N, A, tensor([[ 2.2640e+03, ...\n",
       "93       [device = torch.device('cuda' if torch.cuda.is...\n",
       "94       [FP16 Run: False\\r\\nDynamic Loss Scaling: True...\n",
       "95       [def check, # Only second inside tensor are ex...\n",
       "96       [# -*- coding: utf-8 -*-\\r\\nfrom sentence_spli...\n",
       "97       [folder\\r\\n│     \\r\\n│\\r\\n└--train\\r\\n    └--─...\n",
       "98       [tensor([[0.],                                ...\n",
       "99       [import torch\\r\\ntorch.manual_seed(0)\\r\\nq = t...\n",
       "100      [!pip install coremltools\\r\\nimport coremltool...\n",
       "101      [transform=torchvision.transforms.Compose([tor...\n",
       "102      [backward(), epoch = 0, Batch:0 Acc_test = 0.2...\n",
       "103      [# get close prices from dataset\\r\\ndf_close =...\n",
       "104      [import gym\\r\\nimport pybullet, pybullet_envs\\...\n",
       "106      [input/output size:      128x128\\r\\nsamples pe...\n",
       "107      [NVIDIA GeForce RTX 3070, windows 10 Enterpris...\n",
       "108      [import torch.nn as nn\\r\\nimport torch.optim a...\n",
       "109      [class DQN(nn.Module):\\r\\ndef __init__(self, a...\n",
       "110      [class MyLoss(nn.Module):\\r\\n    # train loss\\...\n",
       "111      [n_vertices = 3\\r\\nedges = [(0, 1), (0, 2), (0...\n",
       "112      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "113      [net2.load_state_dict(net.state_dict()), #incl...\n",
       "114      [prepare_enviroment()\\r\\n, run_python(\"import ...\n",
       "115      [Model definition code:\\r\\n\\r\\n    class GWTN(...\n",
       "116      [dataiter = iter(train_loader), Length of Data...\n",
       "117      [from monai.transforms import AddChannel\\r\\nfr...\n",
       "119      [summary(model,(3,224,224)) , torch.save(model...\n",
       "120      [class GeneratorModel(nn.Module):\\r\\n    def _...\n",
       "121      [WEIGHT = \"bert-base-uncased\"\\r\\n\\r\\nclass Cla...\n",
       "122      [None, None, import torch\\r\\nimport torch.nn a...\n",
       "123      [# note that this custom dataset is not prepar...\n",
       "124      [output = tensor(\\r\\n          \\r\\n         [[...\n",
       "125      [class MyCrossEntropyLoss(nn.Module):\\r\\n    #...\n",
       "127      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "128      [This is the module I want to add\\r\\nh = float...\n",
       "129      [model = mx.model.FeedForward.load('deep3d', 5...\n",
       "130      [multiprocessing.Pipe, n, m, \\r\\nMode: 'torch'...\n",
       "132      [tensor([[[[[ 59,  59,  34,  51]]],\\r\\n\\r\\n\\r\\...\n",
       "133      [from typing import Callable\\r\\nimport matplot...\n",
       "134      [import os\\r\\nimport numpy as np\\r\\nimport cv2...\n",
       "135      [import torch\\r\\n\\r\\n# ...\\r\\n\\r\\nclass MyInte...\n",
       "136      [import tensorflow as tf\\r\\nfrom tensorflow.ke...\n",
       "137      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "139      [ import numpy as np\\r\\n import torch\\r\\n impo...\n",
       "140      [# 8, 9 is SOS and EOS token respetively and 0...\n",
       "141      [class Generator(nn.Module):\\r\\n\\r\\n    def __...\n",
       "142      [import torch\\r\\n\\r\\nprint(torch.cuda.is_avail...\n",
       "143      [import torch\\r\\n\\r\\nprint(torch.cuda.is_avail...\n",
       "144      [EncoderDecoderModel, from transformers import...\n",
       "145      [EncoderDecoderModel, from transformers import...\n",
       "146      [import tqdm\\r\\nimport gpytorch\\r\\nfrom gpytor...\n",
       "147      [ # calculate the partial derivative of the lo...\n",
       "150      [GAN, Generator, class Generator(nn.Module):\\r...\n",
       "151      [import torch\\r\\nimport torch.nn.functional as...\n",
       "152      [CONFIG = {\\r\\n        'BATCH_SIZE' : 1024,\\r\\...\n",
       "154      [nvcc --version\\r\\n\\r\\nnvcc: NVIDIA (R) Cuda c...\n",
       "155      [train_transform = A.Compose(\\r\\n    [\\r\\n    ...\n",
       "156      [EXAMPLE_IMG = \"path to some image\"\\r\\n, towhe...\n",
       "157      [trainer, trainer = pl.Trainer(limit_train_bat...\n",
       "158      [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "160      [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "161      [num_workers, os.cpu_count(), ERROR: Unexpecte...\n",
       "162      [device = 'mps', /AppleInternal/Library/BuildR...\n",
       "164      [predicted =predicted.cpu() \\r\\nlabel=predicte...\n",
       "165      [class Model(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "166      [Dataset\\r\\n|--- Input\\r\\n|    |--- image1.png...\n",
       "167      [input, nn.module, module, output, input, outp...\n",
       "169      [test = torch.rand((1, 3, 224, 224))     # [N,...\n",
       "170      [model(testx).items(), model(testx).parameters...\n",
       "171      [data = ImageFolder(data_dir, transform=transf...\n",
       "172      [np.random.seed(123)\\r\\ngenerator = torch.Gene...\n",
       "173      [img = nib.load()\\r\\nimg = torch.from_numpy(im...\n",
       "174      [import torch\\r\\nmodel=torch.load('best.pt')\\r...\n",
       "175      [from torch.utils.data import Dataset, DataLoa...\n",
       "176      [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "177      [external_grad = torch.tensor([1., 1.])\\r\\nQ.b...\n",
       "179      [y_hat = [ 0.57,0.05,0.14,0.10,0.14], target =...\n",
       "180      [LSTMCell, 32, 400,005, 70, (batch, time step)...\n",
       "182      [  # get the model using our helper function\\r...\n",
       "183      [import torch\\r\\ntorch.manual_seed(0)\\r\\n\\r\\no...\n",
       "184      [import torch\\r\\nimport cv2\\r\\nfrom torchvisio...\n",
       "187      [import logging\\r\\n\\r\\nimport torch\\r\\nimport ...\n",
       "188      [  auto x_data=json_data.at(\"x\").get&lt;std::v...\n",
       "191      [import numpy as np \\r\\narray = np.random.rand...\n",
       "192      [model(x_test).item(), model(x_test).parameter...\n",
       "193      [from fastapi import FastAPI,UploadFile,File\\r...\n",
       "194      [self.conv1 = GINConv(Sequential(Linear(num_no...\n",
       "195      [import os\\r\\nimport numpy as np\\r\\nfrom googl...\n",
       "196      [import numpy as np\\r\\nimport random\\r\\nimport...\n",
       "197      [def closure(self):\\r\\n    lbfgs_optim.zero_gr...\n",
       "198      [net =  cv2.dnn.readNetFromONNX(onnx_model_pat...\n",
       "199      [pred, feature_s = model(imgs)\\r\\nRuntimeError...\n",
       "200      [from torchtext.vocab import Vocab\\r\\nfrom col...\n",
       "201      [var, var, torch.sum(var), torch.sum(torch.sum...\n",
       "203      [y_pred_tensor = model(torch.tensor(X_test.val...\n",
       "204      [batch_output =[]\\r\\n     for data in test_loa...\n",
       "205      [base_state_dict = deepcopy(active_net.main.st...\n",
       "206      [    DataParallel(\\r\\n  (module): Unet(\\r\\n   ...\n",
       "207      [(0, tensor([[0.0024, 0.4513, 1.3045, 0.0350, ...\n",
       "208      [# Specify GPU to be used-\\r\\n%env CUDA_DEVICE...\n",
       "209      [num_labels, AutoConfig.from_pretrained(BERT_M...\n",
       "210      [for epoch in range(epochs):\\r\\n    pd.set_tra...\n",
       "211      [FileNotFoundError: Could not find module 'C:\\...\n",
       "212      [Input: x_0; Output: y\\r\\nx_1 = activation(w_i...\n",
       "213      [main.py, import logging\\r\\nimport os\\r\\nimpor...\n",
       "214      [Wide(\\r\\n  (linear1): Linear(in_features=1894...\n",
       "215      [conda install pytorch torchvision torchaudio ...\n",
       "216      [transform = transforms.Compose([transforms.Re...\n",
       "217      [dim=1, import torch\\r\\n\\r\\ntorch.manual_seed(...\n",
       "218      [conda create -n tox-env python=3.6\\r\\nconda i...\n",
       "219      [if __name__ == \"__main__\":\\r\\n    DEVICE = to...\n",
       "220      [docker run --gpus '\"'device=$CUDA_VISIBLE_DEV...\n",
       "221      [File \"/home/es/anaconda3/envs/pyg-meta/lib/py...\n",
       "222      [torch.nn.BCEWithLogitsLoss, torch.nn.function...\n",
       "223      [import torch\\r\\nimport time\\r\\n\\r\\n# Create d...\n",
       "224      [#after  importing lib \\r\\nT5model = AutoModel...\n",
       "225      [label format = 'YOLO' \\r\\n{class} {x} {y} {w}...\n",
       "227      [# hyper-parameter\\r\\nimage_size = 256\\r\\nlear...\n",
       "228      [propagate, edge_index, x , propagate, Cora , ...\n",
       "229      [A:  Tensor(4x4)     B: [0, 1, 1, 0] output:\\r...\n",
       "230      [transformers.modeling_outputs.BaseModelOutput...\n",
       "231      [class DNN(torch.nn.Module):\\r\\n\\r\\ndef __init...\n",
       "232      [p, q, (b,...), p, q, loss = 0\\r\\nfor outer in...\n",
       "233      [x = torch.tensor([[[1, 2, 3, 4, 5],\\r\\n      ...\n",
       "234      [F.cross_entropy, out[:, :-1:, :], target[:, 1...\n",
       "236      [ import torch\\r\\n torch.__version__\\r\\n'1.12....\n",
       "237      [class DSSN(nn.Module):\\r\\n\\r\\n    def __init_...\n",
       "238      [import pandas as pd;\\r\\nfrom scipy.stats impo...\n",
       "239      [# Define loaders\\r\\nfrom torch.utils.data imp...\n",
       "240      [# Define loaders\\r\\nfrom torch.utils.data imp...\n",
       "241      [train_data = vids_and_label(training_data_set...\n",
       "243      [import os, torch\\r\\nfrom torch.utils.tensorbo...\n",
       "244      [int main(){\\r\\n        float list[500000];\\r\\...\n",
       "245      [import torch\\r\\nimport torchaudio\\r\\n\\r\\nprin...\n",
       "246      [import torch\\r\\nimport torchaudio\\r\\n\\r\\nprin...\n",
       "247      [hidden_size = 4\\r\\nseq_len = x_train.shape[1]...\n",
       "248      [tokenizer.save_pretrained(...), tf.keras.prep...\n",
       "249      [import numpy as np\\r\\nimport scipy as sp\\r\\n\\...\n",
       "250      [input_lengths=[4, 6, 8, 10], (4, 10, C), (4, ...\n",
       "251      [class ConvNet3(nn.Module):\\r\\n\\r\\ndef init(se...\n",
       "252      [predictions, betas, predictions * x = betas, ...\n",
       "254      [src = torch.tensor([1,2,3,4,5]) # the source ...\n",
       "255      [Error loading model\\r\\nUnrecognized data form...\n",
       "256      [# -*- coding: utf-8 -*-\\r\\n\\r\\n\\r\\n\\r\\nimport...\n",
       "257      [# select device\\r\\ndevice = 'cuda' if cuda.is...\n",
       "258      [import sys\\r\\nsys.path.append('..')\\r\\nimport...\n",
       "259      [|===============================+============...\n",
       "260      [index = tensor([[1, 1, 1, …, 0, 0, 1],\\r\\n[0,...\n",
       "261      [I_k, X_k, i, X = [[1, 1, 1],\\r\\n     [2, 2, 2...\n",
       "262      [\\r\\n    df = pd.read_csv('C:/Users/X/Download...\n",
       "264      [python train.py -d mydataset -b 93 --img-size...\n",
       "265      [for it in range(no_it):\\r\\n    optimizer.zero...\n",
       "266      [autobot_vectorize, def autobot_vectorize(imgf...\n",
       "267      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "268      [In [1]: from PIL import Image; import torch; ...\n",
       "269      [import torch\\r\\n\\r\\nmodel = torch.load(\"./yol...\n",
       "270      [import torch\\r\\n\\r\\nmodel = torch.load(\"./yol...\n",
       "272      [validate(), ValueError: An invalid dataloader...\n",
       "273      [test_dataset = torchvision.datasets.Kinetics(...\n",
       "274      [dls = SegmentationDataLoaders.from_label_func...\n",
       "276      [if torch.cuda.is_available():\\r\\n    device =...\n",
       "277      [[0, 0, 0, 3, 2, 1, 4, 0, 0, 0]\\r\\n[1, 9, 5, 3...\n",
       "278      [torch.autograd.set_detect_anomaly(True), +=, ...\n",
       "279      [x = torch.tensor([[1,   0,  0,  0,  0,  0,  0...\n",
       "280      [import tensorflow as tf\\r\\n\\r\\nlogits = tf.ra...\n",
       "281      [if __name__ == \"__main__\":\\r\\n    vid = cv2.V...\n",
       "282      [#not working code, but an idea \\r\\n\\r\\nimport...\n",
       "284      [val==1, x = torch.tensor([[[   0, 2239, 6255,...\n",
       "285      [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "286      [tensor_list, torch.Size([512, 784]) and torch...\n",
       "287      [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "288      [import torch\\r\\nfrom torch.profiler import pr...\n",
       "289      [ dataset = load_json('dataset/panoptic_val201...\n",
       "290                                [bs x n x nc, n, nc, n]\n",
       "291      [# Concentrating on the first 100 samples\\r\\nn...\n",
       "293      [.whl, 413  sudo pip3 install torch-1.4.0-cp38...\n",
       "294      [   from torch_geometric.nn import MessagePass...\n",
       "295      [ File \"C:\\final\\few-shot-indoor-localization-...\n",
       "296      [torch.Tensor, np.ndarray, isinstance, import ...\n",
       "297      [model_input = tf.keras.layers.Input(tensor=in...\n",
       "298      [# q starts as (2, 4096, 320) and then reshape...\n",
       "299      [class MLP_feed(torch.nn.Module):\\r\\n  def __i...\n",
       "300      [trainloader.__getitem__(0), preprocess = tran...\n",
       "301      [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "302      [def load_glove_vectors(glove_file= glove_embe...\n",
       "303      [py -m pip install torch, ERROR: Could not fin...\n",
       "304      [python3 main.py --config-name=unet_train para...\n",
       "305      [mask.shape, pred.shape\\r\\n# (torch.Size([32, ...\n",
       "307      [model = torch.hub.load('NVIDIA/DeepLearningEx...\n",
       "309      [from transformers import Trainer, TrainingArg...\n",
       "310      [op = torch.rand((4,3,5))\\r\\n\\r\\ngt = torch.te...\n",
       "311      [import torch\\r\\nimport multiprocessing as mp\\...\n",
       "312      [class LogisticRegressionPytorch(nn.Module):\\r...\n",
       "313      [m * m, A, m * n, B, m &gt;&gt; n, m, 2000 ~ 3...\n",
       "314      [#neural Network\\r\\n# Fully connected neural n...\n",
       "315      [10/10/2022 07:43:43 - INFO - __main__ - Distr...\n",
       "316      [class BertFakesClassifier(nn.Module):\\r\\n    ...\n",
       "317      [electronics_reivews =  electronics_reivews[['...\n",
       "318      [BNN, B, NxN, BN, BNN, import tensor as th\\r\\n...\n",
       "319      [python==3.7\\r\\npytorch==1.11.0\\r\\npytorch-lig...\n",
       "320      [class Net(nn.Module): ## nn.Module class is u...\n",
       "322      [arr1 = np.array([[ 1.6194, -0.6058, -0.8012],...\n",
       "323      [import torch\\r\\nfrom torchvision import datas...\n",
       "324      [features.size()\\r\\ntorch.Size([1, 48])\\r\\n\\r\\...\n",
       "325      [class UNet(nn.Module):\\r\\n    def __init__(se...\n",
       "326      [# this file is a simple example of how to use...\n",
       "327      [from fastapi import FastAPI, UploadFile\\r\\nfr...\n",
       "328      [Cannot Open shared object file\\r\\n,         i...\n",
       "329      [Conv2D, Conv2D, from torch import nn\\r\\n\\r\\nC...\n",
       "330      [alexnet_weights_best_acc.tar, .tar, .tar, mod...\n",
       "331      [from __future__ import absolute_import\\r\\nfro...\n",
       "332      [X[0] = tensor([\\r\\n  [\\r\\n    [ 1.0000,  7.00...\n",
       "333      [net, net1, seed1, seed, import torch\\r\\nimpor...\n",
       "334      [import scipy.io as io\\r\\nimport torch as th\\r...\n",
       "335      [Traceback (most recent call last):\\r\\n  File ...\n",
       "336      [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "338      [cfg = get_cfg()\\r\\ncfg.MODEL.DEVICE = \"cpu\"\\r...\n",
       "339      [Error using nnet.internal.cnn.onnx.importONNX...\n",
       "340      [v, class myNetwork(nn.Module):\\r\\n    def __i...\n",
       "341      [new_nodes\\r\\n, new_edges = temp_edges.drop(['...\n",
       "344      [img should be PIL Image. Got &lt;class 'numpy...\n",
       "346      [\\r\\n    from torch.utils.data import DataLoad...\n",
       "347      [import torch\\r\\nimport numpy as np\\r\\na = tor...\n",
       "348      [class BCNN(PyroModule):\\r\\n    def __init__(s...\n",
       "349      [# load the Cora dataset\\r\\ntransform = T.Comp...\n",
       "350      [for i, (x, y) in enumerate(zip(test_x, test_y...\n",
       "351      [class BoxHead(nn.Module):#pending\\r\\n    def ...\n",
       "352      [class BoxHead(nn.Module):#pending\\r\\n    def ...\n",
       "354      [# original data:\\r\\nfrom datasets import load...\n",
       "355      [# Keras - IMDB Dataset\\r\\nmodel = Sequential(...\n",
       "358      [for epoch in range(num_epochs):\\r\\n        # ...\n",
       "359      [import torch\\r\\nx = torch.Tensor([0, 0, 1, 1,...\n",
       "361      [  File \"D:\\downloads\\U-2-Net-master\\U-2-Net-m...\n",
       "363      [# pip install compressai\\r\\n# pip install av\\...\n",
       "364      [dataset = ImbCircuitDataset('test'), self.dat...\n",
       "365      [AssertionError: filters should not remove ent...\n",
       "366      [train_loss, train_auc, train_auprc, test_loss...\n",
       "367      [model = model.to('cpu')\\r\\n, RuntimeError: CU...\n",
       "368      [std::vector &lt;at::Tensor&gt; ten_vec;\\r\\nte...\n",
       "369      [class Generator(nn.Module):\\r\\n\\r\\n    def __...\n",
       "370      [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "372      [class statsClass:\\r\\n    def __init__(self, p...\n",
       "373      [# a dict to store the activations\\r\\nactivati...\n",
       "375      [# Hyper-parameters \\r\\ninput_size = 48 \\r\\nhi...\n",
       "376      [import torch.nn as nn\\r\\nfrom torch.autograd ...\n",
       "378      [# Hyperparameters\\r\\nlearning_rate = 0.1\\r\\nn...\n",
       "379      [torch.sparse.sum(), class RGCN_Layer(nn.Modul...\n",
       "380      [.bin, .npy, https://github.com/zhongyy/Face-T...\n",
       "381      [print(f\"Before starting to loop: {psutil.Proc...\n",
       "382      [ctc_loss = nn.CTCLoss(blank=95)\\r\\n, output: ...\n",
       "383      [class RNN(nn.Module):\\r\\n  def __init__(self,...\n",
       "384      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "385      [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "388      [torch.onnx.export, training=TrainingMode.TRAI...\n",
       "389      [class Encoder(nn.Module):                    ...\n",
       "390      [// Save model state\\r\\ntorch::serialize::Outp...\n",
       "391      [predicted_vector = tensor([0.0669, 0.1336, 0....\n",
       "392      [Logging to /tmp/openai-2022-10-04-12-09-07-59...\n",
       "393      [import torch.nn as nn\\r\\n\\r\\nnet = nn.Sequent...\n",
       "394      [import torch.nn as nn\\r\\n\\r\\nnet = nn.Sequent...\n",
       "395      [start_time = frame_start / fps\\r\\nend_time = ...\n",
       "396      [start_time = frame_start / fps\\r\\nend_time = ...\n",
       "397      [repeat_vals = [x.shape[0] // pfinal.shape[0]]...\n",
       "398      [    1.this is that error:  \\r\\n, \\r\\n \\r\\n  F...\n",
       "399      [here my code:\\r\\n\\r\\nclass Net(nn.Module):\\r\\...\n",
       "400      [ def calculate_val_accuracy(valloader, is_gpu...\n",
       "401      [conda install pytorch torchvision torchaudio ...\n",
       "402      [from pathlib import Path\\r\\nimport torchvisio...\n",
       "403      [(cs323V2) conda install matplotlib\\r\\nCollect...\n",
       "404      [input, torch.Size([128, 10]), z, z, N, C = in...\n",
       "405      [import torch\\r\\nfrom torchvision.ops.roi_pool...\n",
       "406      [import torch\\r\\nfrom torch.nn import Linear\\r...\n",
       "407      [NotImplementedError: Could not run 'aten::is_...\n",
       "408      [def criterion_sparse(x,y):\\r\\n    return torc...\n",
       "409      [class Seq2Seq(nn.Module):\\r\\ndef __init__(sel...\n",
       "411      [class GNN(torch.nn.Module):\\r\\ndef __init__(s...\n",
       "412      [self.optimiser_a.zero_grad()\\r\\nloss_a = calc...\n",
       "413      [q = torch.linspace(1, 192, steps=192)\\r\\nq = ...\n",
       "414      [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "415      [__init__, &lt;bound method Module.parameters ...\n",
       "416      [A = torch.randn((2, 4, 3))\\r\\n# batch size = ...\n",
       "417      [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "418      [class QuestionGraphGNN(torch.nn.Module):\\r\\n ...\n",
       "419      [    @staticmethod\\r\\n    def create_new_faste...\n",
       "420      [adj[N, N], degrees[N, N], topk, N, def _lapla...\n",
       "422      [from transformers import AutoModelForQuestion...\n",
       "423      [from transformers import AutoModelForQuestion...\n",
       "424      [model.parameters(), torch.nn, torch.load(mode...\n",
       "425      [File \"/home/antpc/.local/lib/python3.8/site-p...\n",
       "426      [import torchvision.models as models\\r\\ndef ge...\n",
       "427      [[batch_size, n], [batch_size, n, H, W], [1, W...\n",
       "428      [torch.mm, torch.matmul, torch.mul, B = torch....\n",
       "430      [RuntimeError: No CUDA GPUs are available\\r\\n(...\n",
       "432      [# TODO: Define function to create our own neu...\n",
       "433      [input_dim = 25088\\r\\nh1_dim = 4096\\r\\nh2_dim ...\n",
       "434      [a = tensor([0, 2, 5, 1, 0, 0, 4, 3, 0, 0, 0, ...\n",
       "437                                      [len(dataloader)]\n",
       "438      [def load_cifar10_batch(filename):\\r\\n    \"\"\" ...\n",
       "439      [language = 'ru'\\r\\nmodel_id = 'ru_v3'\\r\\nsamp...\n",
       "440      [class ConcatDataset(Dataset):\\r\\n    \"\"\"\\r\\n\\...\n",
       "441      [class ConcatDataset(Dataset):\\r\\n    \"\"\"\\r\\n\\...\n",
       "442      [class ConcatDataset(Dataset):\\r\\n    \"\"\"\\r\\n\\...\n",
       "443      [class ChatDataset(Dataset):\\r\\n\\r\\n    def __...\n",
       "444      [    optimizer = torch.optim.Adam(vae.paramete...\n",
       "445      [DataLoader, ValueError: Unable to create tens...\n",
       "446      [Conv_layer = nn.Sequential(\\r\\n            Ba...\n",
       "447      [pytorch, pytorch, conda, conda install pytorc...\n",
       "448      [from torch.utils.tensorboard import SummaryWr...\n",
       "449      [args = [AttnCRFArguments,\\r\\n        GRUArgum...\n",
       "450      [try {\\r\\n    torch::jit::IValue result = this...\n",
       "451      [conda create --name isaacEnv python=3.8\\r\\n, ...\n",
       "453      [auto target_q_T = torch::rand({5, 10, 1});\\r\\...\n",
       "454      [auto target_q_T = torch::rand({5, 10, 1});\\r\\...\n",
       "455      [f(x + lr*v) &lt;= f(x) + c*ß*func_gradient , ...\n",
       "457      [device = torch.device('cuda')\\r\\ndataset = TU...\n",
       "458      [def mrae_loss(im_true, im_fake):\\r\\n    error...\n",
       "459      [import torch\\r\\nimport clip\\r\\nfrom PIL impor...\n",
       "461      [import torch\\r\\ntorch.use_deterministic_algor...\n",
       "462      [def createdeeplabv3_mobilenet(outputchannels=...\n",
       "463      [model = CIFAR10Classifier()\\r\\ntrainer = pl.T...\n",
       "464      [affine, class DilConv(nn.Module):\\r\\n    def ...\n",
       "465      [token_a_index, token_b_index, isNext, input_i...\n",
       "466      [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "467      [answers = []\\r\\nfor context in all_context:\\r...\n",
       "468      [torch.ones(42, 358).expand(10, -1, -1).shape,...\n",
       "470      [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "471      [    -----------------------------------------...\n",
       "472      [Faster-RCNN, Detectron2, model.pth, config.ym...\n",
       "473      [torch.stft, import torch\\r\\n\\r\\n\\r\\nwin_len =...\n",
       "474      [x = torch.mean(self.relu(torch.sparse.mm(x, s...\n",
       "476      [cudatoolkit=11.3\\r\\npytorch=1.11.0\\r\\ntorchvi...\n",
       "477      [nn.Linear, class TwoInputRNN(nn.Module):\\r\\n ...\n",
       "478      [from torch.utils.tensorboard import SummaryWr...\n",
       "479      [import torch, torchvision\\r\\nfrom torchsummar...\n",
       "480      [docker run --gpus=1 --rm -p8000:8000 -p8001:8...\n",
       "481      [RuntimeError: CUDA error: device-side assert ...\n",
       "482      [import torch\\r\\nn = 100\\r\\nAA = torch.rand(n,...\n",
       "483      [import torch\\r\\nn = 100\\r\\nAA = torch.rand(n,...\n",
       "484      [class SimpleLSTM(nn.Module):\\r\\n    def __ini...\n",
       "485      [dgl==0.1.3,     def _prepare_subgraphs(self, ...\n",
       "486      [full_dataset = torchvision.datasets.ImageFold...\n",
       "489      [Microsoft Windows [Version 10.0.22621.521]\\r\\...\n",
       "490      [from PIL import Image\\r\\nimport onnx\\r\\nimpor...\n",
       "491      [import os\\r\\nos.environ[“CUDA_DEVICE_ORDER”] ...\n",
       "492      [A = torch.randn(5,5)\\r\\nB = torch.einsum(\"ii-...\n",
       "493      [class Predictor(nn.Module):\\r\\n\\r\\n    def __...\n",
       "494      [dgl._ffi.base.DGLError: DGLGraph.from_network...\n",
       "495      [[a, b], [a, b, ab, a^2, b^2]\\r\\n, [a, b, ab, ...\n",
       "496      [adjM = g.adjacency_matrix()\\r\\nadjM\\r\\n, tens...\n",
       "497      [import pathlib\\r\\n\\r\\nimport torch\\r\\nimport ...\n",
       "499      [def to_torch(x, use_gpu=True, dtype=np.float3...\n",
       "500      [state_dict(), class GruModel(nn.Module):\\r\\n ...\n",
       "502      [AssertionError: daemonic processes are not al...\n",
       "504      [import os\\r\\nfrom PIL import Image\\r\\nfrom to...\n",
       "505      [self.up1 = nn.ConvTranspose2d(in_channels=out...\n",
       "506      [def get_gd_pca(X, w):\\r\\n    k = w.shape[-1]\\...\n",
       "508      [# build autoencoder\\r\\nimport torch\\r\\nimport...\n",
       "509      [no signature found for &lt;torch.ScriptMethod...\n",
       "510      [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "511      [with io.BytesIO() as model_file:\\r\\n    model...\n",
       "512      [batch_size = 256\\r\\n\\r\\n# Define transformati...\n",
       "513      [keras.models.Model, from tensorflow import ke...\n",
       "514      [def encode(self, box):\\r\\n    \"\"\"\\r\\n    box ...\n",
       "515      [batch_size==32, batch_size==8, gradient_accum...\n",
       "516      [import numpy as np\\r\\nimport os\\r\\nimport mat...\n",
       "517      [idx, __getitem__, worker_init_fn, def __getit...\n",
       "518      [indices = torch.arange(60000)\\r\\ndataset = da...\n",
       "519      [model              = VAE(input_size ,  lead, ...\n",
       "520      [model              = VAE(input_size ,  lead, ...\n",
       "521      [pptk, torch-scatter, pptk, torch-scatter, ppt...\n",
       "522      [import os\\r\\nimport signal\\r\\nimport socket\\r...\n",
       "523      [# Function to test the model \\r\\nfrom sklearn...\n",
       "524      [l_losses, .backward(), optimizer.step(), t_lo...\n",
       "525      [OSError: [WinError 127] The specified procedu...\n",
       "526      [!, ! pip install -q transformers\\r\\n, import ...\n",
       "527      [git clone --recursive https://github.com/pyto...\n",
       "528      [ File \"ss_training_entrypoint.py\", line 400, ...\n",
       "529      [myfile.csv, imagefile,label\\r\\ntrain/0/16585....\n",
       "530      [myfile.csv, imagefile,label\\r\\ntrain/0/16585....\n",
       "531      [class torch_model_basic(nn.Module):\\r\\n    de...\n",
       "532      [tensor([2, 0, 2, 2, 2, 0, 1, 1, 0, 2, 2, 0, 1...\n",
       "533      [ssim = StructuralSimilarityIndexMeasure(kerne...\n",
       "534      [c = torch.rand((2000, 64, 64)).to('cuda')\\r\\n...\n",
       "539      [import csv\\r\\n\\r\\nfrom torch.utils.data impor...\n",
       "540      [import csv\\r\\n\\r\\nfrom torch.utils.data impor...\n",
       "541      [torch==1.0.0, torchvision==0.2.1, macOS-12.5....\n",
       "542      [void Backend::perform(std::vector&lt;float *&...\n",
       "543      [nn.ReplicationPad2d, nn.ReplicationPad2d, def...\n",
       "544      [nn.ReplicationPad2d, nn.ReplicationPad2d, def...\n",
       "545      [include, include, pytorch, libtorch, +- inclu...\n",
       "547      [import torch.optim as optim\\r\\n\\r\\nclass Grap...\n",
       "548      [class Player:\\r\\n    name = '',\\r\\n    choice...\n",
       "549      [class Player:\\r\\n    name = '',\\r\\n    choice...\n",
       "550      [class customDataset(Dataset):\\r\\n    def __in...\n",
       "551      [import argparse\\r\\nimport os\\r\\nimport torch\\...\n",
       "553      [import os\\r\\nimport time\\r\\nimport cv2\\r\\nimp...\n",
       "554      [\\r\\n    def __init__(\\r\\n            self,\\r\\...\n",
       "555      [nonzeroes = torch.nonzero(x,as_tuple=True)\\r\\...\n",
       "556      [train_labels.json, boxes, f = open('train_lab...\n",
       "557      [audio_length = torchaudio.load(DATASET_PATH)[...\n",
       "558      [mlflow.pyfunc.log_model, mlflow.pytorch.log_m...\n",
       "561      [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "562      [class SynthCollator(object):\\r\\n    \\r\\n    d...\n",
       "563      [myfile.csv, csv_file, imagefile,label\\r\\ntrai...\n",
       "564      [class GraphLevelGNN(pl.LightningModule):\\r\\n\\...\n",
       "565      [(2,ncol), torch.tensor([[1, 2, 3, 7, 8], [3, ...\n",
       "566      [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "567      [def train(mu,lr,batch_size,n_epochs,k,model,u...\n",
       "568      [[ERROR:0] global D:\\a\\opencv-python\\opencv-py...\n",
       "569      [children, ResModel = resnet18(weights=ResNet1...\n",
       "570      [import torch\\r\\nimport torch.nn as nn\\r\\ndevi...\n",
       "571      [# Model\\r\\nmodel = torch.hub.load('/home/yolo...\n",
       "573      [---------------------------------------------...\n",
       "576      [numpy, np.vectorize, if, torch, import numpy ...\n",
       "577      [import warnings\\r\\nfrom collections import de...\n",
       "578      [try:\\r\\n    exp_id = mlflow.create_experiment...\n",
       "579      [== Status ==\\r\\nCurrent time: 2022-09-20 16:1...\n",
       "580      [.csv, #Rows = #Nodes, #Columns = #Features, #...\n",
       "581      [sig, sr = torchaudio.load(audio_file)\\r\\n, sp...\n",
       "582      [model = model.to(device)\\r\\noptimizer = torch...\n",
       "583      [torch.randint, size,   random_idx = torch.ran...\n",
       "585      [    class MyNet(nn.Module):\\r\\n    def __init...\n",
       "586      [def static_quantize(m, data_loader):\\r\\n    b...\n",
       "587      [(working_indices, working_labels, testing_ind...\n",
       "588      [transform = transforms.Compose([transforms.Re...\n",
       "591      [# Hyperparameters\\r\\ninput_size = 9\\r\\nsequen...\n",
       "592      [import torch as T\\r\\nimport torch.nn as nn\\r\\...\n",
       "593      [class CustomDataset(torch.utils.data.Dataset)...\n",
       "594      [import torch    \\r\\nfrom timm.models.resnet i...\n",
       "597      [from PIL import Image\\r\\nimport pickle \\r\\nim...\n",
       "598      [                for *xyxy, conf, cls in rever...\n",
       "599      [autograd::Function, struct my_func: torch::au...\n",
       "601      [import torch\\r\\nimport utils\\r\\nimport os\\r\\n...\n",
       "602      [#In[]\\r\\nclass MysmallNet(nn.Module):\\r\\n    ...\n",
       "603      [nvidia-smi, .to(device), .to(device), nvidia-...\n",
       "604      [bindsnet.pipeline.environment_pipeline, binds...\n",
       "605      [Utilization 0%\\r\\nDedicated GPU memory    0.0...\n",
       "607      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "609      [ points = torch.tensor([[4.0, 1.0], [5.0, 3.0...\n",
       "610      [import matplotlib.pyplot as plt\\r\\nfrom tqdm ...\n",
       "611      [masks = self.mask_pad(contexts, 0).transpose(...\n",
       "612      [validation_epoch_end(), def validation_epoch_...\n",
       "613      [[n, c], nan, nan, for, Input:\\r\\n[[0.25, nan,...\n",
       "614      [transform = torchvision.transforms.Compose(\\r...\n",
       "615      [transform = torchvision.transforms.Compose(\\r...\n",
       "616      [class Model(torch.nn.Module):       #class\\r\\...\n",
       "617      [import numpy as np\\r\\nimport torch \\r\\n\\r\\nx_...\n",
       "618      [s(t) = s0 * e^(-t/decay_constant), s, t, s0, ...\n",
       "619      [from torch.profiler import profile, record_fu...\n",
       "620      [import torch\\r\\nimport torch.multiprocessing ...\n",
       "621      [data = pd.read_csv(\"file_name\")\\r\\nX = data[\"...\n",
       "622      [from transformers import pipeline, TFAutoMode...\n",
       "623      [torch.fx, torch.fx.replace_pattern, torch.min...\n",
       "624      [# What should i add here?\\r\\n... \\r\\n\\r\\nFILE...\n",
       "625      [####This code is for measuring performance su...\n",
       "626      [ce_loss=torch.nn.BCELoss()\\r\\npar=torch.randn...\n",
       "629      [    part1 = torch.exp(torch.clamp(y_true,min=...\n",
       "630      [nvidia-container-runtime, nvidia-smi, docker ...\n",
       "631      [[batch_size, channels, height, width], [b, c,...\n",
       "633      [---------------------------------------------...\n",
       "634      [x, [b,c,h,w], 3x3, K, [c,c,3,3], y = K * x, y...\n",
       "635      [    if torch.cuda.device_count() &gt; 1:\\r\\n ...\n",
       "637      [import gym \\r\\nfrom stable_baselines3 import ...\n",
       "638      [import gym \\r\\nfrom stable_baselines3 import ...\n",
       "639      [class ResNet(nn.Module):\\r\\ndef __init__(\\r\\n...\n",
       "640      [\\r\\ndef dice_loss_grad(y, label):\\r\\n        ...\n",
       "641      [(Batch, Sequence, Height, Width, Channel), da...\n",
       "642      [with, with, if condition:\\r\\n    with blah_bl...\n",
       "643      [with, with, if condition:\\r\\n    with blah_bl...\n",
       "644      [RuntimeError: Expected object of scalar type ...\n",
       "645      [    import torch.nn.functional as f\\r\\n    fr...\n",
       "646      [# when i use Bool in param key_padding_mask\\r...\n",
       "647      [class ArcMarginProduct(nn.Module):\\r\\n    def...\n",
       "649      [  [ x for x in t]\\r\\n  Out[122]: [tensor(-0.1...\n",
       "650      [from efficientnet_pytorch import EfficientNet...\n",
       "652      [x = torch.tensor([1.], requires_grad=True)\\r\\...\n",
       "653      [def round_values(predictions):\\r\\n    # Round...\n",
       "654      [    input_size = 615\\r\\n    output_size = 40\\...\n",
       "656      [def model(observations, num_state):\\r\\n    \\r...\n",
       "657      [scipy.linalg, solve_sylvester, X, torch.linal...\n",
       "659      [[8, 64, 128, 128], [8, 1, 128, 128], import t...\n",
       "660      [AttributeError: module 'torch' has no attribu...\n",
       "661      [Train set targets: [[0.0]], predictions:[0.24...\n",
       "664      [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "665      [import torch\\r\\nimport sys,os\\r\\nimport torch...\n",
       "666      [run.py, import numpy as np # linear algebra\\r...\n",
       "667      [torchvision.utils, draw_bounding_boxes, (xmin...\n",
       "668      [import torch\\r\\na = torch.tensor([2.], requir...\n",
       "669      [import torch\\r\\na = torch.tensor([1.], requir...\n",
       "670      [Traceback (most recent call last):\\r\\n  File ...\n",
       "671      [[batch_size, vocab_size, seq_len], [batch_siz...\n",
       "672      [batch[\"img\"] = [img.cuda() for img in batch[\"...\n",
       "673      [get_data,    train = get_data(root =\"My_train...\n",
       "674      [PyTorch version: 1.11.0\\r\\nIs debug build: Fa...\n",
       "675      [    a = torch.tensor([[1,2,4],[2,1,3]])\\r\\n  ...\n",
       "676      [def __init__(self, in_channels, out_channels,...\n",
       "677                             [n&gt;2, (n-1), n, n, n-1]\n",
       "678      [imgA, imgA[:128,2,:,:] = imgA[:128,1,:,:]\\r\\n...\n",
       "679      [DistributedDataParallel, ProcessRaisedExcepti...\n",
       "680      [import math\\r\\nfrom typing import Tuple\\r\\nim...\n",
       "681      [class BasicBlock(nn.Module):\\r\\n    def __ini...\n",
       "682      [ 1. Share deep-tensor(in a sub-class) i.e. mu...\n",
       "685      [import torch.utils.tensorboard as tb\\r\\nimpor...\n",
       "686      [  \\r\\n  File \"/Users/peterpan/miniforge3/lib/...\n",
       "687      [ValueError: some parameters appear in more th...\n",
       "688      [\"\"\"Non-blocking point-to-point communication....\n",
       "689      [train(), output = model(data), IndexError: Di...\n",
       "690      [%pylab inline\\r\\nimport torch\\r\\n\\r\\n%load_ex...\n",
       "691      [multiprocessing.set_start_method(), spawn, if...\n",
       "693      [net=timm.create_model(model_name=MODEL_NAME,n...\n",
       "694      [(01:00.0 VGA compatible controller: NVIDIA Co...\n",
       "697      [def shufflerow(tensor1, tensor2, axis):\\r\\n  ...\n",
       "698      [transforms.Normalize(mean=[0.75107294, 0.5154...\n",
       "699      [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "700      [\\r\\nimport torch\\r\\nfrom torch.utils.data imp...\n",
       "701      [deeplabv3_resnet50, ValueError: Expected more...\n",
       "702      [batch size = 16 -\\&gt; train/val loss around ...\n",
       "703      [for epoch in range(num_epochs):\\r\\n   train_o...\n",
       "704      [x\\r\\n&gt;tensor([1], device='cuda:0')\\r\\n\\r\\n...\n",
       "705      [ np.random.normal(loc=mean,scale=stdev,size=v...\n",
       "706      [from __future__ import print_function\\r\\nimpo...\n",
       "707      [import torch\\r\\n# import joblib\\r\\nfrom torch...\n",
       "708      [for x, y in train_loader:\\r\\n    aug_x = aug(...\n",
       "709      [import torch\\r\\nt = torch.tensor([[2,3],[4,6]...\n",
       "711      [model_resnet = models.resnet50(pretrained=Tru...\n",
       "714      [x = torch.stack(array_of_test_items)\\r\\ncheck...\n",
       "715      [dataset = datasets.ImageFolder('...', transfo...\n",
       "716      [import torch\\r\\n\\r\\n\\r\\nclass test(torch.util...\n",
       "717      [class classifier (nn.Module):\\r\\ndef __init__...\n",
       "718      [class classifier (nn.Module):\\r\\ndef __init__...\n",
       "719      [eval_result = evaluate(model,val_loader,True,...\n",
       "720      [class LSTM : public torch::nn::Module {\\r\\npr...\n",
       "721      [for epoch in range(num_epochs):\\r\\n\\r\\n#Calcu...\n",
       "722      [def generate_weight_linf_l2_perturbations(alp...\n",
       "723      [from transformers import AutoModelForSequence...\n",
       "725      [# import the torch module\\r\\nimport torch\\r\\n...\n",
       "726      [const torch::Device device = torch::Device(to...\n",
       "728      [model.to(device)\\r\\ncheckpoint = torch.load(\"...\n",
       "729                            [param_groups, torch.optim]\n",
       "730      [&gt;&gt; C:\\SD\\stable-diffusion-main&gt;pytho...\n",
       "731      [class AutoEncoder(nn.Module):\\r\\n\\r\\n    def ...\n",
       "733      [TypeError: unsupported operand type(s) for -:...\n",
       "734      [class YOLOv5ONNX:\\r\\n    def __init__(self, m...\n",
       "735      [import torch.nn as nn\\r\\n...\\r\\n#input is a 2...\n",
       "736      [get_extra_state(), dict, from typing import A...\n",
       "737      [def my_loss_fn(y_true, y_pred):\\r\\n    y_true...\n",
       "738      [# I start with unsorted, non-consecutive dupl...\n",
       "740      [scipy.optimize.minimize, res = minimize(calc_...\n",
       "741      [                            M\\r\\n            ...\n",
       "742      [net1 = SimpleLinearF()\\r\\nopt1 = torch.optim....\n",
       "743      [[1,  9, 18, 27, 36]\\r\\n[2, 10, 19, 28, 37]\\r\\...\n",
       "744      [RuntimeError: a view of a leaf Variable that ...\n",
       "745      [categorical_embed_sizes = [589806, 21225, 256...\n",
       "746      [coreml_model = coremltools.converters.keras.c...\n",
       "747      [import torch\\r\\nb = 3 # batch size\\r\\nh = 5 #...\n",
       "748      [pip install mmcv-full==1.1.5 -f https://downl...\n",
       "749      [ import multiprocessing as multi_processing\\r...\n",
       "751      [CUDA error: out of memory, (val_env) jovyan@j...\n",
       "752      [    import torch\\r\\n    model = torch.hub.loa...\n",
       "753      [Sequential, torch.save(model.state_dict(), PA...\n",
       "754      [a = torch.nn.Parameter(torch.ones(5, 5))\\r\\na...\n",
       "755      [salloc -p p3 -J chem_proj --mincpus=16 --mem=...\n",
       "756      [class u_seta(nn.Module):\\r\\n    def __init__(...\n",
       "757      [class u_seta(nn.Module):\\r\\n    def __init__(...\n",
       "758      [  File \"/home/zakaseb/Thesis/YoloStereo3D/Ste...\n",
       "759      [b=32\\r\\nn_s = 10\\r\\ndim = 64\\r\\nslots_mu = nn...\n",
       "760      [self.model = nn.Sequential(\\r\\n            nn...\n",
       "761      [MINICONDA_INSTALLER_SCRIPT=Miniconda3-py37_4....\n",
       "763      [y = sin(X1) + sin(X2) + ... sin(X10), retain_...\n",
       "764      [nn.L1Loss() + nn.CosineEmbeddingLoss()\\r\\n, -...\n",
       "765      [# Import\\r\\nimport pandas as pd\\r\\nimport tor...\n",
       "766      [ def __getitem__(self,idx): \\r\\n        \\r\\n ...\n",
       "767      [pip install jupyterlab\\r\\npip list\\r\\npython ...\n",
       "769      [class MultiHeadedAttention(nn.Module):\\r\\n   ...\n",
       "770      [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "771      [RuntimeError: Given groups=1, weight of size ...\n",
       "772      [class BertClassificationModel(nn.Module):\\r\\n...\n",
       "773      [class BertClassificationModel(nn.Module):\\r\\n...\n",
       "774      [nn.Softmax(dim=2), criterion = nn.BCELoss(), ...\n",
       "775      [(graphenv) D:\\graph\\pytorch_geometric\\graphgy...\n",
       "776      [import torch\\r\\nimport torch.multiprocessing ...\n",
       "778      [TypeErrorTraceback (most recent call last)\\r\\...\n",
       "780      [model.load_state_dict, torch.save(model.model...\n",
       "781      [import torch\\r\\nif torch.has_mps:\\r\\n    devi...\n",
       "782      [INFO - 2022-09-01 23:27:49,189 - summary - Su...\n",
       "784      [import pandas as pd\\r\\ndata = {'customer_id':...\n",
       "785      [model.eval()\\r\\nmodel.cuda()\\r\\n\\r\\ndummy_inp...\n",
       "786      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "787      [HANDLER_SERVICE = handler_service.__file__\\r\\...\n",
       "788      [\"hipErrorNoBinaryForGpu: Unable to find code ...\n",
       "789      [\"hipErrorNoBinaryForGpu: Unable to find code ...\n",
       "790      [Resnet 50, model = torch.hub.load('facebookre...\n",
       "791      [class BertMy(nn.Module):  \\r\\n    \\r\\n    def...\n",
       "792      [torch.Size([1, 3, 256, 256]), nn.Conv2d(1024,...\n",
       "793      [def train(model, train_dl, valid_dl, loss_fn,...\n",
       "794      [class SegmentationDataset(Dataset):\\r\\n\\r\\n  ...\n",
       "795      [from lasagne.layers import (\\r\\n    Nonlinear...\n",
       "796      [import optuna\\r\\nimport sys\\r\\n\\r\\ndef object...\n",
       "797      [$ python setup.py             \\r\\nusage: setu...\n",
       "798                                      [torch.nn.linear]\n",
       "799      [im = torch.ones(1,3,256,256).half().to(device...\n",
       "800      [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "801      [Softmax(), Softmax(dim=1), Softmax(dim=-1), S...\n",
       "803      [ann = tf.keras.models.Sequential()\\r\\nann.add...\n",
       "804      [evaluate_nodes(), class RBOLoss(torch.nn.Modu...\n",
       "805      [    seed = torch.rand(1, dtype=torch.float64)...\n",
       "806      [from multiprocessing import freeze_support\\r\\...\n",
       "807      [====================\\r\\nNumber of graphs: 560...\n",
       "808      [class CachedMNIST(Dataset):\\r\\n    def __init...\n",
       "809      [from sklearn import datasets\\r\\nimport pandas...\n",
       "810      [    from copy import deepcopy\\r\\nimport numpy...\n",
       "811      [Traceback (most recent call last):\\r\\n  File ...\n",
       "812      [nvidia-smi, pip install torch==1.10.0+cu111 t...\n",
       "813      [import torch\\r\\ntorch.manual_seed(42)\\r\\nx = ...\n",
       "814      [import torch\\r\\ntorch.manual_seed(42)\\r\\nx = ...\n",
       "815      [import torch\\r\\ntorch.manual_seed(42)\\r\\nx = ...\n",
       "817      [f_x1, k, h_x1, h_x1, 12-k, f_x2, f_x1, f_x2, ...\n",
       "818      [max_steps=1, 100, C:\\Users\\r.charij\\AppData\\L...\n",
       "819      [import torch\\r\\nprint('count: ', torch.cuda.d...\n",
       "820      [import torch\\r\\nprint('count: ', torch.cuda.d...\n",
       "821      [import sys\\r\\nimport os\\r\\nsys.path.append(os...\n",
       "822      [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "823      [import torch\\r\\ntorch.__version__\\r\\n '1.12.1...\n",
       "824      [class pcrnetwork(nn.Module):\\r\\ndef __init__(...\n",
       "826      [Exception raised from operator() at /Users/ru...\n",
       "827                                 [NxNx(5+C), NxNx(5+1)]\n",
       "828      [   def __init__(self, folder_path, transform=...\n",
       "829      [# bounding box to tensor\\r\\nboxes = torch.as_...\n",
       "830      [Traceback (most recent call last):\\r\\n  File ...\n",
       "831      [nn.CrossEntropyLoss(),     model = UneXt50()....\n",
       "832      [import numpy as np\\r\\nimport torch\\r\\n\\r\\n# d...\n",
       "833      [import numpy as np\\r\\nimport torch\\r\\n\\r\\n# d...\n",
       "838      [pad_token, torchtext, import spacy\\r\\nimport ...\n",
       "839      [   jac = torch.autograd.functional.jacobian(n...\n",
       "842      [class MLP(nn.Module):\\r\\ndef __init__(self, l...\n",
       "844      [TimeSformer(\\r\\n  (model): VisionTransformer(...\n",
       "845      [AttributeError, import torch\\r\\nimport detect...\n",
       "846      [t1, t2, t1=torch.tensor([[1,2],[3,4],[5,6]])\\...\n",
       "847      [t1, t2, t1=torch.tensor([[1,2],[3,4],[5,6]])\\...\n",
       "848      [Dataset, Dataloader, Dataset, __init__, n = l...\n",
       "849      [    const inputTensor = new Tensor(input, 'fl...\n",
       "850      [class MylossFunc(nn.Module): \\r\\n    def __in...\n",
       "851      [num_workers, from_numpy, import torch\\r\\nimpo...\n",
       "854      [TextEncodeInput must be Union[TextInputSequen...\n",
       "855      [    def acc(y_pred, y_target):\\r\\n        D =...\n",
       "856      [def generic_step(self, train_batch, batch_idx...\n",
       "857      [model = torch.hub.load('facebookresearch/pyto...\n",
       "858      [yaml, DiT, DiT, BeitFeatureExtractor.from_pre...\n",
       "860      [Pytorch, grad_fn=MmBackward, class cam_pose_t...\n",
       "861      [TypeError: forward() got an unexpected keywor...\n",
       "862                     [nn.linear, y = WA+b\\r\\n, W, b, A]\n",
       "864      [data = scaler.transform(filler.transform(data...\n",
       "865      [import torch\\r\\na = torch.randn((2,3,5))\\r\\nb...\n",
       "866      [import torch\\r\\na = torch.randn((2,3,5))\\r\\nb...\n",
       "867      [# Bert-Bilstm-Classfier class\\r\\nclass BertBi...\n",
       "868      [e, y, e, e, y, tensor([[0, 7, 0, 0],\\r\\n     ...\n",
       "869      [e, y, e, e, y, tensor([[0, 7, 0, 0],\\r\\n     ...\n",
       "870      [CUDA error: out of memory, #import the librar...\n",
       "871      [100, 97%, 1.5%, 79%, 86/87%, 0.9/0.5/NO, 86/8...\n",
       "872      [RuntimeError                              Tra...\n",
       "873      [# TRAINING THE MODEL\\r\\nloss_history, loss_hi...\n",
       "874      [collate_fn, def collate_fn(batch):\\r\\n    max...\n",
       "875      [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "876      [.pth, .yaml, Detectron2, thing_classes= ['Non...\n",
       "877      [class Flags(object):\\r\\n\\r\\n  def __init__(se...\n",
       "879      [random_split(), import numpy as np\\r\\nimport ...\n",
       "880      [kthvalue, def suppress_small_probabilities(pr...\n",
       "881      [class Detect(nn.Module):\\r\\n    stride = None...\n",
       "882      [dataset_train, dataset_valid = random_split(d...\n",
       "883      [C:\\Users\\Admin\\Desktop\\yolov5-master\\yolov5-m...\n",
       "884      [import torch\\r\\n\\r\\nx = torch.tensor([3., 4.]...\n",
       "885      [ pip3 install torch torchvision torchaudio --...\n",
       "887      [two images A (source) and B (target)\\r\\n\\r\\nC...\n",
       "888      [assertEqual, def test_preprocess_text_single_...\n",
       "889      [{'bleu': 0.09453580071770594}, --learning_rat...\n",
       "890      [optimizer = optim.Adam([x for x in model.para...\n",
       "892      [__init__(), Parameter, self.weight, input_dim...\n",
       "893      [torchvision.datasets,     path, target = self...\n",
       "894      [URI uri = new URI(\"file:////Users/.../prior.p...\n",
       "895      [train = datasets.ImageFolder('train_images', ...\n",
       "896      [    for batch_idx, (test_data, test_targets) ...\n",
       "897      [    for batch_idx, (test_data, test_targets) ...\n",
       "898      [torch.autograd.Function, class Simulation(tor...\n",
       "899      [if(distance &lt; lastDistance)\\r\\n  AddReward...\n",
       "900      [Models A and B, B, A, B Model, A, B, Model B,...\n",
       "901      [test_comment = 'I am still waiting on my card...\n",
       "902      [test_comment = 'I am still waiting on my card...\n",
       "903      [0/100:  47%|▍| 73/154 [00:32&lt;00:35,  2.27b...\n",
       "905      [#Predicting\\r\\npath = analysis.best_checkpoin...\n",
       "906      [ data.loc[0]['Q_emd_list']\\r\\n'tensor([ 0.121...\n",
       "907      [lin = nn.Linear(out_dim, in_dim), lin.named_p...\n",
       "908      [import torch\\r\\ndef find_pairs(fn, y, n1, n2)...\n",
       "910      [def final_loop(model, dataset, val_data, test...\n",
       "911      [from transformers import GPTJForCausalLM\\r\\ni...\n",
       "913      [torch.autocast, with torch.cuda.amp.autocast(...\n",
       "914      [import torch\\r\\nimport flash\\r\\nfrom flash.im...\n",
       "915      [@contextmanager\\r\\ndef reduce_gpu_usage(large...\n",
       "916      [%cd yolov5\\r\\n%pip install -qr requirements.t...\n",
       "918      [UnexpectedStatusException: Error hosting endp...\n",
       "919      [input_size, Tensor, x, cov, output_size, torc...\n",
       "921      [typename, template, template &lt;typename T, ...\n",
       "922      [typename, template, template &lt;typename T, ...\n",
       "923      [typename, template, template &lt;typename T, ...\n",
       "924      [typename, template, template &lt;typename T, ...\n",
       "925      [typename, template, template &lt;typename T, ...\n",
       "926      [typename, template, template &lt;typename T, ...\n",
       "927      [typename, template, template &lt;typename T, ...\n",
       "928      [typename, template, template &lt;typename T, ...\n",
       "929      [PATH = args.model\\r\\nPATH1 = args.model1\\r\\nP...\n",
       "930      [nn.Conv2d(kernel_size=(1,20), stride=1, group...\n",
       "931      [(base) C:\\&gt;pip3 install torch torchvision ...\n",
       "932      [RuntimeError                              Tra...\n",
       "933      [inputs_train = (6, 581)\\r\\ncoefficients_train...\n",
       "934      [n_epochs= 3000\\r\\nlr = 0.005\\r\\nbatch_size = ...\n",
       "935      [img_path = 'G:/tiff/NC_H08_20220419_0600.tif'...\n",
       "936      [loss tensor(0.2049, device='cuda:0', grad_fn=...\n",
       "937      [image.shape, Given groups=1, weight of size [...\n",
       "938      [from sagemaker.pytorch import PyTorchModel\\r\\...\n",
       "939      [embed_arr_list, for arr in embed_arr_list:\\r\\...\n",
       "940      [torch.scatter, reduce=\"max\", dim=1 and x[i]&g...\n",
       "941      [class MySiameseNet(nn.Module):\\r\\n    def __i...\n",
       "942      [x = torch.sparse_coo_tensor([[0], [1]], [1.],...\n",
       "943      [x = torch.sparse_coo_tensor([[0], [1]], [1.],...\n",
       "944      [# Tokenize sentences van trainingset \\r\\nenco...\n",
       "945      [to(\"cpu\"), to(\"dml\"),     # Putting networks ...\n",
       "946      [net, complex_function, loss = torch.tensor(0....\n",
       "947      [tensor([[1., 1., 1.],\\r\\n        [1., 1., 1.]...\n",
       "948      [import torch\\r\\n\\r\\nclass MyModel(torch.nn.Mo...\n",
       "949      [    optimizer.zero_grad()\\r\\n    loss.backwar...\n",
       "951      [fold1_target_mix001.wav, fold1_target_mix002....\n",
       "952      [import torch\\r\\nfrom transformers import Spee...\n",
       "953      [def EasyOcrTextbatch(self):\\r\\n   batchsize=1...\n",
       "954      [model1 = nn.Sequential(\\r\\n    nn.Conv2d(1, 1...\n",
       "955      [torch.distributed, CUDA_VISIBLE_DEVICES=0,1 p...\n",
       "956      [Trainer, RuntimeError: \"mse_cuda\" not impleme...\n",
       "957      [!pip install lightning-flash\\r\\n, datamodule ...\n",
       "958      [# custom handler file\\r\\n\\r\\n# model_handler....\n",
       "959      [optimizer = torch.optim.SGD(model.parameters(...\n",
       "960      [class MyModel(torch.nn.Module):\\r\\n\\r\\n    de...\n",
       "961      [Falling back to LAION 400M model...\\r\\nGlobal...\n",
       "962      [x, (1,n), d, (1,k), k, x[0:d[0]], x[d[0]:d[1]...\n",
       "963      [TransformerConv, Traceback (most recent call ...\n",
       "964      [Class GNN(torch.nn.Module):\\r\\n    def __init...\n",
       "965      [# set aside 20% of train and test data for ev...\n",
       "966      [torch.Tensor, class Exp(nn.Module):\\r\\n    de...\n",
       "968      [class NeuralNetwork(nn.Module):\\r\\n  def __in...\n",
       "969      [    def forward(self, inp):\\r\\n        # Prep...\n",
       "970      [framework=pytorch, Trainer(), (base) jupyter@...\n",
       "971      [pytorch, DataLoader, import numpy as np\\r\\nim...\n",
       "972      [onnx2pytorch, model = torch.load(\"\")\\r\\nmodel...\n",
       "973      [import os\\r\\nimport torch\\r\\nimport gradio as...\n",
       "974      [for test_input in [test_input_files1, test_in...\n",
       "975      [import os\\r\\nimport time\\r\\nimport torch\\r\\ni...\n",
       "976      [def train_combined(nets, dataset_train, datas...\n",
       "978      [\\r\\nclass v7_infer(Process):\\r\\n    def __ini...\n",
       "979      [list(model.parameters()), VGG16(\\r\\n  (block_...\n",
       "980      [list(model.parameters()), VGG16(\\r\\n  (block_...\n",
       "981      [checkpoint_path = \"../Models/ckpt_camembert.c...\n",
       "982      [du/dt = k d2u/dx2\\r\\n, k, u, x, 0, x=0, t=0, ...\n",
       "983      [from torchtext.vocab import GloVe\\r\\nimport t...\n",
       "984      [nonzero, PyTorch, tensor([ True, False,  True...\n",
       "985      [nonzero, PyTorch, tensor([ True, False,  True...\n",
       "986      [## Standard libraries\\r\\nCHECKPOINT_PATH = \"/...\n",
       "987      [tb = self.logger.experiment  # This is a Summ...\n",
       "988      [tb = self.logger.experiment  # This is a Summ...\n",
       "989      [tb = self.logger.experiment  # This is a Summ...\n",
       "990      [        GN_params = list(np.load('/home/lingh...\n",
       "991      [models = [MyModel().to(f'cuda{i}') for i in r...\n",
       "992      [decoder_alpha = torch.tensor([[0.2, 0.3, 0.3,...\n",
       "993      [AssertionError,  # Load model\\r\\nmodel = Bert...\n",
       "994      [## Standard libraries\\r\\nCHECKPOINT_PATH = \"/...\n",
       "995      [model.state_dict(), bert.embeddings.position_...\n",
       "996      [python -m torch.distributed.launch --nproc_pe...\n",
       "997      [# Create output directory if needed\\r\\nif not...\n",
       "998      [tensor([[0.8771, 0.0976, 0.8186],\\r\\n        ...\n",
       "999      [tensor([[0.8771, 0.0976, 0.8186],\\r\\n        ...\n",
       "1000     [tensor([[0.8771, 0.0976, 0.8186],\\r\\n        ...\n",
       "1001     [def adstock_geometric(x: torch.Tensor, theta:...\n",
       "1002     [[1, 3, 175, 175], import pandas as pd\\r\\nimpo...\n",
       "1003     [def forward(self, x):   \\r\\n    x = self.gen(...\n",
       "1005     [losses_train = []\\r\\nlosses_test = []\\r\\nacc_...\n",
       "1006     [set_seed(30), config = AutoConfig.from_pretra...\n",
       "1007     [set_seed(30), config = AutoConfig.from_pretra...\n",
       "1008     [a = tensor([[5, 2, 3, 24],\\r\\n        [8, 66,...\n",
       "1009     [AttributeError: 'NoneType' object has no attr...\n",
       "1010     [AttributeError: 'NoneType' object has no attr...\n",
       "1011     [AttributeError: 'NoneType' object has no attr...\n",
       "1012     [transform = transforms.Compose([\\r\\n  transfo...\n",
       "1013     [model_ft = train_model(model, criterion, opti...\n",
       "1014     [tensor([[0.3463]]), torch.Size([1014, 512]), ...\n",
       "1015     [(maxSentence,maxWordsPerSentence,VocabSize), ...\n",
       "1016     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "1017     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "1018     [multiprocessing, class GpuQueue:\\r\\n    def _...\n",
       "1019     [## Standard libraries\\r\\nimport os\\r\\nimport ...\n",
       "1020     [## Standard libraries\\r\\nimport os\\r\\nimport ...\n",
       "1021     [class SonnetDataset(Dataset):\\r\\n    def __in...\n",
       "1022     [def euc_no_loop(x,y):\\r\\n  #hint: two broadca...\n",
       "1023     [import torch\\r\\nimport pyaudio as pa\\r\\nimpor...\n",
       "1024     [name: cosy-bunk-3.7\\r\\nchannels:\\r\\n  - conda...\n",
       "1025     [class patch_allocator(nn.Module): \\r\\n    def...\n",
       "1026     [\\r\\nwith open('recovered_autoencoder_network....\n",
       "1027     [# Creating a simple network\\r\\nclass ConvNeur...\n",
       "1028     [import cv2\\r\\nfrom google.colab.patches impor...\n",
       "1029     [def train(data,model):\\r\\n    train_loader, v...\n",
       "1030     [class ViViTBackbone(nn.Module):\\r\\n    \"\"\" Mo...\n",
       "1031     [x=(220-149)/149 = 0.48, 447/6 = 75, x=(220-75...\n",
       "1033     [def forward(self, x):\\r\\n    # return self.mo...\n",
       "1034     [class GraphLevelGNN(pl.LightningModule):\\r\\n ...\n",
       "1036     [df = df.withColumn(\"features\", explode(array(...\n",
       "1037     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "1038     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "1039     [Pytorch, torch.manual_seed(71) # to obtain re...\n",
       "1040     [class LightningClassifier(LightningModule):\\r...\n",
       "1041     [class MyDataLoader(torch.utils.data.Dataset):...\n",
       "1042     [python ERGO.py train lstm mcpas specific cuda...\n",
       "1043     [import torch\\r\\n\\r\\n# define a floating point...\n",
       "1044     [q_{phi)(x), class NormalModel(nn.Module):\\r\\n...\n",
       "1045     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "1046     [def maldroid_noniid(dataset, train_labels, nu...\n",
       "1047     [device = torch.device('cuda')\\r\\nX_train = to...\n",
       "1048     [Downloading: \"https://github.com/ultralytics/...\n",
       "1049     [   idx, data = self._get_data()\\r\\n  File \"/o...\n",
       "1050     [def Iris_Reader(dataset):\\r\\n    train_data, ...\n",
       "1051     [def get_model_obj(model):\\r\\n    model = mode...\n",
       "1052     [A, (1, 768), B, (2, 4, 768), B, A, B[batch][r...\n",
       "1053     [tensor([[0.1834, 0.8166],\\r\\n        [0.3031,...\n",
       "1054     [tensor([[0.1834, 0.8166],\\r\\n        [0.3031,...\n",
       "1055     [um_epochs = 5\\r\\ndevice = torch.device(\"mps\")...\n",
       "1056     [7(S) x 7(S) x (5(B) + 20(C)), [origin_x, orig...\n",
       "1058     [    def multiModal_before_train(self):\\r\\n   ...\n",
       "1059     [ValueError                                Tra...\n",
       "1061     [# Model class must be defined somewhere, Load...\n",
       "1063     [mdmc_reduce, #y_pred -&gt; Output probabiliti...\n",
       "1064     [def mymodule1(x):\\r\\n        ......\\r\\n      ...\n",
       "1065     [extracted_features = torch.tensor(rn_output),...\n",
       "1066     [  File \"/opt/.pycharm_helpers/pydev/_pydev_bu...\n",
       "1067     [train_dataset, [Data(x=[10, 5], edge_index=[2...\n",
       "1068                           [zero_tensor[mask] = array]\n",
       "1070     [python -m torch.distributed.launch --nproc_pe...\n",
       "1071     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1072     [class Autoencoder(nn.Module):\\r\\n   def __ini...\n",
       "1073     [class Transformer(nn.Module):\\r\\n    def __in...\n",
       "1075     [[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\\r\\n, [0....\n",
       "1076     [def train(epoch, tokenizer, model, device, lo...\n",
       "1077     [def train(epoch, tokenizer, model, device, lo...\n",
       "1078     [def pytorchConvolution(img, kernel):    \\r\\n ...\n",
       "1079     [model_mask = BertForMaskedLM.from_pretrained(...\n",
       "1080     [torch.distributions.MultivariateNormal, impor...\n",
       "1081     [y_pred = torch.randn(12) #logits of the rober...\n",
       "1082     [mask = torch.ones(1024, 64, dtype=torch.float...\n",
       "1084     [loss = criterion(y_predicted, y_train), class...\n",
       "1085     [def get_singlescale_features(self,image):\\r\\n...\n",
       "1086     [wandb, wandb,     since = time.time()\\r\\n\\r\\n...\n",
       "1088     [def forward(self):\\r\\n    # Get transition ma...\n",
       "1089     [wandb sweep sweep/simulation/linear-lmcts.yam...\n",
       "1090     [z=(1/2)||Aw-b||^2, A, 4x2, w=[x,y], 2d, b, 4d...\n",
       "1091     [z=(1/2)||Aw-b||^2, A, 4x2, w=[x,y], 2d, b, 4d...\n",
       "1092     [image[:, :, [2,1,0]], std::vector&lt;long&gt;...\n",
       "1093     [## Serve Image\\r\\nuploaded_file = st.file_upl...\n",
       "1094     [## Serve Image\\r\\nuploaded_file = st.file_upl...\n",
       "1095     [(input_channels, output_channels, kernel_size...\n",
       "1096     [optim.SGD(model_conv.fc.parameters(), optimiz...\n",
       "1097     [optim.SGD(model_conv.fc.parameters(), optimiz...\n",
       "1098     [class ConvNet(torch.nn.Module):\\r\\n def __ini...\n",
       "1099     [import os\\r\\nimport sys\\r\\nimport tempfile\\r\\...\n",
       "1100     [trt_model_fp32 = torch_tensorrt.compile(torch...\n",
       "1101     [[[[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\\r...\n",
       "1102     [def build_model(hp):\\r\\n    model = Sequentia...\n",
       "1103     [  import torch.nn.utils.rnn as r\\r\\n\\r\\n  a =...\n",
       "1104     [BLock, dpr = [x.item() for x in torch.linspac...\n",
       "1105     [  from my_folder import encoder\\r\\n\\r\\n  clas...\n",
       "1106     [File /anaconda/envs/azureml_py38_PT_TF/lib/py...\n",
       "1107     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "1108     [a, torch.Size([2, 2, 1, 2]), torch.Size([2, 4...\n",
       "1109     [   grads = torch.autograd.grad(\\r\\n          ...\n",
       "1110     [import torch\\r\\nX = torch.arange(-3, 3, step=...\n",
       "1111     [class MLPModel(nn.Module):\\r\\n\\r\\ndef __init_...\n",
       "1112     [self.conv1 = torch.nn.Conv2d(1, 6, 5, padding...\n",
       "1113     [cnn = models.vgg19(pretrained=True).features....\n",
       "1114     [forward() got an unexpected keyword argument ...\n",
       "1115                       [k, 3, n, k, n, a, b, kx3xn, n]\n",
       "1116     [from sagemaker.debugger import Rule, Debugger...\n",
       "1117     [import torch\\r\\n\\r\\nx = torch.linspace(0, 1, ...\n",
       "1120     [TypeError                                 Tra...\n",
       "1122     [from simpletransformers.classification import...\n",
       "1123     [Directory Structure:\\r\\n\\r\\n - Segmentation\\r...\n",
       "1124     [dataset_dicts = load_coco_json(\"../Downsample...\n",
       "1125     [[70,1], [70,1,1], [70,1], RuntimeError       ...\n",
       "1126     [model = nn.Sequential(\\r\\n    nn.Linear(1, 32...\n",
       "1127     [model = nn.Sequential(\\r\\n    nn.Linear(1, 32...\n",
       "1128     [args = Seq2SeqTrainingArguments(\\r\\n    outpu...\n",
       "1129     [args = Seq2SeqTrainingArguments(\\r\\n    outpu...\n",
       "1131     [import torch\\r\\nfrom torch.distributions impo...\n",
       "1132     [sample_transform = transforms.Compose([\\r\\n  ...\n",
       "1133     ['torch.Size([3,10,15])', convs = nn.ModuleLis...\n",
       "1134     [a, 0, a = [[1,2,2], [1,0,0], [1,3,1]] -&gt; [...\n",
       "1135     [a = []\\r\\nfor n, i in enumerate(X):\\r\\n    a....\n",
       "1136     [tensor([[ 0, 1,  2],\\r\\n        [ 2,  0,  1])...\n",
       "1137     [I am a good man\\r\\nI would like a coffee plea...\n",
       "1138     [\\r\\nclass LinearTransform(tf.keras.Model):\\r\\...\n",
       "1139     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nk...\n",
       "1140     [model.eval()\\r\\n    \\r\\ndevs = [torch.device(...\n",
       "1141     [u,v = foo(x,y), Dataset, Dataloader,     impo...\n",
       "1142     [from data.util import  read_image\\r\\n\\r\\nmode...\n",
       "1143     [300MB, RUN /bin/sh -c pip install -r requirem...\n",
       "1144     [StreamingResponse, def some_unimportant_funct...\n",
       "1145     [self.X = tf.compat.v1.placeholder(tf.int32, [...\n",
       "1146     [torch.nn.Linear, self, class MultipleRegressi...\n",
       "1147     [def __getitem__(self, idx):\\r\\n    mask = tor...\n",
       "1148     [Input In [5], in test_model(agent)\\r\\n      8...\n",
       "1150     [(torch.Size([1, 3, 224, 224])), (torch.Size([...\n",
       "1151     [@app.endpoint('/send_weights', methods=['GET'...\n",
       "1153     [class MyCNN(nn.Module):\\r\\n  def __init__(sel...\n",
       "1154     [weights = torch.tensor([a,b,c....m])\\r\\n# X i...\n",
       "1155     [weights = torch.tensor([a,b,c....m])\\r\\n# X i...\n",
       "1156     [pip install torch torchvision torchaudio --ex...\n",
       "1157     [def choose_action(self, observation):\\r\\n    ...\n",
       "1158     [CC=&lt;my_path_to_gcc&gt; BUILD_SOX=1 USE_CUD...\n",
       "1159     [[[[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\\r...\n",
       "1160     [[[[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\\r...\n",
       "1161     [tensor([0.011 , 0.0041, 0.002 , 0.0248, 0.005...\n",
       "1162     [emotions={\\r\\n  '01':'neutral',\\r\\n  '02':'ca...\n",
       "1163     [from transformers import BertTokenizer, BertM...\n",
       "1164     [forward(), torch.onnx.export(), forward(), to...\n",
       "1165     [def __init__(self):    \\r\\n    super().__init...\n",
       "1166     [def __init__(self):    \\r\\n    super().__init...\n",
       "1167     [image, ProductSerializer, str, image, Product...\n",
       "1168     [import torch\\r\\n\\r\\ndef tensor_like(source_da...\n",
       "1169     [torch.nn.utils.rnn.pad_sequence, import torch...\n",
       "1170     [input_seq[1:, :] = torch.from_numpy(stroke[:-...\n",
       "1171     [import torch\\r\\nfrom torchmetrics.detection.m...\n",
       "1173     [df_data1_cluster = pd.DataFrame(columns = [\"c...\n",
       "1174     [pip install torch==1.12.0 torchvision==0.13.0...\n",
       "1175     [nn.Embedding, nn.EmbeddingBag, nn.EmbeddingBa...\n",
       "1176     [def forward(self,x):\\r\\n        print(\"values...\n",
       "1177     [import torch\\r\\na = torch.tensor([1,2,3])\\r\\n...\n",
       "1178     [pip install tensorflow\\r\\n, pip install trans...\n",
       "1179     [u, s, v = torch.svd(matrix)\\r\\ns_cumsum = tor...\n",
       "1180     [to_sparse(), A_sparse = A.to_sparse()\\r\\n ten...\n",
       "1181     [model = torchvision.models.detection.fasterrc...\n",
       "1182     [import torch\\r\\n\\r\\n\\r\\nstartVal = -5.0\\r\\nal...\n",
       "1183     [trainer.train(), RuntimeError                ...\n",
       "1184     [mobilenet_v3_large, import torchvision\\r\\nimp...\n",
       "1185     [data_loader_original, data_loader_original, d...\n",
       "1186     [model = resnet34_with_table()\\r\\n# Load the m...\n",
       "1187     [import torch\\r\\n\\r\\nlist1 = [\\r\\n[10, 25, 75,...\n",
       "1189     [from transformers import Wav2Vec2Processor, H...\n",
       "1190     [from laserembeddings import Laser\\r\\nlaser = ...\n",
       "1191     [trainer.train(),     RuntimeError            ...\n",
       "1192     [PAD = '&lt;pad&gt;'  # special symbol we use ...\n",
       "1193     [model_hybrid = train_model(\\r\\n    model_hybr...\n",
       "1194     [convolution, full convolution, Matrix&lt;floa...\n",
       "1195     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "1196     [import torch.nn.functional as F\\r\\n\\r\\n\\r\\ncl...\n",
       "1197     [    import torch.nn.functional as F\\r\\n\\r\\n  ...\n",
       "1198     [spaces.Discrete(4), spaces.MultiDiscrete([(1,...\n",
       "1199     [RuntimeError: Caught RuntimeError in DataLoad...\n",
       "1200     [load_best_model_at_end=True, metric_for_best_...\n",
       "1201     [C, R, Sorted_C, c = torch.tensor([[[0, 1, 0, ...\n",
       "1202     [loss = K.mean(K.square(y_pred - y_true), axis...\n",
       "1203     [BertForSequenceClassification, import torch\\r...\n",
       "1205     [class DenseNetConv(torch.nn.Module):\\r\\n    d...\n",
       "1207     [def make_predictions(model, imagePath):\\r\\n# ...\n",
       "1208     [class NeuralNet(nn.Module):\\r\\n    \\r\\n\\r\\n  ...\n",
       "1209     [class RandomDataset(Dataset):\\r\\n    def __in...\n",
       "1210     [&lt;ipython-input-50-b849fcdd95cf&gt; in gene...\n",
       "1211     [criterion = nn.L1Loss()\\r\\nnet = net.cuda()\\r...\n",
       "1212     [import torch\\r\\n\\r\\n    p = torch.arange(0, 1...\n",
       "1213     [import gym\\r\\nimport os\\r\\nimport os.path as ...\n",
       "1214     [dataset = dset.ImageFolder(root=dataroot,\\r\\n...\n",
       "1215     [RuntimeError: grad can be implicitly created ...\n",
       "1216     [class BaseModel(nn.Module):\\r\\n\\r\\n  def __in...\n",
       "1217     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "1218     [RuntimeError: Error(s) in loading state_dict ...\n",
       "1221                          [m, [12, 10], s, [12], m, s]\n",
       "1222     [class Waveunet(nn.Module):\\r\\n    def __init_...\n",
       "1223     [torchaudio.datasets.SPEECHCOMMANDS, torchaudi...\n",
       "1225     [MLM, Pytorch Trainer API, data_collator = Dat...\n",
       "1226     [o = torch.tensor([[[1, 3, 2], [7, 9, 8], [13,...\n",
       "1227     [o = torch.tensor([[[1, 3, 2], [7, 9, 8], [13,...\n",
       "1228     [estimator = PyTorch(\\r\\n    entry_point=\"trai...\n",
       "1229     [import os\\r\\nos.environ[\"PL_TORCH_DISTRIBUTED...\n",
       "1231     [    import time\\r\\n    import copy\\r\\n    imp...\n",
       "1232     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1233     [from torch import nn\\r\\nfrom torch.utils.data...\n",
       "1234                             [torchvision==0.13.0\\r\\n]\n",
       "1235     [conda create -n my-environment python=3.7\\r\\n...\n",
       "1236     [---------------------------------------------...\n",
       "1237     [model_hybrid = train_model(\\r\\nmodel_hybrid, ...\n",
       "1238     [model_hybrid = train_model(\\r\\nmodel_hybrid, ...\n",
       "1239     [def Loss(a):\\r\\n  return a**2\\r\\n\\r\\na=torch....\n",
       "1240     [(2,1024,4,6), (2,512,8,12), nn.ConvTranspose3...\n",
       "1241     [class Decoder(nn.Module):\\r\\n    def __init__...\n",
       "1242                                            [sr=44100]\n",
       "1243     [    for epoch in range(max_epochs):\\r\\n      ...\n",
       "1244     [audio_data_bytes = io.BytesIO()\\r\\ntorch.save...\n",
       "1245     [    checkpoint = torch.load('/content/drive/M...\n",
       "1246     [Z(X, Y) = torch.mm(X.mm(X), Y), .backward(), ...\n",
       "1247     [import torch\\r\\n\\r\\ncouplings_lookup = torch....\n",
       "1248     [.pt, ONNX, OpenVINO, TFLite, from openvino.ru...\n",
       "1249     [public static float[] TORCHVISION_NORM_MEAN_R...\n",
       "1250     [X1: \\r\\n[1 2 3 4 5 6]\\r\\n[5 4 6 7 8 9]\\r\\n[3 ...\n",
       "1251     [model outputs are: (tensor([[0.4512],\\r\\n    ...\n",
       "1252     [import argparse\\r\\nimport torch\\r\\nfrom torch...\n",
       "1253     [class Block(nn.Module):\\r\\ndef __init__(self,...\n",
       "1254     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "1255     [# import the required modules\\r\\nimport torch...\n",
       "1256     [# import the required modules\\r\\nimport torch...\n",
       "1257     [import json\\r\\nimport logging\\r\\nimport sys\\r...\n",
       "1258     [class linearNN(nn.Module):\\r\\ndef __init__(se...\n",
       "1259     [class Generator(nn.Module):\\r\\n  def __init__...\n",
       "1260     [from engine import train_one_epoch, evaluate\\...\n",
       "1261     [Pytorch, Fastai, class FocalLoss(nn.Module):\\...\n",
       "1262     [IoU metric: bbox\\r\\n Average Precision  (AP) ...\n",
       "1263     [conda install jupyter\\r\\nconda install notebo...\n",
       "1264     [inputs, target, 32, inputs[0].shape = (8, 369...\n",
       "1265     [def prepare_data(self):\\r\\n    # download\\r\\n...\n",
       "1266     [import torch\\r\\nimport json\\r\\nfrom torchvisi...\n",
       "1268     [class CovidDataset(torch.utils.data.Dataset):...\n",
       "1269     [x = torch.tensor(2.0, requires_grad=True)\\r\\n...\n",
       "1270     [torch.combinations, inp = torch.tensor([[1, 2...\n",
       "1271     [a=a[torch.randperm(a.size()[0])]\\r\\n, a = tor...\n",
       "1272     [class SegmentationDataSet(data.Dataset):\\r\\nd...\n",
       "1273     [   import torch\\r\\n    import argparse\\r\\n   ...\n",
       "1275     [def input_depth(network: \"torch.nn.Module\") -...\n",
       "1276     [def map_enhance(dataset_dict):\\r\\n    dataset...\n",
       "1277     [In automatic_optimization, when `training_ste...\n",
       "1278     [__init__, forward, class Waveunet(nn.Module):...\n",
       "1279     [num_classes = 10\\r\\nresnet = models.resnet18(...\n",
       "1280     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1281     [model.fit(), val_images = np.array(val_images...\n",
       "1282     [class CustomCNN(BaseFeaturesExtractor):\\r\\n  ...\n",
       "1283     [train, test = train_test_split(eurusd_df, tes...\n",
       "1284     [class EmbeddingLayer(nn.Module):\\r\\n  def __i...\n",
       "1285     [class RNN(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "1286     [class NewsClassifier(nn.Module):\\r\\n  def __i...\n",
       "1287     [with torch.autograd.set_detect_anomaly(True):...\n",
       "1288     [tensorflow, pytorch, def _components_train_st...\n",
       "1289     [Original, DictList, DataFrame, Original, Rela...\n",
       "1290     [RuntimeError: Expected number of channels in ...\n",
       "1291     [torch.eq, def knn_mpatk_loss(query_embeds, qu...\n",
       "1292     [class Handmade_LSTM(torch.nn.Module):\\r\\n    ...\n",
       "1293     [x = np.array([[0, 1, 0, 0, 0],\\r\\n           ...\n",
       "1294     [x = np.array([[0, 1, 0, 0, 0],\\r\\n           ...\n",
       "1295     [x = np.array([[0, 1, 0, 0, 0],\\r\\n           ...\n",
       "1296     [# script.py\\r\\nimport torch\\r\\nimport torch.n...\n",
       "1297     [model = models.densenet161(pretrained=True)\\r...\n",
       "1298     [763104351884.dkr.ecr.us-east-1.amazonaws.com/...\n",
       "1299     [def keras2torch(kerasNet,torchNet,kerasWeighp...\n",
       "1301     [pos_weight, BCEWithLogitsLoss, tensor([1000, ...\n",
       "1302     [RuntimeError: element 0 of tensors does not r...\n",
       "1304     [TensorDataset, DataLoader, tensor_loader = Te...\n",
       "1307     [import torch\\r\\n\\r\\nclass Net(torch.nn.Module...\n",
       "1308     [if torch.cuda.device_count() &gt; 1:\\r\\n     ...\n",
       "1309     [my_results = trainer.predict(model = model, d...\n",
       "1310     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1311     [import sys\\r\\nimport numpy as np\\r\\n\\r\\nimpor...\n",
       "1312     [sequence_representations = []\\r\\nfor i, (_, s...\n",
       "1313     [model_1 = SimpleCnn(n_classes) # model class\\...\n",
       "1314     ['list' object has no attribute 'shape'`\\r\\n, ...\n",
       "1315     [from keras.layers import Conv2D\\r\\nfrom torch...\n",
       "1316     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1317     [ padding=(dilation*(cnn_kernel_size[0]-1)//2,...\n",
       "1318     [ import argparse\\r\\n import time\\r\\n import o...\n",
       "1319     [self(**data), \\r\\nclass BaseDetector(BaseModu...\n",
       "1320     [Epoch: 1, Training Loss: 2.2622, Validation L...\n",
       "1321     [data_loader_iterator = iter(data_loader_secon...\n",
       "1322     [global_fp = []\\r\\nglobal_tp = []\\r\\n\\r\\n# det...\n",
       "1323     [import math\\r\\nimport numpy as np\\r\\nimport t...\n",
       "1326     [torch                1.11.0+cu113\\r\\ntorchaud...\n",
       "1328     [import os \\r\\nos.environ[\"CUDA_VISIBLE_DEVICE...\n",
       "1330     [def crop(request):\\r\\nmodel = torch.hub.load(...\n",
       "1331     [class MultipleFC(nn.Module):\\r\\n    def __ini...\n",
       "1332     [from nni.nas.pytorch import mutables\\r\\n\\r\\nc...\n",
       "1334     [a b c [SEP] d e f, -1 -1 -1 0 1 0 0, loss_fun...\n",
       "1335     [import torch\\r\\n\\r\\nu = torch.tensor([1.,2.,3...\n",
       "1336     [t, (n, x, y), y &gt; x + k, k, t[n, x, y] = -...\n",
       "1337     [import glob\\r\\nimport numpy as np\\r\\nimport o...\n",
       "1338     [Downloading: \"https://download.pytorch.org/mo...\n",
       "1339     [stage, Optional[str], import pytorch_lightnin...\n",
       "1340     [stage, Optional[str], import pytorch_lightnin...\n",
       "1341     [    # Convolution 1\\r\\n    self.cnn1 = nn.Con...\n",
       "1342     [# Converting pretrained BERT classification m...\n",
       "1343     [class Dataset(Dataset):\\r\\n    def __init__(s...\n",
       "1344     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1345     [Expected all tensors to be on the same device...\n",
       "1347     [self.feature, class, TimeSformer(\\r\\n  (model...\n",
       "1348     [parsed_list = [(k, v) for k, v in parsed_seqs...\n",
       "1349     [  File \"/home/miruware/anaconda3/envs/bev/lib...\n",
       "1350     [data_root = os.path.join(os.getcwd(), \"data\")...\n",
       "1351     [from sklearn.metrics import f1_score, roc_auc...\n",
       "1353     [            A   B    C\\r\\n2022-07-23  1  10  ...\n",
       "1355     [def __init__(self):\\r\\n    super()\\r\\n    pos...\n",
       "1356     [GPUS_PER_NODE=8\\r\\nMASTER_ADDR=localhost\\r\\nM...\n",
       "1357     [torch, import tensorflow_probability as tfp\\r...\n",
       "1358     [TimeSformer(\\r\\n  (model): VisionTransformer(...\n",
       "1359     [full_state_update, update, False, from torchm...\n",
       "1360     [KeyError: 'test', dataset = load_dataset('csv...\n",
       "1361     [ - OS information: Ubuntu 18.04 x86_64\\r\\n - ...\n",
       "1362     [import torch\\r\\nimport torchcrf\\r\\n\\r\\nclass ...\n",
       "1363     [# import libraries\\r\\nimport numpy as np\\r\\ni...\n",
       "1364     [[b, c, h, w], [4, 3, 275, 275], [b, n, h, w],...\n",
       "1365     [U, S, Vh = numpy.linalg.svd(A), U, S, Vh = to...\n",
       "1366                    [cfg.SOLVER, cfg.SOLVER.OPTIMIZER]\n",
       "1367                    [cfg.SOLVER, cfg.SOLVER.OPTIMIZER]\n",
       "1368     [import torch\\r\\nfrom timesformer.models.vit i...\n",
       "1369     [class MyClass(nn.Module):\\r\\n    def __init__...\n",
       "1370     [args = TrainingArguments( f\"xlnet-large-finet...\n",
       "1371     [RuntimeError: Too many open files. Communicat...\n",
       "1372     [from torch.utils.data import Subset\\r\\nfrom s...\n",
       "1373     [tochvision, [128, 1, 28, 28]., (28/4)**2=49, ...\n",
       "1374     [import random\\r\\nimport gym\\r\\nimport numpy a...\n",
       "1375     [@mlconfig.register\\r\\nclass NormalizedCrossEn...\n",
       "1376     [NIfTI, MONAI's DynUNet(nnUNet), [num_px_x, nu...\n",
       "1377     [35             acc = categorical_accuracy(pre...\n",
       "1378     [import numpy as np\\r\\nimport time\\r\\nfeatures...\n",
       "1379     [    self.decoder_layer = nn.TransformerDecode...\n",
       "1380     [&gt; File \"C:\\ProgramData\\Anaconda3\\lib\\runpy...\n",
       "1381     [  import tensorflow as tf\\r\\n\\r\\n  from xba i...\n",
       "1382     [class WholeModel:\\r\\n    def __init__(...):\\r...\n",
       "1383     [err = reduce((mu_students - teacher_pred)**2,...\n",
       "1384     [$ python setup.py install\\r\\n\\r\\nBuilding whe...\n",
       "1385     [tensor([0,0,0,0,1,1,2,2,2,3,3,3,3,3]\\r\\n,  A ...\n",
       "1388     [#@title Generate 1K Image\\r\\nfrom google.cola...\n",
       "1389     [torch.onnx.export(\\r\\n    model,\\r\\n    (im, ...\n",
       "1390     [0. I have ground truth image GT. set Input_im...\n",
       "1391     [B*N*H*W, N,     class Net(nn.Module):\\r\\n    ...\n",
       "1392     [nn.Parameter(), requires_grad=True, lparam, r...\n",
       "1395     [RuntimeError: Trying to backward through the ...\n",
       "1396     [main.py, Dataset, py, from torch.utils.data i...\n",
       "1397     [class ActorCritic(nn.Module):\\r\\n    def __in...\n",
       "1398     [class ActorCritic(nn.Module):\\r\\n    def __in...\n",
       "1399     [RuntimeError: Tensor for 'out' is on CPU, Ten...\n",
       "1400     [print(torch.__version__), print(torch.cuda.cu...\n",
       "1401     [import torch\\r\\nfrom timesformer.models.vit i...\n",
       "1402     [# Use PyTorch to check versions, CUDA version...\n",
       "1403     [Masking, pack_padded_sequence, from torch.nn....\n",
       "1404     [[1,2,3,4,5,6,7,8,9,10,11,12] and d is 2; \\r\\n...\n",
       "1405     [multiprocessing.Process, from multiprocessing...\n",
       "1406     [---------------------------------------------...\n",
       "1407     [UnidentifiedImageError: cannot identify image...\n",
       "1408     [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "1409     [sz, bs = 64\\r\\nsz = 256    # the size of tile...\n",
       "1411     [from torch.utils.data import Dataset, DataLoa...\n",
       "1412     [tensor_to_change = tensor([[-36.9127, -45.659...\n",
       "1414                      [(1, 1, 1, 1, 1, 1, 1, 1, 0, 0)]\n",
       "1415     [# create dataset\\r\\nclass carte_dataset(Datas...\n",
       "1416     [model_urls = {\\r\\n    'resnet18': 'https://do...\n",
       "1417     [def softmax(X):\\r\\n    X_exp=torch.exp(X)\\r\\n...\n",
       "1418     [import torch\\r\\nimport torch.nn.functional as...\n",
       "1419     [ with torch.no_grad(), num_classes = 2 \\r\\nnu...\n",
       "1421     [import torch\\r\\nfrom sklearn.metrics import a...\n",
       "1422     [3 by n by k, A, 1 by k by m, x, Ax = B, B, [3...\n",
       "1423     [\\r\\nn_feature= feature_train.shape[1] # numbe...\n",
       "1424     [x, tensor([[1, 2],\\r\\n        [3, 4],\\r\\n    ...\n",
       "1425     [df[\"region\"].replace([\"northeast\", \"southeast...\n",
       "1426     [model=Model()\\r\\nlossfn=nn.BCEWithLogitsLoss(...\n",
       "1427     [model=Model()\\r\\nlossfn=nn.BCEWithLogitsLoss(...\n",
       "1429     [class Generator(object):\\r\\n     def __init__...\n",
       "1430     [torch.Size([bs, c, h, w]), bs=4, c=1,and (h, ...\n",
       "1432     [#Function for feature extraction\\r\\ndef set_p...\n",
       "1433     [#Function for feature extraction\\r\\ndef set_p...\n",
       "1434     [print(eps, episode_x.shape, train_input.shape...\n",
       "1435     [import torch\\r\\n\\r\\ndef unnecessary_compute()...\n",
       "1436     [import torch\\r\\n\\r\\ndef unnecessary_compute()...\n",
       "1438     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1439     [data_tensor = torch.load('tensor_1.pt')  \\r\\n...\n",
       "1440     [import torch\\r\\nimport zmq\\r\\n\\r\\ndef main():...\n",
       "1441     [X, top K, K, int, tensor([[0.6607, 0.1165, 0....\n",
       "1442     [inceptionv4, imagenet, URLError: &lt;urlopen ...\n",
       "1443     [tensor([[0.6607, 0.1165, 0.0278, 0.1950],\\r\\n...\n",
       "1444     [Exception has occurred: NotImplementedError\\r...\n",
       "1445     [model = torchvision.models.detection.fasterrc...\n",
       "1446     [class OptimizeCorners(torch.nn.Module):\\r\\n  ...\n",
       "1447     [from PIL import Image\\r\\nimg = Image.open(\"da...\n",
       "1448     [from PIL import Image\\r\\nimg = Image.open(\"da...\n",
       "1449     [from PIL import Image\\r\\nimg = Image.open(\"da...\n",
       "1451     [\\r\\nimport torch\\r\\nimport torch.nn as nn\\r\\n...\n",
       "1452     [from brevitas.nn import QuantLinear, QuantReL...\n",
       "1453     [real_batch = next(iter(dataloader))\\r\\n(real_...\n",
       "1454     [class AE(torch.nn.Module):\\r\\n    def __init_...\n",
       "1455     [l2_penalty = l2_lambda * sum([(p**2).sum() fo...\n",
       "1456     [def batch_function(M, kernel_size=21, sf=2):\\...\n",
       "1457     [def batch_function(M, kernel_size=21, sf=2):\\...\n",
       "1458     [#here train_images,valid_images is a list of ...\n",
       "1459     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "1460     [import argparse\\r\\n\\r\\nimport torch\\r\\nfrom t...\n",
       "1461     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "1462     [pip install stable-baselines3[extra]\\r\\n, imp...\n",
       "1463     [x, class Upsample(nn.Module):\\r\\n    def __in...\n",
       "1464     [from collections import defaultdict\\r\\nimport...\n",
       "1465     [cfg = get_cfg()\\r\\ncfg.MODEL.DEVICE = 'cpu'\\r...\n",
       "1466     [class ANN_Model(nn.Module):\\r\\n    def __init...\n",
       "1467     [\"\"\"\\r\\nThis python script is the net-class of...\n",
       "1468     [def normalizeImage(paths):\\r\\n    img = cv2.i...\n",
       "1469     ['THC/THC.h': No such file or directory\\r\\n, #...\n",
       "1470     [from torch.autograd.functional import hessian...\n",
       "1471     [dummy_input = torch.randn(800, 1067, 3), torc...\n",
       "1472     [    def configure_optimizers(self):\\r\\n    op...\n",
       "1473     [model.eval(), torch.cuda.manual_seed_all(42)\\...\n",
       "1474     [id(), python,  a = torch.tensor([1, 2, 3])\\r\\...\n",
       "1475     [array = [0,0,0,0,0,0,0]\\r\\nindices = [0, 0, 2...\n",
       "1476     [array = [0,0,0,0,0,0,0]\\r\\nindices = [0, 0, 2...\n",
       "1477     [array = [0,0,0,0,0,0,0]\\r\\nindices = [0, 0, 2...\n",
       "1478     [encoder_outputs, # print(start_pre_ids)\\r\\n\\r...\n",
       "1480     [device = torch.device('cuda:0' if torch.cuda....\n",
       "1481     [L1 = torch.FloatTensor([(i-B).abs().mean(dim=...\n",
       "1483     [--------------------------------\\r\\nUser_id |...\n",
       "1484     [--------------------------------\\r\\nUser_id |...\n",
       "1485     [import pycaret\\r\\nimport numpy as np\\r\\nimpor...\n",
       "1487     [torchaudio, pip, &lt;ipython-input-6-4cf0a64f...\n",
       "1488     [torchaudio, pip, &lt;ipython-input-6-4cf0a64f...\n",
       "1489     [num_worker, prefetch_factor, MyIterable, np.a...\n",
       "1490     [torch model, module, torchvision.models.resne...\n",
       "1491     [    self.root_dir = root_dir\\r\\n    self.imag...\n",
       "1492     [x, y, (num_batches, d), x, y, osum[b, i, j] =...\n",
       "1493     [x, y, (num_batches, d), x, y, osum[b, i, j] =...\n",
       "1494     [#1, #2, optimizer = torch.optim.Adam(model.pa...\n",
       "1495     [num_workers &gt;=1, prefetch_factor * num_wor...\n",
       "1496     [class denoising_model(nn.Module):\\r\\n    def ...\n",
       "1497     [t = tensor([[2.0000,   -inf, -inf],\\r\\n      ...\n",
       "1500     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1501     [import _pickle\\r\\nimport contextlib\\r\\nimport...\n",
       "1504     [t = torch.tensor(\\r\\n            [[1.0, 1.5, ...\n",
       "1505     [t = torch.tensor(\\r\\n            [[1.0, 1.5, ...\n",
       "1506     [def __getitem__(self, index):\\r\\n        \\r\\n...\n",
       "1508     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1509     [t, float, float('-inf'), float('inf'), mask, ...\n",
       "1510     [def make_generator_model():\\r\\n    f = config...\n",
       "1511     [(x, y, z), (x, z), (0.5, -, 0.5), x_data_plac...\n",
       "1512     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1513     [shape, int, def generate_data(w, b, num_examp...\n",
       "1514     [from torch import nn\\r\\n\\r\\nclass Model(nn.Mo...\n",
       "1515     [IOU, 1, TP, IOU, 0.5, 14 x 10 x 128, 14 x 10 ...\n",
       "1516     [import torch\\r\\n\\r\\n@torch.jit.script\\r\\n\\r\\n...\n",
       "1520     [class Custom_dataset(Dataset):\\r\\n    def __i...\n",
       "1521     [ValueError: The implied number of classes (fr...\n",
       "1522     [ValueError: The implied number of classes (fr...\n",
       "1523     [tf.squeeze(tf.random_gamma(shape =(self.n_sam...\n",
       "1524     [dy/dx = cos(x), y(0)=y(2*pi)=0, y(x)=sin(x), ...\n",
       "1525     [l = []\\r\\nfor img in glob.glob('/content/Masc...\n",
       "1526     [l = []\\r\\nfor img in glob.glob('/content/Masc...\n",
       "1527     [model.train()\\r\\nfor epoch in range(3):\\r\\n\\r...\n",
       "1528     [def get_train_augs():\\r\\n  return A.Compose([...\n",
       "1529     [import torch.nn as nn\\r\\nfrom torchvision.mod...\n",
       "1530     [local_model.bn1.num_batches_tracked.fill_(0.)...\n",
       "1531     [torch, shape, t, [3,2], N, M = t.shape, N = 3...\n",
       "1532     [Input, Ground Truth, %280, for, 0.pcd, 1.pcd,...\n",
       "1533     [def define_G(opt):\\r\\n    # COMMENTED PART IS...\n",
       "1534     [import torch\\r\\nfrom torchvision.models.featu...\n",
       "1535     [def check_accuracy(loader, model, device=\"cpu...\n",
       "1536     [output = [bbox_regressions, F.softmax(classif...\n",
       "1539     [# boxes for an image -&gt; [[Class,xCenter,yC...\n",
       "1540     [TEXT = data.Field(tokenize='spacy',\\r\\n      ...\n",
       "1541     [\\r\\n    def __init__(self, in_channels, out_c...\n",
       "1543     [numpy nd array, from_numpy(), mps, device = \"...\n",
       "1545     [s3_input = \"s3://sagemaker-studio-****/traini...\n",
       "1547     [activation = nn.ReLU()\\r\\nclass OneInputBasis...\n",
       "1549     [data_transforms = {\\r\\n    'train': transform...\n",
       "1550     [v0.13.0, conda install -c pytorch torchvision...\n",
       "1551     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1552     [backbone, timm, config = DetrConfig.from_pret...\n",
       "1553     [running_mean, running_var, nn.BatchNorm2d, nn...\n",
       "1554     [[batch_size, classes, time_steps], [batch_siz...\n",
       "1555     [[batch_size, classes, time_steps], [batch_siz...\n",
       "1556     [      8       optimizer.zero_grad()\\r\\n      ...\n",
       "1557     [NotImplementError, torch::kMPS, #include &lt;...\n",
       "1558     [import torch\\r\\naa=torch.tensor([[1,2,3],[4,5...\n",
       "1559     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "1560     [test1 = tf.round(5*tf.random.uniform(shape=(2...\n",
       "1561     [import torch\\r\\nimport numpy as np\\r\\na = tor...\n",
       "1562     [import torch\\r\\nimport numpy as np\\r\\na = tor...\n",
       "1563     [import torch\\r\\nimport numpy as np\\r\\na = tor...\n",
       "1565     [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "1566     [def __init__(self):\\r\\n    super(GPlayer, sel...\n",
       "1567     [import utils\\r\\nimport torch\\r\\n\\r\\n\\r\\nif __...\n",
       "1568     [import utils\\r\\nimport torch\\r\\n\\r\\n\\r\\nif __...\n",
       "1569     [batch_size = 1\\r\\nchannel = 3\\r\\ninput_size =...\n",
       "1571     [def training_step(self, batch, batch_idx):\\r\\...\n",
       "1572     [x_axis = torch.linspace(-5, 5, 1000)\\r\\ny_axi...\n",
       "1573     [1 1 0 0 1 1\\r\\n1 1 0 0 1 1\\r\\n0 0 1 1 0 0\\r\\n...\n",
       "1574     [from sklearn.model_selection import train_tes...\n",
       "1575     [from sklearn.model_selection import train_tes...\n",
       "1576     [allCellsData = torch.load(\"/Users/andresmoren...\n",
       "1577     [from torch import nn\\r\\nimport torch.nn.funct...\n",
       "1578     [data1 = torch.ones(3, 3, 3, requires_grad=Tru...\n",
       "1579     [F tensorflow/stream_executor/cuda/cuda_driver...\n",
       "1580     [def get_iou(boxA, boxB):\\r\\n    # This will c...\n",
       "1581     [ein1 = torch.einsum(\"bi,bij-&gt;bij\",degree_m...\n",
       "1584     [torch.save(vgg_based.state_dict(), 'model1.pt...\n",
       "1585     [# -*- encoding:utf-8 -*-\\r\\nimport torch\\r\\ni...\n",
       "1586     [def __init__(self):\\r\\n        self.tc_h = to...\n",
       "1587     [class FuseNet(nn.Module):\\r\\ndef __init__(sel...\n",
       "1588     [torch.optim , optim.Adam, FullBatchLBFGS, CUT...\n",
       "1590     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "1591     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "1592     [backbone.stem.conv1.weight\\r\\nbackbone.stem.c...\n",
       "1593     [for l in range(1):\\r\\n    model = GTN(num_edg...\n",
       "1594     [CHECKPOINT_GEN = \"output/vanilla/checkpoints/...\n",
       "1595     [import torch\\r\\nfrom torch.autograd.functiona...\n",
       "1596     [n_groups, labels = torch.as_tensor([0, 0, 0, ...\n",
       "1597     [# Copyright (c) Meta Platforms, Inc. and affi...\n",
       "1599     [pipe = pipeline('zero-shot-classification', d...\n",
       "1600     [from torch_geometric.nn import GCNConv\\r\\n, -...\n",
       "1602     [Nodes = 18405, Edges = 67946, Edge type = 4, ...\n",
       "1603     [squares = image_processing('/Users/Me/Downloa...\n",
       "1604     [from torchvision.models import efficientnet_b...\n",
       "1605     [tensor([[ 2992,  1852,  9439,  ...,  2610,  1...\n",
       "1606     [class LSTMClassifier(nn.Module):\\r\\n    def _...\n",
       "1607     [model = AutoModelForSequenceClassification.fr...\n",
       "1609     [[ 8 x 1085 x 1024 ], [8x 4000], [ 8 x 4000], ...\n",
       "1610     [x = 0b11110111\\r\\ny = 0b11001010\\r\\n, z = 0b1...\n",
       "1612     [CPU times: user 4 µs, sys: 1e+03 ns, total: 5...\n",
       "1613     [class Net(T.nn.Module):\\r\\n  def __init__(sel...\n",
       "1614     [\\r\\nclass GAT(torch.nn.Module):\\r\\n    def __...\n",
       "1615     [ import numpy as np\\r\\n img1 = np.random.rand...\n",
       "1616     [import torch\\r\\nx = torch.ones(2, 2, 2, requi...\n",
       "1617     [class Op(nn.Module):\\r\\n    def __init__(self...\n",
       "1618     [datasets.FashionMNIST('.',train = True)\\r\\n, ...\n",
       "1619     [img1 = torchvision.io.read_image(IMAGE1).floa...\n",
       "1620     [import torch\\r\\nfrom transformers import Bert...\n",
       "1621     [x, [batch, time, feature], i, [batch, new_tim...\n",
       "1622     [import torch\\r\\nclass NET(torch.nn.Module):\\r...\n",
       "1623     [nn.ConvTranspose2d, nn.ConvTranspose2d, IN = ...\n",
       "1624     [nn.ConvTranspose2d, nn.ConvTranspose2d, IN = ...\n",
       "1625     [    with torch.no_grad():\\r\\n        for shap...\n",
       "1626     [from torch.utils.data import DataLoader, Data...\n",
       "1627     [    edge_in = torch.ones(len(edge_embeds), le...\n",
       "1628     [model.whatever_function(input), model.forward...\n",
       "1629     [k, 1, -1, k, tensor([[[[[ 0.,  0.,  0.,  0., ...\n",
       "1630     [import random\\r\\nimport numpy as np\\r\\nimport...\n",
       "1631     [loss_lst = []\\r\\n\\r\\nfor epoch in range(50): ...\n",
       "1632     [def main():\\r\\n    start = time.time()\\r\\n\\r\\...\n",
       "1633     [   @staticmethod\\r\\n   def gaussian_preds(pre...\n",
       "1634     [for i, (inputs, labels) in enumerate(data_loa...\n",
       "1635     [import torchvision.transforms as T\\r\\nimport ...\n",
       "1636     [scatter_, dim=0, dim=1,  target = torch.tenso...\n",
       "1638     [X, NUMBER OF POINTS x CHOICES x NUM_FEATURES,...\n",
       "1639     [my_model= torch.nn.Transformer(d_model=512, n...\n",
       "1641     [class VGG16(nn.Module):\\r\\n    def __init__(s...\n",
       "1642     [IN, (A, B, C, D), IDX, [A, B, C], torch.long,...\n",
       "1643     [    self.encoder = MySequential(\\r\\n        *...\n",
       "1644     [(conv0_0): VGGBlock(\\r\\n(vgg): Sequential(\\r\\...\n",
       "1645     [# Import our model\\r\\nfrom model import MVP, ...\n",
       "1646     [# import some common detectron2 utilities\\r\\n...\n",
       "1647     [pip3 install torch torchvision torchaudio --e...\n",
       "1649     [#!/usr/bin/env python3\\r\\nimport h5py\\r\\nimpo...\n",
       "1650     [image = torch.tensor([[6, 9], [8.7, 5.5]])\\r\\...\n",
       "1651     [BatchNorm2d, Sigmoid, Sigmoid, BatchNorm2D, C...\n",
       "1652     [    class linearRegression(torch.nn.Module):\\...\n",
       "1653     [from glob import glob\\r\\nimport sys\\r\\nimport...\n",
       "1654     [conda uninstall pytorch\\r\\npip uninstall torc...\n",
       "1656     [## it initially trains itself here with rando...\n",
       "1657     [list, volumes,     for volume in range(len(vo...\n",
       "1658     [list, volumes,     for volume in range(len(vo...\n",
       "1659     [for name, weight in model.named_parameters(\\r...\n",
       "1660     [UserWarning: Using a target size (torch.Size(...\n",
       "1663                                [__len__, __getitem__]\n",
       "1664     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nn...\n",
       "1665     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nn...\n",
       "1666     [tensor([[0.8762]], grad_fn=&lt;SigmoidBackwar...\n",
       "1668     [def box_builder(self) -&gt; None:\\r\\n \\r\\n   ...\n",
       "1669     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "1670     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "1671     [dataset = Word2VecNegativeSampling(data, num_...\n",
       "1672     [model.load_state_dict(checkpoint['state_dict'...\n",
       "1674     [\\r\\nclass NeuralNet(nn.Module):\\r\\n    def __...\n",
       "1675     [real_samples = next(iter(train_loader))\\r\\nfo...\n",
       "1676     [real_samples = next(iter(train_loader))\\r\\nfo...\n",
       "1677     [from torch import nn\\r\\nhidden = 128\\r\\ndef m...\n",
       "1678     [def forward_features(self, x):\\r\\n    x = sel...\n",
       "1679     [edge_index = tensor([[   0,    0,    0,  ...,...\n",
       "1681     [for step, data in enumerate(dataloader, 0):\\r...\n",
       "1682     [A, B, (M,d), (N,d), D[i,j] = torch.sum((A[i] ...\n",
       "1683     [model = Discriminator()\\r\\nbatch_size = 32\\r\\...\n",
       "1684     [import gym\\r\\nfrom gym import Env\\r\\nimport m...\n",
       "1685     [import torch\\r\\nfrom glob import glob\\r\\nfrom...\n",
       "1686     [class module(nn.Module):\\r\\n        def __ini...\n",
       "1687     [from transformers import AutoTokenizer, AutoM...\n",
       "1688     [X = torch.tensor([1,2,3,4], dtype = torch.flo...\n",
       "1689     [X = torch.tensor([1,2,3,4], dtype = torch.flo...\n",
       "1690     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1691     [P, (B, N, d), Q, (B,N), Q, d, P, 0, Q, P = to...\n",
       "1692     [VGG.eval()\\r\\ntorch.save(VGG, 'torchmodel.pth...\n",
       "1693     [Input -&gt; Encoder -&gt; Output, patch-input...\n",
       "1695     [def forward(self, input_sinogram, sos):\\r\\n  ...\n",
       "1696     [import cv2 \\r\\nimport matplotlib.pyplot as pl...\n",
       "1697     [from flask import Flask, request\\r\\nimport to...\n",
       "1698     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\ni...\n",
       "1699     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1700     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1701     [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "1702     [base_cnn = resnet.ResNet50(\\r\\n    weights=\"i...\n",
       "1703     [from transformers import BlenderbotTokenizer,...\n",
       "1704     [models/BERT-pretrain-1-step-5000.pkl, [TRA], ...\n",
       "1705     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "1706                                        [--dependency]\n",
       "1707     [version.parse(importlib_metadata.version(\"tor...\n",
       "1708     [def text_recoginition(model_path):\\r\\n  conve...\n",
       "1710     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "1711     [(112,112), **Code**\\r\\nimport torch\\r\\nimport...\n",
       "1712     [tensor(319845)\\r\\ntensor(0, device='mps:0')\\r...\n",
       "1714     [# 24, 32, 2\\r\\nclass DQN(torch.nn.Module):\\r\\...\n",
       "1715     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "1716     [import torch\\r\\nimport cv2\\r\\nimport time\\r\\n...\n",
       "1717     [Epoch 0 training...\\r\\n^M  0%|          | 0/1...\n",
       "1718     [block = []\\r\\nfor x in range(0, 224,16):\\r\\n ...\n",
       "1719     [build_dir = \"./\"\\r\\n\\r\\nbase_file_name = \"my_...\n",
       "1720     [import torch\\r\\nimport torchvision as tv\\r\\ni...\n",
       "1721     [FROM pytorch/torchserve:latest\\r\\n\\r\\nCOPY [\"...\n",
       "1722     [0, n-1, n-1, 0, n-1, n = 3\\r\\na = torch.Tenso...\n",
       "1723     [0, n-1, n-1, 0, n-1, n = 3\\r\\na = torch.Tenso...\n",
       "1724     [0, n-1, n-1, 0, n-1, n = 3\\r\\na = torch.Tenso...\n",
       "1725     [data.Dataset, class MeditationsDataset(torch....\n",
       "1726     [c = nn.Conv2d(1, 1, (2, 1), stride=1)\\r\\nx = ...\n",
       "1728     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1729     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "1730     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "1731     [     class Middle_RN50(torch.nn.Module):\\r\\n ...\n",
       "1732     [class Text_Encoder(TextPrep, BaseEstimator):\\...\n",
       "1733     [idx = torch.tensor([[0, 1, 2], [1, 2, 3], [3,...\n",
       "1734     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "1735     [class AdaFDNN(nn.Module):\\r\\ndef __init__(sel...\n",
       "1736     [logits = einsum('b x y d, r d -&gt; b x y r',...\n",
       "1737                                         [backwards()]\n",
       "1738     [tens = torch.tensor(range(64))\\r\\ntens = tens...\n",
       "1739     [#Pytorch\\r\\n\\r\\nclass AdjMSELoss1(nn.Module):...\n",
       "1740     [df_train.head():\\r\\n  country            leag...\n",
       "1741     [huggingface, microsoft/layoutlmv2-base-uncase...\n",
       "1742     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "1743     [unsupported operand type(s) for *: 'float'., ...\n",
       "1744     [seed = 42\\r\\nimport random \\r\\nimport os\\r\\ni...\n",
       "1745     [t = [[1, 2, 3, 4], \\r\\n     [5, 6, 7, 8]]\\r\\n...\n",
       "1746     [5, dense_volume1, 4, coord, for coord in coor...\n",
       "1748     [def train_epoch(\\r\\n  model,\\r\\n  data_loader...\n",
       "1749     [ def forward(self, data):\\r\\n    torch.autogr...\n",
       "1750     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "1751     [class BERTClassification(nn.Module):\\r\\n    d...\n",
       "1752     [import os\\r\\nimport pandas as pd\\r\\nfrom torc...\n",
       "1755     [a = torch.rand((5, 3, 500, 500))\\r\\nb = torch...\n",
       "1756     [&gt; Tensor empty(\\r\\n&gt;     IntArrayRef si...\n",
       "1757     [Loading codes from /content/TransCoder/data/B...\n",
       "1758     [torch.use_deterministic_algorithms(True)\\r\\nt...\n",
       "1759     [\\r\\n# Encoder Utilities\\r\\n\\r\\ndef conv2d_blo...\n",
       "1761     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1763     [def extract(a, t, x_shape):\\r\\n    batch_size...\n",
       "1764     [torch.gather, a = torch.tensor([[4,5,6],[7,8,...\n",
       "1765     [def train_graph_classifier(model_name, **mode...\n",
       "1767     [for quantized_layer, _ in fused_model.named_m...\n",
       "1769     [torch.distribution.Distribution, import torch...\n",
       "1770     [torch.distribution.Distribution, import torch...\n",
       "1771     [from torch import nn\\r\\nlayer1 = nn.Linear(in...\n",
       "1773     [class Trainer():\\r\\n  \\r\\n    def __init__(se...\n",
       "1774     [model = torch.nn.Sequential(\\r\\ntorch.nn.Conv...\n",
       "1775     [net = resnet18(pretrained=True)\\r\\nnet.fc = n...\n",
       "1776     [net = resnet18(pretrained=True)\\r\\nnet.fc = n...\n",
       "1777     [\\r\\n*Traceback (most recent call last):\\r\\n  ...\n",
       "1779     [torch.save(model_ft.state_dict(),'/content/dr...\n",
       "1780     [pytorch_model_summary, class unet_like(nn.Mod...\n",
       "1781     [def residual_block(inputs, filters, kernel_si...\n",
       "1783     [MechClassifier, class MechClassifier(pl.Light...\n",
       "1784     [Pytorch, tensor, OR,  import torch\\r\\n\\r\\n my...\n",
       "1785     [tf.stop_gradient(), torch.no_grad(), model.ev...\n",
       "1786     [torchvision.transforms, TypeError: Input imag...\n",
       "1787     [self._epoch = checkpoint['meta']['epoch']\\r\\n...\n",
       "1788     [nflows, p_1, p_2, transform_1 = CompositeTran...\n",
       "1789     [pip install -r requirements.txt, Getting requ...\n",
       "1791     [source = open('./train_de.de', encoding='utf-...\n",
       "1792     [import torch\\r\\nfrom torch.nn import Paramete...\n",
       "1793     [l = torch.tensor([0, 1, 1, 1], requires_grad=...\n",
       "1794     [torch.onnx.export(model,               # mode...\n",
       "1795     [nn.Module, class Conv2dBlock(torch.nn.Module)...\n",
       "1796     [B=10\\r\\nL=20\\r\\nH=5\\r\\n\\r\\nmat_A=torch.randn(...\n",
       "1797     [b, c, h, w = img_lq.size()\\r\\n\\r\\nE = torch.z...\n",
       "1798     [def train_model(model, criterion, optimizer, ...\n",
       "1799     [def train_model(model, criterion, optimizer, ...\n",
       "1800     [[ip0_0, ip1_0,...,ip4_0], [ip0_1, ip1_1,...,i...\n",
       "1801                                        [[1,N], [N,N]]\n",
       "1803     [def __init__(self,root,root_1,transform,col_l...\n",
       "1804     [tensor_img = torch.where(torch.Tensor(250,250...\n",
       "1805     [    with SummaryWriter(tb_dir) as writer, ope...\n",
       "1806     [fairseq, --ddp-backend, fairseq-train, --ddp-...\n",
       "1808     [X.iloc[0:10, ]\\r\\n0    [[-0.51389, -0.55286, ...\n",
       "1809     [import numpy as np\\r\\nfrom transformers impor...\n",
       "1810     [0, the number of rows - 1, [[1,4],[1,3],[1,2]...\n",
       "1811     [0, the number of rows - 1, [[1,4],[1,3],[1,2]...\n",
       "1812     [image = cv2.imread('image.png')\\r\\n\\r\\naugmen...\n",
       "1813     [class ContrastiveTransformations:\\r\\n  def __...\n",
       "1814     [self.params = list(self.backbone.parameters()...\n",
       "1815     [  if freeze_bert == 'True':\\r\\n        for pa...\n",
       "1816     [np.array([0,0,0,1,1,1,0,0,1,1,0]), [9, 3.5, 7...\n",
       "1817     [nn.linear, nn.LSTMCell, AttributeError: 'tupl...\n",
       "1818     [nn.linear, nn.LSTMCell, AttributeError: 'tupl...\n",
       "1819     [nvidia-smi, mean_discriminator_loss += disc_l...\n",
       "1820     [from torch.utils.tensorboard import SummaryWr...\n",
       "1821       [PyTorch, [24, 512, 768, 1], [24, 512, 14, 14]]\n",
       "1822     [I am getting 'generator' object is not callab...\n",
       "1823     [!wget http://images.cocodataset.org/val2017/0...\n",
       "1824     [e = shap.DeepExplainer(model.double().to('cud...\n",
       "1825     [e = shap.DeepExplainer(\\r\\n        model.to('...\n",
       "1826     [self.W_ch1 = nn.Parameter(\\r\\n            tor...\n",
       "1827     [    All_Y =[]\\r\\n    for Y,z_r in zip(train_y...\n",
       "1828     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "1829     [w = [w1, w2, w3, ...., wn], import torch \\r\\n...\n",
       "1830     [def network_stat(A):\\r\\n  n = A.shape[0]\\r\\n ...\n",
       "1831     [training_args = TrainingArguments(\\r\\n    out...\n",
       "1832     [count = torch.tensor([5, 3], dtype = torch.lo...\n",
       "1833     [sample = torch.Tensor([\\r\\n                  ...\n",
       "1835     [# load all images in a directory into memory\\...\n",
       "1836     [class model(nn.Module):\\r\\n  def __init__(sel...\n",
       "1837     [A = tensor([\\r\\n            [0, 0],\\r\\n      ...\n",
       "1838     [[1, 0, 0, 1], [19000, 65000, 38000, 105000], ...\n",
       "1839     [training_args = TrainingArguments(\\r\\n    out...\n",
       "1840     [RuntimeError: Boolean value of Tensor with mo...\n",
       "1841     [mse_loss = torch.nn.MSELoss()\\r\\n...\\r\\nloss1...\n",
       "1842     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1843     [class pinn(nn.Module):\\r\\n\\r\\ndef __init__(se...\n",
       "1844     [torch.nn.init.kaiming_uniform_, nn.Transforme...\n",
       "1845     [class Model(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "1846     [a = [\\r\\n    [[3, 8, 6, 8, 7],\\r\\n    [9, 7, ...\n",
       "1847     [a = [\\r\\n    [[3, 8, 6, 8, 7],\\r\\n    [9, 7, ...\n",
       "1848     [a = [\\r\\n    [[3, 8, 6, 8, 7],\\r\\n    [9, 7, ...\n",
       "1849     [model = torchvision.models.detection.fasterrc...\n",
       "1851     [ PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\\r...\n",
       "1852     [f1, f2, w.r.t, g, obs_ch1, obs_ch23 = self.in...\n",
       "1853     [with torch.no_grad():\\r\\n            _, polic...\n",
       "1854     [transforms.Resize, import numpy as np\\r\\nimpo...\n",
       "1855     [val = torch.tensor([[1,233],\\r\\n             ...\n",
       "1857     [def tracker_video_visualizer(detector,video_p...\n",
       "1858     [val, (b,n), ind, (b,m), n&gt;m, val, ind, val...\n",
       "1859     [import numpy as np\\r\\nfrom numba import jit\\r...\n",
       "1860     [import torch\\r\\nfrom torch_geometric.datasets...\n",
       "1861     [\\r\\n# initialise network weights\\r\\nW1 = torc...\n",
       "1863     [tokenizer = T5Tokenizer.from_pretrained(\"t5-b...\n",
       "1864     [import coremltools as coremltools\\r\\nimport n...\n",
       "1866     [(b,c,h,w), x, y, (h,w), I=sqrt(|x_amplitude|^...\n",
       "1867     [data = {'Actors': [\"Brad Pitt\", \"Leonardo Di ...\n",
       "1868     [RC_train_config = config.init_dataset_config(...\n",
       "1869     [from transformers import Trainer, TrainingArg...\n",
       "1870     [tf.keras, model = Sequential([\\r\\n    Dense(5...\n",
       "1872     [loader_transform = transforms.Compose([\\r\\ntr...\n",
       "1873     [from torch.nn.modules.loss import BCELoss\\r\\n...\n",
       "1875     [from datasets import load_dataset; load_datas...\n",
       "1876     [File \"DATA\\instance-mask-r-cnn-torch\\venv\\lib...\n",
       "1877     [    test_transforms = transforms.Compose(\\r\\n...\n",
       "1878     [class TrainingParams:\\r\\n    def __init__(sel...\n",
       "1879     [def js(list1, list2):\\r\\n    intersection = l...\n",
       "1880     [model = FCN(1,1,50,4)\\r\\noptimizer = torch.op...\n",
       "1881     [model = FCN(1,1,50,4)\\r\\noptimizer = torch.op...\n",
       "1882     [max_position_embeddings, max_position_embeddi...\n",
       "1883     [x = T.tensor([[0, 3, 0, 5, 9, 8, 2, 0], \\r\\n ...\n",
       "1884     [import numpy as np\\r\\nimport torch\\r\\nfrom PI...\n",
       "1885     [import numpy as np\\r\\nimport torch\\r\\nfrom PI...\n",
       "1886     [14 x 10 x 128, 14, batch_size, 10, sequence_l...\n",
       "1887     [14 x 10 x 128, 14, batch_size, 10, sequence_l...\n",
       "1888     [14 x 10 x 128, 14, batch_size, 10, sequence_l...\n",
       "1890     [14 x 10 x 128 x 128, 14, batch_size, 10, sequ...\n",
       "1891     [include_guard(GLOBAL)\\r\\n\\r\\nset(target_name ...\n",
       "1892     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "1893     [y_pred = model(X_test)\\r\\nprint (y_pred.shape...\n",
       "1894     [import torch\\r\\nfrom timm.models import creat...\n",
       "1895     [__getitem__, def __getitem__(self, index):\\r\\...\n",
       "1896     [ tokens = tf.keras.layers.Input(shape=(MAX_LE...\n",
       "1897     [pytorch, images_batch = torch.from_numpy(np.a...\n",
       "1899     [import torch\\r\\nx = torch.randn(3)\\r\\ny = x +...\n",
       "1900     [threshold_acc, threshold_acc, +-, import nump...\n",
       "1901     [    @staticmethod\\r\\ndef save_cp(epoch, model...\n",
       "1902     [def train_model(model, criterion, optimizer, ...\n",
       "1903     [filename,width,height,class,xmin,ymin,xmax,ym...\n",
       "1904     [ValueError                                Tra...\n",
       "1905     [__call__, Module, torch.nn, __call__, class M...\n",
       "1906     [gen_model = Generator().to(device, non_blocki...\n",
       "1907     [def create_mobilevit(num_classes=2):\\r\\ninput...\n",
       "1908     [a, b, a = torch.LongTensor([[0,1], [0,2], [1,...\n",
       "1909     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1910     [mxm, numpy, x = torch.randn((9052, 512))\\r\\ns...\n",
       "1911     [from datasets import load_dataset\\r\\nimport t...\n",
       "1912     [File \"/usr/local/lib/python3.7/dist-packages/...\n",
       "1913     [class OPT:\\r\\n    def __init__(self, model_na...\n",
       "1914     [class OPT:\\r\\n    def __init__(self, model_na...\n",
       "1916     [tensor([[[[164, 164, 164,  ..., 178, 178, 178...\n",
       "1917     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1918     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1919     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1920     [from transformers import BertForMaskedLM\\r\\n\\...\n",
       "1921     [    -----------------------------------------...\n",
       "1922     [model = model.cuda()\\r\\ndummy_input = torch.r...\n",
       "1923     [pytorch-geometric, pytorch-scatter, pytorch-s...\n",
       "1924     [fastapi==0.78.0\\r\\ngunicorn==20.1.0\\r\\nnumpy=...\n",
       "1926     [f, x(k+1)=x(k)-α▽f(x), α=0.1, f, f(x) = 2*(x^...\n",
       "1927     [ File \"c:\\Users\\david\\Desktop\\cs_agent\\main.p...\n",
       "1928     [class LSTM(nn.Module):\\r\\ndef __init__(self, ...\n",
       "1929     [a = torch.arange(10, dtype = float, requires_...\n",
       "1930     [import torch\\r\\nfrom facenet_pytorch import I...\n",
       "1931     [  class_weights = [5,1,1] \\r\\n\\r\\n  sample_we...\n",
       "1932     [data = pd.read_csv(\"/content/Star3642_balance...\n",
       "1933     [class ConvolutionEncoder(nn.Module):\\r\\n    d...\n",
       "1934     [class Trainer(skorch.NeuralNet):\\r\\n     \"\"\"\\...\n",
       "1935     [Traceback (most recent call last):\\r\\n  File ...\n",
       "1936     [    model_name_or_path = \"HooshvareLab/bert-f...\n",
       "1937     [    from transformers import AutoConfig, Auto...\n",
       "1938     [checkpoint = {\\r\\n        'epoch': epoch + 1,...\n",
       "1939     [model = torchvision.models.detection.fasterrc...\n",
       "1940     [\\r\\n    import numpy as np\\r\\n    from scipy ...\n",
       "1941     [model configuration:\\r\\n\\r\\ndnn(\\r\\n  (encode...\n",
       "1942     [dataset.py, MyData, torch.utils.data.Dataset,...\n",
       "1943     [!python detect.py --weights custom_weights.pt...\n",
       "1944     [import os\\r\\nimport numpy as np\\r\\nimport pan...\n",
       "1945     [set CUDA_VISIBLE_DEVICES '',  import torch\\r\\...\n",
       "1946     [FutureWarning: Passing a set as an indexer is...\n",
       "1947     [torch.mean(a, dim=0) # size is 10x1 and shoul...\n",
       "1948     [def test_pool():\\r\\n    a = np.fromfile(\"in.b...\n",
       "1949     [dataset[i][j], train_dataset = [dataset[i][j]...\n",
       "1950     [nvcc --version, nvcc: NVIDIA (R) Cuda compile...\n",
       "1951     [import os.path\\r\\nimport random\\r\\nimport num...\n",
       "1952     [train_tfms = transforms.Compose([transforms.R...\n",
       "1953     [class MarginRankingLossExp(nn.Module):\\r\\n   ...\n",
       "1954     [torch.narrow(), start, start_indices = [3, 1,...\n",
       "1955     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "1956     [edge_origins = np.array([[0,1,2,3,4],[6,7,8]]...\n",
       "1957     [class NeuralNet(nn.Module):\\r\\n\\r\\n    def __...\n",
       "1958     [from tensorflow.keras.layers import Conv1D, L...\n",
       "1959     [import torch\\r\\nfrom torch_geometric.datasets...\n",
       "1961     [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "1962     [/usr/local/lib/python3.7/dist-packages/torch/...\n",
       "1963     [!python /content/drive/Othercomputers/My\\ Lap...\n",
       "1964     [class BERTClass(torch.nn.Module):\\r\\n    def ...\n",
       "1965     [class BERTClass(torch.nn.Module):\\r\\n    def ...\n",
       "1966     [B =  Tensor([[[1, 2, 3],\\r\\n                 ...\n",
       "1968     [ fa = face_alignment.FaceAlignment(face_align...\n",
       "1969     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "1970     [self(x), loss = -torch.mean(self(x)*y)\\r\\n, s...\n",
       "1972     [\\r\\nclass MyModel(Model):\\r\\n  def __init__(s...\n",
       "1973     [\\r\\nclass MyModel(Model):\\r\\n  def __init__(s...\n",
       "1974     [  0%|          | 0/2 [00:00&lt;?, ?it/s]\\r\\n ...\n",
       "1976     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1977     [    # Hyperparameters\\r\\nrandom_seed = 123\\r\\...\n",
       "1978     [RuntimeError: Given groups=1, weight of size ...\n",
       "1979     [## Package\\r\\n# PyTorch\\r\\nimport torch\\r\\nim...\n",
       "1980     [def box_label(self, box, label='', color=(128...\n",
       "1981     [ val_loaders = []\\r\\n    for nuisance in val_...\n",
       "1982     [class NeuralNetwork(nn.Module):\\r\\n    def __...\n",
       "1983     [class NeuralNetwork(nn.Module):\\r\\n    def __...\n",
       "1984     [$$predicted\\_center * center_variance = \\frac...\n",
       "1985     [import torch\\r\\nimport torchvision\\r\\nfrom co...\n",
       "1986     [t1, t2, b, c,h,w, b,c,h,w, t1[i], t2[j], i, j...\n",
       "1987     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1988     [#defining the loss,optimizer and training fun...\n",
       "1989     [def model(input_shape):\\r\\n    input_layer = ...\n",
       "1990     [def model(input_shape):\\r\\n    input_layer = ...\n",
       "1991     [branch1 = register_module(\"branch1\", torch::n...\n",
       "1992     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1993     [torchinfo, BertClassifier, class BertClassifi...\n",
       "1994     [   inps = torch.FloatTensor(data[0])\\r\\n   tg...\n",
       "1995     [   inps = torch.FloatTensor(data[0])\\r\\n   tg...\n",
       "1997     [import torch\\r\\nimport matplotlib.pyplot as p...\n",
       "1998     [ Traceback (most recent call last):\\r\\nFile \"...\n",
       "1999     [import cv2\\r\\n\\r\\ncap = cv2.VideoCapture(\"vid...\n",
       "2000     [! git clone https://github.com/deshwalmahesh/...\n",
       "2001     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "2002     [Automatic, GradScaler, GradScaler, scaler = t...\n",
       "2003     [import torch\\r\\ndef normalize(x, x_min, x_max...\n",
       "2004                                    [U, (B, I), p%, B]\n",
       "2005     [CMakeLists.txt, cmake_minimum_required(VERSIO...\n",
       "2006     [CMakeLists.txt, cmake_minimum_required(VERSIO...\n",
       "2009     [(1,1,3), xodd, (1,1,2), (112, 1, 1), from tor...\n",
       "2010     [#include &lt;torch/nn/options/fold.h&gt;\\r\\n\\...\n",
       "2011     [save_plots, psutil.virtual_memory(), import t...\n",
       "2012     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "2014     [nn.lstm, nn.LSTM(input_size, hidden_size, dro...\n",
       "2015     [def forward(self, x, y, hidden):\\r\\n    c_0 =...\n",
       "2016     [\\r\\nself._target(*self._args, **self._kwargs)...\n",
       "2017     [RuntimeError: Given groups=1, weight of size ...\n",
       "2018     [input_dim = len(tok2indx)   # size of the voc...\n",
       "2019     [class SentenceBertParallel(nn.Module):\\r\\n   ...\n",
       "2020     [# pytorch framework\\r\\nmsxpsnr = 0\\r\\nfor epo...\n",
       "2021                                  [fairseq-preprocess]\n",
       "2022     [Data, SeqData, from torch_geometric.data impo...\n",
       "2023     [class LSTMmodel(nn.Module):\\r\\n  \\r\\n    def ...\n",
       "2024     [array = np.zeros((10, 8, 3), dtype=np.float32...\n",
       "2025     [MyData, for i in range(100):\\r\\n    exec(\"dat...\n",
       "2026     [# model\\r\\nclass CNNCifar(nn.Module):\\r\\n    ...\n",
       "2027     [BCEWithLogitsLoss, lambda, pytorch, import to...\n",
       "2028     [BCEWithLogitsLoss, lambda, pytorch, import to...\n",
       "2029     [BCEWithLogitsLoss, lambda, pytorch, import to...\n",
       "2030     [       'lrs':lrs}\\r\\n\\r\\nprint('Total time: {...\n",
       "2031     [pip install torchdyn\\r\\n, ERROR: Ignored the ...\n",
       "2032                           [!pip install package-name]\n",
       "2033                           [!pip install package-name]\n",
       "2034                           [!pip install package-name]\n",
       "2035     [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "2036     [pip, pip3 install --pre torch torchvision tor...\n",
       "2037     [(init)\\r\\nlr = 0.0001\\r\\nweight_decay = 0.000...\n",
       "2038     [class Network(nn.Module):\\r\\n, nn.Module, sup...\n",
       "2039     [def train_model(model, criterion, optimizer, ...\n",
       "2040     [import torch\\r\\n\\r\\nX = torch.tensor([1, 2, 3...\n",
       "2042     [class MCC(object):\\r\\n    \\r\\n    def __init_...\n",
       "2043     [probs = policy_network(state)\\r\\nm = Categori...\n",
       "2044     [CNN, QTrainer, class CNN(nn.Module):\\r\\n    d...\n",
       "2045     [\\r\\n\\r\\nclass Net(pl.LightningModule):\\r\\n   ...\n",
       "2046     [train_dataloader = torch.utils.data.DataLoade...\n",
       "2047     [import torchtext\\r\\n\\r\\nagnews_train, agnews_...\n",
       "2048     [StackedResidualLSTM(\\r\\n  (encoder): Recurren...\n",
       "2049     [def get_mean_std(loader,ignore_idx=-1.):\\r\\n ...\n",
       "2050     [transform = transforms.Compose(\\r\\n        [\\...\n",
       "2051     [pip install transformers[torch]\\r\\nfrom trans...\n",
       "2052     [input1 = [\\r\\n[[1, 1, 1], [2, 2, 2], [3, 3, 3...\n",
       "2053     [model.compile, model.fit, nn.CrossEntropyLoss...\n",
       "2054     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2055     [(batch_size, feature_size), prototype, size =...\n",
       "2056     [name: torch\\r\\nchannels:\\r\\n  - defaults\\r\\n ...\n",
       "2057     [name: torch\\r\\nchannels:\\r\\n  - defaults\\r\\n ...\n",
       "2058     [[MASK][MASK][specific_token][MASK][MASK][spec...\n",
       "2059     [import torch\\r\\nfrom torch.multiprocessing im...\n",
       "2061     [groupsize = 4\\r\\ntotalgroups = 3\\r\\npartialsu...\n",
       "2062     [class Generator(nn.Module):\\r\\n    \"\"\"\\r\\n   ...\n",
       "2063                    [pytorch=10.1.2, cudatoolkit=10.1]\n",
       "2064     [import torch\\r\\nfrom torchmetrics import Prec...\n",
       "2065     [**class Attention(nn.Module):\\r\\n    def __in...\n",
       "2068     [running_loss = 0.0\\r\\nfor i, data in enumerat...\n",
       "2069     [running_loss = 0.0\\r\\nfor i, data in enumerat...\n",
       "2070     [  data_transform = {\\r\\n        \"train\": tran...\n",
       "2071     [LSTMCell, cellgate, ingate, forgetgate, outga...\n",
       "2072     [import torch\\r\\nfrom facenet_pytorch import I...\n",
       "2073     [import torch\\r\\nfrom facenet_pytorch import I...\n",
       "2074     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "2075     [A = torch.tensor([0.0316, 0.2338, 0.2338, 0.2...\n",
       "2076     [A = torch.tensor([0.0316, 0.2338, 0.2338, 0.2...\n",
       "2077     [A = torch.tensor([0.0316, 0.2338, 0.2338, 0.2...\n",
       "2079     [wsl --update, python -m torch.utils.bottlenec...\n",
       "2080     [def main(): \\r\\nargs = parser.parse_args()\\r\\...\n",
       "2081     [import torch\\r\\n\\r\\nfor object_id in object_i...\n",
       "2083     [{'0': [[307.6858215332031,\\r\\n   111.24893188...\n",
       "2084     [# Random data-\\r\\nx = torch.rand((10, 20))\\r\\...\n",
       "2085     [clip(x*255+0.5, 0, 255).as(uint8), from colle...\n",
       "2087     [def read_h5(path):\\r\\n    data = h5py.File(pa...\n",
       "2088     [(20, 14, 64, 64), (20, 64, 64, 64), 20, 14, 6...\n",
       "2089     [idx_test, rand_test = torch.randint(3, 10, (4...\n",
       "2090     [    review                                   ...\n",
       "2091     [train_dataloader = DataLoader(\\r\\n        dat...\n",
       "2092     [net = Net(num_classes=7)\\r\\nnet.to(device)\\r\\...\n",
       "2093     [python 3.8.10\\r\\n\\r\\ntorch                1.1...\n",
       "2094     [    for batch, (X, y) in enumerate(dataloader...\n",
       "2096     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "2097     [class ClassifierSiameseLSTM(nn.Module):\\r\\n  ...\n",
       "2098     [import torch\\r\\nfrom transformers import Robe...\n",
       "2099     [my_tensors = [tensor([496, 496, 212, 496, 496...\n",
       "2100     [CUDA kernel errors might be asynchronously re...\n",
       "2102     [sgd, adam, LBFGS, for batch_idx, (inputs, tar...\n",
       "2103     [class SentimentClassifier2(nn.Module):\\r\\n\\r\\...\n",
       "2104     [| NVIDIA-SMI 4--.--.--    Driver Version: 465...\n",
       "2105     [---------------------------------------------...\n",
       "2106     [Image.MAX_IMAGE_PIXELS = None\\r\\n        a = ...\n",
       "2107     [defaultdict(list,\\r\\n            {'train_acc'...\n",
       "2108     [/usr/lib/python3.7/inspect.py in _signature_f...\n",
       "2109     [bert_model = BertModel.from_pretrained(MODEL_...\n",
       "2110     [def train_step(self, state, action, reward, n...\n",
       "2111     [class PatternModel(pl.LightningModule):\\r\\n\\r...\n",
       "2112     [outmap, outmap_min = torch.min(outmap, dim=1,...\n",
       "2113     [[\"je\",\"mange\", \"la\", \"pomme\",\"avec\"] \\r\\n,  [...\n",
       "2114     [[6,7], torch.Size([1, 1, 6, 7]), train_step, ...\n",
       "2115     [class TransferLearning(pl.LightningModule):\\r...\n",
       "2116     [class TransferLearning(pl.LightningModule):\\r...\n",
       "2117     [class TransferLearning(pl.LightningModule):\\r...\n",
       "2118     [class OurDataset(Dataset):\\r\\nspectra_dir = f...\n",
       "2119     [alpha, alpha (float, optional) – smoothing co...\n",
       "2120     [#!pip install -Uqq fastai\\r\\nfrom fastai.visi...\n",
       "2121     [model = torchvision.models.detection.fasterrc...\n",
       "2122     [model = model.to(device), Traceback (most rec...\n",
       "2123     [RuntimeError: CUDA out of memory., nvidia-smi...\n",
       "2124     [torch.nn.utils.spectral_norm, SeparableConv2d...\n",
       "2125     [t = [1, 2, 3, 4, 5, 6, 7, 8, 9], d = [0, 2, 5...\n",
       "2126     [ pip3 install torch torchvision torchaudio --...\n",
       "2127     [BATCH_SIZE = 16\\r\\nEPOCHS = 10\\r\\n\\r\\nclass C...\n",
       "2128     [batch_output0,batch_output1 = get_output_from...\n",
       "2129     [torch.Tensor.index_copy, A, [10, 20, 30], B, ...\n",
       "2130     [CUDA 11.7 nightly, CUDA 11.6 nightly, 11.3, t...\n",
       "2131     [CUDA 11.7 nightly, CUDA 11.6 nightly, 11.3, t...\n",
       "2132     [edge_index, (2, N), (x, y), (y, x), x, y, n1 ...\n",
       "2133     [#Learner\\r\\nlearn = model_type.fastai.learner...\n",
       "2134     [python\\r\\nimport torch\\r\\nX=torch.rand(10,9) ...\n",
       "2135     [\\r\\n&gt;pip3 freeze\\r\\nanyio @ file:///privat...\n",
       "2136     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "2137     [from transformers import RobertaTokenizer\\r\\n...\n",
       "2138     [torch.nn.Linear(\\r\\n    in_features=num_input...\n",
       "2139     [torch.nn.Linear(\\r\\n    in_features=num_input...\n",
       "2140     [class first(nn.Module):\\r\\n    def __init__(s...\n",
       "2141     [def train():\\r\\nmodel.train()\\r\\n\\r\\nloss_all...\n",
       "2143     [y.backward(), z.backward(), y.backward(), z.b...\n",
       "2144     [from torchvision import models    \\r\\nfrom to...\n",
       "2145     [from torchvision import models    \\r\\nfrom to...\n",
       "2146     [#%%\\r\\nlstm1 = LSTM1(num_classes, input_size,...\n",
       "2147     [conda create -n torch-nightly python=3.8 \\r\\n...\n",
       "2148     [conda create -n torch-nightly python=3.8 \\r\\n...\n",
       "2149     [resnet18, model.eval(), model.eval(), from pl...\n",
       "2150     [plt.imsave(f\"./data/FM_spectra/spectrum_{4}.p...\n",
       "2151     [squad, from datasets import load_dataset\\r\\nf...\n",
       "2152     [for step,batch in enumerate(train_dataloader)...\n",
       "2153     [class Dataset(Dataset):\\r\\n    def __init__(s...\n",
       "2154     [class Dataset(Dataset):\\r\\n    def __init__(s...\n",
       "2155     [model_output.detach().cpu().numpy(), ''' Load...\n",
       "2156     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "2158     [resnet18, from pl_bolts.models.autoencoders.c...\n",
       "2159     [class Block(nn.Module):\\r\\n    def __init__(s...\n",
       "2160     [import torch\\r\\nQ = torch.rand((16,128)).cuda...\n",
       "2161     [N_WAY = 5  \\r\\nN_SHOT = 5  \\r\\nN_QUERY = 10  ...\n",
       "2162     [training_data = datasets.MNIST(\\r\\n    root=\"...\n",
       "2163     [from torchvision import models\\r\\nres101 = mo...\n",
       "2164     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "2165     [seq_ent = torch.cat([torch.index_select(seq_o...\n",
       "2167     [#Parameters for Inception V3\\r\\nnum_classes= ...\n",
       "2168     [import runpy\\r\\n\\r\\nrunpy.run_module('test2',...\n",
       "2169     [epochs=20  # train for this number of epochs\\...\n",
       "2170     [Conv2d, class MyConv2d(nn.Module):\\r\\n    def...\n",
       "2171     [py -3.6 -m venv VEnv36\\r\\n, Cython==0.29\\r\\nm...\n",
       "2172     [Line #    Mem usage    Increment  Occurrences...\n",
       "2173     [tensor([[[104.7500, 111.3750, 138.2500, 144.8...\n",
       "2174     [tensor([[[104.7500, 111.3750, 138.2500, 144.8...\n",
       "2175     [with torch.no_grad():\\r\\n    while True:\\r\\n ...\n",
       "2176     [BATCH_SIZE = 16\\r\\nEPOCHS = 200\\r\\n\\r\\nclass ...\n",
       "2177     [  **class UNet(Module):\\r\\n    def __init__(s...\n",
       "2179     [# Create model\\r\\n\\r\\nclass BiLSTM_CRF(nn.Mod...\n",
       "2180     [7, torchmetrics.Accuracy, (16, 7, 36), (16, 7...\n",
       "2181     [torch, def mlp(sizes, activation, output_acti...\n",
       "2182     [target_dir, epoch=100, batch_size=128, import...\n",
       "2183     [def checkpoint_mem(model_name):\\r\\n    checkp...\n",
       "2184     [test_label = torch.zeros([10,10])\\r\\ntest_lab...\n",
       "2185     [i1, i2,...,ik, a[i1][i2]...[ik] = a[pi(i1)][p...\n",
       "2186     [# V3\\r\\nimport torch\\r\\n\\r\\nlanguage = 'ru'\\r...\n",
       "2187     [tensor([[[[209.5000, 222.7500],\\r\\n          ...\n",
       "2188     [y_predicted = self.net(x)\\r\\nz_predicted = se...\n",
       "2189     [pip install -r requirements.txt, ERROR: No ma...\n",
       "2190     [model.to('cpu')\\r\\nfor (batch_idx, batch) in ...\n",
       "2191     [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "2192     [for b in range(batch_size):\\r\\n    for q in r...\n",
       "2193     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "2194     [def GetModel():   \\r\\n    oModel            =...\n",
       "2195     [sample = next(iter(train_loader)), #Pre-proce...\n",
       "2196     [MyData, MyData_1, MyData_100, import torch\\r\\...\n",
       "2197     [MyData, MyData_1, MyData_100, import torch\\r\\...\n",
       "2198     [class MaskedHuberLoss(torch.autograd.Function...\n",
       "2199     [from __future__ import print_function\\r\\nimpo...\n",
       "2200     [output_text = [\"sentence_1. sentence_2. sente...\n",
       "2201     [---------------------------------------------...\n",
       "2202     [import torch\\r\\nmodel = torch.load('pt/model_...\n",
       "2203     [import torch\\r\\nmodel = torch.load('pt/model_...\n",
       "2204     [.pt, DEFAULT_MODEL_PATH = 'models/artemis/bes...\n",
       "2205     [conda install pytorch ... , (\"Connection brok...\n",
       "2206     [!pip install transformers, import transformer...\n",
       "2207     [import torch\\r\\nfrom torch.autograd import Va...\n",
       "2212     [def sin_data(x, T=100):\\r\\n    return np.sin(...\n",
       "2213     [torch, Python 3.7.12 | packaged by conda-forg...\n",
       "2214     [train_loader = trcdata.DataLoader(train_set, ...\n",
       "2215     [import numpy as np\\r\\nimport json\\r\\nimport t...\n",
       "2216     [from torchvision import transforms\\r\\nimport ...\n",
       "2219     [FROM registry.access.redhat.com/ubi8/python-3...\n",
       "2220     [class DecoderAttn(nn.Module):\\r\\ndef __init__...\n",
       "2221     [training_args = TrainingArguments(output_dir=...\n",
       "2222     [File \"&lt;string&gt;\", line 1, in &lt;module&...\n",
       "2223     [really_simple_func, import torch as t\\r\\nimpo...\n",
       "2224     [really_simple_func, import torch as t\\r\\nimpo...\n",
       "2227     [class CSRA(nn.Module): # one basic block \\r\\n...\n",
       "2229     [class MyDataset(Dataset):\\r\\ndef __init__(sel...\n",
       "2230     [tf.keras.layers.Masking, ...\\r\\ndataset.filln...\n",
       "2231     [  CONDA_SUBDIR=osx-arm64 conda create -n nlp2...\n",
       "2233     [weight1*inputA + weight2*inputB = output, inp...\n",
       "2234     [\\r\\n__CUDA Information__\\r\\nError: CUDA devic...\n",
       "2235     [mean(Q(x)*(log Q(x) - log P(x)))\\r\\n, torch.d...\n",
       "2237     [spike_grad = surrogate.fast_sigmoid(slope=5.4...\n",
       "2238     [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "2239     [from threading import Thread\\r\\nfrom djitello...\n",
       "2240     [numpy==1.18.2\\r\\ntorch==1.4.0\\r\\ntorchvision=...\n",
       "2242     [class BreastCancerCNN(ImageClassificationBase...\n",
       "2243     [torch.load(), [2000, 3, 32, 32], data = torch...\n",
       "2244     [import numpy as np\\r\\nimport torch.nn as nn\\r...\n",
       "2245     [import numpy as np\\r\\nimport torch.nn as nn\\r...\n",
       "2246     [6x7, class CNN(nn.Module):\\r\\n    def __init_...\n",
       "2247     [# muiltiple output in one cell\\r\\nfrom IPytho...\n",
       "2248                             [nOut=image+2p-f / s + 1]\n",
       "2249     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\ni...\n",
       "2250     [#Create model\\r\\nmodel = resnet50(\\r\\n    num...\n",
       "2251     [x, x, x = [1,2,1,2,4,5]\\r\\n, [1,2] = 2\\r\\n[2,...\n",
       "2252     [  File \"/usr/local/lib/python3.7/dist-package...\n",
       "2253     [self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1...\n",
       "2254     [fastai, PyTorch, fastai, keras, .fit, sample_...\n",
       "2256     [import time\\r\\nstart_time = time.time()\\r\\nfo...\n",
       "2258     [def __init__(self,\\r\\n             data: pd.D...\n",
       "2259     [Images_path='E:\\Moving_Train/train/images'\\r\\...\n",
       "2261     [class Buffers:\\r\\ndef __init__(self, buffer_c...\n",
       "2262     [color_map = {\\r\\n'0': [0, 0, 0],             ...\n",
       "2263     [class DataSet(torch.utils.data.Dataset):\\r\\n ...\n",
       "2264     [class DataSet(torch.utils.data.Dataset):\\r\\n ...\n",
       "2265     [from __future__ import print_function\\r\\nimpo...\n",
       "2266     [from torch.nn.functional import normalize\\r\\n...\n",
       "2267     [Input =&gt; [[ 1,2,3],\\r\\n           [ 4,5,6]...\n",
       "2268     [Input =&gt; [[ 1,2,3],\\r\\n           [ 4,5,6]...\n",
       "2269     [Input =&gt; [[ 1,2,3],\\r\\n           [ 4,5,6]...\n",
       "2270     [Input =&gt; [[ 1,2,3],\\r\\n           [ 4,5,6]...\n",
       "2272     [ import torchvision.datasets\\r\\nfrom torch im...\n",
       "2273     [.clone(), torch::serialize::OutputArchive\\r\\n...\n",
       "2274     [RuntimeError: Input type (torch.cuda.FloatTen...\n",
       "2275     [train_data = fits.open('./dataset/solar/solar...\n",
       "2276     [import pandas as pd\\r\\nfrom transformers impo...\n",
       "2277     [find_unused_parameters=True, torch.nn.paralle...\n",
       "2278     [%cd ..\\r\\n#start training\\r\\n#-b batch size (...\n",
       "2279     [def __init__():\\r\\n\\r\\ndef __len__():\\r\\n\\r\\n...\n",
       "2280     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "2281     [x_stats = dec(z).float(), import torch.nn.fun...\n",
       "2282     [x_stats = dec(z).float(), import torch.nn.fun...\n",
       "2283     [255, 1, train_transform = transforms.Compose(...\n",
       "2284     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "2285                     [(3, 1, 1), (4, 1, 0), (4, 1, 0)]\n",
       "2286     [import torch\\r\\n\\r\\nsource = [torch.tensor([1...\n",
       "2287     [a.shape, b.shape\\r\\n# (torch.Size([512, 28, 2...\n",
       "2289                              [[867, 768], [621, 768]]\n",
       "2291     [forward, loss.grad_fn, None, if, else, gt, pr...\n",
       "2292     [forward, loss.grad_fn, None, if, else, gt, pr...\n",
       "2293     [num_classes = 2\\r\\n\\r\\nclass Net(torch.nn.Mod...\n",
       "2294     [File \"/root/anaconda3/envs/final/lib/python3....\n",
       "2296     [pip install pytorch, TORCH_CUDA_ARCH_LIST=8.6...\n",
       "2297     [torch.cuda.Event, pip3 install torch torchvis...\n",
       "2298     [model = dict(\\r\\n    type='EncoderDecoder',\\r...\n",
       "2299     [Traceback (most recent call last):\\r\\nFile \"t...\n",
       "2300     [class MRIDataModule(pl.LightningDataModule):\\...\n",
       "2301     [ class MyNet(nn.Module):\\r\\n    def __init__(...\n",
       "2302     [   [165., 193., 148.],\\r\\n   [166., 193., 149...\n",
       "2303     [   [165., 193., 148.],\\r\\n   [166., 193., 149...\n",
       "2304     [torch.nn.MSELoss, RuntimeError: Boolean value...\n",
       "2305     [MAX_LENGTH = 128\\r\\n\\r\\nfrom transformers imp...\n",
       "2306     [C:\\yolov5&gt;python train.py --img 416 --batc...\n",
       "2307     [None, loss.backward(), import numpy as np\\r\\n...\n",
       "2308     [onnxruntime, onnx-1.11.0, onnxruntime_gpu==1....\n",
       "2309     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "2310     [import sentence_transformers as st\\r\\nencoder...\n",
       "2311     [for step, batch in enumerate(train_dataloader...\n",
       "2312     [tf.Variable, new_parameter, tf.Variable, mode...\n",
       "2315     [# choose the training and test datasets\\r\\ntr...\n",
       "2316     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "2317     [checkpoint_callback = ModelCheckpoint(\\r\\n   ...\n",
       "2318     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2319     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2320     [import torch.nn as nn\\r\\n\\r\\nclass RNN(nn.Mod...\n",
       "2321     [a, torch.Size([64,2]), b, torch.Size([64]), b...\n",
       "2322     [a, torch.Size([64,2]), b, torch.Size([64]), b...\n",
       "2323     [PyTorch, #epochs, for i in range(epochs):\\r\\n...\n",
       "2324     [audio_file = './test.mp3'\\r\\n\\r\\naud = AudioU...\n",
       "2325     [tokenizer = BertTokenizerFast.from_pretrained...\n",
       "2326     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "2327     [transform = transforms.Compose([transforms.PI...\n",
       "2329     [B = 2\\r\\nC = 2\\r\\nH = 2\\r\\nW = 3\\r\\nx = torch...\n",
       "2330     [A, 1, 6, B, 5, 0, (6, batch size, 3, 100, 100...\n",
       "2331     [Tensor, int, float, a.dtype == torch.int or a...\n",
       "2332     [num_classes = 4\\r\\nseq_len = 22 \\r\\nclass Ale...\n",
       "2333     [import torch\\r\\nimport torch.multiprocessing ...\n",
       "2334     [x, (N, kernel_size, kc//kernel_size, t, v), k...\n",
       "2335     [x, (N, kernel_size, kc//kernel_size, t, v), k...\n",
       "2337     [emb, mention, # Inputs:\\r\\nemb = tc.tensor([[...\n",
       "2338     [F.softmax(predict_class, dim=1)\\r\\n, Attribut...\n",
       "2339     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "2340     ['''\\r\\ndef extract_beat(signal, qrs_pos, win_...\n",
       "2341     [criterion, ValueError: Target size (torch.Siz...\n",
       "2342     [AssertionError: Torch not compiled with CUDA ...\n",
       "2343     [class Neural_net(nn.Module):\\r\\n    def __ini...\n",
       "2344     [correct += (out == targets).float().sum() acc...\n",
       "2346     [RuntimeError: Ninja is required to load C++ e...\n",
       "2347     [RuntimeError: Ninja is required to load C++ e...\n",
       "2348     [cublasCreate(handle), class GRU(nn.Module):\\r...\n",
       "2349     [backward(), sparse_grad=True, gather, In [1]:...\n",
       "2350     [            let config = MLModelConfiguration...\n",
       "2351     [ipykernel_18388/119274704.py in v_to_h(self, ...\n",
       "2352     [self.train_dataset, self.val_dataset, self.te...\n",
       "2353     [#!/usr/bin/env python3\\r\\n# coding: utf-8\\r\\n...\n",
       "2354     [import torch.multiprocessing as mp\\r\\nimport ...\n",
       "2355     [x_test,y_test = next(iter(dataloader)))\\r\\ny_...\n",
       "2356     [import torch\\r\\n\\r\\nx1 = torch.tensor([[1.0],...\n",
       "2360     [import torch.nn as nn\\r\\n\\r\\nclass Generator(...\n",
       "2361     [hparams, hparams2, import pytorch_lightning a...\n",
       "2362     [ torch.zeros(*size, *, out=None, dtype=None, ...\n",
       "2364     [    n,p = X_input.shape\\r\\n    n_e, p_e = X_e...\n",
       "2365     [class CassavaDataset(Dataset):\\r\\n    def __i...\n",
       "2366     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "2367     [  I have a resnet18 pretrained model, now I w...\n",
       "2368     [b, N, a, b, N, a, 1, N, N, import torch\\r\\n# ...\n",
       "2369     [torch.cuda.empty_cache(), self.batch_training...\n",
       "2371     [#import torch\\r\\nmodel = torch.load(\"model_pa...\n",
       "2372     [import itertools\\r\\nimport numpy as np\\r\\n\\r\\...\n",
       "2373     [import torch\\r\\nimport torch.multiprocessing ...\n",
       "2374     [traced_model = torch.jit.trace(model, input_t...\n",
       "2375     [class DeepFilteringTransferLearning(pl.Lightn...\n",
       "2376     [from happytransformer import HappyTextToText\\...\n",
       "2377     [import torch\\r\\ndevice = \"cuda\" if torch.cuda...\n",
       "2378     [\\r\\n  def eval_model(model, tokenizer_, X, y,...\n",
       "2381     [    class RankingModel(nn.Module):\\r\\n       ...\n",
       "2382     [import torch\\r\\nimport torch.quantization\\r\\n...\n",
       "2383     [    #!/usr/bin/env python\\r\\n    # -*- coding...\n",
       "2384     [    elif data_augmentation == 'lee2019:\\r\\n  ...\n",
       "2385     [python ./testing/rnn_rgp_test.py\\r\\n, ./RGP/a...\n",
       "2386     [class Model(pl.LightningModule):\\r\\n    def _...\n",
       "2388     [import cv2\\r\\nimport torch\\r\\nfrom PIL import...\n",
       "2389     [import cv2\\r\\nimport torch\\r\\nfrom PIL import...\n",
       "2390     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "2392     [self.fc3 = nn.Linear(256, 4)\\r\\n...\\r\\n# in f...\n",
       "2393     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "2394     [max_length, max_length-2, truncation=True, fr...\n",
       "2395     [max_length, max_length-2, truncation=True, fr...\n",
       "2396     [X, torch.Size([3, 1, 20, 20]), (batch_size x ...\n",
       "2397     [coco_eval = pycocotools.cocoeval.COCOeval(coc...\n",
       "2398     [    import torch\\r\\nfrom torch import nn \\r\\n...\n",
       "2399     [nn.BatchNorm2d, (N, C, H, W), N, C, HxW, x^i_...\n",
       "2400     [import numpy as np\\r\\n\\r\\ndef py_cpu_nms(dets...\n",
       "2401     [from torchvision.utils import make_grid\\r\\n\\r...\n",
       "2402     [In [2]: import torch\\r\\nIn [3]: c1 = torch.nn...\n",
       "2403     [scores, argmax(), from transformers import Au...\n",
       "2404     [loss = loss_fn(y_pred, y_true), loss: Tensor,...\n",
       "2405     [RuntimeError: The size of tensor a (?) must m...\n",
       "2407     [loss = nn.CrossEntropyLoss()\\r\\n\\r\\ninput = t...\n",
       "2408     [array([69487,  5770,  5753,   138,  4308,    ...\n",
       "2409     [activation = {}\\r\\n\\r\\ndef get_activation(nam...\n",
       "2410     [!pip install sentencepiece\\r\\n, class RoBERTa...\n",
       "2411     [text_Dataset, __init__, file_list, class text...\n",
       "2412     [def server_aggregate(global_model, client_mod...\n",
       "2413     [x = np.array([[0,254],[14,77]])\\r\\n x\\r\\narra...\n",
       "2414     [ test_image = test_image_tensor.view(1,3,300,...\n",
       "2415     [import torch\\r\\nfrom unets import Unet, thin_...\n",
       "2416     [def my_func():\\r\\n    exec(\"\"\"def my_collate_...\n",
       "2417     [TEXT = Field(tokenize=None) # already has bee...\n",
       "2418     [import torch\\r\\nimport torchtext\\r\\nfrom torc...\n",
       "2419     [ x_train= torch.from_numpy(x_train_tfr)\\r\\n x...\n",
       "2420     [from pytorch_lightning import Trainer\\r\\nfrom...\n",
       "2421     [=============================================...\n",
       "2422     [class CoordConv(nn.Module):\\r\\n    def __init...\n",
       "2423     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "2424     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2425     [img1 = torch.zeros(3, img_size, img_size)\\r\\n...\n",
       "2426                       [[n1, n2, n3], [n1, n2, n3, 1]]\n",
       "2428     [def log_softmax(pred_tensors):\\r\\n    minus_i...\n",
       "2429     [class LinearRegressionModel(torch.nn.Module):...\n",
       "2430     [OSError: [Errno 30] Read-only file system: '/...\n",
       "2431     [T5, model.generate(input_ids), forward functi...\n",
       "2433     [class CustomModel(nn.Module):\\r\\n  def __init...\n",
       "2434     [Encoder, self.encoder, ComponentEmbedding, Co...\n",
       "2435     [category = set([\"Sweden\", \"Iceland\", \"Germany...\n",
       "2436     [category = set([\"Sweden\", \"Iceland\", \"Germany...\n",
       "2437     [A = torch.tensor([[0,0,1], [0,0,2], [1,0,0], ...\n",
       "2438     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "2439     [error: identifier \"atomicAdd_block\" is undefi...\n",
       "2440     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2441     [data_waveform, rate_of_sample = torchaudio.lo...\n",
       "2442     [x, torch.Size([119, 768, 51])\\r\\n, y, torch.S...\n",
       "2443     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "2444     [torch_model =  Sequential(\\r\\n    Flatten(),\\...\n",
       "2445     [mat1 and mat2 shapes cannot be multiplied (61...\n",
       "2446     [mat1 and mat2 shapes cannot be multiplied (61...\n",
       "2448     [for epoch in range(num_epochs):\\r\\n    for (w...\n",
       "2449     [__init__, forward, def __init__(self, bert_co...\n",
       "2450     [class ParamImportance:\\r\\ndef __init__(self, ...\n",
       "2452     [ValueError: 123061 is not in range, class Dat...\n",
       "2453     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "2454     [a = torch.arange(6).reshape(2,3), b=(torch.ra...\n",
       "2455     [cap  = cv2.VideoCapture(0)\\r\\n\\r\\n# loop thro...\n",
       "2456     [class QuantitySkewLabelsSplitter(NumPyDataSpl...\n",
       "2457     [class PennFudanDataset(torch.utils.data.Datas...\n",
       "2458     [model = torchvision.models.detection.fasterrc...\n",
       "2460     [RuntimeError: Error(s) in loading state_dict ...\n",
       "2461     [\\r\\n\\r\\n    from torch.optim import Adam\\r\\n ...\n",
       "2462     [Traceback (most recent call last):\\r\\n  File ...\n",
       "2463     [(512, 2, 2), empty(): argument 'size' must be...\n",
       "2464     [# Name                    Version            ...\n",
       "2465     [# Name                    Version            ...\n",
       "2466     [import torch\\r\\nimport json\\r\\nimport urllib\\...\n",
       "2467     [class Trainer:\\r\\n    def __init__(self, mode...\n",
       "2468     [torch.optim.lr_scheduler.CyclicLR, optimizer ...\n",
       "2470     [import torch.nn.functional as F\\r\\nx = F.pad(...\n",
       "2471     [#x is input\\r\\nkey=nn.Linear(...,bias=False)(...\n",
       "2472     [on_train_epoch_end, import pytorch_lightning ...\n",
       "2474     [class Model(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "2475     [def img_to_patch(x, patch_size, flatten_chann...\n",
       "2476     [num_input = 2\\r\\nnum_output = 1\\r\\n\\r\\n# Inpu...\n",
       "2477     [class CCT(nn.Module):\\r\\ndef __init__(self,\\r...\n",
       "2478     [config_list = [[ne, 100, 2], [ne, 100, 100, 2...\n",
       "2479     [    train_dataset = MET_database(root = train...\n",
       "2480     [from torchsummary import summary\\r\\nsummary(m...\n",
       "2481     [for output, label in zip(iter(ouputs_t), iter...\n",
       "2482     [net_b = NeuralNetClassifier(\\r\\n    Classifie...\n",
       "2483     [self.no = nc + 5, self.no = nc + 5 + 180, cla...\n",
       "2484     [Embeddings, Generator, nn.Transformer, import...\n",
       "2485     [Epoch 1/90:\\r\\nBatch 1/10\\r\\nLoss mean:  tens...\n",
       "2486     [def ssl_loss (y_real, y_pred, window_size=11,...\n",
       "2487     [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "2488     [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "2489     [kwn, en, from transformers import MarianMTMod...\n",
       "2490     [torch.cuda.memory_reserved('cuda:0')\\r\\ntorch...\n",
       "2491     [#PyTorch\\r\\nclass DiceLoss(nn.Module):\\r\\n   ...\n",
       "2492     [class MyModule:\\r\\n  def forward(self, x):\\r\\...\n",
       "2493     [class MyModule:\\r\\n  def forward(self, x):\\r\\...\n",
       "2495     [raise ImportError(textwrap.dedent('''\\r\\nImpo...\n",
       "2496     [python -m svoice.evaluate /home/username/_SVo...\n",
       "2497     [from facenet_pytorch import MTCNN\\r\\nfrom PIL...\n",
       "2498     [def __init__(self, n_classes):\\r\\n    super()...\n",
       "2501     [mat1 and mat2 shapes cannot be multiplied (4x...\n",
       "2502     [def train_one_epoch(model, data_loader, w1, w...\n",
       "2504     [tensor1 = [-0.1, 0.5, 0.08]\\r\\nnew_tensor = [...\n",
       "2505     [def _forward_impl(self, x: Tensor) -&gt; Tens...\n",
       "2506     [for imgs, mask in trainloader:\\r\\n    print(i...\n",
       "2507     [lin = nn.Linear(len(output_from_third), 4)\\r\\...\n",
       "2508     [RuntimeError: Input type (torch.FloatTensor) ...\n",
       "2509     [# dice loss function\\r\\nclass DiceLoss(torch....\n",
       "2510     [!pip install --upgrade transformers\\r\\n\\r\\n!n...\n",
       "2511     [from torchvision import datasets, transforms\\...\n",
       "2512     [class Pred(TransformerPred):\\r\\n    def _get_...\n",
       "2514     [from torch.autograd import Variable\\r\\n\\r\\ntr...\n",
       "2515     [[batch_size, sequence_size, hidden_size], [ba...\n",
       "2517     [data\\r\\n├── 209109\\r\\n│   ├── 1.png\\r\\n│   ├─...\n",
       "2518     [bandSparse, Matrix, N = 100\\r\\nalpha = 0.6\\r\\...\n",
       "2519     [ File \"D:\\GraduationDesign\\project\\Design\\Veh...\n",
       "2520     [class SoccerDataset():\\r\\ndef __init__(self,V...\n",
       "2521     [output = torch.zeros((16, 10)) #10 correspond...\n",
       "2522     [forward, x1, x2, class ConcatMe(nn.Module):\\r...\n",
       "2523     [import math\\r\\nimport numpy as np\\r\\nimport t...\n",
       "2524     [inference, class, 77, Cell Phone, requires_gr...\n",
       "2525     [import os\\r\\nfrom tkinter import Variable\\r\\n...\n",
       "2526     [pip install fastai==1.0.61\\r\\n, brew install ...\n",
       "2527     [pip install fastai==1.0.61\\r\\n, brew install ...\n",
       "2528     [model\\r\\n|- cuts34.pkl\\r\\n|- code\\r\\n  |- inf...\n",
       "2529     [# Sliding window function\\r\\ndef sliding_wind...\n",
       "2530     [ tcav = {}\\r\\n    \\r\\n    def backward_hook(m...\n",
       "2531     [        h_bias = (self.h_bias.clone()).expand...\n",
       "2532     [        h_bias = (self.h_bias.clone()).expand...\n",
       "2533     [x = torch.tensor(x_init, requires_grad=True)\\...\n",
       "2534     [class ConvNet2(nn.Module):\\r\\n    def __init_...\n",
       "2535     [class ConvNet2(nn.Module):\\r\\n    def __init_...\n",
       "2536     [torch.nn.Module, ABC, __init__(), ABC, ABC, o...\n",
       "2537     [a = torch.tensor([[1,2,3], [2,3,4]])\\r\\nb = t...\n",
       "2538     [import torchvision.datasets as datasets\\r\\nfr...\n",
       "2539     [s_labels = []\\r\\nsvhn256_dataloader = data_lo...\n",
       "2540     [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "2542     [max_iter = 500\\r\\nshow_iter = 50\\r\\noptimizer...\n",
       "2543     [torch.Size([channels, width, height])\\r\\n, a,...\n",
       "2544     [class TorchActionMaskModel(TorchModelV2, nn.M...\n",
       "2545     [r, x, (N, C, H, W), (N, C, H*r, W*r), (C, C, ...\n",
       "2546     [net = torch.nn.DataParallel(net), import torc...\n",
       "2547     [[ 5 8 4 3\\r\\n  1 3 5 4\\r\\n  3 9 8 6 ]\\r\\n, [ ...\n",
       "2549     [x, loss, torch.autograd, import torch\\r\\nimpo...\n",
       "2550     [class first_model(nn.Module):\\r\\n    def __in...\n",
       "2551     [import torch\\r\\nimport torch.nn.functional as...\n",
       "2553     [train_transforms = A.Compose(\\r\\n    [\\r\\n   ...\n",
       "2554     [ERROR: Could not find a version that satisfie...\n",
       "2555     [pack_sequence,  from torch.nn.utils.rnn impor...\n",
       "2557     [    actual_loes_score_g = actual_loes_score_t...\n",
       "2558     [class GeneratorNet(nn.Module):\\r\\n    def bri...\n",
       "2559     [center_coordinates = (int(box[0]+(box[2]-box[...\n",
       "2560     [def __getitem__(self, index):\\r\\n    assert i...\n",
       "2561     [transforms.Compose, transform=transforms.Comp...\n",
       "2562     [sgd_config = {\\r\\n    'params' : net.paramete...\n",
       "2563     [sgd_config = {\\r\\n    'params' : net.paramete...\n",
       "2564     [sgd_config = {\\r\\n    'params' : net.paramete...\n",
       "2566     [model\\r\\n|-code\\r\\n  |-shared\\r\\n    |-aws_ut...\n",
       "2567     [class MulticlassClassification(nn.Module):\\r\\...\n",
       "2568     [torch.distributions.MultivariateNormal(torch....\n",
       "2569     [Node2Vec, ImportError                        ...\n",
       "2570     [runtimeerror: unable to open shared memory ob...\n",
       "2571     [import torch\\r\\nimport torch.utils.data\\r\\nim...\n",
       "2572     [#@title\\r\\nexperiment_type = 'ffhq_encode'\\r\\...\n",
       "2573     [a = torch.Tensor((10, 2))\\r\\nb = torch.Tensor...\n",
       "2574     [    pos_t = torch.tensor([\\r\\n            not...\n",
       "2575     [def generate(model: nn.Module, src_text:str):...\n",
       "2576     [or _ in range(80):\\r\\n    for img, label in d...\n",
       "2577     [...\\r\\n1111    007XXXXXL   007 BOND LLC    14...\n",
       "2578     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "2579     [def gera_palavras_candidatas(context, past):\\...\n",
       "2580     [max([x.size() for x in dataset])\\r\\n, tensor(...\n",
       "2581     [def forward(self, input, hidden=None):\\r\\n   ...\n",
       "2582     [tensor([[0, 1, 2, 2],\\r\\n        [2, 4, 2, 4]...\n",
       "2583     [DataLoader, batch_sampler, import torch\\r\\n\\r...\n",
       "2584     [query_idx, doc_idx, torch.cartesian_prod(pred...\n",
       "2585     [#include &lt;iostream&gt;\\r\\n#include &lt;fst...\n",
       "2586     [run codegen_sources/preprocessing/preprocess....\n",
       "2587     [cv2, Canny Edge Detector, [[x1, y1, x2, y2], ...\n",
       "2588     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nd...\n",
       "2589     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "2590     [~$ python3 -c \"import open3d.ml.torch as ml3d...\n",
       "2591     [torch.stack(x, weighted_channels), x, TypeErr...\n",
       "2592     [img_batch, batch_size = 8\\r\\nprct0 = 0.1\\r\\nn...\n",
       "2593     [img_batch, batch_size = 8\\r\\nprct0 = 0.1\\r\\nn...\n",
       "2594     [class CNN(nn.Module):\\r\\n  def __init__(self)...\n",
       "2596     [class CheastCancer_VGG(pl.LightningModule):\\r...\n",
       "2597     [X, Y, Date           | Open              | Hi...\n",
       "2598     [block: Type[Union[BasicBlock, Bottleneck]],\\r...\n",
       "2599     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "2600     [import numpy \\r\\nimport torch.nn as nn\\r\\n\\r\\...\n",
       "2601     [class DeepGraphInfomax(torch.nn.Module):\\r\\n\\...\n",
       "2602     [wget https://developer.download.nvidia.com/co...\n",
       "2603     [    def evaluate(model, loader, num, device):...\n",
       "2604     [from torch.utils.data import Dataset, DataLoa...\n",
       "2605     [ def _init_(self):\\r\\n        super()._init_(...\n",
       "2606     [ def _init_(self):\\r\\n        super()._init_(...\n",
       "2607     [LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\\r\\n...\n",
       "2608     [train_encode = tokenizer(train1, train2,paddi...\n",
       "2609     [    cnn = nn.Sequential()\\r\\n    cnn.add_modu...\n",
       "2610     [data = pd.read_csv('TrackDataNormalized.csv')...\n",
       "2611     [    RANGE = 1000\\r\\n    device = torch.device...\n",
       "2612     [encoder = enCoder()\\r\\nencoder = torch.nn.Dat...\n",
       "2613     [class MyModule(nn.Module):\\r\\n   def update_p...\n",
       "2614     [A = tensor([[ 1.,  2.,  2.,  3.,  3.,  3.,  4...\n",
       "2615     [import torch\\r\\nfrom torch import Tensor,nn\\r...\n",
       "2617     [class IoUEval:\\r\\n    def __init__(self, nthr...\n",
       "2618     [torch.Size([4, 256, 1, 5], torch.Size([4, 256...\n",
       "2619     [def early_stopping(train_loss, validation_los...\n",
       "2620     [def early_stopping(train_loss, validation_los...\n",
       "2622     [    model = torch.hub.load('yolov5', 'custom'...\n",
       "2623     [    model = torch.hub.load('yolov5', 'custom'...\n",
       "2624     [# This is the loss calculation code for train...\n",
       "2625     [model_c = torch.hub.load('ultralytics/yolov5'...\n",
       "2626     [class GCNLayer(torch.nn.Module):\\r\\n    def f...\n",
       "2627     [parameter = torch.tensor([1.0137, 1.0269, 3.1...\n",
       "2628     [libxxx.so, python setup.py build, ➜  pytorch ...\n",
       "2629     [import torch\\r\\nfrom torch import autograd\\r\\...\n",
       "2631     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "2632     [def test(loader):\\r\\n    model.eval()\\r\\n    ...\n",
       "2634     [xlm_r_model = XLMRobertaForSequenceClassifica...\n",
       "2635     [import time\\r\\nimport torch\\r\\nimport psutil\\...\n",
       "2636     [1.10.2+cu113, ffted = torch.rfft(input, 1, on...\n",
       "2637     [(my2022) C:\\Users\\donhu&gt;pip3 install torch...\n",
       "2639     [from PIL import Image\\r\\nfrom torchvision.tra...\n",
       "2640     [XLMRobertaForSequenceClassification, xlm_r_mo...\n",
       "2641     [import csv\\r\\nimport torch\\r\\nimport torch.nn...\n",
       "2642     [get_all_embeddings, ValueError: could not bro...\n",
       "2644     [A = torch.rand((64, 128, 10, 10))\\r\\nB = torc...\n",
       "2645     [nn.ModuleDict(), class LLinear(nn.Module):\\r\\...\n",
       "2646     [nn.sigmoid, class Classifier(nn.Module):\\r\\n ...\n",
       "2647     [nn.Module, model = MyWeirdModel()\\r\\nmodel.pa...\n",
       "2648                 [torch.equal(matrix_1, matrix_2)\\r\\n]\n",
       "2649     [conv1 = nn.Conv2d(3, 16, 3,stride= 2, padding...\n",
       "2650     [   Traceback (most recent call last):\\r\\n    ...\n",
       "2652     [module_list.0.Conv2d.weight\\r\\nmodule_list.0....\n",
       "2653     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "2654     [------Start--------\\r\\nTraceback (most recent...\n",
       "2656     [softMax = torch.nn.Softmax()\\r\\nnew_square = ...\n",
       "2658     [#simplified version of my training method. wh...\n",
       "2659     [{\\r\\n\"in\":[0.052956,0.065460,0.066195,0.04707...\n",
       "2660     [model2 = NeuralNet(config, kernel_size)\\r\\nsk...\n",
       "2661     [def AUTOMAP_Basic_Model(param):\\r\\n    fc_1 =...\n",
       "2663     [optimizer.step(), torch.nn.CrossEntorpyLoss, ...\n",
       "2664     [__getitem__, yield, yield, class CustomDatase...\n",
       "2665     [from effdet.config.model_config import effici...\n",
       "2667     [RuntimeError: one of the variables needed for...\n",
       "2668     [3x32x32, 3x224x224, transforms, preprocess = ...\n",
       "2669     [data = ImageDataLoader.from_folder(path, trai...\n",
       "2670     [Weights &amp; biases, class LogisticRegressio...\n",
       "2671     [path=Path('/content/XRays')\\r\\nnp.random.seed...\n",
       "2672     [is_valid_file, is_valid_file, trainset = torc...\n",
       "2673     [Train Epoch: 1 [0/2048 (0%)]    Loss: 0.65486...\n",
       "2674     [print(action), import cv2\\r\\nimport torch\\r\\n...\n",
       "2676     [class MyModule(nn.Module):\\r\\n    \\r\\n    def...\n",
       "2677     [The input is the Mel-spectrogram shape --&gt;...\n",
       "2678     [loss = criterion(out,target), def dataPrep(li...\n",
       "2679     [loss = criterion(out,target), def dataPrep(li...\n",
       "2680     [torchvision.datasets.ImageFolder, ├── seg_tra...\n",
       "2681     [            opt.zero_grad()\\r\\n            fo...\n",
       "2682     [import torchmetrics\\r\\n\\r\\nclass CheastCancer...\n",
       "2683     [conv2d, _out, conv2d, True True True\\r\\nconv ...\n",
       "2684     [sklearn.preprocessing.StandardScaler, sklearn...\n",
       "2685     [values_mapping = {1: 12, 3: 1, 4: 2, 2: 34, 1...\n",
       "2686     [class UNet(nn.Module):\\r\\n    def __init__(se...\n",
       "2687     [SE_Block, N, SE_Block, SE_Block, SE_Block, cl...\n",
       "2688     [SE_Block, N, SE_Block, SE_Block, SE_Block, cl...\n",
       "2689     [n, t, [1,2,3,4,5,6,7,8,9,10], n = 2, t = 3, [...\n",
       "2690     [def compute_tcav(input_tensor, model, AA, lay...\n",
       "2691     [from torchmetrics.classification import Accur...\n",
       "2692     [fastai, tsai, airpassengers dataset, \\r\\n# Th...\n",
       "2693     [class CNN(nn.Module):\\r\\n  def __init__(self,...\n",
       "2694     [ train_dataset = datasets.MNIST(\\r\\n     13  ...\n",
       "2695     [trainer.fit(model,data_module), -------------...\n",
       "2696     [def validate(test_loader, MLP, epoch):\\r\\n   ...\n",
       "2697     [import torch\\r\\nimport tensorflow as tf\\r\\nim...\n",
       "2698     [@register_torch_op()\\r\\ndef var(context, node...\n",
       "2699     [kernel_size = 3\\r\\nInput_size = N\\r\\nOutput_s...\n",
       "2700     [import torch.nn as nn\\r\\n\\r\\nclass RNN(nn.Mod...\n",
       "2701     [GPU available: True, used: True\\r\\nTPU availa...\n",
       "2702     [GPU available: True, used: True\\r\\nTPU availa...\n",
       "2703     [GPU available: True, used: True\\r\\nTPU availa...\n",
       "2704     [cxx11 ABI, cmake_minimum_required(VERSION 3.2...\n",
       "2705     [torch.bmm, torch.Tensor.to, N = 5\\r\\nM = 10\\r...\n",
       "2706     [(batch_size, src_length), (batch_size, tgt_le...\n",
       "2707     [batch_size = 64\\r\\ntrain_dataset = datasets.M...\n",
       "2708     [batch_size = 64\\r\\ntrain_dataset = datasets.M...\n",
       "2709     [tgt = torch.zeros(batch_size,max_len)\\r\\ntgt[...\n",
       "2710     [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "2711     [from timm.models import create_model\\r\\nmodel...\n",
       "2712     [img = env.render(mode=\"rgb_array\")\\r\\n, resiz...\n",
       "2713     [self_attn = nn.MultiheadAttention(dModel, nhe...\n",
       "2714     [# AE one-block\\r\\nimport time\\r\\nimport numpy...\n",
       "2715     [import torch\\r\\nimport os\\r\\nimport cv2\\r\\n\\r...\n",
       "2716     [label_dict = {'positive': 1, 'negative': 0}, ...\n",
       "2717     [python main_moco.py \\\\r\\n  -a resnet50 \\\\r\\n ...\n",
       "2718     [import torch\\r\\nfrom transformers import Auto...\n",
       "2719     [print(), sys.stderr, print(), print(\"Hello? A...\n",
       "2722     [train_dataset= torchvision.datasets.CIFAR10(r...\n",
       "2723     [class ANNModel(nn.Module):\\r\\n    def __init_...\n",
       "2725     [edge_index, forward(), edge_index, (2, num_ed...\n",
       "2726     [f=alpha + (vnorm/2) #Equation to minimize\\r\\n...\n",
       "2727     [def load_array(data_arrays, batch_size, is_tr...\n",
       "2728     [episode: 85 score: 18 avarage score: 20.21 ep...\n",
       "2729     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "2730     [print(inputs)\\r\\nif self.chat_history_ids is ...\n",
       "2731     [import numpy as np\\r\\nimport torch\\r\\n\\r\\ncla...\n",
       "2733     [.contiguous(memory_format=torch.channels_last...\n",
       "2735     [def deal_json(data):\\r\\n    global task_pipe\\...\n",
       "2736     [train_data=torchvision.datasets.STL10(root='d...\n",
       "2738     [model, pt_backbone = model.backbone\\r\\n\\r\\nst...\n",
       "2739     [def run_epoch(data_iter, model, loss_compute,...\n",
       "2740     [def run_epoch(data_iter, model, loss_compute,...\n",
       "2741     [tgt_batch, def train_epoch(model, optimizer):...\n",
       "2742     [class MyDataSet(Dataset):\\r\\n\"\"\"customize my ...\n",
       "2743     [    class Net(nn.Module):\\r\\n\\r\\n    # Constr...\n",
       "2744     [mask, torch.Size([8, 24, 24])\\r\\n, &gt; torch...\n",
       "2745     [memory = deque =(Transition(state = ..., next...\n",
       "2746     [KeyNotFoundException, optimizer.step(), Cance...\n",
       "2747     [model.train()\\r\\noptimizer.zero_grad()\\r\\nout...\n",
       "2749     [File \"run.py\", line 105, in &lt;module&gt;\\r\\...\n",
       "2750     [from joblib import Parallel, delayed\\r\\nimpor...\n",
       "2751     [from joblib import Parallel, delayed\\r\\nimpor...\n",
       "2752     [class BertClassifier(nn.Module):\\r\\n    def _...\n",
       "2753     [# direccion del directorio de entrenamiento\\r...\n",
       "2756     [main_class, first_branch, second_branch, clas...\n",
       "2757     [shuffle (bool, optional) – set to True to hav...\n",
       "2758     [train_dataloader, (2000,3), train_dataloader,...\n",
       "2759     [GCP Vertex platform, Pytorch, HuggingFace, co...\n",
       "2760     [%load_ext tensorboard\\r\\nexperiment_log_dir =...\n",
       "2762     [class Encoder(nn.Module):\\r\\n    \\r\\n    def ...\n",
       "2764     [python -c \"import torch; print(torch.version....\n",
       "2765     [ import torchvision, UserWarning: Failed to l...\n",
       "2767     [from typing import Iterable, Callable, Tuple\\...\n",
       "2768     [[E ProcessGroupNCCL.cpp:719] [Rank 0] Watchdo...\n",
       "2769     [XLMRobertaModel, encoder.layer.*, from transf...\n",
       "2770     [import torch\\r\\ntorch.set_printoptions(precis...\n",
       "2771     [class MF(nn.Module):\\r\\n    \\r\\n    def __ini...\n",
       "2772     [def IoU(inputs: torch.Tensor, labels: torch.T...\n",
       "2773     [from torchbiggraph.converters.import_from_tsv...\n",
       "2776     [RuntimeError                              Tra...\n",
       "2777     [10, (1,10,768), last_hidden_state[:,index-1,:...\n",
       "2778     [Dummy Data, # NOTE: psuedo-code\\r\\nclass Time...\n",
       "2780     [module load anaconda\\r\\nconda activate\\r\\ncon...\n",
       "2781     [    model = build_model(cfg) \\r\\n    path = '...\n",
       "2782     [x = torch.tensor([[1,1,1,1],\\r\\n             ...\n",
       "2783     [x = torch.tensor([[1,1,1,1],\\r\\n             ...\n",
       "2784     [raw_dataset[\"sentiment\"][\"content\"][:50]\\r\\na...\n",
       "2785     [%%time\\r\\nhistory = [evaluate(model, valid_dl...\n",
       "2787     [ValueError: Parameter 'weight' of module Conv...\n",
       "2788     [torch.utils.data.DataLoader, torch.utils.data...\n",
       "2789     [\\r\\n'''\\r\\n1D intersection over union loss fu...\n",
       "2790     [['I like python',\\r\\n 'I am learning python',...\n",
       "2793     [trainer, def get_resampled_weights(self, batc...\n",
       "2794     [out = torch.einsum(\"nhql,nlhd-&gt;nqhd\", [att...\n",
       "2795     [share_memory(), torch.multiprocessing.Pool, s...\n",
       "2796     [ErrorTypeError: __init__() takes 1 positional...\n",
       "2797     [import os\\r\\nimport pandas as pd\\r\\nfrom torc...\n",
       "2798     [    File \"D:\\software\\python3\\lib\\site-packag...\n",
       "2799     [with torch.no_grad():\\r\\n    input_data = tor...\n",
       "2800     [import torch\\r\\nx = torch.tensor([1.0,2.0,3.0...\n",
       "2801     [class Parent(nn.Module):\\r\\n\\r\\n  def __init_...\n",
       "2802     [Keras, TensorFlow, \\r\\nimages, labels = next(...\n",
       "2804     [import torch\\r\\nimport torchrec\\r\\n\\r\\nimport...\n",
       "2805     [transforms.Normalize(mean=[], std=[]), Runtim...\n",
       "2806     [class AutoEncoder(nn.Module):\\r\\n\\r\\n    def ...\n",
       "2808     [import os\\r\\nimport torch\\r\\nimport torchvisi...\n",
       "2809     [class Parent(nn.Module):\\r\\n\\r\\n  def __init_...\n",
       "2810     [class BioQADataSet(Dataset):\\r\\n      def __i...\n",
       "2811     [def forward(self, input_data):\\r\\n    x = sel...\n",
       "2812     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "2813     [class NeuralNetwork(nn.Module):\\r\\n    def __...\n",
       "2814     [t = torch.ones([10, 3])\\r\\n, [\\r\\n    [3.0, 3...\n",
       "2815     [t = torch.ones([10, 3])\\r\\n, [\\r\\n    [3.0, 3...\n",
       "2816     [t = torch.ones([10, 3])\\r\\n, [\\r\\n    [3.0, 3...\n",
       "2817     [image, label = val_dset.__getitem__(20)\\r\\npr...\n",
       "2818     [config = [10, 100, 100, 100, 100, 100, 100, 1...\n",
       "2819     [class Fc(nn.Module):\\r\\n    def __init__(self...\n",
       "2820     [RuntimeError: one of the variables needed for...\n",
       "2821     [mnist_train = torchvision.datasets.FashionMNI...\n",
       "2822     [class Attention(nn.Module):\\r\\n   def __init_...\n",
       "2823     [pathlib.Path, DistributedDataParallel, Path(\"...\n",
       "2824     [resnet.fc = nn.Linear(512, 10)\\r\\n, ResNet(\\r...\n",
       "2825     [#include &lt;iostream&gt;\\r\\n#include &lt;mem...\n",
       "2826     [ garbage collect, while loss &gt; epsilon:\\r\\...\n",
       "2827     [ a_list = [3,23,53,32,53]\\r\\n a_tensor = torc...\n",
       "2828     [output = model(batch_X)       \\r\\n_, pred = t...\n",
       "2829     [class BasicBlock(nn.Module):\\r\\n    expansion...\n",
       "2830     [class Model(nn.Module):\\r\\ndef __init__(self,...\n",
       "2831     [import cudf, pandas, gc, torch\\r\\n\\r\\n# on th...\n",
       "2832     [#example on one image\\r\\nmnist_train = torchv...\n",
       "2833     [class WritingDataset(Dataset):\\r\\n    def __i...\n",
       "2834     [tanh, tanh, import numpy as np\\r\\n\\r\\nlookup_...\n",
       "2836     [class SquarePad:\\r\\n    def __call__(self, im...\n",
       "2839                           [model.half().to(\"cuda:0\")]\n",
       "2841     [import glob\\r\\nimport random \\r\\n\\r\\nfrom tor...\n",
       "2842     [## Specify Batch Size\\r\\ntrain_batch_size = 3...\n",
       "2843     [enter code here\\r\\n\\r\\nClassifier(\\r\\n      (...\n",
       "2844     [pytorch,  torch.save(model.state_dict(), 'mod...\n",
       "2845     [x = torch.Tensor([[1,2,3,4],[4,3,2,1]])\\r\\nma...\n",
       "2846     [cfg = get_cfg()\\r\\ncfg.merge_from_file(model_...\n",
       "2847     [DataLoader, ConcatDataset, collate_fn, Datase...\n",
       "2848     [model.load_from_checkpoint(\"/path/to/checkpoi...\n",
       "2849     [import numpy as np\\r\\nfrom random import rand...\n",
       "2850     [# save source image\\r\\nutils.save_image(data....\n",
       "2851     [nsteps=215\\r\\nnepoch=3\\r\\nbest_val_acc = 0\\r\\...\n",
       "2852     [20.04, GTX 1050TI, 11.3, nvidia-smi, Wed Apr ...\n",
       "2853     [class Parent(nn.Module):\\r\\n\\r\\n    def __ini...\n",
       "2854     [net = SimpleConvolutionalNetwork()\\r\\n\\r\\ntra...\n",
       "2855     [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndat...\n",
       "2856     [torch-geometric, torch 1.4.0, torch-geometric...\n",
       "2857     [optimizer_adam = optim.Adam(params_to_update,...\n",
       "2858     [--extra-index-url, pip install -r requirement...\n",
       "2859     [ih, ih_l0, import torch\\r\\nfrom torch import ...\n",
       "2860     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "2861     [def get_train_transform():\\r\\n    return A.Co...\n",
       "2862     [class Conv(nn.Module):\\r\\n    # Standard conv...\n",
       "2863     [stn(), grid = F.affine_grid(theta, x.size())\\...\n",
       "2864     [torch-summary, class DeepLearningModel(Module...\n",
       "2865     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "2866     [|, \\, 1, import cv2\\r\\nimport easyocr\\r\\nimpo...\n",
       "2867     [class Plain_MLP1(nn.Module):\\r\\n    def __ini...\n",
       "2868     [best.th\\r\\nconfig.json\\r\\nmeta.json\\r\\nmetric...\n",
       "2869     [while loop, import torch\\r\\nimport torch.nn.f...\n",
       "2871     [import torch\\r\\nimport torchvision.models as ...\n",
       "2872     [MongoDB, MongoDB 5.0.6, PymongoDB 4.0.2, Pyth...\n",
       "2874     [x1, x2, x3, x_train, y_train, x_test, y_test,...\n",
       "2875     [active, [batch_full,], terminated, active, ~t...\n",
       "2876     [import torch\\r\\nimport torch.nn as nn\\r\\ntorc...\n",
       "2877     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nw =...\n",
       "2879     [class Generator(nn.Module):    #38\\r\\n    def...\n",
       "2880     [class AR_model:\\r\\ndef __init__(self, length=...\n",
       "2881     [File \"/Users/lion/Documents/MyLab/web_workspa...\n",
       "2882     [PyTorch, DataLoader, class CustomLoader(torch...\n",
       "2883     [model = nn.DataParallel(model), RuntimeError:...\n",
       "2884     [def get_model(lr=0.001):\\r\\n    model = tf.ke...\n",
       "2885     [outputAlignment, RuntimeError: Expected all t...\n",
       "2886     [x = torch.tensor([0,0,0,1,1,2,2,2,2], dtype=t...\n",
       "2887     [x = torch.tensor([0,0,0,1,1,2,2,2,2], dtype=t...\n",
       "2888     [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "2889     [model = torch.hub.load('ultralytics/yolov5', ...\n",
       "2890     [class BART(nn.Module):\\r\\n    def __init__(se...\n",
       "2891     [device  = torch.device(\"cuda\")\\r\\nMODEL = MLP...\n",
       "2892     [transform = transforms.Compose(\\r\\n    [cv_re...\n",
       "2893     [self.model = DQNetwork(11, 256, 3)\\r\\n, class...\n",
       "2894     [randint, \\*, torch.randint(low=0, high, size,...\n",
       "2895     [import torch\\r\\n\\r\\nT = 1000\\r\\n\\r\\ntime = to...\n",
       "2896     [dbpedia_ckp_path = “./checkpoint/dbpedia_curr...\n",
       "2897     [from __future__ import print_function\\r\\n# im...\n",
       "2898     [dataset['train'], dataset['test'] = torch.uti...\n",
       "2899     [import torch\\r\\nfrom torchvision.models.convn...\n",
       "2900     [tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.00...\n",
       "2901     [import numpy as np \\r\\nimport pandas as pd \\r...\n",
       "2902     [import torch.nn as nn\\r\\n\\r\\nclass NeuralNetw...\n",
       "2903     [FROM python:slim\\r\\nWORKDIR /app\\r\\nCOPY . .\\...\n",
       "2904     [[0.0000,  0.0000,  0.0000,  0.0000,  0.0000, ...\n",
       "2905     [class UpwardsConv1d(nn.Module):\\r\\n    \"\"\"\\r\\...\n",
       "2906     [ x = F.relu(self.fc1(x)), class Net(nn.Module...\n",
       "2907     [ tensor_a = [1, 2, 3]\\r\\n       [4, 5, 6]\\r\\n...\n",
       "2908     [ tensor_a = [1, 2, 3]\\r\\n       [4, 5, 6]\\r\\n...\n",
       "2909     [class SupConLoss(nn.Module):\\r\\n    def __ini...\n",
       "2910     [from torchvision import transforms simple_tra...\n",
       "2911     [device=\"cpu\"\\r\\nlr=3e-5#1e-3\\r\\nnum_training_...\n",
       "2912     [RuntimeError: Error(s) in loading state_dict ...\n",
       "2913     [x = function(x), function(x), x, True, return...\n",
       "2914     [class ImageDataset(Dataset):\\r\\n\\r\\ndef __ini...\n",
       "2915     [    import torch\\r\\n    from torch.nn import ...\n",
       "2916     [facebook/hubert-base-ls9601, facebook/hubert-...\n",
       "2917     [import tensorflow as tf\\r\\nimport os\\r\\nfrom ...\n",
       "2918     [def str_to_slice_indices(slicing_str: str):\\r...\n",
       "2919     [def str_to_slice_indices(slicing_str: str):\\r...\n",
       "2920     [model = DeepGraphInfomax(128, pos_summary_t)....\n",
       "2921     [cam = GradCAM(nn_module=densenet, target_laye...\n",
       "2922     [dist.init_process_group(backend=opt.dist_back...\n",
       "2923     [x, arg1, arg2, scalar_net, x = torch.rand(bat...\n",
       "2924     [train_data, valid_data, test_data = torchtext...\n",
       "2925     [torch.stack, RuntimeError: stack expects each...\n",
       "2926     [u = tensor([[0.0000, 0.1429, 0.2857, 0.4286, ...\n",
       "2927     [u = tensor([[0.0000, 0.1429, 0.2857, 0.4286, ...\n",
       "2928     [ torch.load(\"/home/user/path/to/resnet50_full...\n",
       "2929     [import os\\r\\nfrom PIL import ImageFile\\r\\nimp...\n",
       "2930     [Pytorch, tensorflow, padding='same', class Di...\n",
       "2931     [num_classes = 2\\r\\nclass CNN(nn.Module):\\r\\n\\...\n",
       "2932     [class FlauBertForClassification(nn.Module):\\r...\n",
       "2934     [self.layers_li = []\\r\\nfor i in range(num_lay...\n",
       "2935     [    import torch\\r\\n    from torch import nn\\...\n",
       "2936     [#!/bin/bash\\r\\n#SBATCH --time=00:03:00\\r\\n#SB...\n",
       "2937     [1.000000015047466e+30, #define NAN __int_as_f...\n",
       "2938     [torch.stack, out = torch.empty(length, n)\\r\\n...\n",
       "2939     [class SimpleBinaryClassifier(nn.Module):\\r\\n ...\n",
       "2940     [pytorch, torch.conv1d, convolve, convolve, li...\n",
       "2941     [pytorch, torch.conv1d, convolve, convolve, li...\n",
       "2942     [_GLIBCXX_USE_CXX11_ABI, torch._C._GLIBCXX_USE...\n",
       "2943     [class Encoder(nn.Module):\\r\\ndef init(self, i...\n",
       "2944     [Dense(50, ReLU) -&gt; Dense(50, ReLU) -&gt; D...\n",
       "2945     [def load_checkpoint(checkpoint_file, model, o...\n",
       "2946     [    Collecting package metadata (current_repo...\n",
       "2947     [(64, 1, 103, 8), nn.Conv2d, (64, 32, 43, 8), ...\n",
       "2948     [class AudioClassifier(nn.Module):\\r\\n    def ...\n",
       "2949     [cross_edge_index, from torch_geometric.data.b...\n",
       "2951     [import torch \\r\\n\\r\\npreds = torch.randn(4, 1...\n",
       "2952     [import torch\\r\\nfrom datetime import datetime...\n",
       "2953     [level_stride = 8\\r\\nloc = torch.zeros(H * W, ...\n",
       "2954     [10:47:19 AM django-face-restore: ERROR: Could...\n",
       "2957     [    class SomeModel(torch.nn.Module)\\r\\n     ...\n",
       "2959     [def test_gradient_penalty(image_shape):\\r\\n  ...\n",
       "2960     [class SimpleLinear(Module):\\r\\n    \"\"\"\\r\\n   ...\n",
       "2961     [transform=transforms.Compose([transforms.ToTe...\n",
       "2962     [def preprocess_function(examples):\\r\\n    ret...\n",
       "2964     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "2965     [1only batches of spatial targets supported (3...\n",
       "2966     [processed_data, .pt, data_0.pt, data_1.pt, da...\n",
       "2967     [ for i in range(len(bboxes)):\\r\\n    bbox = b...\n",
       "2968     [nn.ConvTranspose2d, (64,128), (64,1,103,8), c...\n",
       "2969     [while(self.dumb_turn):\\r\\n    #The opponent c...\n",
       "2970     [  torch::jit::script::Module module_af;\\r\\n  ...\n",
       "2971     [x = torch.randint(0, 256, (100000, 48), dtype...\n",
       "2972     [torch::Tensor test = torch::empty({ 2,3,4 });...\n",
       "2973     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "2974     [    image        = PIL.......\\r\\n\\r\\n    imag...\n",
       "2975     [clc;clear;\\r\\nnp = py.importlib.import_module...\n",
       "2976     [class Net1(nn.Module):\\r\\n    def __init__(se...\n",
       "2977     [import torchvision.transforms as transforms\\r...\n",
       "2978      [x = [[1,2,3,4,5]]\\r\\n, x= [[1,2,3,11,4,5]]\\r\\n]\n",
       "2980     [import math\\r\\nimport os\\r\\nimport torch\\r\\ni...\n",
       "2981     [torch.from_numpy(g_list[1]['sentence_vector']...\n",
       "2982     [dist.init_process_group(\\r\\n        backend='...\n",
       "2983     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "2985     [dataset = load_dataset('cats_vs_dogs', split=...\n",
       "2986     [    for images, targets in metric_logger.log_...\n",
       "2987     [class Dataset(Dataset):\\r\\n    def __init__(s...\n",
       "2988     [f, x,y, t, import torch\\r\\n# Space (x,y) and ...\n",
       "2989     [import torch\\r\\nimport librosa\\r\\nimport libr...\n",
       "2990     [class Model(nn.Module):\\r\\n    def __init__(\\...\n",
       "2991     [EP0_elapsed_time: 3.3021082878112793 sec\\r\\nE...\n",
       "2992     [ python3 run.py --input_folder test_images/ol...\n",
       "2993     [    class CSIDataset(pl.LightningDataModule):...\n",
       "2994     [torch.set_num_threads(multiprocessing.cpu_cou...\n",
       "2995     [A =tensor([[0.2846, 0.9896, 0.0401, 0.7612],\\...\n",
       "2996     [timestamp,message,logStreamName\\r\\n1648240674...\n",
       "2997     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "2998     [tensor([[ 1., -5.],\\r\\n        [ 2., -4.],\\r\\...\n",
       "2999     [tensor([[ 1., -5.],\\r\\n        [ 2., -4.],\\r\\...\n",
       "3000     [self.tune_config = {\\r\\n    \"batch_size\": tun...\n",
       "3001     [class NN(nn.Module):\\r\\n    def __init__(self...\n",
       "3002     [train_dataset = torchvision.datasets.FashionM...\n",
       "3003                                     [pip install mkl]\n",
       "3004     [class Optimization:\\r\\n    def __init__(self,...\n",
       "3006     [# Implementation of CNN/ConvNet Model\\r\\nclas...\n",
       "3007     [def training_step(self, batch: tuple, batch_n...\n",
       "3008     [def training_step(self, batch: tuple, batch_n...\n",
       "3009     [DataLoader, uint8, img_size, class DataLoader...\n",
       "3010     [AttributeError: 'Tensor' object has no attrib...\n",
       "3011     [RuntimeError: Attempted to set the storage of...\n",
       "3012     [transform_train = transforms.Compose([\\r\\n   ...\n",
       "3013     [a = torch.tensor([[ 0.,  1.,  2.],\\r\\n       ...\n",
       "3014     [a = torch.tensor([[ 0.,  1.,  2.],\\r\\n       ...\n",
       "3015     [loss1 = (t/(t+1)) * cross_entropy (only when ...\n",
       "3016     [class DNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "3018     [@app.route(\"/json\", methods=['GET', 'POST', '...\n",
       "3019     [# Loading trained model on MNIST\\r\\ngooglenet...\n",
       "3020     [filename | actual class | predicted class\\r\\n...\n",
       "3021     [inference_image_uri = sagemaker.image_uris.re...\n",
       "3022     [-1, 0, 0, 1, %matplotlib inline\\r\\n\\r\\nimport...\n",
       "3023     [bert_model_1 = XLNetForSequenceClassification...\n",
       "3024     [def get_mean_std(loader):\\r\\n  sum = 0\\r\\n  s...\n",
       "3025     [__call__(), class MyClass:\\r\\n  def __init__(...\n",
       "3026     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3027     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3028     [result, b, c, h, w = 4, 100, 200, 200\\r\\npoin...\n",
       "3029     [import torch.nn as nn\\r\\nclass CNN(nn.Module)...\n",
       "3030     [class CustomImageDataset(Dataset):\\r\\n    def...\n",
       "3031     [input1.shape = C*H*W, a1.shape = H\\*W, output...\n",
       "3032     [I have extended vocabulary by adding extra to...\n",
       "3033     [!python train.py --outdir=/stylegan2-ada-pyto...\n",
       "3034     [#Put both the modules in a single module\\r\\n\\...\n",
       "3035     [x_train = []\\r\\ny_train = []\\r\\nx_test = []\\r...\n",
       "3036     [def _obtain_indices(self):\\r\\n\"\"\"\\r\\nSet the ...\n",
       "3037     [RuntimeError                              Tra...\n",
       "3038     [__enter__ and __exit__, with statement, torch...\n",
       "3039     [ embedding = nn.Embedding(10, 3)\\r\\n input = ...\n",
       "3040     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3041     [n_elts = 4\\r\\nx = torch.FloatTensor([0,1,1,0]...\n",
       "3044     [num_classes = 3 # num of objects to identify ...\n",
       "3046     [#set-up code\\r\\nimport random\\r\\nimport torch...\n",
       "3047     [# Setting tranform for train and test data\\r\\...\n",
       "3048     [x, y, [3,2,3], [3,2], [3,2,3], import torch\\r...\n",
       "3050     [for epoch in range(num_epochs):\\r\\n    train_...\n",
       "3051     [train_dir = 'images'\\r\\ntrain_mask_dir = 'mas...\n",
       "3052     [print(\"Training Shape\", X_train_tensors.shape...\n",
       "3053     [class DenseNet(pl.LightningModule):\\r\\n    de...\n",
       "3054     [ValueError: num_samples should be a positive ...\n",
       "3055     [(4, 100, 56, 56), t = torch.zeros((4, 100, 56...\n",
       "3056     [1:\"stingray\", #!/usr/bin/env python\\r\\n# codi...\n",
       "3057     [def train(epoch):\\r\\n    running_loss = 0.0\\r...\n",
       "3058     [LSTM, AutoRegressiveBaseModelWithCovariates, ...\n",
       "3059     [\\r\\n#Make train function (simple at first)\\r\\...\n",
       "3060     [linear_transformed_nodes_repeated = linear_tr...\n",
       "3061     [cv2.error: OpenCV(4.5.5) :-1: error: (-5:Bad ...\n",
       "3062     [enumerate,  for i, data in enumerate(train_dl...\n",
       "3063     [Tensor, Tesnor.data, import torch\\r\\n\\r\\na = ...\n",
       "3064     [pip install torch-1.8.0-cp36-cp36m-linux_x86_...\n",
       "3065     [linear_transformed_nodes_repeated = linear_tr...\n",
       "3066     [if best_valid_loss is None or valid_loss &lt;...\n",
       "3067     [\"image_datasets\", for x in ['train', 'val'], ...\n",
       "3068     [\"image_datasets\", for x in ['train', 'val'], ...\n",
       "3069     [from detectron2.data.datasets import register...\n",
       "3070     [import cv2 \\r\\nimport numpy as np \\r\\nfrom pa...\n",
       "3073     [torch.save({\\r\\n        'epoch': epoch,\\r\\n  ...\n",
       "3074     [model_path = config.model_path\\r\\nclass BertF...\n",
       "3075     [raise RuntimeError('DataLoader worker (pid(s)...\n",
       "3076     [for i in range(epochs):\\r\\n    data = modify_...\n",
       "3077     [a = [[15,30,0,2], [-1,-1,-1,-1], [10, 20, 40,...\n",
       "3078     [a = [[15,30,0,2], [-1,-1,-1,-1], [10, 20, 40,...\n",
       "3079     [class DiceMetric1(nn.Module):\\r\\n    def __in...\n",
       "3080     [#Make train function (simple at first)\\r\\ndef...\n",
       "3081     [a = torch.Tensor([[1, 2, 3], [4, 5, 6]]).to(t...\n",
       "3082     [a = torch.Tensor([[1, 2, 3], [4, 5, 6]]).to(t...\n",
       "3083     [a = torch.Tensor([[1, 2, 3], [4, 5, 6]]).to(t...\n",
       "3085     [ for batch_id, sample in enumerate(train_load...\n",
       "3086     ['''\\r\\nInputs:\\r\\n- W: A PyTorch tensor of sh...\n",
       "3087     [UpSampling2D, keras, torch.nn.UpsamplingNeare...\n",
       "3088     [class SaveBestModel:\\r\\n    \"\"\"\\r\\n    Class ...\n",
       "3089     [import torch.nn.functional as F\\r\\n\\r\\nweight...\n",
       "3090     [joblib.dump(results, \"./results.sav\")  \\r\\n, ...\n",
       "3091     [best.pt, Process finished with exit code 139 ...\n",
       "3092     [EPOCHS = 50\\r\\nBATCH_SIZE = 16\\r\\n# Transform...\n",
       "3093     [def build_model(SHAPE, nb_classes, bn_axis, s...\n",
       "3094     [from sklearn.datasets import make_regression\\...\n",
       "3095     [x = [[1,2,3,4,5,6],\\r\\n     [7,8,9,10,11,12]]...\n",
       "3096     [from torchvision import models\\r\\nfrom torchs...\n",
       "3097     [def test(net, img, hyperparams):\\r\\n\\r\\nnet.e...\n",
       "3098     [# load model and tokenizer and define length ...\n",
       "3100     [model = BertForPreTraining('bert-base-uncased...\n",
       "3101     [import os\\r\\nimport ast\\r\\nimport torch\\r\\nim...\n",
       "3102     [tensor, A, Tensor, A = [1, 2, 3, 4], indexes ...\n",
       "3103     [tensor, A, Tensor, A = [1, 2, 3, 4], indexes ...\n",
       "3105     [trainedmodelpath = \"model.th\"\\r\\ntorch.save({...\n",
       "3107     [inspect.signature(torch.empty),  import inspe...\n",
       "3108     [n_nodes = extended_adj.shape[0]\\r\\nn_edges = ...\n",
       "3109     [for batch in dataloader:\\r\\n    video_sns = b...\n",
       "3110     [Epoch [0], last_lr: 0.00100, train_loss: 1.71...\n",
       "3111     [directions∗num_layers, batch, hidden_size, 0,...\n",
       "3112     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "3114     [import gc\\r\\ndef train(model, iterator, optim...\n",
       "3115     [\\r\\nEpoch [0], last_lr: 0.00100, train_loss: ...\n",
       "3117     [tensor([[0,0,1], [1,0,0]]) == tensor([[0,0,1]...\n",
       "3118     [torch.save(model.state_dict(), 'model.pt'), i...\n",
       "3119     [PyTorch, import torch.nn as nn\\r\\nimport torc...\n",
       "3120     [p, a, a = torch.empty(size=[50] + list(p.shap...\n",
       "3121     [torch.tensor(), x\\r\\nOut[155]: \\r\\ntensor([[[...\n",
       "3122     [torch.cuda.synchronize, torch.cuda.synchroniz...\n",
       "3123     [input_ = torch.randn(1,1,8,1)\\r\\n\\r\\ninput_.s...\n",
       "3124     [batch_output = batch_output[batch_mask, ...]\\...\n",
       "3125     [batch_output = batch_output[batch_mask, ...]\\...\n",
       "3126     [ModelCheckpoint, checkpoint_callback = ModelC...\n",
       "3127     [next(train_iter)\\r\\nnext(train_iter)\\r\\n, pri...\n",
       "3129     [class Detr(pl.LightningModule):\\r\\n\\r\\n    de...\n",
       "3130     [x1, x2 = torch.tensor_split(x,2), import torc...\n",
       "3131     [class RNN_LSTM(nn.Module):\\r\\ndef __init__(se...\n",
       "3132     [RuntimeError: Caught RuntimeError in DataLoad...\n",
       "3133     [class SimplexPotentialProjection(object):\\r\\n...\n",
       "3134     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "3135     [class MultiClass(nn.Module):\\r\\n    def __ini...\n",
       "3136     [.requires_grad_(), param.grad.zero_(), param,...\n",
       "3137     [.requires_grad_(), param.grad.zero_(), param,...\n",
       "3138     [BCELossWithLogits, BatchNorm1d, BCELossWithLo...\n",
       "3139     [#set batch size\\r\\nBATCH_SIZE = 16\\r\\n\\r\\ntra...\n",
       "3140     [ X1=[[var1_t_1, var2_t_1, var3_t_1],\\r\\n     ...\n",
       "3141     [torch.hub.load, model = torch.hub.load(\\r\\n  ...\n",
       "3142     [class Layer1 : torch::nn::Module {\\r\\n    pub...\n",
       "3144     [iob = np.array(\\r\\n    [0, 1, 2, 2, 2, 2, 2, ...\n",
       "3145     [a, 2, 1403, b, a.shape = (2, 1403) # a is 2D ...\n",
       "3146     [a, 2, 1403, b, a.shape = (2, 1403) # a is 2D ...\n",
       "3147     [def test():\\r\\n #look at the values of the te...\n",
       "3148     [(400, 164), (400,64), (400,100), torch_lstm.w...\n",
       "3149     [image_datasets, transforms= transforms.Compos...\n",
       "3151     [print(classification_report(test.targets.cpu(...\n",
       "3152     [#Replace the Final layer of pretrained vgg16 ...\n",
       "3153     [model = CNN_GRU()\\r\\nmodel.eval()\\r\\nlist_mix...\n",
       "3154     [batch_outer = torch.einsum('bi, bj -&gt; bij'...\n",
       "3155     [print(roi_cls_loc.shape)  \\r\\n# torch.Size([1...\n",
       "3156     [optimizer = torch.optim.Adam(model.parameters...\n",
       "3157     [def sample(input_shape):\\r\\n  input_layer = I...\n",
       "3158     [pytorch, pre-trained, Swin-Transformer, DeepL...\n",
       "3159     [\\r\\nTraceback (most recent call last):\\r\\n  F...\n",
       "3160     [x.shape = [32, 256, 96, 3], patch.shape = [16...\n",
       "3161     [nn.Linear(B, C), t1 = t1.transpose(1,2)\\r\\nco...\n",
       "3162     [f_1 = linear_layer(x)\\r\\n\\r\\nf_2 = linear_lay...\n",
       "3163     [Large = Tensor([[0, 1, 3, 0, 0, 0],\\r\\n      ...\n",
       "3164     [Large = Tensor([[0, 1, 3, 0, 0, 0],\\r\\n      ...\n",
       "3166     [class TEN_Network(nn.Module):\\r\\n    def __in...\n",
       "3167     [    class LSTMClassifier(pl.LightningModule):...\n",
       "3168     [.to(device), # to create a batch iterator\\r\\n...\n",
       "3170     [class ConvNet(nn.Module):\\r\\n  def __init__(s...\n",
       "3171     [cat_x = torch.cat([x, x1]), import torch\\r\\nf...\n",
       "3172     [cat_x = torch.cat([x, x1]), import torch\\r\\nf...\n",
       "3173     [\\r\\n        if 'CTC' in opt.Prediction:\\r\\n  ...\n",
       "3174     [[N,L,E], batch_first=True, N, L, E, [N,S,E], ...\n",
       "3175     [tensor([[-0.0150,  0.1234],\\r\\n    [-0.0184, ...\n",
       "3176     [#Create dataset loader class\\r\\nclass Dataset...\n",
       "3177     [[W NNPACK.cpp:79] Could not initialize NNPACK...\n",
       "3178     [Transformer(\\r\\n  (encoder): Encoder(\\r\\n    ...\n",
       "3179     [_log_alpha, self._log_alpha = torch.log(torch...\n",
       "3180     [from torch.nn.utils import weight_norm\\r\\nW =...\n",
       "3181     [torch.nn.RNN, import torch\\r\\nimport torch.nn...\n",
       "3182     [class cls(nn.Module):\\r\\n    def __init__(sel...\n",
       "3183     [encoder_output,   linear_head_output =  ViT(i...\n",
       "3184     [@torch.no_grad()\\r\\ndef evaluate_loss(model, ...\n",
       "3185     [module.py, from .modules import Module, attem...\n",
       "3186     [train, train/dogs, train/cats, /, # we move d...\n",
       "3188     [# creates lists containing each pair\\r\\norigi...\n",
       "3189     [typing.Union, torch.float, typing.Union, torc...\n",
       "3190     [RuntimeError: The size of tensor a (5158) mus...\n",
       "3191     [def train_model(model, optimizer, train_loade...\n",
       "3192     [trainData = datasets.ImageFolder(\\r\\n    root...\n",
       "3193     [def vae_loss(recon_loss, mu, logvar): \\r\\n   ...\n",
       "3194     [from sklearn.preprocessing import StandardSca...\n",
       "3195     [def train_model(model, optimizer, data_loader...\n",
       "3196     [        x = torch.rand(1, 3, 360, 640)\\r\\n   ...\n",
       "3197     [for name, module in model.named_modules():\\r\\...\n",
       "3198     [trainer = pl.Trainer(max_epochs = config['n_e...\n",
       "3200     [    def forward(self, x):\\r\\n        hidden_0...\n",
       "3201     [    def forward(self, x):\\r\\n        hidden_0...\n",
       "3202     [def binary_focal_loss(pred, truth, gamma=2., ...\n",
       "3203     [RuntimeError: CUDA error: the launch timed ou...\n",
       "3204     [#define transforms\\r\\ntransforms= transforms....\n",
       "3205     [      File \"/home1/huangjiawei/miniconda3/env...\n",
       "3206     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "3208     [import math\\r\\nimport torch\\r\\nimport random\\...\n",
       "3209     [{\\r\\n    \"optim\": \"adamw_torch\",\\r\\n    \"eval...\n",
       "3210     [XLM Roberta large, \"a2-highgpu-4g\" ,accelerat...\n",
       "3211     [Traceback (most recent call last):\\r\\nFile \"C...\n",
       "3212     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "3213     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "3214     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "3215     [from sklearn import svm\\r\\nfrom sklearn impor...\n",
       "3216     [from sklearn import svm\\r\\nfrom sklearn impor...\n",
       "3217     [x=np.arrage(24)\\r\\nft=torch.FloatTensor(x)\\r\\...\n",
       "3218     [x=np.arrage(24)\\r\\nft=torch.FloatTensor(x)\\r\\...\n",
       "3219     [AttributeError                            Tra...\n",
       "3221     [RuntimeError: CUDA error: the launch timed ou...\n",
       "3222     [import random\\r\\ntotal_steps = 1\\r\\nseed = 42...\n",
       "3223     [def process_df(partition_tuple):\\r\\n    curre...\n",
       "3224     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\na...\n",
       "3225     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\na...\n",
       "3226     [class NMF_NMI(torch.autograd.Function):\\r\\n  ...\n",
       "3227     [def train(dataloader, model, loss_fn, optimiz...\n",
       "3229     [ FROM us-docker.pkg.dev/vertex-ai/training/tf...\n",
       "3230     [class MYDataset(Dataset):\\r\\n    def __init__...\n",
       "3231     [#In = [[1,2,3,4,5,6,7],\\r\\n        [1,5,4,2,6...\n",
       "3232     [T, d1 x d2 x d3 x ... dk, I, p x q, I, T, q &...\n",
       "3233     [def displayImg(path):\\r\\n    img = cv2.imread...\n",
       "3234     [def displayImg(path):\\r\\n    img = cv2.imread...\n",
       "3235     [transforms.Normalize([0.485, 0.456, 0.406], [...\n",
       "3237     [class ConvBlock(nn.Module):\\r\\n    def __init...\n",
       "3238     [data_transform = {\\r\\n    \"train\": A.Compose(...\n",
       "3239     [data_transform = {\\r\\n    \"train\": A.Compose(...\n",
       "3240     [data_transform = {\\r\\n    \"train\": A.Compose(...\n",
       "3241     [import torch\\r\\nimport numpy as np\\r\\nx = tor...\n",
       "3242     [output_dir = './model_save/'\\r\\nif not os.pat...\n",
       "3243     [import detectron2\\r\\nfrom detectron2.utils.lo...\n",
       "3244     [[13764] WARNING: file already exists but shou...\n",
       "3245     [def plot_loss(train_loss, validation_loss, ti...\n",
       "3246     [[W CudaIPCTypes.cpp:92] Producer process trie...\n",
       "3247     [batch_size = 50\\r\\nvalidation_split = .2\\r\\ns...\n",
       "3248     [import albumentations as A\\r\\ntrain_transform...\n",
       "3249     [def __init__(..., d_model=256, ...):\\r\\n   se...\n",
       "3250     [model = _get_detection_model(num_classes)\\r\\n...\n",
       "3253     [def yolo_body(inputs, num_anchors, num_classe...\n",
       "3254     [!conda install pytorch cpuonly -c pytorch -y ...\n",
       "3255     [class MyTrainData(Dataset):\\r\\n    def __init...\n",
       "3256     [import coremltools as ct\\r\\nimport os\\r\\nimpo...\n",
       "3257     [RuntimeError: Input and hidden tensors are no...\n",
       "3258     [        -------------------------------------...\n",
       "3259     [#Device\\r\\ndevice = torch.device(\"cuda:0\" if ...\n",
       "3260     [df_train=pd.read_csv('CLASSIFIER_train',sep='...\n",
       "3261     [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "3262     [def predict(model, dataloader, device):\\r\\n''...\n",
       "3263     [lloss, dloss, total_loss.backwards(), Runtime...\n",
       "3265     [import torch.nn as nn\\r\\n\\r\\nembed_dim = 4\\r\\...\n",
       "3266     [model.train()\\r\\nrunning_loss = 0\\r\\nrunning_...\n",
       "3268     [self.batch_norm2 = nn.BatchNorm1d(num_filters...\n",
       "3269     [def train(train_loader, net, epoch):\\r\\n\\r\\n ...\n",
       "3270     [import torch.onnx\\r\\n\\r\\nfrom ddpg_agent impo...\n",
       "3271     [10, 1, 0, 1, matplotlib.pyplot.hist, import t...\n",
       "3272     [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "3273     [(8, 2), (8, 4), (8, 6), (8, 3, x), torch.cat,...\n",
       "3274     [fastai, PyTorch, ..., from fastai import *\\r\\...\n",
       "3275     [state, torch.Size([N, 2**n, 2**n]), state[[0,...\n",
       "3276     [train_loader = torch.utils.data.DataLoader(mn...\n",
       "3277     [StackedResidualLSTM(\\r\\n  (encoder): Recurren...\n",
       "3278     [   # Get top 1 prediction for all images\\r\\n ...\n",
       "3279     [class Net(nn.Module):\\r\\n    \\r\\n    def __in...\n",
       "3280     [to_dense(), to_sparse, x = torch.tensor([[[Tr...\n",
       "3281     [import torch\\r\\na = torch.tensor(1, device='c...\n",
       "3282     [tensorflow, pytorch, tanh, import numpy as np...\n",
       "3283     [ #batch_size=256\\r\\n #pred output for single ...\n",
       "3284     [Traceback (most recent call last):\\r\\n  at bl...\n",
       "3285     [data, data.x, from torch_geometric.data impor...\n",
       "3286     [PyTorch, bye, sys.exit(0), {\\r\\n  \"intents\": ...\n",
       "3287     [out = model(...)\\r\\nout=torch.cat([out['hidde...\n",
       "3288     [def get_pad_mask(tokens, i_pad=0):\\r\\n      \"...\n",
       "3289     [all_gather, if gpu == 0:\\r\\n    q = torch.ten...\n",
       "3290     [api.route, detected_images, filtered_images, ...\n",
       "3292     [def train(model,criterion,optimizer,iters):\\r...\n",
       "3293     [--test\\r\\n---pos_label 14, 11051\\r\\n---neg_la...\n",
       "3294     [# globs.shape = [64, 16]\\r\\n# x.shape = [4335...\n",
       "3295     [from catboost import CatBoostRegressor\\r\\nmod...\n",
       "3296     [-fold 1\\r\\n--train\\r\\n---pos_label 42, 32882\\...\n",
       "3297     [`#!/bin/csh\\r\\n\\r\\n#SBATCH --cpus-per-task=1\\...\n",
       "3298     [[1, 2, 3, 4, 5], [0.5, 1, 1.5, 2, 2.5], [[1, ...\n",
       "3299     [target = {}\\r\\n        target['boxes'] = boxe...\n",
       "3300     [validation_epoch_end, validation_step, valida...\n",
       "3301     [import torchvision\\r\\n\\r\\nmodel = torchvision...\n",
       "3302     [class MNIST_model(nn.Module):\\r\\n    def __in...\n",
       "3303     [x, l, x, l, RuntimeError: Expected all tensor...\n",
       "3304     [x = torch.rand((3, 5))\\r\\n, x, y, num_col, x,...\n",
       "3305     [df_train=pd.read_csv('CLASSIFIER_train',sep='...\n",
       "3306     [if f1_scores &lt;= 0.5:\\r\\n        anomaly_st...\n",
       "3307     [(input + 2*padding - filter size)/stride + 1,...\n",
       "3308     [from mxnet import nd, np\\r\\nimport numpy as n...\n",
       "3309     [import torch\\r\\n\\r\\ndef model(x, W, b):\\r\\n  ...\n",
       "3310     [def build_model(dropout_rate=0.5):\\r\\n\\r\\n   ...\n",
       "3311     [output, bin_count=torch.bincount(torch.where(...\n",
       "3313     [\"\"\"\\r\\nfrom psutil import *\\r\\nprint(cpu_coun...\n",
       "3314     [def intersection_over_union(boxes_preds, boxe...\n",
       "3315     [def intersection_over_union(boxes_preds, boxe...\n",
       "3316     [x, x, tf.keras.layers.Embedding(83, 256, batc...\n",
       "3318     [df_train=pd.read_csv('CLASSIFIER_train',sep='...\n",
       "3319     [transforms.Normalize, data_transforms, \\r\\n# ...\n",
       "3320     [classification_dataset = TimeSeriesDataSet(\\r...\n",
       "3321     [df_train=pd.read_csv('CLASSIFIER_train',sep='...\n",
       "3322     [class ClassDataset(Dataset):\\r\\n    def __ini...\n",
       "3323     [torch.save(model, 'model.pt'), model = torch....\n",
       "3324     [class FeedForewardNN(nn.Module):\\r\\n    def _...\n",
       "3325     [import torch\\r\\n\\r\\nx = torch.randn(10, 1)  #...\n",
       "3326     [c = torch.empty(4)\\r\\n\\r\\na = torch.tensor(2....\n",
       "3327     [torch.Tensor.view(), torch.tensor.transpose()...\n",
       "3328     [image.to(torch.float32), targets.to(torch.flo...\n",
       "3329     [import torchmetrics\\r\\ntargets=[]\\r\\npreds=[]...\n",
       "3330     [| W0308 23:13:21.249563    40 sampler.cpp:139...\n",
       "3331     [from transformers import BertTokenizer, BertF...\n",
       "3332     [LR = 0.0001\\r\\noptim = keras.optimizers.Adam(...\n",
       "3333     [class Policy(nn.Module):\\r\\n    \\r\\n    def _...\n",
       "3334     [     def __init__(self,classes):\\r\\n       su...\n",
       "3335     [                                           0 ...\n",
       "3336     [query, key, value, batch_size = 1\\r\\nsequence...\n",
       "3337     [torch.fx.Tracer, call_module, class MyTracer(...\n",
       "3338     [*My Training Model*\\r\\ndef train(model,criter...\n",
       "3340     [from detectron2.engine import DefaultTrainer\\...\n",
       "3342     [TypeError: unsupported operand type(s) for +:...\n",
       "3343     [: No `configure_optimizers()` method defined....\n",
       "3344     [pip,  import torchvision; torchvision.__versi...\n",
       "3345     [pip,  import torchvision; torchvision.__versi...\n",
       "3346     [macs, params = profile(model, inputs=(image, ...\n",
       "3348     [torchio,     RuntimeError                    ...\n",
       "3349     [\\r\\nclass FFC(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "3350     [n_gpu: 0\\r\\n\\r\\narch: \\r\\n    type: MobileNet...\n",
       "3351     [Process, torch.multiprocessing, DistributedSa...\n",
       "3352     [scaler = torch.cuda.amp.GradScaler(enabled = ...\n",
       "3353     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3355     [with open(os.path.join(log_dir, 'scratch_trai...\n",
       "3356     [import os\\r\\nimport torch\\r\\nimport numpy as ...\n",
       "3357     [torch.Size([16, 3, 448, 448])\\r\\n, ----------...\n",
       "3358     [  print (os.getcwd())\\r\\n   /mnt/batch/tasks/...\n",
       "3360     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3361     [class ConvolutionalNet(nn.Module):\\r\\n  def _...\n",
       "3362     [NaN, class AutoEncoder(pl.LightningModule):\\r...\n",
       "3363     [    torch.einsum('aijk,aijh-&gt;ajkh', f, g)\\...\n",
       "3365     [Z, getUpdatedZ, import torch\\r\\nimport torch....\n",
       "3366     [nn.Parameter, some_param = nn.Parameter(data=...\n",
       "3367     [class CharLSTM(nn.Module):\\r\\ndef __init__(se...\n",
       "3368     [# model building\\r\\nclass CNN(nn.Module):\\r\\n...\n",
       "3370     [Lite Interpreter verson number does not match...\n",
       "3371     [torch.nn.init.normal_(nn.Conv2d(1,1,1, 1,1 )....\n",
       "3372     [torch.nn.init.normal_(nn.Conv2d(1,1,1, 1,1 )....\n",
       "3373     [torch.nn.init.normal_(nn.Conv2d(1,1,1, 1,1 )....\n",
       "3374     [x1 = []\\r\\nx2 = []\\r\\nx = []\\r\\n\\r\\nfor s in ...\n",
       "3375     [tensor1, tensor2, a = torch.tensor([[0,5],[1,...\n",
       "3376     [Returns an iterator over module parameters, m...\n",
       "3377     [[], &lt;class 'torch.Tensor'&gt;, tensor([[-5...\n",
       "3378     [[], &lt;class 'torch.Tensor'&gt;, tensor([[-5...\n",
       "3379     [class MyModule(nn.Module):\\r\\n    def __init_...\n",
       "3380     [1)\\r\\nUserWarning: positional arguments and a...\n",
       "3381     [&gt; ValueError                              ...\n",
       "3382     [from transformers import BertTokenizer, BertF...\n",
       "3383     [from simpletransformers.language_representati...\n",
       "3384     [import os\\r\\nimport matplotlib.pyplot as plt\\...\n",
       "3385     [763104351884.dkr.ecr.eu-west-2.amazonaws.com/...\n",
       "3386     [import torch\\r\\nfrom torch.autograd import Fu...\n",
       "3387     [torch.round(), tensor([ 8.5040e+00,  7.3818e+...\n",
       "3388     [torch.round(), tensor([ 8.5040e+00,  7.3818e+...\n",
       "3389     [input_size = 200000\\r\\nhidden_size = 2\\r\\nnum...\n",
       "3390     [class MLP(nn.Module):\\r\\n      def __init__(s...\n",
       "3391     [x, y, class Model(nn.Module):\\r\\n    # コンストラク...\n",
       "3392     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "3394     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "3396     [[1, 1, 1], 0.3, [2, 3, 4], import torch\\r\\nim...\n",
       "3397     [in_t = torch.tensor([[14,  7,  6,  2],\\r\\n   ...\n",
       "3398     [in_t = torch.tensor([[14,  7,  6,  2],\\r\\n   ...\n",
       "3400     [from pytorch_quantization import nn as quant_...\n",
       "3402     [torch.Flatten(), self.mse(), nn.MSELoss(), nn...\n",
       "3403     [os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\", mai...\n",
       "3404     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3405     [n, (n, i, j), (i, j*n), n=2, i=2, j=2, m = to...\n",
       "3406     [split, m = [[2, 3, 5, 7],\\r\\n     [11, 13, 17...\n",
       "3407     [    def forward(self, input):\\r\\n        feat...\n",
       "3408     [import torch\\r\\n\\r\\nsample = torch.arange(0,4...\n",
       "3409     [import torch, torchmetrics\\r\\npreds = torch.t...\n",
       "3410     [data, (B, N, D), B, N, D, data.mean(dim=1), (...\n",
       "3411     [X = X.unsqueeze(-1)\\r\\nY = Y.unsqueeze(-1)\\r\\...\n",
       "3412     [# function to train the model\\r\\ndef train():...\n",
       "3414     [from __future__ import division, print_functi...\n",
       "3415     [x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])\\r\\...\n",
       "3416     [import os\\r\\nimport torch\\r\\nfrom torch.utils...\n",
       "3418     [google colab, google colab, from detectron2.c...\n",
       "3419     [u, x, u(x), u, x, x, x_1, x_2, ..., x_n,  , u...\n",
       "3420     [## Building the neural network\\r\\nimport torc...\n",
       "3421     [class CNN(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "3422     [class Generator(nn.Module):\\r\\n    def __init...\n",
       "3423     [def train_model(model, criterion, optimizer, ...\n",
       "3424     [/usr/local/lib/python3.7/dist-packages/ipyker...\n",
       "3425     [import torch\\r\\n\\r\\ndevice = torch.device('cu...\n",
       "3426     [class ConvolutionalVAE(nn.Module):\\r\\n    \\r\\...\n",
       "3427     [class FeatureEmbedder(nn.Module):\\r\\n    # Di...\n",
       "3428     [hidden_size = 128, num_layers = 2, class LSTM...\n",
       "3429     [feature_path = 'features.pt'\\r\\nfeatures = to...\n",
       "3430     [import torch\\r\\ny_pred = torch.tensor([[0.194...\n",
       "3431     [256x256, 512x512, 1024x1024, batch_size=64, R...\n",
       "3433     [Traceback (most recent call last):\\r\\n  File ...\n",
       "3434     [    import os\\r\\n    import tarfile\\r\\n    im...\n",
       "3435     [logosftmax, softmax, self.softmax = nn.Softma...\n",
       "3436     [pytorch, mkl, conda install ipykernel jupyter...\n",
       "3437     [class Net(nn.Module):\\r\\n        def __init__...\n",
       "3438     [class Net(nn.Module):\\r\\n        def __init__...\n",
       "3439     [length, loss, score = length*f1+loss*f2, A = ...\n",
       "3440     [class CNN_LSTM(nn.Module):    \\r\\ndef __init_...\n",
       "3441     [print(\"Trainloss\", Trainloss) \\r\\n\\r\\nprint(\"...\n",
       "3442     [class Mod(nn.Module):\\r\\n    def __init__(sel...\n",
       "3443     [def _make_convo_layers(architecture) -&gt; to...\n",
       "3444     [def apply_nms(orig_prediction, iou_thresh=0.3...\n",
       "3445     [def apply_nms(orig_prediction, iou_thresh=0.3...\n",
       "3446     [a = [[1,1,1], [2,2,2], [3,3,3]], b = [0,0,0],...\n",
       "3447     [a = [[1,1,1], [2,2,2], [3,3,3]], b = [0,0,0],...\n",
       "3448     [a = [[1,1,1], [2,2,2], [3,3,3]], b = [0,0,0],...\n",
       "3449     [test_path = \"asl_data/test/\" #path to the fol...\n",
       "3451     [cudaLaunchKernel, ---------------------------...\n",
       "3452     [CUDA time avg, aten::conv2d, 22us, 3ms, 512, ...\n",
       "3453     [torch-sparse, pip install torch-scatter -f ht...\n",
       "3454     [def get_samples_from_component(self,batchSize...\n",
       "3455     [torch.quantization.fuse_modules(model, module...\n",
       "3456     [# example 1\\r\\nimport torch\\r\\na = torch.rand...\n",
       "3457     [logits_tensor, (1910, 164, 33), logits_tensor...\n",
       "3458                                [image_urls, offer_id]\n",
       "3460     [pipenv install torch, pipenv install --extra-...\n",
       "3461     [h = g(W1.input1 + V1.input2 + b)\\r\\noutput1 =...\n",
       "3462     [h = g(W1.input1 + V1.input2 + b)\\r\\noutput1 =...\n",
       "3463     [h = g(W1.input1 + V1.input2 + b)\\r\\noutput1 =...\n",
       "3464     [Index out of range, cd = CustomDataset(df)\\r\\...\n",
       "3465     [class SequenceClassifier(nn.Module):\\r\\n\\r\\n ...\n",
       "3466     [class SequenceClassifier(nn.Module):\\r\\n\\r\\n ...\n",
       "3467     [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "3468     [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "3469     [[W TensorImpl.h:1408] Warning: Named tensors ...\n",
       "3470     [IndexError: index out of range in self, impor...\n",
       "3471     [from torchvision import transforms as torchtr...\n",
       "3472     [torchmetrics.Accuracy, import torch, torchmet...\n",
       "3473     [torchmetrics.Accuracy, import torch, torchmet...\n",
       "3475     [kwargs = {\"alpha\": 0.25, \"gamma\": 2.0, \"reduc...\n",
       "3476     [LightningModule, test_step, def test_step(sel...\n",
       "3477     [x0 = torch.tensor([1.5, .1])\\r\\nQ = torch.ten...\n",
       "3478     [class MixModel(nn.Module):\\r\\n    def __init_...\n",
       "3479     [params, x, params[i], y, loss.backward(), par...\n",
       "3480     [params, x, params[i], y, loss.backward(), par...\n",
       "3481     [    PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) ...\n",
       "3482     [checkpoint = {'state_dict': model.state_dict(...\n",
       "3484     [scripted_model = torch.jit.trace(detector.mod...\n",
       "3485     [M = torch.Tensor([[[[2.4,5.5,1], [3.44,5.43,1...\n",
       "3486     [t, l=(5,4,6), t, l, # Case when the subset le...\n",
       "3487     ['''\\r\\n\\r\\nrun simulation and store \\r\\n    1...\n",
       "3488     [pytorch, conda, Intel MKL FATAL ERROR: This s...\n",
       "3489     [pytorch, conda, Intel MKL FATAL ERROR: This s...\n",
       "3490     [string_input = \"The cat is black\" \\r\\ntokens_...\n",
       "3491     [class CrossEntropyLoss2d(torch.nn.Module):\\r\\...\n",
       "3492     [Pytorch, model.layers[-1].output_shape # tens...\n",
       "3494     [numpy, torch.from_numpy(x), import torch \\r\\n...\n",
       "3495     [Input1 --&gt; CNNLayer \\r\\n                  ...\n",
       "3496     [class MixModel(nn.Module):\\r\\n    def __init_...\n",
       "3498     [focal loss, # IMPLEMENTATION CREDIT: https://...\n",
       "3499     [# packages in environment at C:\\Users\\noami\\a...\n",
       "3500     [Traceback (most recent call last):\\r\\n, if ha...\n",
       "3501     [torch.nn.CosineEmbeddingLoss, loss_function =...\n",
       "3502     [class MixModel(nn.Module):\\r\\n    def __init_...\n",
       "3503     [Solving environment: | Killed , conda install...\n",
       "3504     [sum(u - grad_x(network(x))), u, x, funcApprox...\n",
       "3505     [nb_epoch = 10\\r\\nfor epoch in range(1, nb_epo...\n",
       "3506     [import torch\\r\\nfrom torchvision import model...\n",
       "3507     [torch.no_grad(), RuntimeError: Only Tensors o...\n",
       "3509     [train_one_epoch, evaluate, model.train(), @to...\n",
       "3510     [train_one_epoch, evaluate, model.train(), @to...\n",
       "3511     [train_one_epoch, evaluate, model.train(), @to...\n",
       "3512     [from torchvision import datasets\\r\\nimport to...\n",
       "3513     [from torchvision import datasets\\r\\nimport to...\n",
       "3514     [Feature: [tensor(150), tensor(1., dtype=torch...\n",
       "3515     [0, 1, 1500, class Net(nn.Module):\\r\\n    def ...\n",
       "3516     [0, 1, 1500, class Net(nn.Module):\\r\\n    def ...\n",
       "3520     [# shape = (6, 3)\\r\\nA = torch.tensor([[1, 2, ...\n",
       "3521     [# Load data\\r\\ntrainset = datasets.MNIST('~/....\n",
       "3522     [Traceback (most recent call last):   File \"tr...\n",
       "3523     [RuntimeError: Expected all tensors to be on t...\n",
       "3524     [ds = load_dataset(\"common_voice\", 'zh-TW', sp...\n",
       "3525     [tensor = torch.Tensor([[1., 0., 0., 0., 0.],\\...\n",
       "3527     [512 x 64 x 64, 512 x 56 x 56, gray, copy and ...\n",
       "3528     [class BertClassifier(nn.Module):\\r\\n    def _...\n",
       "3529     [torch.utils.data.dataset, import torch\\r\\nimp...\n",
       "3530     [dataset = ImageFolderWithPaths(\\r\\n    data_d...\n",
       "3531     [BertForSequenceClassification, transformers, ...\n",
       "3534     [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "3535     [A = tensor([[[6, 3, 8, 3],\\r\\n         [1, 0,...\n",
       "3536     [A = tensor([[[6, 3, 8, 3],\\r\\n         [1, 0,...\n",
       "3537     [RuntimeError: DataLoader worker exited unexpe...\n",
       "3538     [AttributeError: 'list' object has no attribut...\n",
       "3539     [ValueError: not enough values to unpack (expe...\n",
       "3540     [if __name__== '__main__':\\r\\n    model= UNet(...\n",
       "3541     [Implement a neural network for a generator wi...\n",
       "3542     [(400, 46, 55, 46), 46,55,46, np.max(data[1]),...\n",
       "3544     [class ClassifierModel(nn.Module):\\r\\ndef __in...\n",
       "3545     [WeightedRandomSampler, # 1st attempt\\r\\nself....\n",
       "3546     [---------------------------------------------...\n",
       "3547     [def activation_func(input):\\r\\n\\r\\n    for ba...\n",
       "3548     [def training(self, epoch):\\r\\n    self.model....\n",
       "3549     [x = torch.tensor([[1], [1], [1], [1], [1]], d...\n",
       "3550     [validation_step, class DialogActsLightningMod...\n",
       "3553     [yolov5/utils/flask_rest_api/restapi.py, model...\n",
       "3554     [    def forward(self, imgs):\\r\\n      \"\"\"It t...\n",
       "3555     [import os\\r\\nimport numpy as np\\r\\nimport tor...\n",
       "3556     [BertClassifier(\\r\\n  (bert): BertModel(\\r\\n  ...\n",
       "3557     [nn.Conv3d(in_channels=128, out_channels=64, k...\n",
       "3558     [datasetA=[1.jpg,2.jpg,..........n.jpg] // RGB...\n",
       "3559     [#Model Creation \\r\\nimport torch \\r\\nimport r...\n",
       "3560     [std::vector&lt;std::vector&lt;float&gt;&gt; v...\n",
       "3561     [# Example of target with class indices\\r\\nlos...\n",
       "3563     [import torch\\r\\n\\r\\n# Make some data\\r\\ntorch...\n",
       "3564     [wavernn = WaveRNN(upsample_scales=[5,5,8], n_...\n",
       "3565     [A, (b, 2, x, y), B, (b, 2, x, y, 3), dim=1, A...\n",
       "3566     [.ckpt, import torch\\r\\nimport torch.nn as nn\\...\n",
       "3567     [import torch\\r\\ntorch.manual_seed(1)\\r\\nfeatu...\n",
       "3568     [import torch\\r\\ntorch.manual_seed(1)\\r\\nfeatu...\n",
       "3570     [lista2 = [0, 60, 120, 180, 240, 300, 360, 420...\n",
       "3571     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "3573     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "3574     [import torch\\r\\nimport numpy as np\\r\\n\\r\\na =...\n",
       "3575     [class Data_set(Dataset):\\r\\n    \\r\\n    def _...\n",
       "3576     [## data loader\\r\\ndef create_balanced_DataLoa...\n",
       "3577     [#!/usr/bin/env python3\\r\\nimport pdb\\r\\nimpor...\n",
       "3578     [def Exec_ShowImgGrid(ObjTensor, NumCh=1, NumS...\n",
       "3579     [RuntimeError: Found dtype Double but expected...\n",
       "3581     [import torch\\r\\na1, a2 = torch.tensor([1,2], ...\n",
       "3582     [data_dir = 'tiny-224/'\\r\\nnum_workers = {'tra...\n",
       "3583     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "3584     [(user, item), user_emb = torch.nn.Embedding(n...\n",
       "3585     [from transformers import AutoTokenizer, AutoM...\n",
       "3586     [def _segm_model(name, backbone_name, num_clas...\n",
       "3587     [Compiled slug size: 789.8M is too large (max ...\n",
       "3588     [Compiled slug size: 789.8M is too large (max ...\n",
       "3589     [Compiled slug size: 789.8M is too large (max ...\n",
       "3590     [Compiled slug size: 789.8M is too large (max ...\n",
       "3591     [log = {\\r\\n            \"total_reward\": torch....\n",
       "3592     [import torch\\r\\nimport torchvision\\r\\n\\r\\nimp...\n",
       "3593     [from transformers import AutoTokenizer, AutoM...\n",
       "3594     [import torch \\r\\nimport torch.nn.functional a...\n",
       "3595                                    [[1,2,3], 1, 2, 3]\n",
       "3596     [.csv, .csv, node,feature1,feature2,feature3\\r...\n",
       "3597     [features, avgpool, classifier, model = torch....\n",
       "3599     [class Bert_CRF(BertPreTrainedModel):\\r\\ndef _...\n",
       "3600     [w = f(v), Lv = q+Dw, w, v, q, D, L, D, [l1  0...\n",
       "3601     [if(optim_argument):\\r\\n    optimizers = [torc...\n",
       "3602     [// scatter.h\\r\\n#include &lt;iostream&gt;\\r\\n...\n",
       "3603     [torch.nn.Conv2d?, (N, C_{\\text{in}}, H, W), (...\n",
       "3604                              [npx react-native start]\n",
       "3606     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "3607     [poly = PolynomialFeatures(2,interaction_only=...\n",
       "3609     [hyperparam_input_neurons = 54\\r\\nhyperparam_h...\n",
       "3610     [def backpropagation(model, y_true, y_pred):\\r...\n",
       "3611     [File ~/Library/Python/3.9/lib/python/site-pac...\n",
       "3612     [!pip install pytorch-lightning==0.9.0 \\r\\nimp...\n",
       "3613     [!pip install pytorch-lightning==0.9.0 \\r\\nimp...\n",
       "3614     [targets = torch.flatten(target_tensor)\\r\\npre...\n",
       "3615     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3616     [Traceback (most recent call last):\\r\\n  File ...\n",
       "3617     [import torch\\r\\nfrom transformers import Auto...\n",
       "3618     [diam_int,diam_est,ok\\r\\n37.782,125.507,0\\r\\n4...\n",
       "3619     [w = torch.normal(0, 0.01, size=(2,1), require...\n",
       "3620                                 [A[i, j, :], B[i, j]]\n",
       "3621     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "3622     [pip3 install torch==1.10.2+cu113 torchvision=...\n",
       "3623     [...\\r\\nfrom joblib import Parallel, delayed, ...\n",
       "3624     [def train(train_loader, MLP, epoch, criterion...\n",
       "3625     [p = \"path/to/image\"\\r\\np = Image.open(p)\\r\\np...\n",
       "3626     [class PytorchLayer(nn.Module):\\r\\n    def __i...\n",
       "3627     [from matplotlib import pyplot as plt\\r\\nimpor...\n",
       "3628     [Sum of input lengths does not equal the lengt...\n",
       "3630     [class VAE(pl.LightningModule):\\r\\n\\r\\n\\r\\n\\r\\...\n",
       "3631     [torch.utils.data.Dataset, __getitem__, class ...\n",
       "3632     [torch.utils.data.Dataset, __getitem__, class ...\n",
       "3633     [max(), 1, import torch\\r\\nimport torch.nn as ...\n",
       "3634     [lambda = 1\\r\\nxi = 1e-3\\r\\n\\r\\ntotal_tasks = ...\n",
       "3635     [from transformers import RobertaModel\\r\\nimpo...\n",
       "3636     [AttributeError: 'function' object has no attr...\n",
       "3637     [x.py, y.py, y.py, A, B, A, B, run, x.py, A, f...\n",
       "3638     [import numpy as np\\r\\nimport random\\r\\nimport...\n",
       "3639     [InceptionResnetV1, pytorch_facenet, model.las...\n",
       "3640     [tmp = torch.tensor([[ 0,  0,  0,  0,  1,  1, ...\n",
       "3641     [struct TestNet : torch::nn::Module {\\r\\n\\r\\n ...\n",
       "3642     [import torch\\r\\nimport numpy as np\\r\\n\\r\\na =...\n",
       "3643     [import torch\\r\\nimport numpy as np\\r\\n\\r\\na =...\n",
       "3645     [Gathers candidate values according to IDs.\\r\\...\n",
       "3646     [-, folder0\\r\\n-cats\\r\\n-dogs\\r\\n\\r\\nfolder1\\r...\n",
       "3647     [test_model.py, import numpy as np\\r\\nimport j...\n",
       "3648     [def caption_image_beam_search(encoder, decode...\n",
       "3649     [from datasets import load_dataset\\r\\nfrom tra...\n",
       "3650     [(line 138) pdb.set_trace()\\r\\n\\r\\n(line 140) ...\n",
       "3651     [y=self.linear(out), import torch\\r\\nimport to...\n",
       "3652     [Learner, loss.backward(), AttributeError: 'No...\n",
       "3653     [conda install pytorch torchvision torchaudio ...\n",
       "3654     [conda install pytorch torchvision torchaudio ...\n",
       "3655     [Pytorch, torch.einsum(), torch.bmm, class Sel...\n",
       "3656     [map style, IterableDataset, class VisionTrans...\n",
       "3657     [import torch.nn.functional as F\\r\\nclass AEC(...\n",
       "3658     [sys.path.append('..')\\r\\nfrom utils import *\\...\n",
       "3659     [{'age': {'f1': 0.9339622641509434,\\r\\n       ...\n",
       "3660     [[m.state_dict() for m in models], ReferenceEr...\n",
       "3661     [def train_loop(dataloader, model, optimizer):...\n",
       "3662     [def federated_learning(diagnosis_title, hospi...\n",
       "3663     [import torch \\r\\nimport transformers\\r\\nmodel...\n",
       "3664     [import torch\\r\\nimport torch.functional as F\\...\n",
       "3665     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3666     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3667     [from torch import tensor\\r\\n\\r\\ndef foo(x):\\r...\n",
       "3668     [import torch\\r\\nimport cv2\\r\\nimport numpy as...\n",
       "3669     [import os\\r\\nfrom torchvision import transfor...\n",
       "3670     [    for epoch in range(max_epochs):  # loop o...\n",
       "3671     [import torch\\r\\nimport os\\r\\nfrom torchvision...\n",
       "3672     [import torch \\r\\nimport torch.nn.functional a...\n",
       "3673     [#%% import file\\r\\n\\r\\ndf = pd.read_csv('coor...\n",
       "3674     [enter code here:\\r\\n    def freeze_model(mode...\n",
       "3675     [x = x.to(memory_format=torch.channels_last)\\r\\n]\n",
       "3676     [state_action_values = net(t_states_features)....\n",
       "3677     [def evaluate(self, batch, stage=None):\\r\\n   ...\n",
       "3678     [U1, ||X-(U1 @ U1.T)@X||^2, U1.T, U1, @, ||, X...\n",
       "3679     [class TSModel(pl.LightningModule):\\r\\n    def...\n",
       "3680     [class TSModel(pl.LightningModule):\\r\\n    def...\n",
       "3681     [ import torch\\r\\n sp_mat = torch.sparse_coo_t...\n",
       "3682     [import torch.utils.data as data_utils\\r\\n\\r\\n...\n",
       "3683     [torch.arange(0, 3).view(-1, *[1]*3)\\r\\n, tens...\n",
       "3684     [def train_model(train_dl, model):\\r\\n    # de...\n",
       "3685     [from torch import nn\\r\\nimport torch\\r\\nfrom ...\n",
       "3686     [@property\\r\\n    def sample_shape(self):\\r\\n ...\n",
       "3687                        [has_storage(), torch::Tensor]\n",
       "3689     [(grid / torch.max(grid) - 0.5) * 2, def bilin...\n",
       "3690     [scale = torch.tensor([[1.0824, 1.0296, 1.0065...\n",
       "3691     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "3692     [[0, 0, 0, 0], import torch\\r\\nimport torch.di...\n",
       "3693     [def evaluate(model, val_dataloader):\\r\\n    \"...\n",
       "3694     [    def hook_t(module, input, output):\\r\\n   ...\n",
       "3695     [class MnistCNN(nn.Module):\\r\\n    def __init_...\n",
       "3696     [import torch\\r\\nx = torch.linspace(-5, 5, 200...\n",
       "3698     [def inhouse_model(row) -&gt; \"pos or neg clas...\n",
       "3699     [---------------------------------------------...\n",
       "3700     [class AlexNet(nn.Module):\\r\\ndef __init__(sel...\n",
       "3701     [class BertClassifier(nn.Module):\\r\\n    \"\"\"\\r...\n",
       "3702     [cn_loss = torch.nn.CrossEntropyLoss(weight=tr...\n",
       "3704     [import os\\r\\nfrom statistics import mode\\r\\nf...\n",
       "3706     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "3707     [gauss_train_loader = torch.utils.data.DataLoa...\n",
       "3708     [gauss_train_loader = torch.utils.data.DataLoa...\n",
       "3709     [mnist_trainset = datasets.MNIST(root='./data'...\n",
       "3710     [tokenizer(\"hello, my name\", truncation=True, ...\n",
       "3711     [...\\r\\nFile \"/home/ubuntu/stylegan3/training/...\n",
       "3712     [    // run not okay\\r\\n    // Create a vector...\n",
       "3714     [torch_pretrained = torchvision.models.alexnet...\n",
       "3715     [cmake .., CMake Error: The following variable...\n",
       "3716     [class ResBlock(nn.Module):\\r\\n    def __init_...\n",
       "3717     [class CatDogDataset(Dataset):\\r\\n    \\r\\n    ...\n",
       "3718     [class CustomDataset(Dataset):\\r\\n    def __in...\n",
       "3719     [seq = Sequential()\\r\\n\\r\\nseq.add(ConvLSTM2D(...\n",
       "3720     [# preprocessing\\r\\ndata_transform = transform...\n",
       "3721     [from functools import partial\\r\\nfrom torchvi...\n",
       "3722     [def _ntuple(n):\\r\\n    def parse(x):\\r\\n     ...\n",
       "3723     [tensor([[17,  0],\\r\\n        [93,  0],\\r\\n   ...\n",
       "3725     [torch.nn.CrossEntropyLoss, y_est, [batch_size...\n",
       "3726     [f, R^n -&gt; R, a = torch.ones(n,)\\r\\n\\r\\nb =...\n",
       "3727     [from torch import nn\\r\\nfrom pytorch_lightnin...\n",
       "3728     [float, torch.Tensor, torch.float32, a = torch...\n",
       "3730     [skorch, sklearn, import torch\\r\\nimport numpy...\n",
       "3732     [AttributeError: 'Tensor' object has no attrib...\n",
       "3733     [f, f = lambda x: torch.sum(x)  # sum across a...\n",
       "3734     [import torch\\r\\nimport torchvision\\r\\n\\r\\nmod...\n",
       "3735     [for name, layer in model.named_modules():\\r\\n...\n",
       "3736     [triangular_solve, .pow(2), detect_anomaly, to...\n",
       "3737     [vector&lt;torch::tensor&gt;, int a = 10;\\r\\ns...\n",
       "3738     [torch.Size([27])\\r\\ntorch.Size([27, 20])\\r\\nt...\n",
       "3739     [def __init__(self, n_features, hidden_size, b...\n",
       "3740     [__getitem__, from typing import List, Tuple, ...\n",
       "3741     [    os.makedirs(\"./outputs/model\", exist_ok=T...\n",
       "3742     [loadedM = AE3class(encoded_space_dim=2,NumFL1...\n",
       "3743     [# install dependency\\r\\npip install astunpars...\n",
       "3744     [# Grab a batch of real images from the datalo...\n",
       "3745     [X_test, list[list], y_test, list[Path], first...\n",
       "3746     [    for log_prob, value, R in zip(log_prob_li...\n",
       "3747     [def generate_batch(data_batch):\\r\\n  src_batc...\n",
       "3748     [with torch.no_grad():\\r\\n  params = params - ...\n",
       "3749     [class tempModel(nn.Module):\\r\\ndef __init__(s...\n",
       "3750     [yyyyyyyyyyyyyyyyyyyy\\r\\n, PDDFTGCVIAWNSNNLDSK...\n",
       "3751     [v = integrate.quad(lambda self,s: (torch.Tens...\n",
       "3752     [[batch_size, (4 + 1 + num_classes) * num_anch...\n",
       "3753     [import torch.nn.functional as F\\r\\n\\r\\nclass ...\n",
       "3754     [matrice1 = temp.unsqueeze(0)  \\r\\nprint(M.sha...\n",
       "3756     [fig = plt.figure()\\r\\nax = fig.add_subplot(11...\n",
       "3757     [class Model_LSTM(nn.Module):\\r\\n\\r\\n    def _...\n",
       "3759     [class psiModel(nn.Module):\\r\\ndef __init__(se...\n",
       "3760     [tensor([[0, 5],\\r\\n        [1, 4],\\r\\n       ...\n",
       "3761                    [nn.BCEWithLogitsLoss, pos_weight]\n",
       "3762     [txt = \"This was nice place\"\\r\\nmodel = transf...\n",
       "3763     [torch.Size([22]), tensor([-20.1659, -19.7022,...\n",
       "3764              [Dataset, [0,180], __getitem__, Dataset]\n",
       "3765     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "3766     [---------------------------------------------...\n",
       "3767     [from transformers import MBartForConditionalG...\n",
       "3769     [data = b1.send(bob)\\r\\ndata.shape  # torch.Si...\n",
       "3770     [def dataload(self,train_path,batch_train,test...\n",
       "3771     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "3772     [CUDA out of memory, Model, device = torch.dev...\n",
       "3773     [seq_model = nn.Sequential(\\r\\nnn.Linear(1, 13...\n",
       "3774     [In [16]: MLP\\r\\nOut[16]:\\r\\nDecoderMLP(\\r\\n  ...\n",
       "3775     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3776     [In[2]   tokenizer = T5Tokenizer.from_pretrain...\n",
       "3777     [# Custom dataloader \\r\\n\\r\\nfrom torch.utils....\n",
       "3778     [import torch\\r\\n\\r\\nimport detectron2\\r\\nfrom...\n",
       "3780     [setup(), mp.spawn(), def setup(rank, world_si...\n",
       "3781     [class BertClassifier(nn.Module):\\r\\n    \"\"\"\\r...\n",
       "3782     [torch.gather(), [2, 4, 3], [2,2,3], torch.gat...\n",
       "3783     [torch.gather(), [2, 4, 3], [2,2,3], torch.gat...\n",
       "3785     [num_workers=0, /opt/conda/lib/python3.6/site-...\n",
       "3786     [class CustomClass:\\r\\n    def __init__(self, ...\n",
       "3787     [Traceback (most recent call last):\\r\\n  File ...\n",
       "3788     [from torch import FloatTensor\\r\\n\\r\\ndef new_...\n",
       "3789     [cuda = torch.cuda.is_available()\\r\\nfor data,...\n",
       "3790     [!pip install -U -q PyDrive\\r\\nfrom pydrive.au...\n",
       "3791     [L, S, S, S, L, L, L, L, L, import torch\\r\\nim...\n",
       "3792     [Efficientnet-b6, PyTorch, Fastai, PATH = '../...\n",
       "3793                                     [n x 3, n, n x 3]\n",
       "3794     [val_score: 0.0, from argparse import Argument...\n",
       "3795     [pytorch-lightening, forward(), nn.LSTM(... bi...\n",
       "3797     [l = [ list(range(1000)),list(range(1000,2000)...\n",
       "3798     [import torch\\r\\n\\r\\nclass TensorWrapper(torch...\n",
       "3800     [train_dataset = torchvision.datasets.FashionM...\n",
       "3801     [                _controller.startImageStream(...\n",
       "3802     [def train(data_loader, model, optimizer, sche...\n",
       "3803     [value = torch.zeros(3) # [0, 0, 0]\\r\\nindex =...\n",
       "3804     [auto output_tensors = torch::from_blob(output...\n",
       "3805     [from vision_transformer_pytorch import Vision...\n",
       "3806     [num_epochs = 5\\r\\neval_every = len(train_load...\n",
       "3807     [nn.CrossEntropyLoss, nn.CrossEntropyLoss, cla...\n",
       "3808     [ from torchvision.models.utils import load_st...\n",
       "3809     [total_timesteps=, model.learn(), stables_base...\n",
       "3810     [A = torch.tensor([1, 2, 3, 4])\\r\\n, ind1 = to...\n",
       "3811     [def train(num_epoch = 10,len_vocab = 1, num_h...\n",
       "3812     [python -m torch.distributed.run --nproc_per_n...\n",
       "3813     [class Model_GRU_1(nn.Module):\\r\\n\\r\\n    def ...\n",
       "3814     [initialize_config_dir(config_dir=exp_dir, \".h...\n",
       "3815     [22059265, 17488129, 1e+02, 2.6e+02, class RNe...\n",
       "3817     [pip install torch, C:\\Users\\Ahmad Sadek&gt;pi...\n",
       "3818     [def activation():\\r\\n    # return nn.Sin()\\r\\...\n",
       "3819     [def activation():\\r\\n    # return nn.Sin()\\r\\...\n",
       "3820     [def my_loss(y_recon, y_real, brain_hidden, br...\n",
       "3821     [pip install allennlp==1.0.0 allennlp-models==...\n",
       "3822     [pip install torch &gt;= 1.7.1, ERROR: Could n...\n",
       "3823     [M, M.clone(), M.clone(), requires_grad=False,...\n",
       "3825     [import torch\\r\\nimport torch.multiprocessing ...\n",
       "3826     [class NER(object):\\r\\n    def __init__(self, ...\n",
       "3827     [loss, pred_labels, val, test, class Classifie...\n",
       "3828     [tensor([[[[0.1352, 0.5110, 0.7585,  ..., 0.90...\n",
       "3829     [import torch\\r\\n\\r\\nuse_cuda = torch.cuda.is_...\n",
       "3830     [process(),  def process(self, images, edges, ...\n",
       "3833     [Qualcomm Snapdragon 821 w/ 4GB LPDDR4 1866MHz...\n",
       "3834     [model = Sequential()\\r\\nmodel.add(LSTM(100, a...\n",
       "3836     [cv2.VideoCapture, import time\\r\\nimport cv2\\r...\n",
       "3837     [import transformers\\r\\nfrom transformers impo...\n",
       "3838                                       [dtype, Tensor]\n",
       "3839     [import glob\\r\\nimport cv2\\r\\nimport numpy as ...\n",
       "3840     [X.shape = (10000,), y = [0, 7, 9995], [\\r\\n X...\n",
       "3841     [X.shape = (10000,), y = [0, 7, 9995], [\\r\\n X...\n",
       "3843     [ minibatch = torch.rand ((4, 2))\\r\\n    \\r\\n ...\n",
       "3844     [AssertionError                            Tra...\n",
       "3845     [.grad, None, #!/usr/bin/env python3\\r\\n#\\r\\n#...\n",
       "3846     [feature_extractor = DetrFeatureExtractor(retu...\n",
       "3847     [step(), class DPSGD(torch.optim.SGD):\\r\\n    ...\n",
       "3850     [    def __init__(self, adjacency: np.array):\\...\n",
       "3851     [embedding(), class RNNClassifier(nn.Module):\\...\n",
       "3852     [for epoch in range(n_iters):\\r\\n  y_hat = for...\n",
       "3853     [class MyDataSet(torch.utils.data.Dataset):\\r\\...\n",
       "3854     [a, ba,c,h,w, a, b, ba,2, dtype=torch.int16, b...\n",
       "3855     [def accuracy_multi1(inp, targ, thresh=0.5, si...\n",
       "3856     [Collecting package metadata (current_repodata...\n",
       "3857     [---------------------------------------------...\n",
       "3858     [def doubly_stochastic_normalise(E):\\r\\n    \"\"...\n",
       "3859     [AttributeError: Caught AttributeError in Data...\n",
       "3860     [AttributeError: Caught AttributeError in Data...\n",
       "3861     [for episode in range(n_episodes):\\r\\n        ...\n",
       "3862     [auto ToTensor(cv::Mat img, bool show_output =...\n",
       "3863     [for epoch in range(epochs):\\r\\n    with tqdm(...\n",
       "3864     [---------------------------------------------...\n",
       "3865     [track_higher_grads, track_higher_grads=False,...\n",
       "3866     [import hiddenlayer as hl\\r\\n\\r\\nmodel1 = torc...\n",
       "3867     [   for images, targets in metric_logger.log_e...\n",
       "3868     [# loop through images\\r\\nfor inputs in tqdm(i...\n",
       "3869     [input shape: 16 32 32 3\\r\\nindex shape: 16 32...\n",
       "3870     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "3871     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "3872     [Traceback (most recent call last):\\r\\n  File ...\n",
       "3873     [class Net(nn.Module):\\r\\n        def __init__...\n",
       "3874     [224 x 224, 16x16, 196, uf = nnf.unfold(img, k...\n",
       "3875     [hyperparam_input_neurons = 54\\r\\nhyperparam_h...\n",
       "3876     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "3878     [flutter:\\r\\n  uses-material-design: true\\r\\n ...\n",
       "3879     [def finetune_resnet(file_train_classes, file_...\n",
       "3880     [glBindTexture(GL_TEXTURE_2D, imageTexture.get...\n",
       "3882     [class SimpleRNN(nn.Module):\\r\\ndef __init__(s...\n",
       "3884     [# X.shape = (batch, M, D)\\r\\n# Y.shape = (N, ...\n",
       "3885     [cnn = torchvision.models.resnet50(pretrained=...\n",
       "3887     [class LSTM(nn.Module):\\r\\n\\r\\n  def __init__(...\n",
       "3888     [    raise NotSupportedError(ctx_range, _varar...\n",
       "3889     [0: {\"sentence\": ['word_1', 'word_2', 'word_3'...\n",
       "3890     [class MiniImageNet(Dataset):\\r\\n\\r\\n    def _...\n",
       "3891     [class MiniImageNet(Dataset):\\r\\n\\r\\n    def _...\n",
       "3892     [a, myfunc(a, b, c, d), myfunc(), myfunc(a, b,...\n",
       "3893     [(&lt;class 'RuntimeError'&gt;, RuntimeError('...\n",
       "3896     [class DivisiveNormBlock(nn.Module):\\r\\n\\r\\n  ...\n",
       "3897     [ mean_train = torch.Tensor(np.mean(train_vert...\n",
       "3898     [ mean_train = torch.Tensor(np.mean(train_vert...\n",
       "3899     [tokenizer = AutoTokenizer.from_pretrained(\"He...\n",
       "3900     [class ConvNeuralNet(nn.Module):\\r\\n#  Determi...\n",
       "3903     [from numpy import eye, log\\r\\nfrom scipy.stat...\n",
       "3904     [root_dir\\r\\n│\\r\\n└───folder1\\r\\n│   │   file0...\n",
       "3905     [root_dir\\r\\n│\\r\\n└───folder1\\r\\n│   │   file0...\n",
       "3906     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "3907     [# Specify path to MNIST dataset-\\r\\npath_to_d...\n",
       "3908     [/usr/local/lib/python3.7/dist-packages/torch/...\n",
       "3909     [class Predict_segmentation:\\r\\n\\r\\n    def __...\n",
       "3910     [pytorch, all_reduce,  print(f'{rank=}, before...\n",
       "3911     [#SBATCH --mem-per-cpu=20G\\r\\n#SBATCH --cpus-p...\n",
       "3912     [rnn_model2_cov = RNNModel(model= 'GRU',     \\...\n",
       "3913     [rnn_model2_cov = RNNModel(model= 'GRU',     \\...\n",
       "3914     [for i in range(2):\\r\\n\\r\\n    X_fake = gen_mo...\n",
       "3915     [import torch\\r\\nimport clip\\r\\nfrom glob impo...\n",
       "3916     [RuntimeError                              Tra...\n",
       "3917     [class DivisiveNormBlock(nn.Module):\\r\\n\\r\\nde...\n",
       "3918     [def _branch_routings(self):\\r\\n# structure = ...\n",
       "3919     [class FullyConnected(nn.Sequential):\\r\\n\\r\\n\"...\n",
       "3921     [Z = np.random.choice([0,1],size=(100,100))\\r\\...\n",
       "3922     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3923     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3924     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3925     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3926     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3927     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3928     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3929     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3930     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3931     [pip install -U steem\\r\\n, pycrypto, pip insta...\n",
       "3932     [from torchmetrics import Accuracy\\r\\naccuracy...\n",
       "3933     [torch.randint(5,7,(100,))\\r\\n\\r\\ntensor([6, 6...\n",
       "3934     [torch.randint(5,7,(100,))\\r\\n\\r\\ntensor([6, 6...\n",
       "3935     [import torch \\r\\n, inputs = torch.tensor([[[[...\n",
       "3936     [train[0][0].shape \\r\\n(4096,)\\r\\n, from colle...\n",
       "3937     [class Trainer():\\r\\n  def __init__(self,param...\n",
       "3939     [x = torch.randn(3,64,161,161)\\\\r\\nmodel = nn....\n",
       "3940     [OrderedDict([('first', tensor([[[ 0.4713, -0....\n",
       "3941     [LSTMClassifier, forward(), tag_space = self.c...\n",
       "3942     [python train.py --config=yolact_resnet50_cig_...\n",
       "3943     [224x224, 16x16, (16*16), (224*224), 224x224, ...\n",
       "3944     [class CustomDataset(torch.utils.data.Dataset)...\n",
       "3945     [torch.cartesian_prod(*tensors), UserWarning: ...\n",
       "3946     [datalist, torch_geometric.data.Data, num_node...\n",
       "3947     [datalist, torch_geometric.data.Data, num_node...\n",
       "3949     [mnist_train = torchvision.datasets.MNIST(root...\n",
       "3950     [import torch.multiprocessing as mp\\r\\n\\r\\ncla...\n",
       "3951     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3952     [python generate.py --outdir=out --trunc=1 --s...\n",
       "3953     [sample = torch.tensor(\\r\\n    [[2, 7, 3, 1, 1...\n",
       "3954     [import torch\\r\\nfrom models.deit import deit_...\n",
       "3955                                       [2n x m, n x m]\n",
       "3956     [pip install torch==1.4.0+cu92 torchvision==0....\n",
       "3961     [importlib, import torch.nn as nn\\r\\nimport to...\n",
       "3962     [N_train = int(0.8*len(df))\\r\\ntrain_ds,test_d...\n",
       "3963     [# Initialization\\r\\nvar_model_statemapper = N...\n",
       "3964     [train_net.py --config-file our_training_confi...\n",
       "3965     [class Predict:\\r\\n    def __init__(self, file...\n",
       "3966     [class BO:\\r\\n    def __init__(self):\\r\\n     ...\n",
       "3967     [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "3968     [torchaudio, collate_fn, def pad_sequence(batc...\n",
       "3970     [from sklearn.cluster import KMeans\\r\\n# from ...\n",
       "3971                            [n x 3, torch.linalg.norm]\n",
       "3972     [data = torch.Tensor([0.5,0.4,1.2,1.1,0.4,0.4]...\n",
       "3974     [GraphConv, GCNConv, embedding_size, 1479, Run...\n",
       "3975     [class CustomNN(torch.nn.Module):\\r\\n    def _...\n",
       "3976     [LABEL VECTOR [array([0., 1.]), array([0., 1.]...\n",
       "3977     [def knn(x, k):\\r\\n    inner = -2 * torch.matm...\n",
       "3979     [(batchsize, 512, 14, 14), (batchsize, 512, 15...\n",
       "3980     [(batchsize, 512, 14, 14), (batchsize, 512, 15...\n",
       "3982     [torchvision, model = resnet50(pretrained=True...\n",
       "3983     [10.2, Using torch 1.10.1+cu102 (NVIDIA GeForc...\n",
       "3984     [Traceback (most recent call last):\\r\\n   File...\n",
       "3985     [class GroupConv1D(nn.Module):\\r\\ndef __init__...\n",
       "3986     [def forward(self, x):\\r\\n        # save the r...\n",
       "3987     [x=layer(x), def get_features(img,model):\\r\\n ...\n",
       "3988                 [3 x 3, n x 3 x 3, 3x1, n x 3, n x 3]\n",
       "3989     [import torch\\r\\nimport pandas as pd\\r\\nimport...\n",
       "3990     [rank = 0, for param in model.parameters():\\r\\...\n",
       "3992     [    //some steps connecting to middleware and...\n",
       "3993     [python3 bird_01_pretrain.py\\r\\n\\r\\nNamespace(...\n",
       "3995     [__getitem__, Dataset, for i in range(epoch):\\...\n",
       "3996     [class BlenderPoseDataset(Dataset):\\r\\n    \\r\\...\n",
       "3997     [    def _forward_impl(self, x: Tensor) -&gt; ...\n",
       "3998     [2d vector a\\r\\n \\r\\n    |\\r\\n    v\\r\\n  dim-0...\n",
       "4000                  [_VF.unique_dim(), torch._unique2()]\n",
       "4001     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "4002     [RuntimeError: Expected all tensors to be on t...\n",
       "4003     [$ uname -r, (3.7.10/envs/python37cuda) ➜  ~ n...\n",
       "4004     [torch.div(self.indices_buf, vocab_size, out=s...\n",
       "4005     [pip3 install torch==1.10.1 torchvision==0.10....\n",
       "4006     [\\r\\nclass Model_GRU(nn.Module):\\r\\n\\r\\n    de...\n",
       "4007     [RuntimeError: Input, output and indices must ...\n",
       "4008     [torch.tensor([0.0, 1.2, 0.1, 0.01, 2.3, 99.2,...\n",
       "4009     [conda install tensorflow-gpu==1.15.0\\r\\nColle...\n",
       "4011     [class BertClassifier(nn.Module):\\r\\n     \\r\\n...\n",
       "4012     [import pandas as pd\\r\\nimport time\\r\\n\\r\\nfro...\n",
       "4013     [def validation_epoch_end(self, outputs):\\r\\n ...\n",
       "4014     [def validation_epoch_end(self, outputs):\\r\\n ...\n",
       "4015     [torch.topk(input, k, dim=None, largest=True, ...\n",
       "4016     [T = transforms.Compose([\\r\\n            trans...\n",
       "4017     [def network():\\r\\ninputs = Input(name='inputs...\n",
       "4018     [n_features = 5\\r\\nn_layers = 3 \\r\\nn_hidden=6...\n",
       "4019     [from collections import OrderedDict\\r\\nod = O...\n",
       "4020     [\\r\\n\\r\\n\\r\\nclass Model_GRU(nn.Module):\\r\\n\\r...\n",
       "4022     [class SimDataset(Dataset):\\r\\n    def __init_...\n",
       "4023     [conda_pytorch_p36, 417.6 MB, 173.0 MB, 104.8 ...\n",
       "4024     [learner.dls.means (and stds), procs = [Catego...\n",
       "4025     [test_dataset = load_dataset(\"scientific_paper...\n",
       "4026     [import torch\\r\\nimport kornia\\r\\npoints_src =...\n",
       "4027     [for parameter in model.X1.parameters():\\r\\n  ...\n",
       "4029     [**ERROR:'Sequential' object has no attribute ...\n",
       "4030     [def training(melu, total_dataset, batch_size,...\n",
       "4032     [x, x = tensor([  1,  2,  3,  4,  5],\\r\\n     ...\n",
       "4033     [type of X is:  &lt;class 'list'&gt;\\r\\nX: [te...\n",
       "4037     [o_t, import torch import \\r\\ntorch.nn as nn\\r...\n",
       "4039     [x1, x2, 1x68x8x8,  tmp_batch, tmp_channel, tm...\n",
       "4042     [**tensor = torch.Tensor(image_n.transpose(2, ...\n",
       "4043     [class TernarizeOp():\\r\\n    def __init__(self...\n",
       "4044     [    from neural_compressor.experimental impor...\n",
       "4045     [k-fold, NaN, NaN, Epoch 19: 100%|████████████...\n",
       "4047     [import torch\\r\\ntorch.zeros((5,10))\\r\\n\\r\\n t...\n",
       "4048     [device = torch.device(\"cuda:0\")\\r\\nmodel = Be...\n",
       "4049     [# ---- Prepare training set ----\\r\\nx_data = ...\n",
       "4051     [class MonetaryLoss(nn.Module):\\r\\n    def __i...\n",
       "4052     [import torch\\r\\nfrom simpletransformers.quest...\n",
       "4053     [scores, lists, scores, (x, 8), lists, (x, 8, ...\n",
       "4054     [torch.no_grad, detach, actor, SomeDistributio...\n",
       "4056     [# Hugging face\\r\\nfrom transformers import Ma...\n",
       "4058     [pytorch_forecasting.TimeSeriesDataSet, input_...\n",
       "4059     [**model = torch.load(os.path.join(model_path,...\n",
       "4060     [class Add(nn.Module):\\r\\n    def __init__(sel...\n",
       "4061     [class Add(nn.Module):\\r\\n    def __init__(sel...\n",
       "4062     [    input_names = ['speakers', 'texts', 'src_...\n",
       "4063     [vcvars64.bat, cl.exe, (detectron_env) e:\\TRON...\n",
       "4065     [import torch\\r\\nimport torch.distributions as...\n",
       "4066     [yolov5s.pt, $ python3 detect.py --nosave --so...\n",
       "4068     [train, def train(epochs, train_loader, test_l...\n",
       "4069     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "4070     [Cannot insert a Tensor that requires grad as ...\n",
       "4071     [No module named 'midas.dpt_depth'; 'midas' is...\n",
       "4072     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "4074     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nc...\n",
       "4075     [Expected 4-dimensional input for 4-dimensiona...\n",
       "4076     [import torch\\r\\nfrom torchvision import model...\n",
       "4077     [import torch\\r\\nfrom torchvision import model...\n",
       "4079     [import os.path as osp\\r\\nimport numpy as np\\r...\n",
       "4080     [pretrained = KeyedVectors.load(args.pretraine...\n",
       "4081     [class PositionalEncoding(nn.Module):\\r\\ndef _...\n",
       "4082     [text = torch.from_numpy(data['text']).long()....\n",
       "4085     [class Policy(nn.Module):\\r\\n    \"\"\"\\r\\n    im...\n",
       "4086     [with open(\"local/data/ImageNetLabels.txt\", \"r...\n",
       "4087     [torch.utils.data.DistributedSampler(datasetPC...\n",
       "4088     [torch.multiprocessing, import torch\\r\\nimport...\n",
       "4089     [Loading model.engine for TensorRT inference.....\n",
       "4092     [.pth, model = Classifier()    # The Model Cla...\n",
       "4093     [curl -X OPTIONS http://localhost:8081, /model...\n",
       "4094     [dataloader, model, model, model.eval()\\r\\nFX ...\n",
       "4096     [CNN(\\r\\n  (conv1): Conv2d(3, 8, kernel_size=(...\n",
       "4097     [.to(self.device),   ab = torch.lgamma(torch.t...\n",
       "4098      [loss1, loss2, loss, loss1 + loss2, loss, loss1]\n",
       "4099     [00:02.0 VGA compatible controller: Cirrus Log...\n",
       "4100     [#hyperprams\\r\\nlearning_rate = 5e-4\\r\\n#3 for...\n",
       "4101     [tensor, xy, xy, xy = torch.rand(100,4)\\r\\nind...\n",
       "4103     [ # Create a single layer to replace the two l...\n",
       "4104     [tensor = torch.Tensor([[[1, 0, 0, 7], [0, 1, ...\n",
       "4105     [torch.zeros(1).cuda(), torch.cuda.is_availabl...\n",
       "4106     [conda_pytorch_p36, # define the tokenizer\\r\\n...\n",
       "4107     [import torch\\r\\nimport torch.distributed as d...\n",
       "4108     [caffe2::TypeMeta, std::vector, Torch::Tensor,...\n",
       "4109     [class Forward_function(torch.nn.Module):\\r\\nd...\n",
       "4111     [Pytorch 1.10, optimizer = torch.optim.LBFGS(P...\n",
       "4112     [np.add, def foo_numpy(x: np.ndarray, y: np.nd...\n",
       "4113     [vtxp_tensor, vtxc_tensor, torch::Tensor vtxp_...\n",
       "4114     [torch.distribution.Categorical, loss = (-1. *...\n",
       "4115     [add_graph(model, data), Question1, Qeustion2,...\n",
       "4116     [--profile-all, scalene --html --outfile prof....\n",
       "4117     [Compiled slug size: 789.8M is too large (max ...\n",
       "4118     [#building a convolutional neural network for ...\n",
       "4120     [out = model(input), out = model.forward(input...\n",
       "4121     [class MyLayer(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "4122     [training_step, import torch\\r\\nimport torch.n...\n",
       "4124     [nn.Linear, nn.Linear, X, m x p, y, m, p, clas...\n",
       "4125     [python content/stylegan2-pytorch/convert_weig...\n",
       "4126     [UserWarning: Failed to load image Python exte...\n",
       "4127     [tokenizer_org = BertTokenizer.from_pretrained...\n",
       "4128     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4129     [\\r\\nclass_weights=tf.constant([0.21, 0.45, 0....\n",
       "4131     [torch.Size([1, 12, 1000])\\r\\ntorch.Size([1, 1...\n",
       "4132     [gc1 = GCNConv(18, 16)\\r\\nspectral_norm(gc1)\\r...\n",
       "4133     [grad_list = [ ]\\r\\n\\r\\nfor data in test_loade...\n",
       "4134     [import shap \\r\\nbatch = next(iter(test_dl))\\r...\n",
       "4135     [with h5py.File(dset_filepath, \"r\", libver='la...\n",
       "4136     [---------------------------------------------...\n",
       "4137     [#conda install \\r\\n!wget -c https://repo.anac...\n",
       "4138     [X = torch.tensor( [[2.,1.,-3], [-3,4,2]], req...\n",
       "4139     [model.train()\\r\\n\\r\\nfor i, (img, target) in ...\n",
       "4140     [def calc_loss(pred, target, metrics, bce_weig...\n",
       "4141     [import torch\\r\\nimport fastai\\r\\nimport numpy...\n",
       "4142     [model = Transformer(\\r\\nsrc_tokens=src_tokens...\n",
       "4143     [def get_box_scores(cfg, pred_class_logits, pr...\n",
       "4144     [AdamParamState, adam.cpp, AdamParamState, #in...\n",
       "4145     [import torch\\r\\n\\r\\n\\r\\ndef my_transform(vec)...\n",
       "4146     [import torch\\r\\n\\r\\n\\r\\ndef my_transform(vec)...\n",
       "4147     [class NewsGroupsDataset(torch.utils.data.Data...\n",
       "4148     [class NewsGroupsDataset(torch.utils.data.Data...\n",
       "4149     [(3,128,128), import torch\\r\\nimage = Generato...\n",
       "4150     [for _ in trange(epochs):\\r\\n    for x, y in t...\n",
       "4151     [(image, label)\\r\\n\\r\\n([[..],[..],[..]], 6)  ...\n",
       "4152     [1.7.1, conda_pytorch_latest_p36, import onnxr...\n",
       "4153     [var = 0\\r\\nif random.uniform(0, 1) &lt; 0.5:\\...\n",
       "4154     [import torch\\r\\nx = torch.rand(64, 64, 25, 25...\n",
       "4155     [class BDRAR(nn.Module):\\r\\n    def __init__(s...\n",
       "4156     [class BDRAR(nn.Module):\\r\\n    def __init__(s...\n",
       "4157     [class BDRAR(nn.Module):\\r\\n    def __init__(s...\n",
       "4159     [import torch\\r\\nimport torch.nn as nn\\r\\ndic ...\n",
       "4160     [import torch\\r\\nimport torch.nn as nn\\r\\ndic ...\n",
       "4161     [import torch\\r\\nimport torch.nn as nn\\r\\ndic ...\n",
       "4162     [import torch\\r\\nimport torch.nn as nn\\r\\ndic ...\n",
       "4165     [class LitAutoEncoder(pl.LightningModule):\\r\\n...\n",
       "4166     [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndLd...\n",
       "4167     [# Imports\\r\\nimport pandas as pd\\r\\nimport nu...\n",
       "4168     [DataLoader, train_data = datasets.ANY(root='d...\n",
       "4169     [def embedding_concat(x, y):\\r\\n    B, C1, H1,...\n",
       "4170     [    def feature_extractor ( audio_file_dir ):...\n",
       "4171     [self.skip_add = nn.quantized.FloatFunctional(...\n",
       "4172     [x, x\\r\\n\\r\\ntensor([[0., 0., 0., 0., 0., 0., ...\n",
       "4173     [for epoch in range(num_epochs):\\r\\n        op...\n",
       "4174     [a = torch.rand(3, 4, dtype=torch.float32)\\r\\n...\n",
       "4175     [import torch\\r\\nimport torchvision\\r\\n\\r\\ndev...\n",
       "4176     [def summarize(articles):\\r\\nsummaries = []\\r\\...\n",
       "4177     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "4178     [Traceback (most recent call last):\\r\\nFile \"e...\n",
       "4180     [model = keras.models.Sequential([    \\r\\nkera...\n",
       "4181     [bert_base_uncased, run_pretraining.py, model....\n",
       "4182     [torch.autograd.grad(output,input), import tor...\n",
       "4183     [obj1=Net()\\r\\nobj2=Net()\\r\\noptimizer_1 = tor...\n",
       "4184     [FeatureExtractorNetworkLSTM(\\r\\n  (fenet): Mo...\n",
       "4186     [ [v.grad.data for v in modelA.parameters()]\\r...\n",
       "4188     [from torchvision import models\\r\\nimport torc...\n",
       "4191     [backward(), from time import time\\r\\nimport t...\n",
       "4192     [import torch\\r\\nimport torch.distributed as d...\n",
       "4194     [print('y_true ', y_true)\\r\\ny_true tensor([[ ...\n",
       "4195     [pip3 install torch==1.10.1+cpu torchvision==0...\n",
       "4196     [def get_function(network, loader):\\r\\n    '''...\n",
       "4198     [class AutoEncoder(nn.Module):\\r\\ndef __init__...\n",
       "4199     [import onnx\\r\\nimport torch \\r\\nimport torch....\n",
       "4201     [networkx, import pandas as pd\\r\\nimport numpy...\n",
       "4202     [def indices_to_packed(names, input_size):\\r\\n...\n",
       "4203     [nn.Linear, sparselinear, connectivity, nnz, p...\n",
       "4204     [class AutoEncoderNew(nn.Module):\\r\\n    def _...\n",
       "4205     [tokenizer = tr.RobertaTokenizer.from_pretrain...\n",
       "4206     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "4207     [AutoEncoderNew(), class AutoEncoderNew(nn.Mod...\n",
       "4208     [def compute_metrics(eval_pred):\\r\\n    \\r\\n  ...\n",
       "4209     [def compute_metrics(eval_pred):\\r\\n    logits...\n",
       "4210     [a, torch.ones(1,3,2), torch.ones(5,3,2), torc...\n",
       "4211     [class DQN(nn.Module):\\r\\n  def __init__(self,...\n",
       "4212     [--&gt; Loading model: ./rknn_models/model_356...\n",
       "4213     [#The following code does NOT throw an error:\\...\n",
       "4214     [class customDataset:\\r\\n    def __init__(self...\n",
       "4216     [LambdaLayer, class LambdaLayer(LightningModul...\n",
       "4217     [import gym\\r\\nfrom gym import wrappers\\r\\n\\r\\...\n",
       "4218     [conda install pytorch torchvision torchaudio ...\n",
       "4219     [conda install pytorch torchvision torchaudio ...\n",
       "4220     [File \"GPT\\lib\\site-packages\\torch\\nn\\modules\\...\n",
       "4221     [AssertionError: Attribute 'stuff_dataset_id_t...\n",
       "4222     [features=[]\\r\\nlabels=[]\\r\\n#here the data is...\n",
       "4224     [TypeError: conv1d() received an invalid combi...\n",
       "4225     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "4226     [# Imports\\r\\nimport pandas as pd\\r\\nimport nu...\n",
       "4227     [a = torch.randn(2, 2)\\r\\na = ((a * 3) / (a - ...\n",
       "4228     [trainer = Trainer(\\r\\n    gpus=0,\\r\\n    max_...\n",
       "4230     [# original Pytorch code\\r\\nclass AdjMSELoss2(...\n",
       "4231     [class MultiClassClassifer_Optuna_beta(nn.Modu...\n",
       "4232     [embedding_dims = 5\\r\\nW1 = Variable(torch.ran...\n",
       "4233     [def __init__(self, num_classes, input_size, h...\n",
       "4234     [class Loss(torch.nn.Module):\\r\\n    @staticme...\n",
       "4235     [...\\r\\nRequirement already satisfied: threadp...\n",
       "4237     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4238     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4239     [print(summary(model, input_size=([(10,1684,40...\n",
       "4240     [my_tensor, s x b x c, indices, b, my_tensor[0...\n",
       "4242     [def train_step(self, x, y):\\r\\n    self._opti...\n",
       "4243     [timm, \"justMyCode\": false, timm, torchvision,...\n",
       "4244     [File \"GPT\\lib\\site-packages\\torch\\nn\\modules\\...\n",
       "4245     [File \"GPT\\lib\\site-packages\\torch\\nn\\modules\\...\n",
       "4246     [RuntimeError: Expected all tensors to be on t...\n",
       "4247     [ModuleNotFoundError: No module named 'gensim'...\n",
       "4248     [import torch\\r\\nimport torchvision\\r\\ndummy_i...\n",
       "4249     [def fast_hist(label,pred, n):  \\r\\n    k = (l...\n",
       "4250     [device = get_device()\\r\\nprint(device)\\r\\ndef...\n",
       "4251     [import torch\\r\\n\\r\\n\\r\\ndef dht_calculate_tra...\n",
       "4252     [nn.MultiheadAttnetion, class Decoder(nn.Modul...\n",
       "4253     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "4255     [import torch\\r\\n\\r\\n...\\r\\nself.create_net()\\...\n",
       "4256     [&lt;|startoftext|&gt;~^~@\"Yes, but one forget...\n",
       "4257     [class Policy(nn.Module):\\r\\n    \"\"\"\\r\\n    im...\n",
       "4258     [model_path = \"./path_to_directory_with_config...\n",
       "4259     [def init_models(opt):\\r\\n\\r\\n#generator initi...\n",
       "4260     [from simpletransformers.classification import...\n",
       "4261     [test_dataset = datasets.MNIST(root='./mnist_d...\n",
       "4262     [Epoch 0: 100%|█████████▉| 2315/2318 [02:05&lt...\n",
       "4263     [Got 42078387/23040000 with acc 182.63\\r\\nDice...\n",
       "4264     [x = torch.tensor([[\\r\\n      [10, 20, 30]\\r\\n...\n",
       "4265     [# My encoder layer\\r\\nencoder_layer = nn.Tran...\n",
       "4266     [Runtime error: Unable to handle autograd's th...\n",
       "4267                                 [[256,17,2], [17,17]]\n",
       "4268     [# X_train.shape : 4M samples x 2K features\\r\\...\n",
       "4269     [\\r\\nimport numpy as np\\r\\nimport pandas as pd...\n",
       "4270     [nn.LSTM, batch_size * seq_size * embedding_si...\n",
       "4271     [model = BertForSequenceClassification.from_pr...\n",
       "4272     [    self.backbone = Backbone()\\r\\n\\r\\n    sel...\n",
       "4273     [X, MLP, net, net.forward(X), forward, import ...\n",
       "4274     [MODELS = [\\r\\n      ('xlm-mlm-enfr-1024'   ,\"...\n",
       "4275     [MODELS = [\\r\\n      ('xlm-mlm-enfr-1024'   ,\"...\n",
       "4276     [my_tensor = tensor([[ 1],\\r\\n                ...\n",
       "4277     [torch.nn.parallel.DistributedeDataParallel, t...\n",
       "4278     [MnistModule, training_step, nn.Module, out = ...\n",
       "4281     [CrossEntropyLoss, Softmax, import torch\\r\\nfr...\n",
       "4282     [import torch\\r\\nimport os\\r\\n\\r\\nf = []\\r\\nfo...\n",
       "4283     [torch.nn.DataParallel, torch.nn.functional, t...\n",
       "4284     [pip install torch-1.1.0-cp37-cp37m-linux_x86_...\n",
       "4285     [ File \"cupy/cuda/runtime.pyx\", line 126, in c...\n",
       "4286     [def loss_(self, target_vol, positive_vol, neg...\n",
       "4287     [\\r\\nimport pandas as pd\\r\\nimport numpy as np...\n",
       "4288     [import torch\\r\\n\\r\\nmodel = torch.hub.load('u...\n",
       "4289     [import torch\\r\\n\\r\\nmodel = torch.hub.load('u...\n",
       "4290     [import torch\\r\\n\\r\\nmodel = torch.hub.load('u...\n",
       "4291     [import torch\\r\\nfrom sklearn.base import Base...\n",
       "4292     [policy = Policy()\\r\\npolicy_old = Policy()\\r\\...\n",
       "4293     [pip install -r requirements.txt, yacs\\r\\nopen...\n",
       "4294     [some_data = eval(\"arr[:,[ci]]\")\\r\\n\\r\\n#or\\r\\...\n",
       "4295     [from transformers import AutoModelForMaskedLM...\n",
       "4296     [from transformers import AutoModelForMaskedLM...\n",
       "4297     [a,  a\\r\\ntensor([[2, 8],\\r\\n        [3, 0],\\r...\n",
       "4298     [def my_collate(batch):\\r\\n    x = [np.array(i...\n",
       "4299     [ClientError: InputConfiguration: No pth file ...\n",
       "4300     [# Input\\r\\n[\\r\\n  [8, -2, 9],\\r\\n  [7, 100, -...\n",
       "4301     [python train_mlm.py sentence-transformers/LaB...\n",
       "4302     [hidden = encoder(imgs)\\r\\nreconstructed = dec...\n",
       "4303     [a = torch.tensor([[4, 3, 5, 0, 2, 1],\\r\\n    ...\n",
       "4304     [model.onnx, with TemporaryDirectory() as temp...\n",
       "4305     [C:\\Users\\USER&gt;python\\r\\nPython 3.8.10 (tag...\n",
       "4306     [ def __init__(self, model_tag='prithivida/par...\n",
       "4307     [T = torch.FloatTensor([[2.6, 5], [1.7, 6], [3...\n",
       "4308     [.pth, 15.pth, 30.pth, 45.pth, 60.pth, 75.pth,...\n",
       "4309     [import os\\r\\nimport random\\r\\nimport numpy as...\n",
       "4310     [a = torch.tensor([[3, 1, 5, 0, 4, 2],\\r\\n    ...\n",
       "4311     [a = torch.tensor([[3, 1, 5, 0, 4, 2],\\r\\n    ...\n",
       "4312     [a = torch.tensor([[3, 1, 5, 0, 4, 2],\\r\\n    ...\n",
       "4313     [train function\\r\\n\\r\\ndef train_fn(loader, mo...\n",
       "4316     [engine.say(audio)\\r\\n\\r\\nengine.runAndWait()\\...\n",
       "4317     [# https://pytorch.org/tutorials/beginner/tran...\n",
       "4318     [Text, Sentiment, Text                     Sen...\n",
       "4319     [Text, Sentiment, Text                     Sen...\n",
       "4320     [Text, Sentiment, Text                     Sen...\n",
       "4321     [mat_all = torch.zeros((N,M,M))\\r\\n, mat_all, ...\n",
       "4322     [class GAPModel(nn.Module):\\r\\n  def __init__(...\n",
       "4323     [def parse_data(Images_folder, train_df):\\r\\n ...\n",
       "4324     [torch.tensor, inp = torch.tensor([[1, 3],[0, ...\n",
       "4325     [IterableDataset, pytorch, class EchoDataset(t...\n",
       "4326     [# Keras — this works, conceptually\\r\\nlayer_1...\n",
       "4327     [import torch\\r\\nfrom torch.autograd import Va...\n",
       "4328     [class TripletLoss(nn.Module):\\r\\n    def __in...\n",
       "4329     [ class DQN(nn.Module):\\r\\n     def __init__(s...\n",
       "4330     [from keras.models import Sequential\\r\\nmodel ...\n",
       "4331     [torch.nn.CrossEntropyLoss, import torch\\r\\n\\r...\n",
       "4332     [import torch\\r\\n\\r\\nembedding_vectors = torch...\n",
       "4335     [train_any_t5_task.py, from transformers impor...\n",
       "4336     [class net_core(nn.Module):\\r\\n    def __init_...\n",
       "4337     [x = torch.randn(100, 90, 90)\\r\\nw = torch.ran...\n",
       "4338     [spiking_model.visualize_all_neurons(x)&gt; \\r...\n",
       "4339     [def masktensor(X, array_of_indices):\\r\\n    r...\n",
       "4340     [A, [B, N, D], I, A, [1, 2048, 768], I = [ [0,...\n",
       "4341     [class SoundDataset(Dataset):\\r\\n  def __init_...\n",
       "4343     [import torch\\r\\nimport albumentations as A\\r\\...\n",
       "4344     [class RolloutBuffer:\\r\\n    def __init__(self...\n",
       "4345     [torch.save(single_tensor, 'tensor_&lt;idx&gt;...\n",
       "4347     [tokenized_datasets[\"train\"][:8]\\r\\n, dtype, d...\n",
       "4348     [tokenized_datasets[\"train\"][:8]\\r\\n, dtype, d...\n",
       "4349     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "4350     [        with h5py.File(self.hdf5file, \"r\") as...\n",
       "4351     [file[seconds][person][camera]. \\r\\n,  file[th...\n",
       "4353     [filelist = glob(\"train/im/*.tif\")\\r\\nmask_lis...\n",
       "4354     [train_dataloader = torch.utils.data.DataLoade...\n",
       "4355     [def score(model, tokenizer, sentence,  mask_t...\n",
       "4356     [torchvision.models.ResNet, CondBatchNorm2d, B...\n",
       "4357     [class alpha(nn.Module):\\r\\n    '''\\r\\n    Thi...\n",
       "4358     [gradient_accumulation_steps = 5\\r\\nfor batch_...\n",
       "4359     [current_Q = self.net(state, model=\"online\")[n...\n",
       "4360     [model.extract_features, features = model.extr...\n",
       "4361     [def build_vocab(data_iter, tokenizer):\\r\\n\"\"\"...\n",
       "4362     [#### Parallel process initiated with torch.di...\n",
       "4364     [A, N, (0,D-1), B, (N,D), B, A, A[0] = 2, A[1]...\n",
       "4366     [output.loss, output.logits, class MyQAModel(p...\n",
       "4367     [from_networkx, import pandas as pd\\r\\nimport ...\n",
       "4368     [def Model(self, model_name=\"resnet18\",gpu_dev...\n",
       "4369     [class RegretModel(nn.Module):\\r\\n\\r\\n    def ...\n",
       "4370     [import sys\\r\\nimport torch\\r\\nfrom collection...\n",
       "4371     [model_name = \"mrm8488/flaubert-small-finetune...\n",
       "4372     [model_name = \"mrm8488/flaubert-small-finetune...\n",
       "4373     [nn.Modules, def dice_loss(y_pred, y_real):\\r\\...\n",
       "4374     [batch_X = batch_X.to(device=device, dtype=tor...\n",
       "4375     [What is the difference?, clone(), However, in...\n",
       "4377     [  import os\\r\\n  import cv2 as cv\\r\\n  import...\n",
       "4378     [data, (2092, 64, 64, 3), Red = data[:,:,:,0]\\...\n",
       "4379     [$ srun -C gpu -N 1 -c 8 -n 1 --gpus-per-task=...\n",
       "4380     [    import React from 'react';\\r\\n// import t...\n",
       "4381     [class SynthData(torch.nn.Module):\\r\\n    def ...\n",
       "4383     [class CVAE(nn.Module):\\r\\n    def __init__(se...\n",
       "4384     [weight, x, self.fc_nn, num_features, x.shape(...\n",
       "4385     [def load_pair(fname):\\r\\nmat = loadmat(fname)...\n",
       "4386     [torchvision.datasets.MNIST('./', download=Tru...\n",
       "4387     [obj = {\"features\": features, \"labels\": labels...\n",
       "4388     [def forward(self, x):\\r\\n    #Encoder Process...\n",
       "4389     [def cross_entropy(self, pred, target):\\r\\n   ...\n",
       "4390     [model_ft = torch.hub.load('facebookresearch/d...\n",
       "4391     [class ConvNet(nn.Module):\\r\\ndef _init_(self,...\n",
       "4392     [Epoch: 1\\r\\ncorrect: 234, N_test: 468 ------&...\n",
       "4393     [Epoch: 1\\r\\ncorrect: 234, N_test: 468 ------&...\n",
       "4394     [tb_logger = pl_loggers.TensorBoardLogger(args...\n",
       "4396     [output, output, with torch.set_grad_enabled(t...\n",
       "4397     [output, output, with torch.set_grad_enabled(t...\n",
       "4398     [x_indices, x_tokens, x_indices, x_tokens, # x...\n",
       "4399     [class Recommender(pl.LightningModule):\\r\\n   ...\n",
       "4400     [class NBeatsBlock(t.nn.Module):\\r\\n    def __...\n",
       "4401     [def save_checkpoint(model, epoch, optimizer, ...\n",
       "4402     [a, b, a = torch.randn(100,100)\\r\\ntensor([[ 1...\n",
       "4403     [        \"boundingPoly\": {\\r\\n            \"nor...\n",
       "4404     [X = np.asarray(skin_df1['image'].tolist())\\r\\...\n",
       "4405     [from dataset import MyCustomDataset\\r\\nfrom t...\n",
       "4406     [from dataset import MyCustomDataset\\r\\nfrom t...\n",
       "4407     [class regression(nn.Module):\\r\\n    def __ini...\n",
       "4408     [class regression(nn.Module):\\r\\n    def __ini...\n",
       "4409     [import torch\\r\\nfrom torch_sparse import Spar...\n",
       "4411     [embedding, Encoder, Decoder, from torch impor...\n",
       "4412     [dataset = MyDataset(train,y_train_one_hot)\\r\\...\n",
       "4413     [# x_raw is a list of bug report descriptions....\n",
       "4414     [(0) : Sequential(\\r\\n      (0): Dropout3d(p=0...\n",
       "4415     [original_model=torch.load('model_best.pth',ma...\n",
       "4417     [x = [[[0, 1], [2, -1]], [[5, 1], [-10, -100]]...\n",
       "4418     [loss_fn = nn.CTCLoss(reduction='mean', zero_i...\n",
       "4419     [criterion = nn.CrossEntropyLoss(reduction='me...\n",
       "4420     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "4421     [conv1 = tf.layers.conv2d(inputs=input, filter...\n",
       "4422     [tokenize = lambda x: x.split()\\r\\ncomment= Fi...\n",
       "4423     [none, [B], def torch_compute_confidence_inter...\n",
       "4424     [ ''' I am trying to classify image using PyTo...\n",
       "4425     [import cv2\\r\\nimport torchvision.models as mo...\n",
       "4426     [source_t=tensor[[101,2001,2034,1045,202,3454,...\n",
       "4427     [source_t=tensor[[101,2001,2034,1045,202,3454,...\n",
       "4428     [(xmin, ymin, xmax, ymax)\\r\\n(504.886322021484...\n",
       "4429     [a function that helps to combine images and t...\n",
       "4430     [import numpy as np\\r\\nfrom numpy import asarr...\n",
       "4431     [sample_tensor = tensor([ 0.6676,  0.0917,  0....\n",
       "4432     [def plot_grad_flow(named_parameters):\\r\\n    ...\n",
       "4433     [1,74,127,92,139,47\\r\\n, class CreateDataLoade...\n",
       "4435     [def my_conv(input):\\r\\n    # make torch tenso...\n",
       "4436     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4438     [import torch.multiprocessing as mp\\r\\nfrom to...\n",
       "4439     [DDP(mdl), ddp_mdl.module.state_dict(), def sa...\n",
       "4440     [class CNN(nn.Module):\\r\\n\\r\\n# Contructor\\r\\n...\n",
       "4441     [cfg = get_cfg()\\r\\nadd_maskformer2_config(cfg...\n",
       "4442     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4443     [A  # Shape: batch_size X Y\\r\\n, index_x  # Sh...\n",
       "4444     [done, class DQN:\\r\\n    def __init__(self, en...\n",
       "4445     [./__init__.py\\r\\n./maingui.py\\r\\n./sharedData...\n",
       "4446     [def forward(self, x):\\r\\n    x = self.relu(se...\n",
       "4447                        [tf.linalg.diag_part, PyTorch]\n",
       "4448                        [tf.linalg.diag_part, PyTorch]\n",
       "4449     [class LSTM(nn.Module):\\r\\n\\r\\n    def __init_...\n",
       "4450     [bids[bids&gt;=0]\\r\\n&gt; tensor([0.6249, 0.21...\n",
       "4451     [import numpy as np\\r\\nfrom patchify import pa...\n",
       "4452     [import numpy as np\\r\\nfrom patchify import pa...\n",
       "4453     [outputs, from sklearn.decomposition import PC...\n",
       "4454     [torch.matmul, nn.Module, forward(), forward()...\n",
       "4455     [ train_loader = DataLoader(dataset = train_se...\n",
       "4458     [train_points_loader = DataLoader(train_points...\n",
       "4459     [import torch, ('base': conda), ('pytorch': co...\n",
       "4460     [class MultiClassClassifer(nn.Module):\\r\\n  #d...\n",
       "4461     [torch.nn.Module, import torch\\r\\nfrom torch i...\n",
       "4462     [(224,224,3), (100, 100, 24, 224, 224, 3)\\r\\n-...\n",
       "4463     [torch.tensor, x, (4,5,1), PyTorch, (20,1), 64...\n",
       "4465     [import torch.nn as nn\\r\\n\\r\\nclass MultiClass...\n",
       "4466     [targets = zeros.scatter_(1, targets.unsqueeze...\n",
       "4467     [s = time.time()\\r\\nadj_matrices = batched_nat...\n",
       "4469     [torch                 1.10.0+cu113\\r\\ntorch-c...\n",
       "4470     [b = [[[4, 20], [1, -1]], [[1, 2], [8, -1]], [...\n",
       "4471     [import numpy as np\\r\\nimport scipy\\r\\nimport ...\n",
       "4472     [import torch.nn as nn\\r\\n\\r\\nclass MultiClass...\n",
       "4473     [import torch.nn as nn\\r\\n\\r\\nclass MultiClass...\n",
       "4474     [(1000, 100, 8), (n_samples, n_timesteps, n_fe...\n",
       "4475     [from torch.nn import Conv2d\\r\\nx = torch.rand...\n",
       "4476     [import torch; print(torch.cuda.is_available()...\n",
       "4477     [__getitem__(), .hdf5, __init__(), # imports\\r...\n",
       "4478     [criterion = nn.CrossEntropyLoss(weight=torch....\n",
       "4479     [\\r\\nclass ModelA(nn.Module):\\r\\n  def __init_...\n",
       "4480     [def train(model, train_loader, optimizer,sche...\n",
       "4481     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "4482     [    x = torch.tensor(3.)\\r\\n\\r\\n    w = torch...\n",
       "4483     [parameters_to_prune = (\\r\\n    (model.input_l...\n",
       "4485     [আমি ভাত খাই খাই খাই খাই ও বিকালে খেলি, আমি ভা...\n",
       "4486     [X = tensor([[1, 2, 3],\\r\\n            [4, 5, ...\n",
       "4487     [a = [[4, 2, 1, 6],[1, 2, 3, 8], [92, 4, 23, 5...\n",
       "4488     [torch with CUDA enabled, pip command, Pytorch...\n",
       "4489     [    class MyDataset(Dataset):\\r\\n      def __...\n",
       "4490     [Collecting fairseq\\r\\n  Using cached fairseq-...\n",
       "4491     [def load_trained_bert(\\r\\n    num_classes: in...\n",
       "4492     [model = my_model()\\r\\nmodel.load_state_dict(t...\n",
       "4493     [model = my_model()\\r\\nmodel.load_state_dict(t...\n",
       "4494     [#!/usr/bin/env python\\r\\nimport random\\r\\nimp...\n",
       "4495     [class InvertibleLeakyReLU(nn.Module):\\r\\n  de...\n",
       "4497     [class my_model(nn.Module):\\r\\ndef __init__(se...\n",
       "4498     [class my_model(nn.Module):\\r\\ndef __init__(se...\n",
       "4499     [cuda==11.0, pytorch, conda install pytorch cu...\n",
       "4500     [class RolloutEncoder(nn.Module):\\r\\n    def _...\n",
       "4501     [def sd(data):\\r\\n    # Number of observations...\n",
       "4502     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "4504                        [(n, height, width, channels)]\n",
       "4505     [torch.size([6000, 30, 30, 9]), torch.size([60...\n",
       "4509     [import os\\r\\nimport torch\\r\\nimport torchvisi...\n",
       "4510     [self.layer2 = self._make_layer(block, 32, blo...\n",
       "4512     [\\r\\nscaler1 = torch.cuda.amp.GradScaler()\\r\\n...\n",
       "4513     [+--------------------------------------------...\n",
       "4514     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4515     [RuntimeError: Error building extension 'fused...\n",
       "4516     [RuntimeError: Error building extension 'fused...\n",
       "4517     [Test loss:  8.86368179321289\\r\\nTest loss:  5...\n",
       "4518     [[1, 2], [ [ 2, 0],\\r\\n  [ 0, 3] ].\\r\\n, class...\n",
       "4519                                  [torch.tensor, None]\n",
       "4520     [INPUT:\\r\\nnetwork    : instance of classifier...\n",
       "4522     [a, b, c, d = g(a, b) # g is some functions\\r\\...\n",
       "4524     [import multiprocessing as mp\\r\\nimport torch\\...\n",
       "4525     [ This IS expected if you are initializing Fla...\n",
       "4527     [RuntimeError: shape '[128, -1]' is invalid fo...\n",
       "4528     [RuntimeError: shape '[128, -1]' is invalid fo...\n",
       "4529     [def batch_rank_loss(clss, embs):\\r\\n    '''\\r...\n",
       "4530     [#Infer the feature representation for trainin...\n",
       "4531     [from transformers import RobertaTokenizer, Ro...\n",
       "4532     [RuntimeError: stack expects each tensor to be...\n",
       "4534     [BCEWithLogitsLoss(), RuntimeError: The size o...\n",
       "4535     [[32,64,64,3], [batch, timeframes, frequency_b...\n",
       "4536     [[32,64,64,3], [batch, timeframes, frequency_b...\n",
       "4537     [class MyDataset(Dataset):\\r\\n    \\r\\n    def ...\n",
       "4538     [RuntimeError: result type Float can't be cast...\n",
       "4539     [encoded_txts=[[array([1,2,3]), array ([1,2,3]...\n",
       "4540     [Feature train shape:\\r\\n(2338834, 21)\\r\\nTarg...\n",
       "4541     [# Model setup\\r\\nself.model = Sequential(\\r\\n...\n",
       "4542     [class newsDataset(torch.utils.data.Dataset):\\...\n",
       "4543     [def optimize_scale(self, epochs=5, comp_scale...\n",
       "4544     [for num,(sample_img, sample_label) in enumera...\n",
       "4545     [## Model training\\r\\ntokenizer = AutoTokenize...\n",
       "4546     [reduction='sum', output = model(data)\\r\\nloss...\n",
       "4548     [ def __init__(self, dim,initial_values = 1e-4...\n",
       "4549     [image = ImageList.from_tensors([image])\\r\\nfe...\n",
       "4550     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "4551     [AutoTokenizer.from_pretrained('roberta-base')...\n",
       "4552     [C:\\Users\\Username\\MINICO~1\\envs\\SPACY_~1\\lib\\...\n",
       "4553     [(batchsize, seq_len, channels, img_height, im...\n",
       "4554     [\\r\\n    import matplotlib.pyplot as plt\\r\\n  ...\n",
       "4555     [\\r\\n    import matplotlib.pyplot as plt\\r\\n  ...\n",
       "4556     [from transformers import BertTokenizer, BertF...\n",
       "4557     [from transformers import BertModel, BertForMa...\n",
       "4558     [tensorflow, tensor = np.random.RandomState(42...\n",
       "4559     [tensorflow, tensor = np.random.RandomState(42...\n",
       "4560     [image = np.random.rand(2,3,32,32)\\r\\n\\r\\ntorc...\n",
       "4561     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "4562     [Pytorch, train_dataset, test_dataset = torch....\n",
       "4564     [A = [[0, 3], [0, 0], [0, 1]],\\r\\n, A_sorted =...\n",
       "4565     [torch.utils.data.DataLoader, num_workers, /je...\n",
       "4566     [def scatter_max_2(src, index, out):\\r\\nsrc_sh...\n",
       "4567     [class Module(nn.Module):\\r\\n  def __init__(se...\n",
       "4568     [import torch\\r\\n\\r\\nfoo = torch.tensor([1,2,3...\n",
       "4569     [x_train = torch.FloatTensor(x_train)\\r\\nValue...\n",
       "4570     [reticulate, use_virtualenv(\"r-reticulate\")\\r\\...\n",
       "4571     [def train(self):\\r\\n    self.model.train()\\r\\...\n",
       "4572     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4573     [cudatoolkit               10.2.89         hfd...\n",
       "4574     [shap_values = e.shap_values(sequences_to_expl...\n",
       "4575     [from simpletransformers.language_representati...\n",
       "4576     [        ╭----- (pretrained model) ------ resu...\n",
       "4577                                           [torch.cat]\n",
       "4580     [import torch\\r\\na = torch.arange(12, dtype=to...\n",
       "4581     [classifier.0.conv_1.conv2d.weight  :  torch.S...\n",
       "4582     [classifier.0.conv_1.conv2d.weight  :  torch.S...\n",
       "4583     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4584     [class Net2(nn.Module):\\r\\n  def __init__(self...\n",
       "4585     [print(torch.__version__, torch.cuda.is_availa...\n",
       "4586     [import torch\\r\\nfrom torch.autograd import Va...\n",
       "4587     [Z = torch.zeros_like(E)\\r\\nZ = repeat(Z, 'b c...\n",
       "4588     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "4589     [def optimize_model(self):\\r\\n    if self.memo...\n",
       "4590     [ngrams = [\\r\\n    (\\r\\n        [test_sentence...\n",
       "4591     [A: with shape BxHxW and values in {0,1}, wher...\n",
       "4592     [#Load resnet\\r\\ndef get_model():\\r\\n    model...\n",
       "4593     [#Load resnet\\r\\ndef get_model():\\r\\n    model...\n",
       "4594     [x (Tensor, optional) – Node feature matrix wi...\n",
       "4595     [with torch.no_grad(), with torch.no_grad(), r...\n",
       "4597     ['''for example, when the number of character ...\n",
       "4598     [:/cb/pytorch_1000000000000/work/aten/src/ATen...\n",
       "4599     [\\r\\nimport os\\r\\nimport torch\\r\\nimport torch...\n",
       "4600     [==============NVSMI LOG==============\\r\\n\\r\\n...\n",
       "4601     [class SiameseNetwork(nn.Module):\\r\\n    def _...\n",
       "4602     [  # Generator\\r\\n  y_d_hat_r, y_d_hat_g, fmap...\n",
       "4603     [model = SSD with mobilenetV3\\r\\nlibrary = pyT...\n",
       "4604     [Expected 4-dimensional input for 4-dimensiona...\n",
       "4605     [X = torch.einsum(\"rij, sij -&gt; rs\", A, A)\\r...\n",
       "4606     [# in tensorflow - keras : \\r\\nfrom tensorflow...\n",
       "4607     [ResNetClassifier(\\r\\n  (feature_extractor): S...\n",
       "4608     [epochs = 10\\r\\nbatch_size = 128\\r\\nlr = 0.008...\n",
       "4610     [def forward_and_backward(x):\\r\\n    # Run in ...\n",
       "4611     [pytorch-forecasting==0.9.0\\r\\npytorch-lightni...\n",
       "4612     [prompt_ids, RuntimeError: Boolean value of Te...\n",
       "4613     [def face_match(img_path, data_path): # img_pa...\n",
       "4614     [Conv2d, conv1 = torch.nn.Conv2d(3, 16, stride...\n",
       "4615     [Conv2d, conv1 = torch.nn.Conv2d(3, 16, stride...\n",
       "4617     [ImageFolder, # Loading in data\\r\\n\\r\\ndataroo...\n",
       "4618     [# Version A: \\r\\nw = np.random.uniform(low=-0...\n",
       "4619     [         cropped_images =[]\\r\\n\\r\\n         i...\n",
       "4620     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "4621     [          2 import math\\r\\n          3 import...\n",
       "4622     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4623     [batch_size = 64\\r\\nepoch = 100\\r\\nlamda = 0.0...\n",
       "4624     [def __init__(self, n_inputs, n_outputs_arr):\\...\n",
       "4626     [args.scheduler=None\\r\\n--------------------- ...\n",
       "4627     [ t = torch.tensor([[1, 0, 1, 1]]).T\\r\\n p = t...\n",
       "4628     [class AlexNet(nn.Module):\\r\\n    def __init__...\n",
       "4629     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4631     [boto3==1.20.19\\r\\nflashtorch==0.1.3\\r\\nmatplo...\n",
       "4632     [[tensor([[225., 297.,  69.,  ..., 169., 223.,...\n",
       "4634     [i1 = tr.tensor(0.0, requires_grad=True)\\r\\ni2...\n",
       "4636     [X_train, X_test, y_train, y_test = train_test...\n",
       "4637     [class compute_crossentropyloss_manual:\\r\\n   ...\n",
       "4638     [probabilities  + label \\r\\n        [ 0.1701, ...\n",
       "4639     [transformers.BertForMaskedLM, .txt, transform...\n",
       "4640     [pipenv install torch===1.4.0 torchvision===0....\n",
       "4641     [def gen_batch(BATCH_SIZE):\\r\\n    labels = to...\n",
       "4642     [def build_backbone_2d(self, model_info_dict):...\n",
       "4643     [ vidcap = cv2.VideoCapture(args.videoFile)\\r\\...\n",
       "4644     [filelist = sorted(glob.glob(test_img_folder+\"...\n",
       "4645     [for parameter in myModel.parameters():\\r\\n   ...\n",
       "4647                                         [import timm]\n",
       "4649     [A(s_t) = R(t+1) + \\gamma V(S_{t+1}) - V(S_t),...\n",
       "4650     [pytorch, tf.Dataset, def convert_pytorch_data...\n",
       "4651     [def gen_batch(BATCH_SIZE):\\r\\n    labels = to...\n",
       "4652                             [default_hp_metric=False]\n",
       "4653     [from detectron2.engine import DefaultTrainer\\...\n",
       "4654     [def bpr_loss(data, graph):\\r\\n    final_emb =...\n",
       "4655     [loss = loss_fn(outputs, torch.max(labels, 1)[...\n",
       "4657     [1 0  0.171429  1 0 0  0.966805  0\\r\\n0 1  0.0...\n",
       "4658     [.mp4, eval.mp4, pytorch, nn, nn, .png, eval.m...\n",
       "4659     [.mp4, eval.mp4, pytorch, nn, nn, .png, eval.m...\n",
       "4660     [step :  0 loss :  0.0016425768844783306\\r\\nst...\n",
       "4661     [A=np.random.dirichlet(np.ones(70000),1000)\\r\\...\n",
       "4662     [[batch, channels, frames, freq_bins], [batch,...\n",
       "4663     [my_dls.show_batch()\\r\\nres = L(b).map(partial...\n",
       "4664     [import torch\\r\\nimport torch.utils.data as da...\n",
       "4665     [cur_step = 0\\r\\ngenerator_losses = []\\r\\ndisc...\n",
       "4666     [--------------------- META-TRAIN ------------...\n",
       "4667     [1.8.1+cu111, torch&gt;=1.8.1, 1.8.1+cu111, 1....\n",
       "4668     [def get_parameters(model):\\r\\n    group_no_we...\n",
       "4669     [    values = [float(ret.return_value)]\\r\\nVal...\n",
       "4670     [[11/29 20:16:31 d2.utils.events]:  eta: 0:24:...\n",
       "4671     [p = torch.randn(5, 7)\\r\\nval, idx = p.topk(3,...\n",
       "4672     [import os  \\r\\nimport torch \\r\\nmodel = torch...\n",
       "4673     [import os  \\r\\nimport torch \\r\\nmodel = torch...\n",
       "4674     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "4675     [RuntimeError: 0INTERNAL ASSERT FAILED at \"../...\n",
       "4676     [img = process_img(\"./data/house.jpg\", 128)\\r\\...\n",
       "4677     [It is not possible to directly backpropagate ...\n",
       "4678     [It is not possible to directly backpropagate ...\n",
       "4679     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4680     [BUFFER_SIZE : 100000\\r\\nTARGET_UPDATE_FREQ : ...\n",
       "4682     [class NeuralNetwork(nn.Module):\\r\\n    def __...\n",
       "4683     [tns = torch.tensor([1,0,1])\\r\\ntns.mean()\\r\\n...\n",
       "4684     [class VGG16(torch.nn.Module):\\r\\n    def __in...\n",
       "4685     [nvidia-container-runtime, nvidia-docker, $ do...\n",
       "4686     [11701*300=3510300, TORCH.BINCOUNT, TORCH.UNIQ...\n",
       "4687     [def make_pairs(images, labels):\\r\\n    # init...\n",
       "4688     [(pgqa) raphy@pc:~/pythonMatters/PathGenerator...\n",
       "4689     [import gym\\r\\nimport numpy as np\\r\\nimport to...\n",
       "4690     [import torch_geometric\\r\\nfrom torch_geometri...\n",
       "4691     [xxx=torch.tensor([True,True,False,True])\\r\\nx...\n",
       "4693     [batch x sentence length x embedding dim, a = ...\n",
       "4694     [nvcc -V, nvcc -V\\r\\nnvcc: NVIDIA (R) Cuda com...\n",
       "4695     [nvcc -V, nvcc -V\\r\\nnvcc: NVIDIA (R) Cuda com...\n",
       "4696     [nvcc -V, nvcc -V\\r\\nnvcc: NVIDIA (R) Cuda com...\n",
       "4697     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4698     [self.ACTClassifier = nn.Sequential(\\r\\n      ...\n",
       "4699     [Traceback (most recent call last):\\r\\n  File ...\n",
       "4700     [model = nn.Sequential(\\r\\n        nn.Linear(6...\n",
       "4701     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "4702     [model.train()\\r\\nfor epoch in range(epochs):\\...\n",
       "4703     [num_classes = 2\\r\\nnum_epochs = 1\\r\\nbatch_si...\n",
       "4704     [x = torch.tensor([[[ 2.1137, -1.3133,  0.7930...\n",
       "4705     [import torch.nn as nn\\r\\ntorch.manual_seed(ra...\n",
       "4706     [class ResidualBlock(nn.Module):\\r\\n def __ini...\n",
       "4707     [import os\\r\\nimport numpy as np\\r\\nimport tor...\n",
       "4708     [init.py, \\mmdetection\\mmdet\\datasets, @DATASE...\n",
       "4709     [def softmax(scores: torch.Tensor):\\r\\n    max...\n",
       "4710     [backbone = timm.create_model(model_name=\"swin...\n",
       "4711     [X = torch.randn(30,1,2)  # [batch_size, dim_1...\n",
       "4712     [def __getitem__(self, index):\\r\\n        path...\n",
       "4713     [dill, def _load_model_and_optimizer_from_chec...\n",
       "4714     [torch.cuda.Stream(),     self.input_stream = ...\n",
       "4715     [def phase_shifters(y_alpha=0, x_alpha=0, shap...\n",
       "4716     [DartsTrainer(model,\\r\\n                      ...\n",
       "4717     [they don't print the training accuracy during...\n",
       "4718     [TaskManager.cpp, pip install -e ., setup.py, ...\n",
       "4719     [class AddGaussianNoise(object): \\r\\n\\r\\n    d...\n",
       "4720     [class AddGaussianNoise(object): \\r\\n\\r\\n    d...\n",
       "4722     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "4723     [def train(model, optimizer, dataloader, num_e...\n",
       "4725     [class SomeNetwork(nn.Module):\\r\\n    def __in...\n",
       "4726     [imgs_pred = model(imgs_input)\\r\\n#compare pre...\n",
       "4727     [e_loss = []\\r\\neta = 2 #just an example of va...\n",
       "4728     [network = '\\uC18C\\uB140\\uC758\\uC138\\uACC4'\\r\\...\n",
       "4729     [def batch_generator(dataset, input_shape = (2...\n",
       "4730     [def batch_generator(dataset, input_shape = (2...\n",
       "4731     [\\r\\na.shape = torch.Size([32, 20])\\r\\na[0]=te...\n",
       "4732     [ PRETRAINED_MODEL_NAME = \"roberta-base\"\\r\\nfr...\n",
       "4733     [class TrainFeeder(Dataset):\\r\\n    def init(s...\n",
       "4734     [class CNN1(nn.Module):\\r\\n    def __init__(se...\n",
       "4735     [IMG_WIDTH = IMG_HEIGHT = 224\\r\\n\\r\\nclass Ale...\n",
       "4736     [IMG_WIDTH = IMG_HEIGHT = 224\\r\\n\\r\\nclass Ale...\n",
       "4738     [import torch\\r\\n\\r\\nbatch_size = 2\\r\\nseq_len...\n",
       "4739     [class Trainer:\\r\\n    \"\"\"Object used to facil...\n",
       "4741     [arr, idx, arr, idx, arr = torch.zeros(size = ...\n",
       "4742     [ X_train\\r\\n[tensor([  101,  3533...='cuda:0'...\n",
       "4743     [class NLUModel(nn.Module):\\r\\ndef __init__(se...\n",
       "4744     [!python -m venv .env\\r\\n, !source .env/bin/ac...\n",
       "4745     [model_state_dict = torch.load(\"../MODELOS/TRA...\n",
       "4746     [batch_size = 64, class Net(nn.Module):\\r\\n   ...\n",
       "4747     [torchvision, datasets.ImageFolder, train_data...\n",
       "4749     [pytorch, torchtext, torchvision, torchaudio, ...\n",
       "4750     [class SegmentationDataset(Dataset, ImageTrans...\n",
       "4751     [/home/x/Pytorch/coursework1/data/train_set\\r\\...\n",
       "4752     [my_sampler = dgl.dataloading.MultiLayerFullNe...\n",
       "4753     [model=Sequential()\\r\\nmodel.add(Conv2D(filter...\n",
       "4754     [image, mask, albumentations.Normalize(mean, s...\n",
       "4755     [import matplotlib.pyplot as plt\\r\\nimport sea...\n",
       "4756     [def __getitem__(self, index):\\r\\n    image_pa...\n",
       "4757     [pip install -v --disable-pip-version-check --...\n",
       "4759     [class MydataSet(Dataset):\\r\\ndef __init__(sel...\n",
       "4760     [---------------------------------------------...\n",
       "4761     [p, x, (batch_size, input_size), (batch_size),...\n",
       "4762     [def Model(LongestWord,AllCharLength,totalspel...\n",
       "4763     [loss.backward(), /home/user/anaconda3/lib/pyt...\n",
       "4764     [trainer.evaluate()\\r\\n, dataset = DatasetModu...\n",
       "4765     [M[N,C], 0, 1, Y[N,1], [0,C-1], ds[N,M], grad[...\n",
       "4767     [import torch\\r\\nimport os\\r\\n\\r\\npaths = os.l...\n",
       "4768     [ x[-6&lt;x and x&lt;0] = x[-6&lt;x and x&lt;0...\n",
       "4770     [import torch\\r\\n\\r\\nimport ray\\r\\n\\r\\ntrainin...\n",
       "4771     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "4773     [    2021-11-22 09:58:25,083 [INFO ] W-9001-de...\n",
       "4775                    [[[3, 5, 10, 11], [1, 5, 10]]\\r\\n]\n",
       "4776     [...\\r\\n\\r\\n# Optimization step.\\r\\noptimizer....\n",
       "4777     [class Potsdam_Microgrid_DS1(Dataset):\\r\\n    ...\n",
       "4778     [tensor([ 5,  10,  2,  3,  4], device='cuda:0'...\n",
       "4779     [ACTOR_LAYER_SIZES: (128, 256, 128)\\r\\n, # inp...\n",
       "4780     [torch.nn.LayerNorm, batch_size, seq_size, dim...\n",
       "4781       [Bx3xHxW, Bx3FxHxW, F=64, 0, f, f, 0, F-1, for]\n",
       "4783     [import pandas as pd\\r\\n  \\r\\n# initialize dat...\n",
       "4784     [(base) name@server:~$ conda activate ENV_0\\r\\...\n",
       "4785     [predictions = tensor([[33, 34,  7,  5,  5, 23...\n",
       "4786     [for epoch in range(N_EPOCHS):\\r\\n    model.tr...\n",
       "4787     [for epoch in range(N_EPOCHS):\\r\\n    model.tr...\n",
       "4790     [x1*torch.reshape(x2,(x2.size(dim=0),x2.size(d...\n",
       "4791     [torch.nn.Conv2d(in_channels, out_channels, ke...\n",
       "4793     [torch.nn.functional.binary_cross_entropy, def...\n",
       "4794     [A.shape=torch.Size([16, 309,128])\\r\\nA = A.un...\n",
       "4795     [nvidia-smi, 402MiB /  7973MiB, nvidia-smi, 78...\n",
       "4796     [RuntimeError: one of the variables needed for...\n",
       "4797     [RuntimeError: one of the variables needed for...\n",
       "4798     [#@title Setup\\r\\nimport pkg_resources\\r\\nprin...\n",
       "4799     [newModel = CNNSEG()\\r\\nnewModel.load_state_di...\n",
       "4800     [PyTorch, for data in test_loader:\\r\\n     bre...\n",
       "4801     [model.to(device), device = cuda:0, X.to(devic...\n",
       "4802     [import torch\\r\\n\\r\\nclass VerySimple(torch.nn...\n",
       "4803     [x, y, x=torch.tensor([[1, 6, 7, 5, 6],\\r\\n   ...\n",
       "4804     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "4805     [VGG16, nvidia-smi,   model = torchvision.mode...\n",
       "4806     [loss = BCELoss()\\r\\nopt   = optim.AdamW  (mod...\n",
       "4808     [`!python train.py --img 415 --batch 16 --epoc...\n",
       "4809     [.item, ValueError: only one element tensors c...\n",
       "4810     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4811     [output, output, with torch.set_grad_enabled(t...\n",
       "4812     [class Conv2DFunctionCustom(Function):\\r\\n    ...\n",
       "4813     [Batch size &gt; 1 not implemented! Falling ba...\n",
       "4814     [IncompatibleModuleException: Model contains i...\n",
       "4815     [CUDA not available - defaulting to CPU. Note:...\n",
       "4817     [\\r\\n###First network\\r\\n\\r\\nclass LambdaBase(...\n",
       "4818     [\\r\\n###First network\\r\\n\\r\\nclass LambdaBase(...\n",
       "4819     [model = PyTorchModel(\\r\\n    name=\"d2-sku110k...\n",
       "4820     [import torchvision\\r\\nfrom torchvision import...\n",
       "4821     [from tensorboard.backend.event_processing.eve...\n",
       "4822     [from tensorboard.backend.event_processing.eve...\n",
       "4823     [CrossEntropyLoss, BCELoss, ValueError: Target...\n",
       "4824     [model = torchvision.models.vgg16(pretrained=T...\n",
       "4825     [int, troch.tensor, df_test = pd.DataFrame([3,...\n",
       "4827     [/pytorch/aten/src/ATen/native/cuda/IndexKerne...\n",
       "4828     [Data(x=[75, 4], edge_index=[2, 346], edge_att...\n",
       "4829     [train = X_train\\r\\ntargets_numpy = train.labe...\n",
       "4830     [train_loader = tf.data.Dataset.from_tensor_sl...\n",
       "4831     [with tf.variable_scope(name) as scope:\\r\\n   ...\n",
       "4832     [ for epoch in range(arg.epochs):\\r\\n        f...\n",
       "4833     [EMG0 Feature1, Feature2, Feature3 ...\\r\\nEMG1...\n",
       "4834     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "4838     [lambda t:f64[20000,20000] u:f64[20000,10]:\\r\\...\n",
       "4839     [    [31mERROR: pip's dependency resolver does...\n",
       "4840     [data_transform_test = transforms.Compose([tra...\n",
       "4841     [A, B, N = 3, 4, 5\\r\\nmy_old_tensor = torch.on...\n",
       "4842     [Batch size &gt; 1 not implemented! Falling ba...\n",
       "4843     [!pip install torch==1.8.1 torchvision torchte...\n",
       "4844     [multiprocessing.Pool, from allennlp.predictor...\n",
       "4845     [torch.Size([15000, 23]), snnTorch, [time x ba...\n",
       "4846     [class GRU(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "4847     [forward, B = netG_A(A)  # G_A(A), transfering...\n",
       "4848     [[1,1,2,2,3,3] =&gt; ([1,2,3],[2,2,2])\\r\\n, ([...\n",
       "4849     [[1,1,2,2,3,3] =&gt; ([1,2,3],[2,2,2])\\r\\n, ([...\n",
       "4850     [text_field = Field(tokenize='spacy', lower=Tr...\n",
       "4851     [\\r\\nclass adaptive_implicit_trans(layers.Laye...\n",
       "4852     [import spacy\\r\\nfrom torchtext.datasets impor...\n",
       "4853     [outputs = self.decoder_stage2(torch.cat([shor...\n",
       "4854     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "4855     [# Load the model\\r\\nmodel = CNNSEG()\\r\\nmodel...\n",
       "4856     [# Load the model\\r\\nmodel = CNNSEG()\\r\\nmodel...\n",
       "4858     [Google's: pwcca_mean=0.21446671574218149\\r\\nG...\n",
       "4859     [all_probs, index_separator = 2\\r\\nall_probs =...\n",
       "4860     [export LIBTORCH=./libtorch\\r\\ngit clone https...\n",
       "4861     [t = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, ...\n",
       "4862     [(cx, cy, w, h, a), (x1,y1,x2,y2,x3,y3,x4,y4),...\n",
       "4863     [Embedding(5119, 25), emb = nn.Embedding.from_...\n",
       "4864     [import spacy\\r\\nfrom torchtext.datasets impor...\n",
       "4865     [tensordata.t() \\r\\n, torch.t(tensordata), ten...\n",
       "4866     [inp = torch.tensor([1.0])\\r\\n, class Model_up...\n",
       "4867     [  File \"train_mm.py\", line 448, in &lt;module...\n",
       "4869     [class ScaleLayer(layers.Layer):\\r\\n    def __...\n",
       "4870     [RuntimeError: Given groups=1, weight of size ...\n",
       "4871     [RuntimeError: Given groups=1, weight of size ...\n",
       "4872     [model = AutoEncoder(num_items, args.inner_lay...\n",
       "4873     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4874     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4875     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4876     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4877     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4878     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4879     [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "4880                                                 [NAN]\n",
       "4882                                                 [NAN]\n",
       "4883     [torch.utils.save_image, attack(), def attack(...\n",
       "4884     [import numpy as np\\r\\na = np.random.randint(0...\n",
       "4885     [import numpy as np\\r\\na = np.random.randint(0...\n",
       "4886     [Pure python energy function :   0.79002 +- 0....\n",
       "4887     [class Model(torch.nn.Module):\\r\\n    def __in...\n",
       "4888     [import cv2,glob\\r\\nimport numpy as np\\r\\nfrom...\n",
       "4889     [dataset = datasets.load_iris()\\r\\ndata = data...\n",
       "4890     [dataset = datasets.load_iris()\\r\\ndata = data...\n",
       "4891     [A\\r\\ntensor([[0.1, 0.4, 0.5],\\r\\n        [0.5...\n",
       "4892     [class LSTM_regr(torch.nn.Module) :\\r\\n    def...\n",
       "4893     [im = x[0]\\r\\npreprocess = transforms.Compose(...\n",
       "4894     [im = x[0]\\r\\npreprocess = transforms.Compose(...\n",
       "4895     [CrossEntropyLoss, CrossEntropyLoss, class MLP...\n",
       "4898     [\\r\\nA = torch.tensor([[1,1,1,1,1],\\r\\n       ...\n",
       "4899     [nn.Conv1d(), # Definition of Conv1d()\\r\\nself...\n",
       "4900     [\\r\\nimport torch\\r\\nimport torch.nn.functiona...\n",
       "4901     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4902     [class Attention(nn.Module):\\r\\n    def __init...\n",
       "4903     [# ===========================================...\n",
       "4904     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4905     [model_1, processor_1 = pretrained_model(), pr...\n",
       "4906     [/path/outputs/lg , Model, import os\\r\\nfrom t...\n",
       "4907     [estimator = PyTorch(entry_point='entry.py',\\r...\n",
       "4909     [def test(self):\\r\\n    model = BoxModel(100, ...\n",
       "4910     [device = torch.device('cpu')\\r\\nstate_dict = ...\n",
       "4911     [x, theta, theta, f, x, # minimal example of t...\n",
       "4912     [import numpy as np\\r\\n\\r\\nx = np.arange(2)   ...\n",
       "4913     [python3 detect.py --source 0\\r\\ndetect: weigh...\n",
       "4914     [torch.nn.Linear(in_features, out_features, bi...\n",
       "4915     [(1, 3, 16, 9), tensor([[[[ 0.,  0.,  0.,  0.,...\n",
       "4916     [(1, 3, 16, 9), tensor([[[[ 0.,  0.,  0.,  0.,...\n",
       "4918     [# example of pix2pix gan for satellite to map...\n",
       "4919     [pack_padded_sequence, ragged_tensors, &lt;eos...\n",
       "4921     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\na...\n",
       "4922     [#This function by Rodolfo Saldanha\\r\\ndef spl...\n",
       "4923     [x, y, metadata, for x, y_true, metadata in tr...\n",
       "4924     [class Net(nn.Module):\\r\\n   \\r\\n    def __ini...\n",
       "4926     [&gt; device = torch.device(\"cuda:0\" if torch....\n",
       "4927     [FROM 763104351884.dkr.ecr.us-east-1.amazonaws...\n",
       "4928     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4929     [ def forward(self, x, text_len):\\r\\n, dummy_i...\n",
       "4931     [python3 -c 'import torch; print(torch.cuda.is...\n",
       "4932     [from numpy.core.numeric import indices\\r\\nimp...\n",
       "4933     [Ax = B, U.dot(s).dot(Vh) ~ SVD(X), U, s, Vh, ...\n",
       "4934     [class encodingBlock(nn.Module):\\r\\n    def __...\n",
       "4935     [# Create some dummy data: we establish a line...\n",
       "4936     [import torch.optim as optim\\r\\nfrom torch.opt...\n",
       "4937     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "4938     [---------------------------------------------...\n",
       "4939                               [PyTorch, inplace=True]\n",
       "4941     [np_array1 = np.array([0.99995])\\r\\nprint(np_a...\n",
       "4942     [nomkl, import os\\r\\n\\r\\nos.environ['KMP_DUPLI...\n",
       "4944     [class linear_regression_glove(torch.nn.Module...\n",
       "4945     [\\r\\n{'loss': 1.1328, 'learning_rate': 4.99426...\n",
       "4946     [class RetinaFaceDatasetVideoNew(torch.utils.d...\n",
       "4947                       [views.py, models.py, views.py]\n",
       "4948           [[[0,1,2, ... 19],\\r\\n[0,1,2, ... 19]]\\r\\n]\n",
       "4949     [[10.2, nan]\\r\\n[10.0, 5.0]\\r\\n[nan, 3.2]\\r\\n,...\n",
       "4950     [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "4951     [class LambdaBase(nn.Sequential):\\r\\n    def _...\n",
       "4952     [from torch import nn\\r\\n\\r\\nclass myNN(nn.Mod...\n",
       "4953     [def meandice(pred, mask):\\r\\n    weit = 1 + 5...\n",
       "4954     [torch.device('cuda', 0)\\r\\n, Found GPU%d %s w...\n",
       "4955     [import torch.distributed as dist\\r\\nimport to...\n",
       "4956     [total = 0\\r\\n# since we're not training, we d...\n",
       "4957     [# Main Loop 1\\r\\nnum_epochs = 10 \\r\\nprint(f\"...\n",
       "4958                   [epochs = 10, lr=0.1, 0.1, 0, 0.01]\n",
       "4959     [# packages in environment at D:\\ProgramData\\A...\n",
       "4961     [from torchvision.models.resnet import resnet5...\n",
       "4962     [class MLP(nn.Module):\\r\\n  def __init__(self)...\n",
       "4963     [X_norm = (X - X.mean(dim=0)) / X.std(dim=0)  ...\n",
       "4964     [nn.Module,     def forward(self, x: Tensor, i...\n",
       "4965     [tensor([[0., 0., 0., 0.],\\r\\n    [0., 1., 1.,...\n",
       "4966     [python ./test.py --name deepfashionHD --datas...\n",
       "4967     [if rank == 0:\\r\\n    store = dist.TCPStore(os...\n",
       "4968     [transformers, trainer.save_model(model_name)\\...\n",
       "4970     [        indices = ...\\r\\n        X = ...\\r\\n ...\n",
       "4971     [        at::Tensor tensor2 = torch::from_blob...\n",
       "4972     [label = torch.LongTensor(label).cuda()\\r\\n\\r\\...\n",
       "4973     [class MLP(nn.Module):\\r\\n  def __init__(self)...\n",
       "4974     [x = torch.Tensor(np.random.rand(2, 48, 8, 8))...\n",
       "4976     [current_loc = pathlib.Path(__file__).parent.a...\n",
       "4977     [import os\\r\\nimport torch\\r\\nimport matplotli...\n",
       "4979     [self.features.append(nn.Conv2d(1, 6, 5))\\r\\ns...\n",
       "4981     [class Encoder(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "4982     [class Gen_Block(nn.Module):\\r\\n    def __init...\n",
       "4983     [## DOUBLE Q DEEP LEARNING NETWORK\\r\\nclass Sn...\n",
       "4984     [## DOUBLE Q DEEP LEARNING NETWORK\\r\\nclass Sn...\n",
       "4985     [X = (X - X.mean(dim=0)) / X.std(dim=0)\\r\\ncor...\n",
       "4986     [__getitem__(), AttributeError                ...\n",
       "4987     [model = gcam.inject(model, output_dir=\"output...\n",
       "4988     [FloatTensor, T, [F, X, Y], X, Y, F, T[:, x, y...\n",
       "4989     [constructor, forward, forward, forward, const...\n",
       "4990     [ERROR: pip's dependency resolver does not cur...\n",
       "4991     [mdl.train(), mdl.test(), def meta_train_fixed...\n",
       "4992     [ memory = sample(observation)\\r\\n replay_buff...\n",
       "4993     [Draw, angle_loss2, import torch\\r\\nimport tor...\n",
       "4994     [Out[1]: BatchNorm2d(32, eps=0.001, momentum=0...\n",
       "4995     [net.train(), def test(db, net, device, epoch,...\n",
       "4996     [A = Tensor([[[a 2x2 mat AAA1], [a 2x2 mat BBB...\n",
       "4997     [    g.eval()\\r\\n    for param in g.parameters...\n",
       "4998     [tensor.contiguous(), RuntimeError: invalid ar...\n",
       "5000     [        torch.save(model.state_dict(), '/home...\n",
       "5001     [class TiedAutoEncoder(nn.Module):\\r\\ndef __in...\n",
       "5002     [import cupy as cp\\r\\nfrom cupyx.scipy.ndimage...\n",
       "5003     [C = torch.quantile(A, B, dim=1, keepdim=True)...\n",
       "5004     [ File \"/content/drive/My Drive/EditNTS-Google...\n",
       "5005     [from transformers import AutoModel, AutoToken...\n",
       "5006     [RuntimeError: Input type (torch.cuda.FloatTen...\n",
       "5007     [RuntimeError: Input type (torch.cuda.FloatTen...\n",
       "5008     [if torch.cuda.is_available() == False and dev...\n",
       "5009     ['''\\r\\nRead Edges and features from csv file\\...\n",
       "5011     [catalyst,       agent_1_feat_0  agent_1_feat_...\n",
       "5012     [v, q, v_trans, eta, for i in range(10):\\r\\n  ...\n",
       "5013     [class BatchNorm(nn.Module):\\r\\n    def __init...\n",
       "5014     [conda install -c anaconda cudatoolkit\\r\\ncond...\n",
       "5015     [for i in range(10):\\r\\n    print('i =', i, ' ...\n",
       "5017     [forward(), def forward(self, input_features, ...\n",
       "5018     [from transformers import RobertaForMaskedLM, ...\n",
       "5019     [pip3 install torch==1.10.0+cu113 torchvision=...\n",
       "5020     [a, float32, [M, N], b, int64, [K], b, c, b, c...\n",
       "5021     [field = Wrong_U_param(r, theta, positions)\\r\\...\n",
       "5022     [import networkx as nx\\r\\nimport matplotlib.py...\n",
       "5026     [review_text = \"I love completing my todos! Be...\n",
       "5027     [review_text = \"I love completing my todos! Be...\n",
       "5028     [RuntimeError: stack expects each tensor to be...\n",
       "5029     [a = torch.tensor([[[[1,2], [2,3], [3,4]],  [[...\n",
       "5031     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5032     [a, b, k[i][j] = exp( -(a[i]-b[j])**2 ), impor...\n",
       "5033     [a, b, k[i][j] = exp( -(a[i]-b[j])**2 ), impor...\n",
       "5035     [    import torch.nn as nn\\r\\n    from torch.n...\n",
       "5036     [def improve(self, state):\\r\\n        step_cou...\n",
       "5037     [setup.py, package_data = {'mypackage': ['mode...\n",
       "5038     [nn.Linear, A = [[a0,a1,a2,a2,a2], \\r\\n     [a...\n",
       "5040     [main, (software1) myusername@mylaptopname:~/f...\n",
       "5042     [import sys\\r\\nimport subprocess\\r\\nsys.path.a...\n",
       "5044     [def loss_fcn(outputs, labels):\\r\\n    from sk...\n",
       "5045     [    self.device = torch.device('cpu')  \\r\\n\\r...\n",
       "5046                               [requires_grad = False]\n",
       "5048     [class Seq2SeqTokenCLS(nn.Module):\\r\\n    def ...\n",
       "5050     [v = torch.div(t, n[:, None])\\r\\n, v, t, n, None]\n",
       "5051     [class traindataset(Dataset):\\r\\n    def __ini...\n",
       "5052     [T, (8, 8, 4, 4), x, y, x = tensor([1, 2, 3, 1...\n",
       "5054     [torchvision.datasets.CIFAR10, torch.utils.dat...\n",
       "5055     [ARG PYTORCH=\"1.6.0\"\\r\\nARG CUDA=\"10.1\"\\r\\nARG...\n",
       "5056     [class test_model(nn.Module):\\r\\n    def __ini...\n",
       "5058     [Conv2d(128, 256, 3, padding=1, stride=2)\\r\\n,...\n",
       "5059     [def get_skorch_classifier():\\r\\n    X_train_m...\n",
       "5060     [nn.Embedding, import torch\\r\\nimport gensim\\r...\n",
       "5061     [UserWarning: \"D:\\Anaconda3\\envs\\pytorch\\lib\\s...\n",
       "5062     [[1, 1, 4, 4], ConvTranspose2D, stride=2, padd...\n",
       "5063     [[1, 1, 4, 4], ConvTranspose2D, stride=2, padd...\n",
       "5064     [from torchvision import transforms\\r\\nfrom to...\n",
       "5065     [    def forward(self, torch_input):\\r\\n      ...\n",
       "5066     [train.csv, test.csv, test.csv, preds, target ...\n",
       "5067     [class SelfAttentionPooling(nn.Module):\\r\\n   ...\n",
       "5068     [output = UNet(input)\\r\\n, (batch_size,1,128,1...\n",
       "5069     [output = UNet(input)\\r\\n, (batch_size,1,128,1...\n",
       "5070     [IterableDataset, testfile.txt, 0 - Dummy line...\n",
       "5071     [IterableDataset, testfile.txt, 0 - Dummy line...\n",
       "5072     [class CNN_Model(nn.Module):\\r\\n  def __init__...\n",
       "5073     [# Store a complete trajectory for a single ep...\n",
       "5074     [loss.backward(), nvidia-smi, def train_loop(m...\n",
       "5075     [Error(Logfile):, Script for model interaction...\n",
       "5076     [torch.optim, optim.SGD([\\r\\n                {...\n",
       "5077     [torch.optim, optim.SGD([\\r\\n                {...\n",
       "5078     [from keras.preprocessing.text import Tokenize...\n",
       "5079     [model = Model(config) \\r\\nmodel.load_state_di...\n",
       "5081     [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "5082     [for loop, validation_fn, TypeError, None, def...\n",
       "5083     [v, w, n, x, n, k, i_0, i_{k-1}, x = [0,0,3,6,...\n",
       "5084     [from torch.nn.utils import weight_norm as wn\\...\n",
       "5085     [import flax.linen as jnn \\r\\nimport jax\\r\\nim...\n",
       "5086     [# Preliminaries\\r\\nfrom torchtext.data import...\n",
       "5087     [File = open('info.txt','r')\\r\\nusername = inp...\n",
       "5090     [class linear_regression(torch.nn.Module):\\r\\n...\n",
       "5091     [learn = text_classifier_learner(dbunch_clas, ...\n",
       "5092     [from torchvision.models.vgg import *\\r\\n\\r\\ni...\n",
       "5093     [from focal_loss import BinaryFocalLoss\\r\\n, c...\n",
       "5094     [model.eval(), model.eval(), std::vector&lt;to...\n",
       "5095     [for epoch in range(epochs):\\r\\n    model.trai...\n",
       "5096     [from PIL import Image\\r\\nfrom torchvision imp...\n",
       "5097     [Traceback (most recent call last):\\r\\n  File ...\n",
       "5098     [from torchvision import transforms\\r\\nfrom to...\n",
       "5099     [from torchvision import transforms\\r\\nfrom to...\n",
       "5100     [from torchvision import transforms\\r\\nfrom to...\n",
       "5101     [for obj_num in range(obj_vecs.shape[0]): #bat...\n",
       "5102     [#visualize training data\\r\\nmy_dataset_train_...\n",
       "5103     [---------------------------------------------...\n",
       "5104     [tensor([[ 337,  337,  337,  ...,  340,  340, ...\n",
       "5105     [transform = transforms.Compose([\\r\\n    trans...\n",
       "5106     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5107     [tags = []\\r\\nfor intent in intents['intents']...\n",
       "5108     [tags = []\\r\\nfor intent in intents['intents']...\n",
       "5109     [tags = []\\r\\nfor intent in intents['intents']...\n",
       "5110     [tags = []\\r\\nfor intent in intents['intents']...\n",
       "5111     [tags = []\\r\\nfor intent in intents['intents']...\n",
       "5112     [conv2d, torch.nn.functional, cuda, A = torch....\n",
       "5113     [class RNNBaseline(nn.Module):\\r\\ndef __init__...\n",
       "5114     [# netD.zero_grad() # Q: why we don't do this?...\n",
       "5115     [# netD.zero_grad() # Q: why we don't do this?...\n",
       "5116     [config, TypeError: empty() received an invali...\n",
       "5118     [AssertionError: Torch not compiled with CUDA ...\n",
       "5119     [os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" ...\n",
       "5120     [#fixme: k-fold cross validation\\r\\nn_crossVal...\n",
       "5121     [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "5122     [python ~/ultimate-utils/tutorials_for_myself/...\n",
       "5123     [[tensor([[0.4839, 0.3282, 0.1773,  ..., 0.293...\n",
       "5124     [[tensor([[0.4839, 0.3282, 0.1773,  ..., 0.293...\n",
       "5125     [[tensor([[0.4839, 0.3282, 0.1773,  ..., 0.293...\n",
       "5127     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5128     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5129     [import os\\r\\nfrom PIL import Image\\r\\nfrom to...\n",
       "5130     [image   -)  shape: torch.Size([3, 850, 600]),...\n",
       "5131     [C:\\Program Files\\Python39\\lib\\site-packages\\s...\n",
       "5133     [for, import torch\\r\\nimport numpy as np\\r\\n\\r...\n",
       "5134     [for, import torch\\r\\nimport numpy as np\\r\\n\\r...\n",
       "5135     [mode: ['baseline', 'advanced']\\r\\nparam_a: [1...\n",
       "5136     [from sklearn.model_selection import train_tes...\n",
       "5138     [num_train_batches = 20\\r\\n\\r\\n# QAT takes tim...\n",
       "5139     [# create dataset and dataloaders\\r\\nmax_encod...\n",
       "5141     [    def __getitem__(self, idx):\\r\\n      sequ...\n",
       "5142     [encoder = AutoModelForSequenceClassification....\n",
       "5143     [A = torch.tensor([[1, 2], [3, 4]])\\r\\nB = tor...\n",
       "5144     [A = torch.tensor([[1, 2], [3, 4]])\\r\\nB = tor...\n",
       "5146     [X_data:\\r\\n(200000, 6)\\r\\n[[ 0.00237987  0.00...\n",
       "5147     [splitfolders.ratio(\"content/data\", output=\"ou...\n",
       "5148     [from torch import nn\\r\\n\\r\\nclass XORLinear(n...\n",
       "5149     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5150     [class ImageClassificationBase(nn.Module):\\r\\n...\n",
       "5151     [ import torch\\r\\n torch.cuda.is_available()\\r...\n",
       "5152     [[E ProcessGroupNCCL.cpp:630] [Rank 3] Watchdo...\n",
       "5153     [[E ProcessGroupNCCL.cpp:630] [Rank 3] Watchdo...\n",
       "5154     [[E ProcessGroupNCCL.cpp:630] [Rank 3] Watchdo...\n",
       "5155     [RuntimeError: Error(s) in loading state_dict ...\n",
       "5156     [inp_fields = Field(sequential = False, use_vo...\n",
       "5157     [base_model = torch.hub.load('pytorch/vision:v...\n",
       "5158     [class ConvNet(nn.Module):\\r\\n  def __init__(s...\n",
       "5159     [checkpoint = torch.load(\"Model/SPAN/SPAN-PT-R...\n",
       "5160     [model.load_state_dict(torch.load(model_name))...\n",
       "5161     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "5162     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "5163     [*cudatoolkit=10.0.130=0\\r\\ncudnn=7.6.4=cuda10...\n",
       "5164     [model = load_model(path)\\r\\nif torch.cuda.dev...\n",
       "5165     [INPUT : A (tensor of FP32, [1, 4, 1024, 256])...\n",
       "5166     [class JointDataset(torch.utils.data.Dataset):...\n",
       "5167     [x_train, x_test, y_train, , y_test, x_train =...\n",
       "5168     [x_train, x_test, y_train, , y_test, x_train =...\n",
       "5169     [# params = number of parameters\\r\\n# 1 MiB = ...\n",
       "5170     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "5171     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5172     [import torch.nn as nn\\r\\nfrom pytorch_lightni...\n",
       "5174     [INPUT : A (tensor of FP32, [1, 4, 1024, 256])...\n",
       "5175     [\"RuntimeError: CUDA out of memory. Tried to a...\n",
       "5176     [class ConvBlock(nn.Module):\\r\\n    def __init...\n",
       "5178     [AttributeError                            Tra...\n",
       "5179     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5180     [ nvcc --version\\r\\nnvcc: NVIDIA (R) Cuda comp...\n",
       "5181     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "5182     [batch_size, preds, labels, import os\\r\\nimpor...\n",
       "5183     [analysis = tune_robert_asha(num_samples=2)\\r\\...\n",
       "5184     [# GRU layer\\r\\nself.gru = nn.GRU(64, 32, bidi...\n",
       "5185     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "5186     [class SelfSupervisedModel(pl.LightningModule)...\n",
       "5187     [x1 = torch.Size([1, 512, 177])\\r\\nx2 = torch....\n",
       "5189     [trf = transforms.Compose([\\r\\n    transforms....\n",
       "5190     [import pandas as pd\\r\\nimport os\\r\\nimport to...\n",
       "5192     [class ChordClassificationNetwork(nn.Module):\\...\n",
       "5193     [tensor([[-0.7909, -0.6041]], grad_fn=&lt;LogS...\n",
       "5195               [[197, 1, 768], [197,1,128], nn.Conv()]\n",
       "5196     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "5197     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "5198     [             MSCI World   S&amp;P 500   ...  ...\n",
       "5199     [val_data = data from a previous experiment\\r\\...\n",
       "5200     [Traceback (most recent call last):\\r\\n  File ...\n",
       "5202     [Sim = torch.rand((5, 5))\\r\\nsamples_idx = [0]...\n",
       "5203     [Sim = torch.rand((5, 5))\\r\\nsamples_idx = [0]...\n",
       "5204     [Sim = torch.rand((5, 5))\\r\\nsamples_idx = [0]...\n",
       "5205     [opset.ts:48 Uncaught (in promise) TypeError: ...\n",
       "5206     [import os\\r\\nimport torch\\r\\n\\r\\ndevice = (\"c...\n",
       "5207     [import os\\r\\nimport torch\\r\\n\\r\\ndevice = (\"c...\n",
       "5208     [calculate_bleu_score, def calculate_bleu(data...\n",
       "5209     [from transformers import pipeline\\r\\nclassifi...\n",
       "5210     [from transformers import pipeline\\r\\nclassifi...\n",
       "5211     [!python train.py --img 800 --batch 32 --epoch...\n",
       "5212     [print(\"%.8f\" % np.max(np.abs(before -after)))...\n",
       "5213     [print(\"%.8f\" % np.max(np.abs(before -after)))...\n",
       "5214     [class MK7AutoPilot(nn.Module):\\r\\n\\r\\n    def...\n",
       "5215     [._parameters, model = nn.Linear(10, 10)\\r\\npr...\n",
       "5216     [._parameters, model = nn.Linear(10, 10)\\r\\npr...\n",
       "5217     [PyTorch, class Model(nn.Module):\\r\\n    def _...\n",
       "5218     [class SwelltrainDataset(T.utils.data.Dataset)...\n",
       "5219     [RuntimeError: Input type (torch.cuda.FloatTen...\n",
       "5220     [net = CustomNet()\\r\\nmse_loss = torch.nn.MSEL...\n",
       "5221     [Subset, SubsetRandomSampler, Subset, SubsetRa...\n",
       "5222     [Pytorch, IoULoss, def IoULoss(inputs, targets...\n",
       "5223     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\ne...\n",
       "5224     [        for name, param in model.named_parame...\n",
       "5225     [H5 file, H5 file, code, multi videos, single ...\n",
       "5226     [a = tensor([[1., 1., 2.],\\r\\n            [1.,...\n",
       "5227     [My Pseudo Code\\r\\nINPUT(FP32) :\\r\\n Embedded ...\n",
       "5228     [torch.Size([3, 48, 48]) 0\\r\\n, model.fc = nn....\n",
       "5229     [tf.keras.layers.StringLookup, vocab = [\"a\", \"...\n",
       "5230     [tf.keras.layers.StringLookup, vocab = [\"a\", \"...\n",
       "5231     [tf.keras.layers.StringLookup, vocab = [\"a\", \"...\n",
       "5232                                            [nan, nan]\n",
       "5233     [nn.ModuleList,     class testModel(nn.Module)...\n",
       "5234     [class CBOW(torch.nn.Module):\\r\\n    def __ini...\n",
       "5235     [self.p1 = nn.Parameter(), def __init__(self, ...\n",
       "5236     [self.inital_value = nn.Parameter(torch.randn(...\n",
       "5237     [srcIndex &lt; srcSelectDimSize, Epoch [1/100]...\n",
       "5238     [dropout = 1, nn.LSTM, input_dim = 16\\r\\nhidde...\n",
       "5239     [use_gpu = torch.cuda.is_available()\\r\\nlearni...\n",
       "5240     [import torch\\r\\na = torch.tensor([2., 3.], re...\n",
       "5241     [=============================================...\n",
       "5242     [import torch, torchvision\\r\\nimport torch.nn ...\n",
       "5243     [class linear_model(nn.Module):\\r\\n    def __i...\n",
       "5244     [_stateless, nn, import torch\\r\\nfrom torch im...\n",
       "5245     [_stateless, nn, import torch\\r\\nfrom torch im...\n",
       "5246     [Tensor, Tensor, Tensor, dims, (2, 3), (2, 3, ...\n",
       "5247     [import logging\\r\\n\\r\\nimport torch\\r\\nfrom to...\n",
       "5248     [import augly.image as imaugs\\r\\nimport augly....\n",
       "5250     [autopep8==1.4.3\\r\\ncertifi==2020.6.20\\r\\ncffi...\n",
       "5251     [class Autoencoder(nn.Module):\\r\\n    def __in...\n",
       "5252     [loss = - log_prob(action) * R, def main():\\r\\...\n",
       "5253     [class CustomSchedule(tf.keras.optimizers.sche...\n",
       "5254     [import torch as th\\r\\nfrom torch.autograd imp...\n",
       "5255     [    def get_models(args):\\r\\n    \\r\\n    \\r\\n...\n",
       "5256     [        self.conv1 = nn.Conv2d(in_channels=1,...\n",
       "5257     [def train_net_ap(self, idx):\\r\\n    s, a, r, ...\n",
       "5261     [class GRULinear(nn.Module):\\r\\n    def __init...\n",
       "5263     [    Traceback (most recent call last):\\r\\n   ...\n",
       "5264     [File \"/home/ferdiko/fastmoe/examples/transfor...\n",
       "5265     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5266     [model = torch.load(\"models/MobileNetV2_CLEF_S...\n",
       "5268     [class Summarizer(pl.LightningModule):\\r\\n  de...\n",
       "5269     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5270     [class DSET:\\r\\n    def __init__(self, load_fi...\n",
       "5273     [mp3, torchaudio.info(path), metadata = torcha...\n",
       "5274     [for epoch in range(2000):\\r\\n    for i in ran...\n",
       "5275     [mlflow.pytorch.log_model(net, artifact_path=\"...\n",
       "5276     [y=tensor([958,  85, 244, 182, 294])\\r\\n, scor...\n",
       "5277     [y=tensor([958,  85, 244, 182, 294])\\r\\n, scor...\n",
       "5278     [model.fc = nn.Sequential(\\r\\n        nn.Conv2...\n",
       "5279     [def train_model(model, train_loader, val_load...\n",
       "5280     [nn.Module, class Net(torch.nn.Module):\\r\\n   ...\n",
       "5281     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5282     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5285     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5287     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5288     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5292     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5293     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5294     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5295     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5297     [def method(self, blah):\\r\\n    def __init__(?...\n",
       "5298                    [batch.to(\"cuda\"), __getitem()___]\n",
       "5300     [padding = 2, strides = 2, kernel = (5,5), pad...\n",
       "5302     [Dataset, __getitem__(), (250, 150), DataLoade...\n",
       "5303     [class CLIPNN(nn.Module):\\r\\n\\r\\n    def __ini...\n",
       "5304     [torch.no_grad(), with torch.no_grad():\\r\\n   ...\n",
       "5305     [argmax, int_to_char = dict((i, c) for i, c in...\n",
       "5306     [.to(self.device), mask = torch.tril(torch.one...\n",
       "5307     [save_image, save_image(final_images, \"./outpu...\n",
       "5308     [(s(t-α), s(t), s(t+1)), L = max(d(s(t+1) , s(...\n",
       "5310     [def simple_loss(pred, mask):   # regression c...\n",
       "5311     [model = torch.hub.load('.', 'custom', path='r...\n",
       "5312     [TimeSeriesDataSet, import numpy as np\\r\\nimpo...\n",
       "5313     [nn.Module, M_outer, M_inner, M_sub, class M_o...\n",
       "5314     [def __init__(self):\\r\\n    super(Net, self)._...\n",
       "5315     [def __init__(self):\\r\\n    super(Net, self)._...\n",
       "5316     [Traceback (most recent call last):\\r\\n  File ...\n",
       "5317     [FROM pymesh/pymesh:latest\\r\\n\\r\\nWORKDIR /app...\n",
       "5319     [os.environ['TORCH_HOME'] = '../input/torchvis...\n",
       "5320     [os.environ['TORCH_HOME'] = '../input/torchvis...\n",
       "5321     [import torch\\r\\nx = torch.randn(100,100,devic...\n",
       "5322     [def train_alexnet(), IndexError: only integer...\n",
       "5323     [indices = torch.tensor([2, 4, 5])\\r\\n\\r\\n# De...\n",
       "5324     [class LeNet(nn.Module):\\r\\n    def __init__(s...\n",
       "5325     [(QGN) ubuntu@ip-172-31-13-114:~/QGN$ python t...\n",
       "5326     [class NormalAutoEncoder(nn.Module)):\\r\\n    d...\n",
       "5327     [RuntimeError: Error(s) in loading state_dict ...\n",
       "5328     [torch.argmax, original_array, max_vals, indic...\n",
       "5330     [Pytorch, Anaconda, Stable (1.9.1), LTS(1.8.2)...\n",
       "5331     [#No obvious errors here to me\\r\\nC:\\...\\examp...\n",
       "5332     [ model = detection.fasterrcnn_resnet50_fpn(pr...\n",
       "5333     [net = nn.Linear(54, 7)\\r\\noptimizer = optim.S...\n",
       "5334     [class LSTM1(nn.Module):\\r\\ndef __init__(self,...\n",
       "5335     [class Dataset2(torch.utils.data.Dataset):\\r\\n...\n",
       "5336     [test_dataloader = DataLoader(test_dataset, ba...\n",
       "5337     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "5338     [model = train_mask_net(64)\\r\\n, def train_mas...\n",
       "5339     [trainloader = torch.utils.data.DataLoader(tra...\n",
       "5340     [scaler.step(optimizer), Traceback (most recen...\n",
       "5341     [def main():\\r\\n    parser = argparse.Argument...\n",
       "5342     [masked_select, x = torch.tensor([[1., 2., 2.,...\n",
       "5343     [Error: return torch._C._nn.cross_entropy_loss...\n",
       "5345     [datasets.GeneratorBasedBuilder, _generate_exa...\n",
       "5346     [class LayerWithCustomGrad(nn.Module):\\r\\n    ...\n",
       "5348     [n, d = {0:\"batched data\", 1:\"batched data\", 2...\n",
       "5349     [nvcc –V , nvidia-development-kit, sudo apt in...\n",
       "5350     [nn.NLLLoss(), True, nn.NLLLoss(), import torc...\n",
       "5351     [download_file_from_google_drive, download_fil...\n",
       "5353     [.pth, model = GatherModel()\\r\\nmodel.load_sta...\n",
       "5354     [!nvidia-smi, +-------------------------------...\n",
       "5355     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "5356     [ class SinusDataset(Dataset):\\r\\n\\r\\n    def ...\n",
       "5357     [PyTorch, class Net(torch.nn.Module):\\r\\n    d...\n",
       "5359     [    public Tensor recognize(Bitmap image){\\r\\...\n",
       "5360     [arr = torch.rand((2, 3, 3, 3)), arr = tensor(...\n",
       "5361     [nn.Embedding, embedding_dim, num_node, train_...\n",
       "5362     [nn.Embedding, embedding_dim, num_node, train_...\n",
       "5363     [D, import torch\\r\\nimport pyro\\r\\nimport pyro...\n",
       "5364     [nn.Embedding,     def embedding_lookup(self, ...\n",
       "5365     [def variable_from_sentence(sentence):\\r\\n  ve...\n",
       "5367     [weight.grad, weight.prev_v, nn.Parameter, .da...\n",
       "5368     [from torch.utils.data import DataLoader,Datas...\n",
       "5369     [torch==1.7.1+cu101, import torch\\r\\na = torch...\n",
       "5370     [fastai v0.7.0, conv_learner, tfms_from_model(...\n",
       "5371     [def IoU(predict: torch.Tensor, target: torch....\n",
       "5373     [torch.nn.Sigmoid(), torch.nn.BCELoss, Runtime...\n",
       "5374     [torch.nn.functionnal.pad, F.pad(array, [-1,-1])]\n",
       "5375     [nn.Mudule, input_ @ self.weight, forward, inp...\n",
       "5376     [ValueError: Using a target size (torch.Size([...\n",
       "5377     [for epoc in range(1, nb_epochs+1):\\r\\n  #init...\n",
       "5378     [for epoc in range(1, nb_epochs+1):\\r\\n  #init...\n",
       "5379     [torch.autograd.grad(), x = torch.rand(6, requ...\n",
       "5380     [A = torch.rand(5, 100, 20) # Original Tensor\\...\n",
       "5381     [A = torch.rand(5, 100, 20) # Original Tensor\\...\n",
       "5382     [def IoU(predict: torch.Tensor, target: torch....\n",
       "5383     [model = torch.nn.Sequential(\\r\\n        torch...\n",
       "5384     [model = torch.nn.Sequential(\\r\\n        torch...\n",
       "5385     [nn.Parameter, nn.Parameter, [1.0605, 1.0715, ...\n",
       "5386     [sbatch --gpus=1 -t 100 python train.py\\r\\n, G...\n",
       "5387     [weights=[0.00000001,1/112,1/116,1/180,1/81,1/...\n",
       "5391     [b, torch.Size([10, 10, 51]), a = np.array([0,...\n",
       "5392     [train_model(), retain_graph = True, loss.back...\n",
       "5394     [def randomQuantization(w, w_global, ratio, de...\n",
       "5395     [class my_network(nn.Module):\\r\\n\\r\\ndef __ini...\n",
       "5396     [model = Resnet34() #I have changes some layer...\n",
       "5397     [(64, 224, 224), # x will have shape of (64, 2...\n",
       "5400     [ RuntimeError: Expected all tensors to be on ...\n",
       "5401     [ RuntimeError: Expected all tensors to be on ...\n",
       "5402     [Resnet_Classifier(\\r\\n  (activation): ReLU()\\...\n",
       "5403     [Resnet_Classifier(\\r\\n  (activation): ReLU()\\...\n",
       "5404     [loader = Dataloader(..., total=800000)\\r\\nfor...\n",
       "5405     [Traceback (most recent call last):\\r\\n\\r\\n  F...\n",
       "5406     [np.random.seed(0)\\r\\nm_numpy = np.random.choi...\n",
       "5407     [np.random.seed(0)\\r\\nm_numpy = np.random.choi...\n",
       "5408     [# This training code is based on the `run_glu...\n",
       "5409     [samples, list, tensor, import torch\\r\\nimport...\n",
       "5410     [samples, list, tensor, import torch\\r\\nimport...\n",
       "5411     [samples, list, tensor, import torch\\r\\nimport...\n",
       "5412     [Traceback (most recent call last):\\r\\nFile \"D...\n",
       "5413     [!python train.py --gpus=1 --cfg=$config --met...\n",
       "5414     [Traceback (most recent call last):\\r\\n  File ...\n",
       "5415     [def my_softmax(x):\\r\\n    exp = x.exp()\\r\\n  ...\n",
       "5416     [import math\\r\\n\\r\\ndef makebatches(x_train,y_...\n",
       "5417     [for i in range(0,len(x)):\\r\\n    for j in ran...\n",
       "5418     [for i in range(0,len(x)):\\r\\n    for j in ran...\n",
       "5419     [K1 = -mmread('full1_0.1.A').tocoo()  \\r\\nK1_n...\n",
       "5421     [max_length, tokenizer = BertTokenizer.from_pr...\n",
       "5423     [forward(), def forward(self, x):\\r\\n    \"\"\" N...\n",
       "5424     [   # Initialize our Trainer\\r\\n    trainer = ...\n",
       "5425     [   # Initialize our Trainer\\r\\n    trainer = ...\n",
       "5426     [   # Initialize our Trainer\\r\\n    trainer = ...\n",
       "5427     [   # Initialize our Trainer\\r\\n    trainer = ...\n",
       "5428     [img = Image.open(\"/content/drive/MyDrive/5812...\n",
       "5429     [\\r\\n    class Net(nn.Module):\\r\\n        def ...\n",
       "5431     [affine = transforms.RandomAffine([-15, 15], s...\n",
       "5432     [    |--------+------+----------+----------|\\r...\n",
       "5433     [import copy\\r\\nimport torch\\r\\nimport torch.n...\n",
       "5434     [import copy\\r\\nimport torch\\r\\nimport torch.n...\n",
       "5435     [model_conv = torchvision.models.vgg16(pretrai...\n",
       "5436     [KeyError                                  Tra...\n",
       "5437     [# -*- coding: utf-8 -*-\\r\\n\"\"\"x.ipynb\\r\\n\\r\\n...\n",
       "5438     [import torch\\r\\nfrom torch import nn\\r\\nclass...\n",
       "5439     [class NNBase(nn.Module):\\r\\n\\r\\ndef training_...\n",
       "5440     [torch.distributed.new_group([a,b,c,d]), a,b,c,d]\n",
       "5441     [class MyModel(nn.Module):\\r\\ndef __init__(sel...\n",
       "5443     [from torchvision import models\\r\\n\\r\\nmodel =...\n",
       "5444     [def loss_func(result, target) -&gt; torch.Ten...\n",
       "5445     [os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2,3,4...\n",
       "5446     [CxH\\r\\n, H, C, H, W, torch.mul(A, W).mean(1) ...\n",
       "5447     [enter def visualize_model(model,num_images=6)...\n",
       "5448     [flow_from_dataframe, flow_from_dataframe(\\r\\n...\n",
       "5449     [from torch.autograd import grad\\r\\ntrain_loss...\n",
       "5450     [# Initialize x, y and z to values 4, -3 and 5...\n",
       "5451     [# Initialize x, y and z to values 4, -3 and 5...\n",
       "5452     [# Initialize x, y and z to values 4, -3 and 5...\n",
       "5454     [from nemo.collections.tts.models import Tacot...\n",
       "5456     [unet_learner, .fine_tune(n), label, for i in ...\n",
       "5458     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "5459     [RuntimeError: CUDA error: no kernel image is ...\n",
       "5460     [class NNModel(nn.Module):\\r\\n    \\r\\n    def ...\n",
       "5461     [class Discriminator(nn.Module):\\r\\ndef __init...\n",
       "5462     [from transformers import CTRLTokenizer, TFCTR...\n",
       "5463     [a: torch.Size([16, 1]), b: torch.Size([16, 12...\n",
       "5464     [torch.distributed.init_process_group(backend=...\n",
       "5465     [nn.Sequential(list(model.children())[:7])\\r\\n...\n",
       "5466     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "5467     [import torch\\r\\nimport pandas as pd\\r\\nimport...\n",
       "5468     [pip3 install torch==1.7.1+cu110 torchvision==...\n",
       "5469     [y = x_1^T A x_2 + b , a = tf.matmul(tf.matmul...\n",
       "5470     [mean_n = alpha * mean_{n-1} + (1-alpha) * sam...\n",
       "5471     [.apply(), def mutate(m):\\r\\n    if type(m) ==...\n",
       "5472     [.apply(), def mutate(m):\\r\\n    if type(m) ==...\n",
       "5473     [bart.base, torch.hub, bart = torch.hub.load('...\n",
       "5474     [   def dump_embedding(self, weight):\\r\\n     ...\n",
       "5475                                                [None]\n",
       "5477     [import numpy as np\\r\\nimport torch\\r\\n\\r\\ndef...\n",
       "5478     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "5479     [\"\"\"\\r\\n    Usages:\\r\\n        CUDA_VISIBLE_DE...\n",
       "5481     [RuntimeError: gather_out_cuda(): Expected dty...\n",
       "5482     [import torch\\r\\n\\r\\n# Model\\r\\nmodel = torch....\n",
       "5483     [class Build_Model(nn.Module):\\r\\n    def __in...\n",
       "5484     [nn.Module, from torch import nn\\r\\n\\r\\nfrom c...\n",
       "5486     [class PositionalEncoding(nn.Module):\\r\\n    \\...\n",
       "5487     [pip install 'lightning-flash[image]', import ...\n",
       "5488     [a = torch.tensor([[1,0,1,0],\\r\\n             ...\n",
       "5489     [import torch\\r\\nimport pyro\\r\\npyd = pyro.dis...\n",
       "5491     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5492     [class NeuralNetwork(nn.Module):\\r\\n    def __...\n",
       "5493     [WeightedRandomSampler, train_labels.head(5)\\r...\n",
       "5494     [class Concat(nn.Module):\\r\\n    def __init__(...\n",
       "5495     [class Concat(nn.Module):\\r\\n    def __init__(...\n",
       "5496     [ def loss(self,pred,y_true):\\r\\n    pred = to...\n",
       "5497     [Dataset, Dataset,    def __getitem__(self, i)...\n",
       "5498     [model_d = torch.load(f'{conf.save_path}/DeepP...\n",
       "5499     [env: ‘pkg-config’: No such file or directory\\...\n",
       "5500     [env: ‘pkg-config’: No such file or directory\\...\n",
       "5501     [env: ‘pkg-config’: No such file or directory\\...\n",
       "5502                        [get_weights(), set_weights()]\n",
       "5503     [def forward(self, text):\\r\\n    # text is sha...\n",
       "5505     [def prune_model_l1_unstructured(model, layer_...\n",
       "5506     [class Network(nn.Module):\\r\\ndef __init__(sel...\n",
       "5507     [N = x.shape[0] # x.shape = (N,d)\\r\\nG = torch...\n",
       "5508     [dataset, matplotlib, import dgl\\r\\nimport tor...\n",
       "5509     [class ResNetMSTAR(pl.LightningModule):\\r\\ndef...\n",
       "5511     [    model.eval()\\r\\n    x = torch.randn(1, 3,...\n",
       "5512     [G, g_loss = self.D(fake_images)\\r\\ng_loss = g...\n",
       "5513     [(metalearning_gpu) miranda9~/automl-meta-lear...\n",
       "5514     [(metalearning_gpu) miranda9~/automl-meta-lear...\n",
       "5515     [en_core_web_trf, class SpacyExtractor():\\r\\n ...\n",
       "5516     [class Mnist_Net(nn.Module):\\r\\ndef __init__(s...\n",
       "5517     [class LeNet5(nn.Module):\\r\\n\\r\\n    def __ini...\n",
       "5520     [def get_embeddings(model, data_loader, device...\n",
       "5521     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "5522     [from torch import nn\\r\\nimport torch\\r\\nx = t...\n",
       "5523     [wEncoder = torch.randn(D,1, requires_grad=Tru...\n",
       "5524     [wEncoder = torch.randn(D,1, requires_grad=Tru...\n",
       "5525     [class CSVDataset(Dataset):\\r\\n    # load the ...\n",
       "5526     [import torch, torchvision\\r\\nroot_dataset =\"....\n",
       "5527     [from tensorpack import dataflow\\r\\n\\r\\nds = [...\n",
       "5528     [out = F.adaptive_avg_pool3d(input=out, output...\n",
       "5530     [class RoBERT_Model(nn.Module):\\r\\n\\r\\n    def...\n",
       "5531     [%reload_ext tensorboard\\r\\n%tensorboard --log...\n",
       "5532     [%reload_ext tensorboard\\r\\n%tensorboard --log...\n",
       "5533     [import tensorflow\\r\\nfrom tensorflow.keras.la...\n",
       "5534     [import tensorflow\\r\\nfrom tensorflow.keras.la...\n",
       "5535     [# example input\\r\\ndf = pd.DataFrame({'_id': ...\n",
       "5536     [$$C_{ij} = \\max_k \\bigg\\{ \\sum_l \\bigg( W_{ik...\n",
       "5537     [$$C_{ij} = \\max_k \\bigg\\{ \\sum_l \\bigg( W_{ik...\n",
       "5538     [import numpy as np\\r\\nimport torch\\r\\n\\r\\n\\r\\...\n",
       "5540     [def func(x,y):\\r\\n  return torch.exp(torch.si...\n",
       "5541     [def train():\\r\\nmodel.train()\\r\\noptimizer.ze...\n",
       "5542     [def compute_total_variation_loss(img, weight)...\n",
       "5543     [import torch.nn as nn\\r\\nimport torchsparse.n...\n",
       "5544     [from transformers import (\\r\\n    TrOCRConfig...\n",
       "5545     [RuntimeError: expected scalar type Long but f...\n",
       "5546     [from summarizer import Summarizer, Transforme...\n",
       "5547     [dataset = TensorDataset(encoded_dict['input_i...\n",
       "5548     [dataset = TensorDataset(encoded_dict['input_i...\n",
       "5549     [layer = nn.Linear(4, 1, bias=False)\\r\\nweight...\n",
       "5552     [from transformers.modeling_outputs import Seq...\n",
       "5553     [class CoalDataset(Dataset):\\r\\n    def __init...\n",
       "5554     [log_prob, from torch import distributions\\r\\n...\n",
       "5555     [data_root='D:/AuxiliaryDocuments/NYU/'\\r\\nraw...\n",
       "5557     [torchac, Using /home/neetu/.cache/torch_exten...\n",
       "5558     [a = torch.tensor([1.0, 2.0, 3.0], requires_gr...\n",
       "5559     [a = torch.tensor([1.0, 2.0, 3.0], requires_gr...\n",
       "5560     [import torchtext\\r\\nfrom torchtext.legacy.dat...\n",
       "5561     [import torchtext\\r\\nfrom torchtext.legacy.dat...\n",
       "5562     [unlabeled, Degree of rotation, class SesemiTr...\n",
       "5563     [conda install PyTorch torchvision torchaudio ...\n",
       "5564     [import torch\\r\\nfrom transformers import Bert...\n",
       "5565     [import torch\\r\\nfrom transformers import Bert...\n",
       "5566     [lst, N, epsilon, tau, (N,N,N), mask, mask[i][...\n",
       "5567     [def __init__(self):\\r\\n    super(C3D, self)._...\n",
       "5568     [dataloaders = zip(labeled_trainloader, [None]...\n",
       "5569     [def myCEE(outputs,targets):\\r\\n    exp=torch....\n",
       "5570     [\\r\\ntransformPipeline=Compose([\\r\\n          ...\n",
       "5571     [class VAE(nn.Module):\\r\\n    def __init__(sel...\n",
       "5572     [d_labels_a = torch.zeros(128)\\r\\nd_labels_b =...\n",
       "5573     [A = modelA()\\r\\nB = modelB()\\r\\n\\r\\noptimizer...\n",
       "5574     [A = modelA()\\r\\nB = modelB()\\r\\n\\r\\noptimizer...\n",
       "5577     [Package typing-extensions conflicts for:\\r\\nt...\n",
       "5578     [Package typing-extensions conflicts for:\\r\\nt...\n",
       "5579     [conda install -y pytorch==1.9 torchvision tor...\n",
       "5580     [conda install -y pytorch==1.9 torchvision tor...\n",
       "5581     [(synthesis) miranda9~/ultimate-utils $ python...\n",
       "5582     [(synthesis) miranda9~/ultimate-utils $ python...\n",
       "5583     [pip3 install torch==1.8.2+cu111 torchvision==...\n",
       "5584     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "5585     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "5586     [tensor([266, 103,  84,  12,  32,  34,   1, 52...\n",
       "5587     [tensor([266, 103,  84,  12,  32,  34,   1, 52...\n",
       "5588     [tensor, (910, 270, 1), numpy, (N, 3), (920, 2...\n",
       "5589     [\\r\\ndef getTransform():\\r\\n    transform_list...\n",
       "5590     [from transformers.modeling_outputs import Seq...\n",
       "5591     [ x = torch.tensor([[1,2],[3,4]],dtype=torch.f...\n",
       "5592     [t1 = torch.tensor([1,2,3])\\r\\nt2 = torch.tens...\n",
       "5593     [t1 = torch.tensor([1,2,3])\\r\\nt2 = torch.tens...\n",
       "5594     [optim = torch.optim.Adam(model.parameters(), ...\n",
       "5595     [vocab, torchtext, from torchtext.vocab import...\n",
       "5597     [layer = torch.nn.LSTM(128, 512, num_layers=3)...\n",
       "5598     [https://github.com/tufts-ml/GAN-Ensemble-for-...\n",
       "5599     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "5601     [python train.py --img 640 --batch 8 --epochs ...\n",
       "5602     [len(), torch.utils.random_sample(), torch.uti...\n",
       "5603     [#Access to Drive\\r\\nfrom google.colab import ...\n",
       "5604     [src_key_padding_mask, src_key_padding_mask, i...\n",
       "5605     [11.4, GeForce RTX 3060 Laptop(6gb), Windows 1...\n",
       "5608     [RuntimeError: Input type (torch.FloatTensor) ...\n",
       "5609     [class inside(nn.Module):\\r\\n    def __init__(...\n",
       "5610     [class MyDataset(Data.Dataset):\\r\\n  def __ini...\n",
       "5611     [namedtuple, from collections import namedtupl...\n",
       "5613     [# These are BERT and tokenizer definitions\\r\\...\n",
       "5614     [model = torch.hub.load('ultralytics/yolov5', ...\n",
       "5615     [RuntimeError: Error(s) in loading state_dict ...\n",
       "5616     [class logit(nn.Module):\\r\\n    def __init__(s...\n",
       "5617     [INFO:root:len(y_actu): 21401\\r\\nINFO:root:len...\n",
       "5618     [k &gt; 0, (hidden_size, num_directions * hidd...\n",
       "5619     [import os\\r\\n\\r\\nimport gym\\r\\nimport matplot...\n",
       "5620     [nn.Upsample, import torch\\r\\nimport imageio\\r...\n",
       "5621     [for sentence in list(data_dict.values()):\\r\\n...\n",
       "5622                                    [P1, torch.Tensor]\n",
       "5623     [from torch import tensor, arange\\r\\n\\r\\nprint...\n",
       "5624     [data = np.load('slices.npy')\\r\\ndata = np.res...\n",
       "5625     [data = np.load('slices.npy')\\r\\ndata = np.res...\n",
       "5626     [!wget -P /tmp https://github.com/gravitogen/h...\n",
       "5627     [CrossEntropyLoss, Adam, class CNN(nn.Module):...\n",
       "5628     [(env_hal) pi@raspberrypi:~ $ python3 -m pip i...\n",
       "5629     [    normFactor=0\\r\\n    for gaussianInd in ra...\n",
       "5630     [class AlexNet(nn.Module):\\r\\ndef __init__(sel...\n",
       "5631     [class MultiViewTransformerNetworkAveragingInd...\n",
       "5632                    [Type=='Graphic', Type=='Product']\n",
       "5633     [PATH, LD_LIBRARY_PATH, environment.yml, Pytho...\n",
       "5634     [PATH, LD_LIBRARY_PATH, environment.yml, Pytho...\n",
       "5635     [torch.cuda.is_available(), torch.cuda.is_avai...\n",
       "5636     [def data_preprocess():\\r\\n    \\r\\n    batch_s...\n",
       "5637     [from torchvision import transforms, datasets\\...\n",
       "5638     [Dropout, DropPath, DropConnect, def drop_path...\n",
       "5639     [Dropout, DropPath, DropConnect, def drop_path...\n",
       "5640                               [input @ weight.T \\r\\n]\n",
       "5641     [import pytorch_lightning as pl\\r\\nfrom torchv...\n",
       "5642     [import pytorch_lightning as pl\\r\\nfrom torchv...\n",
       "5643     [import pytorch_lightning as pl\\r\\nfrom torchv...\n",
       "5644     [(proxy) [jalal@goku proxynca_pp]$ CUDA_VISIBL...\n",
       "5645     [(proxy) [jalal@goku proxynca_pp]$ CUDA_VISIBL...\n",
       "5646     [$ pip install torch==1.9.0+cu111 torchvision=...\n",
       "5647     [best_acc = 0\\r\\n# optionally resume from a ch...\n",
       "5648     [class vgg16(torch.nn.Module):\\r\\n    def __in...\n",
       "5649     [TypeError: Caught TypeError in DataLoader wor...\n",
       "5650     [early_stopping_callback = EarlyStopping(monit...\n",
       "5651     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5652     [RuntimeError: one of the variables needed for...\n",
       "5653     [RuntimeError: one of the variables needed for...\n",
       "5654     [    def learn(self):\\r\\n\\r\\n        self.beta...\n",
       "5655     [torch.nn.Conv2d, torch.nn.BatchNorm2d, torch....\n",
       "5656     [model = Autoencoder.encoder(), class Autoenco...\n",
       "5657     [torch.cuda.synchronize()\\r\\nstart = time.time...\n",
       "5658     [import cv2\\r\\nimport threading\\r\\nfrom facene...\n",
       "5659     [import cv2\\r\\nimport threading\\r\\nfrom facene...\n",
       "5661     [(0-100), (0-1), (0-1), (0-100), conf, classes...\n",
       "5662     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nA...\n",
       "5663     [conda install pytorch torchvision -c pytorch\\...\n",
       "5664     [class Transforms:\\r\\n    def __init__(self, t...\n",
       "5665     [class Transforms:\\r\\n    def __init__(self, t...\n",
       "5666     [MaxPool1d, max_pool1d() input tensor must hav...\n",
       "5667     [MaxPool1d, max_pool1d() input tensor must hav...\n",
       "5668     [MaxPool1d, max_pool1d() input tensor must hav...\n",
       "5669     [(batch_size, 1024, 16, 16), class MultiAtrous...\n",
       "5670     [NN.module, class ChannelPool(nn.Module):\\r\\n ...\n",
       "5671     [class TrainImages(Dataset):\\r\\n    def __init...\n",
       "5672     [Dataset, (Channels, Depth, Height, Width), .p...\n",
       "5673     [BERT, BERTimbau, Transformers, Trainer, PyTor...\n",
       "5674     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "5675     [model = nnet(4, 2, 1)\\r\\ncriterion = nn.Cross...\n",
       "5676     [wandb.watch(model, log='all', log_freq=3), le...\n",
       "5677     [device = torch.device('cuda:0')\\r\\nrand = 123...\n",
       "5678     [class linear_NN(nn.Module):\\r\\n  \\r\\n  def __...\n",
       "5679     [!pip install cloud-tpu-client==0.10 https://s...\n",
       "5680     [torch.Size([4, 3, 2]), tensor([[[0.4003, 0.27...\n",
       "5681     [torch.Size([4, 3, 2]), tensor([[[0.4003, 0.27...\n",
       "5682     [torch.Size([4, 3, 2]), tensor([[[0.4003, 0.27...\n",
       "5683     [BS = x.shape[0]\\r\\nN = x.shape[1]\\r\\nout = to...\n",
       "5684     [for i in range(time):\\r\\n    optimizer.zero_g...\n",
       "5685     [from torchvision import models\\r\\nimport torc...\n",
       "5686     [from torchvision import models\\r\\nimport torc...\n",
       "5687     [ for i in range(seq_len):\\r\\n\\r\\n        m_t ...\n",
       "5688     [import torch\\r\\nfrom transformers import Adam...\n",
       "5690     [with profile(activities=[ProfilerActivity.CPU...\n",
       "5691     [class model(nn.Module)\\r\\n    def __init__()\\...\n",
       "5692     [learning_rate = 0.001\\r\\nnum_epochs = 50\\r\\n\\...\n",
       "5693     [\\r\\ndef saveEntirePopulation(keyPath, populat...\n",
       "5694     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "5695     [for epoch in range(N_EPOCHS):\\r\\n    # gets d...\n",
       "5696     [CrossEntropyLoss, LogSoftmax, NLLLoss, model_...\n",
       "5697     [CrossEntropyLoss, LogSoftmax, NLLLoss, model_...\n",
       "5698     [CrossEntropyLoss, LogSoftmax, NLLLoss, model_...\n",
       "5699     [loss, at::Tensor, lossThreshold, double, loss...\n",
       "5700     [torch.utils.data.Dataset, DataLoader, list_id...\n",
       "5701     [pytorch, Sagemaker, estimator.fit, Sagemaker ...\n",
       "5702     [torch.nn.Conv2d(3, 49, 4, bias=True)\\r\\n, tor...\n",
       "5703     [for i in my_list:\\r\\n    print(i.shape) #[1, ...\n",
       "5704     [vgg-16, unlabeled dataset, X,  features = vgg...\n",
       "5706     [python setup.py develop, RUN git clone https:...\n",
       "5707     [from torchvision import models, datasets, tra...\n",
       "5708     [scale_transform = torchvision.transforms.Rand...\n",
       "5709     [scale_transform = torchvision.transforms.Rand...\n",
       "5710     [# Training and Validation\\r\\ndef train(resnet...\n",
       "5711     [torch.max(), torch.return_types.max, torch.ti...\n",
       "5712     [512x512, einops, 32, 256, 256x1024, 0, 1, 2, ...\n",
       "5713     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nc...\n",
       "5714     [Number of operations that will run on Edge TP...\n",
       "5715     [batch_size=1, text, torch.Size([11, 300]), de...\n",
       "5718     [torch.onnx.export, onnx.load, model.doc_strin...\n",
       "5720     [path = \"gs://bucket_name/model/model.pt\"\\r\\nt...\n",
       "5721     [JupyterLab, AWS SageMaker, conda_pytorch_late...\n",
       "5722     [data = torch.tensor([[0,1,2], [3,4,5], [6,7,8...\n",
       "5723     [import torch\\r\\n\\r\\nbatch_size = 256\\r\\ntime_...\n",
       "5724     [multi-label text classification, Hugging Face...\n",
       "5725     [def calculate_gradient_penalty(real_images, f...\n",
       "5726     [import torchvision\\r\\nfrom torchvision.datase...\n",
       "5727     [from torch.utils.data import Dataset, DataLoa...\n",
       "5728     [test=Mydataset(data_root,transforms,'image_tr...\n",
       "5729     [gather, (1,200,61,1632), 1632, idx, (4,1632),...\n",
       "5730     [\\r\\nimport torch.nn as nn\\r\\nimport torch.opt...\n",
       "5732              [data.adj_t, edge_index, [2, num_edges]]\n",
       "5733     [class Model_CAE(nn.Module):\\r\\n    def __init...\n",
       "5734     [import cv2\\r\\nimport numpy as np\\r\\n\\r\\n# cen...\n",
       "5735     [if train_acc &gt; last_train_acc and val_acc ...\n",
       "5736     [import torch, torchvision\\r\\nfrom torch impor...\n",
       "5737     [model = ViTModel.from_pretrained('google/vit-...\n",
       "5738     [hook_fn(m,x,y), nn.Transformer,  out = transf...\n",
       "5739     [earlyStopping = EarlyStopping(monitor='f1_sco...\n",
       "5740                                                   [1]\n",
       "5741                                            [4, 10, 3]\n",
       "5742     [K, K,      MLP (for male)                 MLP...\n",
       "5743     [tensor([\\r\\n    [0, 1, 0, 1], # A\\r\\n    [1, ...\n",
       "5744     [ input -&gt; (1,3,112,112), inference_input -...\n",
       "5745     [a = torch.rand(2,3,4)\\r\\nb = torch.rand(2,3,4...\n",
       "5746     [def Ordinal_Pooling_NN(x):\\r\\n  wights = torc...\n",
       "5747     [ RuntimeError                              Tr...\n",
       "5748     [#Code for Loading model\\r\\nfrom fastai import...\n",
       "5749     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5750     [def adjust_learning_rate(optimizer, epoch, ar...\n",
       "5751     [import torch\\r\\nfrom torch_geometric.data imp...\n",
       "5752     [  # Flatten\\r\\n  train = x_train.view(num_tra...\n",
       "5753     [  # Flatten\\r\\n  train = x_train.view(num_tra...\n",
       "5754     [conda, cudatoolkit=11.2, conda install pytorc...\n",
       "5755     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "5756     [from torchvision.models.detection import fast...\n",
       "5757     [class Network(nn.Module):\\r\\n    \\r\\n    def ...\n",
       "5761     [padding=True, truncation=True, max_length = 1...\n",
       "5762     [padding=True, truncation=True, max_length = 1...\n",
       "5763     [class encoder(torch.nn.Module):\\r\\ndef __init...\n",
       "5764     [class encoder(torch.nn.Module):\\r\\ndef __init...\n",
       "5765     [CUDA out of memory, out of memory, import tor...\n",
       "5766     [(2, 3, 2, 2), (batch_size, channels, height, ...\n",
       "5767     [(2, 3, 2, 2), (batch_size, channels, height, ...\n",
       "5768     [import torch, Traceback (most recent call las...\n",
       "5769     [class MyDataset(Dataset):\\r\\n\\r\\n    def __in...\n",
       "5770                              [torch.matmul(P, T)\\r\\n]\n",
       "5772     [import torch\\r\\nlin=torch.nn.Linear; act=torc...\n",
       "5773     [torch.save(model, '/content/drive/MyDrive/myM...\n",
       "5774     [random.seed(seed)\\r\\nnp.random.seed(seed)\\r\\n...\n",
       "5776     [S, T, S = torch.rand((3,2,1))\\r\\nT = torch.on...\n",
       "5777     [S, T, S = torch.rand((3,2,1))\\r\\nT = torch.on...\n",
       "5778     ['''\\r\\n    self._buffer is an object of multi...\n",
       "5780     [self.sequential = nn.Sequential()\\r\\ninput_di...\n",
       "5781     [DataParallel(\\r\\n  (module): DenseNet121(\\r\\n...\n",
       "5783     [(fashcomp) [jalal@goku fashion-compatibility]...\n",
       "5784     [[torch.combinations(doc_ids, r=2) for doc_ids...\n",
       "5785     [if self.l2_norm:\\r\\n    norm = torch.norm(mas...\n",
       "5786     [data, train_mask, train_mask, train_mask, dat...\n",
       "5787     [data, train_mask, train_mask, train_mask, dat...\n",
       "5788     [(fashcomp) [jalal@goku fashion-compatibility]...\n",
       "5789     [(fashcomp) [jalal@goku fashion-compatibility]...\n",
       "5790     [data = [torch.tensor(vocab(tokenizer(item)), ...\n",
       "5791     [with torch.profiler.profile(\\r\\n        sched...\n",
       "5792     [**kwargs, class Model(nn.Module):\\r\\n\\r\\ndef ...\n",
       "5794     [[batch_Size, Channels, Depth, Height, Width]\\...\n",
       "5795     [import torch \\r\\na = torch.arange(120).reshap...\n",
       "5796     [class FeatureExtractor(tf.keras.Model):\\r\\n  ...\n",
       "5797     [class data_test(Dataset):\\r\\ndef __init__(sel...\n",
       "5798     [self.layer1 = self._make_layer(block, 64, lay...\n",
       "5799     [model = Resnet_18.resnet18(pretrained=True, e...\n",
       "5800     [z, x, y, x, [0 0 0 1 1 2 2 2 2], y, x, [1 1 0...\n",
       "5801     [z, x, y, x, [0 0 0 1 1 2 2 2 2], y, x, [1 1 0...\n",
       "5802     [a = torch.randn(40, 6)\\r\\nb = torch.randn(40)...\n",
       "5803     [Conv1d, Conv1d, [batch, channels, sequence_le...\n",
       "5804     [# define our batch having 4 grayscale images ...\n",
       "5805     [def build_model():\\r\\n    \\r\\n    # Inputs to...\n",
       "5806     [correct, pred, target, pred, def accuracy(out...\n",
       "5807     [resnet = torchvision.models.segmentation.segm...\n",
       "5808     [Y, X, torch.autograd.grad(Y, X, grad_outputs=...\n",
       "5809     [Threshold, class Threshold(nn.Module):\\r\\ndef...\n",
       "5810     [import datetime as dt\\r\\nimport functools\\r\\n...\n",
       "5811     [import datetime as dt\\r\\nimport functools\\r\\n...\n",
       "5812     [from __future__ import print_function\\r\\n\\r\\n...\n",
       "5814     [image-folders/\\r\\n   ├── class_0/\\r\\n   |   ├...\n",
       "5815     [resnet18 = models.resnet18(pretrained=True)\\r...\n",
       "5816     [# create dataset\\r\\ndataset = IMU_dataset()\\r...\n",
       "5817     [batch_size=128, class LeNet(nn.Module):\\r\\n  ...\n",
       "5818     [model = nn.Conv2d(3,3,kernel_size=5, stride=1...\n",
       "5819     [(2, 3),  index = torch.empty(6).random_(0,8)....\n",
       "5820     [from pl_bolts.datamodules import CIFAR10DataM...\n",
       "5821     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "5822     [&gt; trace = torch.jit.trace(model, input_bat...\n",
       "5823     [&gt; trace = torch.jit.trace(model, input_bat...\n",
       "5824     [x[train], y[train]\\r\\n, (311, 3, 224, 224), (...\n",
       "5825     [for i in inputs:\\r\\n    # Step through the se...\n",
       "5826     [import torch\\r\\nfrom torch import nn\\r\\nin_ch...\n",
       "5828     [.onnx, retinaface.onnx, .ptl, .pt, // I want ...\n",
       "5829     [BertTokenizer, t = BertTokenizer.from_pretrai...\n",
       "5830     [ segmentation_mask\\r\\narray([[1, 0, 0, 0, 0],...\n",
       "5831     [class GRU(nn.Module):\\r\\n    def __init__(sel...\n",
       "5832     [class aDataset(torch.utils.data.Dataset):\\r\\n...\n",
       "5833     [class Attention_module(tf.keras.layers.Layer)...\n",
       "5835     [LongformerModel, LongformerTokenizerFast, Lon...\n",
       "5836     [class ToTensor(object):\\r\\n\"\"\"Convert ndarray...\n",
       "5837     [#load model\\r\\nmodel = torch.load('/content/d...\n",
       "5838     [float16 &lt;-&gt; complex32\\r\\nfloat32 &lt;-&...\n",
       "5839     [import os\\r\\nfrom torch.nn.parallel import Di...\n",
       "5840     [import os\\r\\nfrom torch.nn.parallel import Di...\n",
       "5841     [test_custom_resnet18.ipynb, from __future__ i...\n",
       "5842     [import torch\\r\\ndef function(x,y):\\r\\n    f =...\n",
       "5843     [custom_resnet18.py, import torch\\r\\nimport to...\n",
       "5844     [ids = [int(p.sum().item()) for p in model.par...\n",
       "5845     [conda remove -n &lt;env&gt; --all, import, py...\n",
       "5846     [y = torch.randint(0, 3, (10,)), collections.C...\n",
       "5847     [transformers, from transformers import AutoTo...\n",
       "5848     [AttributeError: 'tuple' object has no attribu...\n",
       "5849     [import cv2\\r\\nimport gym\\r\\nimport numpy as n...\n",
       "5850     [element 0 of tensors does not require grad an...\n",
       "5851     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\n\\...\n",
       "5852     [w, b, w, b, n_input, n_output = 5, 3\\r\\nx = t...\n",
       "5853     [w, b, w, b, n_input, n_output = 5, 3\\r\\nx = t...\n",
       "5854     [from captum.attr import LayerGradCam\\r\\n, lay...\n",
       "5855     [import coremltools as ct\\r\\nimport torch\\r\\ni...\n",
       "5856     [...\\r\\nnn.Conv2d(28 * filters_multiplier, 28 ...\n",
       "5857     [somnath@somnath-Inspiron-5558:~/LaneDetection...\n",
       "5858     [prune = float(0.1)\\r\\ndef prune_weights(torch...\n",
       "5859     [import numpy as np\\r\\nimport os\\r\\nimport tim...\n",
       "5860     [model = Sequential()\\r\\nmodel.add(LSTM(10, in...\n",
       "5861     [nn.Dropout, clip_grad_norm_(model.parameters(...\n",
       "5862     [\"Train.py\"\\r\\n\\r\\nimport sys\\r\\nimport os\\r\\n...\n",
       "5863     [batch_size = 128\\r\\nimage_size = (64,64)\\r\\ns...\n",
       "5864     [def tokenize_word(text):\\r\\n  return nltk.wor...\n",
       "5865     [def tokenize_word(text):\\r\\n  return nltk.wor...\n",
       "5866     [[1, 512, 512, 3], [1, 20, 512, 512], (0, 0, 0...\n",
       "5867     [class RegressionDataset(Dataset):\\r\\n    \\r\\n...\n",
       "5868     [Train dataset length: 27569\\r\\nTest dataset l...\n",
       "5869     [# !pip install torch==1.9.0\\r\\n# !pip install...\n",
       "5871     [image_size = (64,64)\\r\\nstats = (0.5, 0.5, 0....\n",
       "5872     [      tokenizer = BertTokenizer.from_pretrain...\n",
       "5873     [pytorch, Tensorflow, pytorch, import tensorfl...\n",
       "5874     [RuntimeError: Given groups=1, weight[512, 3, ...\n",
       "5875     [class CNNClassifier(Classifier):  # nn.Module...\n",
       "5876     [def get_adapted_loss_for_minibatch(loss):\\r\\n...\n",
       "5877     [class Test(nn.Module):\\r\\n    def __init__(se...\n",
       "5879     [model_checkpoint = \"distilbert-base-uncased\"\\...\n",
       "5880     [x[k], x[:, k], x = torch.ones(2,3,4).transpos...\n",
       "5881     [class ClassificationModel(nn.Module):\\r\\n    ...\n",
       "5882     [pytorch, self.conv_layer = nn.Sequential(\\r\\n...\n",
       "5883     [pytorch, self.conv_layer = nn.Sequential(\\r\\n...\n",
       "5884     [x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\\r\\nx =...\n",
       "5885     [x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\\r\\nx =...\n",
       "5886     [import torch.nn as nn\\r\\nclass D(nn.Module):\\...\n",
       "5887     [import numpy as np\\r\\nimport torchvision\\r\\ni...\n",
       "5888     [fun convertArrayToBitmapTensorFlow(\\r\\n      ...\n",
       "5889     [train_log_dir = f'logs/{datetime.datetime.now...\n",
       "5890     [class Test(nn.Module):\\r\\n    def __init__(se...\n",
       "5891     [class Cnn(nn.Module):\\r\\n    def __init__(sel...\n",
       "5892     [%%bash\\r\\nMINICONDA_INSTALLER_SCRIPT=Minicond...\n",
       "5893     [(fashcomp) [jalal@goku fashion-compatibility]...\n",
       "5894     [nn.CrossEntropyLoss(), labels = torch.hstack(...\n",
       "5895     [self.gen, make_gen_block, __init__, make_gen_...\n",
       "5896     [paths = [['./a.wav', './b.wav'], ['./c.wav', ...\n",
       "5897     [scipy.linalg.toeplitz, def toeplitz_torch(c, ...\n",
       "5898     [class ConvBlock(nn.Module):\\r\\n    def __init...\n",
       "5899     [def train_test_dataset(dataset, test_split=0....\n",
       "5900     [def train_test_dataset(dataset, test_split=0....\n",
       "5901     [[tool.poetry.dependencies].\\r\\npython = \"^3.8...\n",
       "5902     [import torch\\r\\nimport torch.nn.functional as...\n",
       "5903     [   # Importing the libraries\\r\\nfrom __future...\n",
       "5904     [model = torch.nn.Linear(1,1).to(device)\\r\\nx_...\n",
       "5905     [transformer.encodeplus(), start_scores, end_s...\n",
       "5906     [torch_dep = dependency('torch'), main = execu...\n",
       "5907     [permute, torch.Size([512, 256, 3, 3]), torch....\n",
       "5908     [image = cv2.imread('...')\\r\\n, mtcnn, resnet,...\n",
       "5909     [1.csv:\\r\\n\\r\\n1, 2, 3\\r\\n4, 5, 6\\r\\n7, 8, 9\\r...\n",
       "5911     [class ResNet(nn.Module):\\r\\ndef __init__(self...\n",
       "5912     [~/.bashrc, # libtorch linking path\\r\\nexport ...\n",
       "5913     [A, (M, N), B, (M, P), A, A, B, 0, In[1]: impo...\n",
       "5914     [# Get content, style features and create gram...\n",
       "5915     [import torch\\r\\n\\r\\ny_dim = 1\\r\\nx = torch.ra...\n",
       "5916     [[9866, 128, 128, 3], import os\\r\\nimport nump...\n",
       "5917     [[9866, 128, 128, 3], import os\\r\\nimport nump...\n",
       "5918     [import torch\\r\\nimport pandas as pd\\r\\nfrom t...\n",
       "5919     [    def train_(self, x, y, lr, steps, path=No...\n",
       "5920     [nn.GRU(96, 96, bias=True), weight_ih_l0, (288...\n",
       "5921     [conda install pytorch torchvision torchaudio ...\n",
       "5922     [(fashcomp) [jalal@goku fashion-compatibility]...\n",
       "5923     [File \"main.py\", line 138, in main\\r\\n    chec...\n",
       "5925     [pip3 list\\r\\nPackage             Version\\r\\n-...\n",
       "5926     [a = torch.nn.BCELoss\\r\\n\\r\\n, b = torch.nn.BC...\n",
       "5927     [a = torch.nn.BCELoss\\r\\n\\r\\n, b = torch.nn.BC...\n",
       "5928     [import torch\\r\\nt = torch.Tensor([[[11,12],[2...\n",
       "5929     [# Store params at the best validation accurac...\n",
       "5930     [# Store params at the best validation accurac...\n",
       "5931     [\"\"\"Object detection using YOLOv5\\r\\n\\r\\nPokem...\n",
       "5933     [from pathos.multiprocessing import Processing...\n",
       "5934     [from scipy.optimize import fsolve\\r\\nfrom sci...\n",
       "5935     [x, batch_size x d x S, S, d, past_size + pres...\n",
       "5936     [PyTorch, Google Colaboratory, Accelerator, GP...\n",
       "5937     [class BaseDataset(Dataset):\\r\\n    def __init...\n",
       "5938     [from __future__ import print_function\\r\\nimpo...\n",
       "5939     [nvcc: NVIDIA (R) Cuda compiler driver\\r\\nCopy...\n",
       "5940     [def forward(self, x):\\r\\n    features = self....\n",
       "5941     [FROM pytorch/pytorch:1.7.0-cuda11.0-cudnn8-ru...\n",
       "5942     [class LitModel(pl.LightningModule):\\r\\n    de...\n",
       "5944     [vgg11, vgg13, vgg16, vgg19, \"chenyaofo/pytorc...\n",
       "5945     [vgg11, vgg13, vgg16, vgg19, \"chenyaofo/pytorc...\n",
       "5946     [model = Model(opt)\\r\\ndummy_input = torch.ran...\n",
       "5947     [checkpoint = torch.load(\"\\my_checkpoint_40.pt...\n",
       "5948     [# NB: Only run in TPU environment\\r\\n!pip ins...\n",
       "5949     [# NB: Only run in TPU environment\\r\\n!pip ins...\n",
       "5950     [# NB: Only run in TPU environment\\r\\n!pip ins...\n",
       "5951     [my_proj, Poetry, PyTorch, Dockerfile, bash, p...\n",
       "5952     [self.conv4, self.conv5, import torch\\r\\nfrom ...\n",
       "5953     [from torch.utils.data import DataLoader, Tens...\n",
       "5954     [        MIM_N_cell = []\\r\\n        MIM_S_cell...\n",
       "5955     [import torch\\r\\nimport torch.nn as nn\\r\\ntorc...\n",
       "5956     [import torch\\r\\nimport torch.nn as nn\\r\\ntorc...\n",
       "5957     [y_true_2[range(y_true_2.shape[0]), y_true.lon...\n",
       "5958     [[(3, 1920, 1080), 60fps, 10sec], def train(da...\n",
       "5959     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "5960     [optimizer = torch.optim.Adam(\\r\\n            ...\n",
       "5962                             [torch.manual_seed(seed)]\n",
       "5963     [{(0, 0): 1, (0, 1): 1, (0, 2): -1, (0, 3): 1,...\n",
       "5964     [def RecEvaluate(model, g, features, users_eva...\n",
       "5965     [*mat1 dim 1 must match mat2 dim 0*\\r\\n,     (...\n",
       "5966     [GPU available: False, used: False\\r\\nTPU avai...\n",
       "5967     [GPU available: False, used: False\\r\\nTPU avai...\n",
       "5968     [for epoch in range(n_epochs):\\r\\n    print(f\"...\n",
       "5969     [[2, 1, 1024], torch.nn.Linear, (N,∗,Hin), tor...\n",
       "5970     [model = PosTaggingModel(num_pos_tag=num_pos_t...\n",
       "5971     [.pth, import os\\r\\nimport torch\\r\\nassert os....\n",
       "5972     [3*3, A = [[1,0,1],[0,1,1],[1,0,0]], B = [1,2,1]]\n",
       "5973     [network.train()  \\r\\n\\r\\nbatch_losses = []\\r\\...\n",
       "5974     [  // define inputs\\r\\n  int batch = 3; // bat...\n",
       "5975     [import torch_geometric, import torch\\r\\nimpor...\n",
       "5976     [def get_X_y(df):\\r\\n    ''' This function tak...\n",
       "5977     [class AmazonReviewsDataset(torch.utils.data.D...\n",
       "5978     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "5980     [Epoch   Training Loss   Validation Loss Accur...\n",
       "5981     [best_model_path = trainer.checkpoint_callback...\n",
       "5983     [DataLoader, train_loader = DataLoader(train_d...\n",
       "5984     [HybridLoss, RuntimeError: one of the variable...\n",
       "5985     [from transformers import AutoTokenizer, AutoM...\n",
       "5986     [tensor = tensor.squeeze().argmax(0).detach();...\n",
       "5987     [import torchvision.datasets as dset\\r\\nimport...\n",
       "5988     [5, 20, nClass=5\\r\\nfeature_dim=20\\r\\n\\r\\ngain...\n",
       "5989     [onnxruntime.capi.onnxruntime_pybind11_state.R...\n",
       "5990     [    actions = [agent.select_action(state) for...\n",
       "5991     [   torch::jit::script::Module module;\\r\\n   t...\n",
       "5992     [   torch::jit::script::Module module;\\r\\n   t...\n",
       "5993     [[array([4, 7, 1, 5, 4, 2, 9, 6, 8, 5, 8, 4, 4...\n",
       "5994     [nan, import torch\\r\\nx = torch.randn(4,3)\\r\\n...\n",
       "5995     [import albumentations as A\\r\\n\\r\\n    A.Compo...\n",
       "5996     [RuntimeError: expected backend CPU and dtype ...\n",
       "5997     [dist.sample(), states = T.tensor(state[b], dt...\n",
       "5998     [new_min, new_max, import torch\\r\\nx = torch.r...\n",
       "6000     [#! /bin/bash\\r\\n\\r\\n#SBATCH --job-name 'SQuAD...\n",
       "6001     [loss_fn = torch.nn.BCELoss()\\r\\nlr = 1e-3\\r\\n...\n",
       "6002     [import time\\r\\nstart_time=time.time()\\r\\n\\r\\n...\n",
       "6003                                 [wav2vec2, Trainer()]\n",
       "6004     [class KITTIRAWDataset(KITTIDataset):\\r\\n\\r\\nd...\n",
       "6005     [google/bigbird-pegasus-large-arxiv, Attention...\n",
       "6006     [grad_outputs, torch.autograd.grad, grad_outpu...\n",
       "6007     [class ConcatDataset(torch.utils.data.Dataset)...\n",
       "6008     [predict(), sagemaker.predictor, class StringP...\n",
       "6009     [pred = prod_outputs(train_loader, model), _, ...\n",
       "6010     [class PyTorchNetwork(nn.Module):\\r\\n    def _...\n",
       "6011     [transform = transforms.Compose(\\r\\n    [\\r\\n ...\n",
       "6012     [patch_size = 224\\r\\nresult = torch.zeros((pat...\n",
       "6013     [#Training data\\r\\nclass IrisDataset(T.utils.d...\n",
       "6015     [Trainer, CustomCallback, class MyCallback(Tra...\n",
       "6017     [class IndexedDataset(Dataset):\\r\\n\\r\\ndef __i...\n",
       "6018     [class IndexedDataset(Dataset):\\r\\n\\r\\ndef __i...\n",
       "6019     [Accelerate, Accelerate, pip, Anaconda, accele...\n",
       "6020     [COVER = 1\\r\\nSTEGO = 0\\r\\n\\r\\nclass CustomIma...\n",
       "6021     [import torch\\r\\nb = torch.tensor([[1,1,1],[4,...\n",
       "6022     [self.models[\"pose_encoder\"] = \\\\r\\n     netwo...\n",
       "6023     [K_FOLD = 5\\r\\nfraction = 1 / K_FOLD\\r\\nunit =...\n",
       "6024     [def __getitem__(self, index):\\r\\n    img, lab...\n",
       "6025     [model1.reformer.embeddings.position_embedding...\n",
       "6026     [model1.reformer.embeddings.position_embedding...\n",
       "6027     [output=  (torch.zeros(2, 3),\\r\\n          tor...\n",
       "6028     [output=  (torch.zeros(2, 3),\\r\\n          tor...\n",
       "6029     [training = TimeSeriesDataSet(\\r\\n    df_train...\n",
       "6030     [class SelfAttention(nn.Module):\\r\\n    def __...\n",
       "6032     [import os\\r\\nfrom networks.CNN import ResNet\\...\n",
       "6033     [torch.reshape, for name, value in samples.ite...\n",
       "6034     [user_id | content_id\\r\\n1       | 23\\r\\n1    ...\n",
       "6035     [File \"train_bart.py\", line 89, in train\\r\\n  ...\n",
       "6038                                              [spaces]\n",
       "6039     [    env = gym.make('MountainCar-v0')\\r\\n    #...\n",
       "6040     [   output = [{'boxes': tensor([[0.0000e+00, 2...\n",
       "6041     [   output = [{'boxes': tensor([[0.0000e+00, 2...\n",
       "6042     [import torch\\r\\nfrom transformers import GPT2...\n",
       "6043     [mlflow server --backend-store-uri sqlite:///m...\n",
       "6044     [pred=torch.tensor([[8,5,3,2,6,1,6,8,4],[2,5,1...\n",
       "6045     [loader, optimizer, model, loss_fn = ...\\r\\nsw...\n",
       "6046     [prox = nn.Threshold(0,0)\\r\\ndef l2_regularize...\n",
       "6047     [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "6048     [pickle, torch, import pickle\\r\\n\\r\\nwith open...\n",
       "6049     [from sagemaker.pytorch import PyTorch\\r\\n\\r\\n...\n",
       "6050     [def fit(train_loader, val_loader, model, loss...\n",
       "6051     [print(set(list(df['label'])))\\r\\n&gt; {0, 1, ...\n",
       "6052     [# INPUT\\r\\ntensor([[ 8,  3,  1, 16,  2, 22,  ...\n",
       "6053     [tensor([1, 2, 3, 4]), tensor([[0, 3], [2, 1],...\n",
       "6054     [Empty                                     Tra...\n",
       "6057     [AutoModelForSeq2SeqLM.from_pretrained(), Cust...\n",
       "6058     [import os\\r\\nos.environ['TF_CPP_MIN_LOG_LEVEL...\n",
       "6059     [for img_loc in list(self.train_data)[idx]:\\r\\...\n",
       "6060     [for img_loc in list(self.train_data)[idx]:\\r\\...\n",
       "6061     [for img_loc in list(self.train_data)[idx]:\\r\\...\n",
       "6064     [  import torch\\r\\nTraceback (most recent call...\n",
       "6065     [def load_and_cache_examples(args, tokenizer, ...\n",
       "6066     [cuda runtime error (710) : device-side assert...\n",
       "6067     ['\"hostname -I\"' is not recognized as an inter...\n",
       "6069     [Create your backbone from timm\\r\\nbackbone = ...\n",
       "6070     [batch_size = 128\\r\\ntrain_dataloader = traini...\n",
       "6071     [def train(epoch, loader, loss_fn, optimizer, ...\n",
       "6073     [def __init__(self):\\r\\n    super(NetworkDense...\n",
       "6074     [led-base-16384, Approach 1 using HuggingFace ...\n",
       "6076     [.py, AttributeError: Can't pickle local objec...\n",
       "6078     [    const ImageFrame&amp; frame =\\r\\n        ...\n",
       "6079     [import torch\\r\\nx = torch.tensor([[0.3992, 0....\n",
       "6080     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nx =...\n",
       "6081     [import torch\\r\\nimport torchvision\\r\\n, class...\n",
       "6082     [CUDA: Out of Memory, model = model.load_state...\n",
       "6083     [criterion = nn.MSELoss()\\r\\noptimizer = optim...\n",
       "6084     [nan, [[29.87819, 121.54944999999998], [24.231...\n",
       "6085     [for epoch in range(0, max_epochs):\\r\\n    mod...\n",
       "6087     [N, True, True, N, False, N = 3\\r\\ninput = ten...\n",
       "6089     [translate_sentence, Args:\\r\\n    src_field -&...\n",
       "6091     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6092     [class decoderNW(nn.Module):\\r\\n    def __init...\n",
       "6093     [def train(nets, loaders, optimizer, criterion...\n",
       "6094     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6095     [from sentence_transformers import SentenceTra...\n",
       "6096     [from sentence_transformers import SentenceTra...\n",
       "6097     [test = ['0.01171875', '0.01757812', '0.029296...\n",
       "6098     [class DogsVSCats:\\r\\n    IMG_SIZE = 50\\r\\n   ...\n",
       "6099     [/home/maxs/dev/mdb/venv38/lib/python3.8/site-...\n",
       "6101     [a_tensor, torch.Tensor, a_tensor.data.max, a_...\n",
       "6104     [def sdf(model_output, gt):\\r\\n    gt_sdf = gt...\n",
       "6105     [def train_model(model, net, criterion, optimi...\n",
       "6106     [.to(device), with pf.profile() as prof :\\r\\n ...\n",
       "6107     [estimator = PyTorch(entry_point='test_trainer...\n",
       "6108     [nn.Module, class My_model(nn.Module)\\r\\n, tas...\n",
       "6109     [nn.Module, class My_model(nn.Module)\\r\\n, tas...\n",
       "6110     [nn.Module, class My_model(nn.Module)\\r\\n, tas...\n",
       "6112     [output (input_dy) → tensor of size [4] , outp...\n",
       "6113     [import sys, os, pdb\\r\\nimport numpy as np\\r\\n...\n",
       "6116     [def train_model(model, ...):\\r\\n       ...\\r\\...\n",
       "6117     [NCHW, NHWC, C, H, W, NHWC, for (N){\\r\\n  for ...\n",
       "6118     [writer.add_scalar, writer.add_histogram, y, x...\n",
       "6119     [torch.nn.DataParallel, [2021-08-03 09:01:00,8...\n",
       "6120     [from tensorflow.keras.preprocessing import im...\n",
       "6121     [            if FLAGS.output_path is not None:...\n",
       "6122     [class MyDropout(nn.Module):\\r\\n    def __init...\n",
       "6124     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6125     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6127     [training_step(), Trainer, training_step(), tr...\n",
       "6129     [The following columns in the training set  do...\n",
       "6130     [import torch\\r\\nfrom torch.autograd import Fu...\n",
       "6133                                 [train.py, pelee_voc]\n",
       "6134     [a, mask, True, a = torch.arange(1,17).reshape...\n",
       "6135     [normalize = torchvision.transforms.Normalize(...\n",
       "6137     [normalize = torchvision.transforms.Normalize(...\n",
       "6138     [u = torch.rand_like(model_out), policy = F.so...\n",
       "6140     [Dataset, DataLoader, l = [tensor1, tensor2, t...\n",
       "6141     [buffered_arange, torch.arange, def buffered_a...\n",
       "6142     [import torch\\r\\n\\r\\nembeddings = torch.nn.Emb...\n",
       "6143     [# load my data.\\r\\ntrain_dataset = Finetuning...\n",
       "6144     [ \\r\\n    if sample &gt; eps_threshold:\\r\\n   ...\n",
       "6146     [pos_weight, pos_weight, positive sample, nega...\n",
       "6147     [import torch as pt\\r\\nfrom torch.utils.data i...\n",
       "6148     [def test_data(mdl):\\r\\n    #Input new data\\r\\...\n",
       "6149     [three_by_four, tensor([[0.7421, 0.1584, 0.323...\n",
       "6150     [CrossEntropyLoss, BCELoss, BCELoss, -yi*log(p...\n",
       "6151     [CrossEntropyLoss, BCELoss, BCELoss, -yi*log(p...\n",
       "6152     [CrossEntropyLoss, BCELoss, BCELoss, -yi*log(p...\n",
       "6153     [df = pd.read_csv(\"train.csv\", index_col=0)\\r\\...\n",
       "6154     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "6155     [loss =  F.binary_cross_entropy_with_logits(ou...\n",
       "6156     [nn.CrossEntrophyLoss(), nn.BCELoss(), ValueEr...\n",
       "6157     [nn.CrossEntrophyLoss(), nn.BCELoss(), ValueEr...\n",
       "6158     [nn.Module, nn.Sequential, nn.Module, nn.Seque...\n",
       "6159     [pip install git+https://github.com/huggingfac...\n",
       "6160     [pip install git+https://github.com/huggingfac...\n",
       "6161     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "6162     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6163     [padding = (2, 2, 2, 2)\\r\\nimg = torch.nn.func...\n",
       "6164     [self.cache, class DescriptorDataset(torch.uti...\n",
       "6165     [self.cache, class DescriptorDataset(torch.uti...\n",
       "6167     [x = torch.tensor(3.0)\\r\\nprint(id(x))\\r\\nx = ...\n",
       "6168     [RuntimeError: gather_out_cpu(): Expected dtyp...\n",
       "6169     [class BertArticleClassifier(nn.Module):\\r\\n  ...\n",
       "6170     [bitwise_or, torch.bitwise_or, numpy, np.bitwi...\n",
       "6171     [Tensor.expand(), expand(), elements_in_memory...\n",
       "6172     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6173     [import torch\\r\\nx = torch.tensor(3.0, require...\n",
       "6174     [torch.autograd.set_detect_anomaly(True), Runt...\n",
       "6175     [---------------------------------------------...\n",
       "6176     [torch.Tensor.topk, input = torch.tensor([0.2,...\n",
       "6177     [.cpp, .cu, TORCH_CUDA_ARCH_LIST=7.2 CC=gcc-7 ...\n",
       "6178     [#Function to return a dataloader\\r\\n#x_train ...\n",
       "6179     [from torchinfo import summary\\r\\nfrom transfo...\n",
       "6181     [TypeError: Traceback (most recent call last)\\...\n",
       "6182     [backward(), class ExpModelTunable(torch.nn.Mo...\n",
       "6183     [tns = torch.FloatTensor([3])\\r\\nx = Variable(...\n",
       "6184     [train_path='/content/drive/MyDrive/Dataset_ma...\n",
       "6185     [train_path='/content/drive/MyDrive/Dataset_ma...\n",
       "6186     [*Part1*: learnable preprocess​\\r\\n*Part2*: Mi...\n",
       "6187     [model_name_or_path = \"facebook/wav2vec2-base-...\n",
       "6188     [class CustomTrainDataset(Dataset):\\r\\n    '''...\n",
       "6189     [class CustomTrainDataset(Dataset):\\r\\n    '''...\n",
       "6190     [PyTorch, from torchinfo import summary\\r\\nfro...\n",
       "6191     [%pip install pytorch2keras\\r\\n%pip install on...\n",
       "6192     [%pip install pytorch2keras\\r\\n%pip install on...\n",
       "6193     [class Cust_LSTMCell(nn.Module):\\r\\ndef __init...\n",
       "6194     [RuntimeError: Redis has started but no raylet...\n",
       "6196     [RuntimeError: Given groups=1, weight of size ...\n",
       "6197     [RuntimeError: Given groups=1, weight of size ...\n",
       "6198     [torch([0]) , torch([1])....,torch([25]), A,B,...\n",
       "6199     [torch([0]) , torch([1])....,torch([25]), A,B,...\n",
       "6200     [RuntimeError: CUDA error: CUBLAS_STATUS_INVAL...\n",
       "6201     [# Get vertices, faces, and auxiliary informat...\n",
       "6203     [a + b, torch.sub(a, b), a, b, torch.Tensor, t...\n",
       "6204     [scipy.signal.convolve2d, scipy.optimize.quad,...\n",
       "6205     [torch.onnx.export(net.to('cpu'), test_input,'...\n",
       "6206     [torch.onnx.export(net.to('cpu'), test_input,'...\n",
       "6207     [def create_data_loader(df, tokenizer, max_len...\n",
       "6208     [__getitem__,     def __init__(self,\\r\\n      ...\n",
       "6209     [class DiceLoss(torch.nn.Module):\\r\\n    def _...\n",
       "6210     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6211     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6212     [if epo%1000 == 0:\\r\\n    print(f'Epoch {epo}'...\n",
       "6213     [def create_adj(a):\\r\\n    a[a&gt;0.5] = 1\\r\\n...\n",
       "6214     [a = np.array([[0.0,1.0,2.0,3.0,4.0], [0.0,1.0...\n",
       "6216     [data = torch.randn((N, M))\\r\\nindex = torch.r...\n",
       "6217     [import torch\\r\\nimport torchvision.models as ...\n",
       "6218     [!pip install datasets\\r\\n!pip install transfo...\n",
       "6219     [def train(loop):\\r\\n  for i, batch in enumera...\n",
       "6220     [torch==1.9.0, tensorboard==2.5.0, data = np.r...\n",
       "6221     [--dataset-type=voc\\r\\n\\r\\n        --dataset-t...\n",
       "6222     [torch.Size([8, 3, 16, 16]), class Net(nn.Modu...\n",
       "6223     [ (array([[0.0727882 , 0.82148589, 0.9932996 ,...\n",
       "6224     [glove.840B.300d, {'word': GloVE embedding}, C...\n",
       "6225     [torch.nn.DataParallel(), nn.DataParallel(), d...\n",
       "6226     [n_epochs = 3\\r\\nbest_valid_loss = float('inf'...\n",
       "6227     [x = torch.arange(1, 601)\\r\\nx = x.reshape(20,...\n",
       "6228     [ResNet50 = torchvision.models.resnet50(pretra...\n",
       "6229     [import torch\\r\\n\\r\\nx = torch.ones(5)  # inpu...\n",
       "6230     [Wi, A, B, C, (64, 48, 48, 48), (w0 * A + w1 *...\n",
       "6231     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "6232     [import torch.nn as nn\\r\\n\\r\\nnet = nn.Sequent...\n",
       "6233     [train_inputs = torch.tensor(input_ids)\\r\\ntra...\n",
       "6234     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6235     [/usr/local/lib/python3.7/dist-packages/torch/...\n",
       "6236     [from efficientnet_pytorch import EfficientNet...\n",
       "6238     [x = tensor([3.,4.,10.]).requires_grad_()\\r\\nd...\n",
       "6239     [class Dataset(Dataset):\\r\\n    def __init__(s...\n",
       "6240     [import torch\\r\\nimport torchvision.models as ...\n",
       "6241     [input_data = skimage.io.imread(file_path)\\r\\n...\n",
       "6242     [torch.positive(input), Tensor, input, bool, b...\n",
       "6243     [def calc_gradients(D_train_batch, E_train_bat...\n",
       "6244     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "6245     [nn.EmbeddingBag, nn.Linear, self.embedding = ...\n",
       "6249     [train_dataset = torchvision.datasets.FashionM...\n",
       "6250     [train_dataset = torchvision.datasets.FashionM...\n",
       "6251     [conda list torch, AttributeError             ...\n",
       "6252     [conda            : 4.10.1\\r\\njupyter core    ...\n",
       "6253     [[[1,2,3],\\r\\n [4,5,6],\\r\\n [7,8,9]]\\r\\n, [[5,...\n",
       "6254     [get_constant_schedule, get_constant_schedule_...\n",
       "6255     [text = ['hey how are you','good i am fine','h...\n",
       "6256     [conda list torch, num_epochs = 10\\r\\nfor epoc...\n",
       "6257     [inference_{gpu_id}.py, Input1: GPU_id, Input2...\n",
       "6258     [TypeError: embedding(): argument 'indices' (p...\n",
       "6259     [tensor(200*[2*list[]], tensor(200*[4*list[]])...\n",
       "6260     [17x64x64, forward(), def forward(self, x, img...\n",
       "6262     [def train_epoch(self):\\r\\nfor epoch in tqdm.t...\n",
       "6263     [datasets = {\\r\\n    x:LungDataset(\\r\\n       ...\n",
       "6264     [input = torch.randn(8, 3, 50, 100)\\r\\n\\r\\nm =...\n",
       "6265     [input = torch.randn(8, 3, 50, 100)\\r\\n\\r\\nm =...\n",
       "6266     [x, idxs, x, idxs, torch.gather, torch.gather,...\n",
       "6267     [10,000*10,000, 10,00,000, 100*100, 10,000, 20...\n",
       "6268     [s_max, q_max, class LSTM(nn.Module):\\r\\ndef _...\n",
       "6269     [dataloader = DataLoader(dataset, batch_size=3...\n",
       "6270     [loss = 0.0\\r\\nfor i in range(10):\\r\\n     x =...\n",
       "6271     [#Bunch of inputs\\r\\n\\r\\ninp_IRI = Input(shape...\n",
       "6272     ['Linear.weight': tensor([[1.3696, 0.6309], [1...\n",
       "6273     [class LSTMClassifier(nn.Module):\\r\\n\\r\\n    d...\n",
       "6274     [# Prepare dataset by concatenating Train/Test...\n",
       "6275     [my_tensor = torch.tensor([0.1, 0.2, 0.2, 0.1,...\n",
       "6276     [my_tensor = torch.tensor([0.1, 0.2, 0.2, 0.1,...\n",
       "6278     [class WeightedBCELoss(nn.Module):\\r\\n    def ...\n",
       "6279     [RUN cd /tmp/ \\\\r\\n &amp;&amp; git clone https...\n",
       "6280     [\\r\\n\\r\\n\\r\\nfrom torch import nn\\r\\nfrom tran...\n",
       "6281     [nvidia-smi.exe, +----------------------------...\n",
       "6282     [nvidia-smi.exe, +----------------------------...\n",
       "6283     [image size = 128 * 128\\r\\npatch_size = 8\\r\\nd...\n",
       "6284     [class MLP3(nn.Module):\\r\\n    \\r\\n    def __i...\n",
       "6285     [import torch\\r\\nfrom torch_sparse import Spar...\n",
       "6286     [        \\r\\nself.critic_optimizer.zero_grad()...\n",
       "6287     [class SimpleMLP(nn.Module):\\r\\n  def __init__...\n",
       "6288     [lr=2e-6, lr=1e-6, optimizer = AdamW(model.par...\n",
       "6289     [lr=2e-6, lr=1e-6, optimizer = AdamW(model.par...\n",
       "6290     [def __init__(self, model, a=None, b=None, alp...\n",
       "6291     [t = torch.rand(2,3)\\r\\nprint(t)\\r\\ntensor([[0...\n",
       "6293     [class DoubleConv2D(nn.Module):\\r\\n  def __ini...\n",
       "6294     [from torch.autograd.gradcheck import zero_gra...\n",
       "6295     [vision.image.Image, cv2.Videocapture, frame, ...\n",
       "6296     [self.actor = nn.Sequential(\\r\\n   nn.Linear(s...\n",
       "6297     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nt...\n",
       "6298     [pip install torch==1.4.0+cpu torchvision==0.5...\n",
       "6299                       [MultiHeadAttention, Embeeding]\n",
       "6300     [data_list = []\\r\\nngraphs = 500\\r\\nfor i in r...\n",
       "6301     [device = torch.device( \"cuda\" if torch.cuda.i...\n",
       "6302     [class CustomDataset(Dataset):\\r\\n    def __in...\n",
       "6303     [class Modello1(nn.Module):\\r\\n\\r\\n#struttura ...\n",
       "6304     [estimator =\\r\\n                Estimator(imag...\n",
       "6305     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6306     [from transformers import RobertaConfig\\r\\n\\r\\...\n",
       "6307     [1. tensor (Tensor) – buffer to be registered....\n",
       "6308     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "6309     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6310     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6312     [torch.Size([128, 64])\\r\\n, torch.Size([1, 128...\n",
       "6313     [File \"touch_detect.py\", line 24, in &lt;modul...\n",
       "6314     [.pth, RuntimeError: Error(s) in loading state...\n",
       "6315     [DigitSensor with SensorDataSources.RAW data s...\n",
       "6316     [torch.empty(), torch.randn(), tmp = torch.ran...\n",
       "6317     [class UNet(nn.Module):\\r\\ndef __init__(self):...\n",
       "6318     [(x,y), radius=1.5, X = torch.DoubleTensor(100...\n",
       "6320     [&lt;ipython-input-16-53ecab33b355&gt; in &lt;...\n",
       "6321     [x = torch.from_numpy(np.linspace(1,100,num=10...\n",
       "6322     [where, main = torch.randn(64, 1, 28, 28)\\r\\no...\n",
       "6323     [from torch_geometric.data import Data\\r\\n,   ...\n",
       "6325                                 [@, @=, tokenizer.py]\n",
       "6327     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\n\\...\n",
       "6328     [        self.optimizer = torch.optim.Adam([\\r...\n",
       "6329     [for b in batchsize:\\r\\n  for i in N: \\r\\n    ...\n",
       "6330     [for b in batchsize:\\r\\n  for i in N: \\r\\n    ...\n",
       "6331     [(SCALNet) C:\\Users\\Gigabyte pc\\Desktop\\COUNTI...\n",
       "6332     [x = vl_nnconv(x, 'size', [3 3 3 nfilters(i)],...\n",
       "6333     [def my_generator():\\r\\n    for i in range(len...\n",
       "6334     [# create new conda env\\r\\nconda create -n han...\n",
       "6335     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6336     [add_scalar, for epoch in total_epochs:\\r\\n   ...\n",
       "6337     [x = [1,2,3,4,5,6,7,8,9,10], x = ['a', 'b', 'c...\n",
       "6338     [images = []\\r\\nimage_labels = []\\r\\n\\r\\nfor i...\n",
       "6339     [def my_loss(outputs,targets,fin_val):\\r\\n    ...\n",
       "6340     [+--------------------------------------------...\n",
       "6341     [t_c = torch.tensor([0.5, 14.0, 15.0, 28.0, 11...\n",
       "6342     [AttributeError: module 'torchaudio._internal....\n",
       "6344     [dataset = trainDataset()\\r\\ntrain_loader = Da...\n",
       "6346     [import os\\r\\nimport torch\\r\\nimport tarfile\\r...\n",
       "6347     [import os\\r\\nimport torch\\r\\nimport tarfile\\r...\n",
       "6348     [def _load_function(idx):\\r\\nidx = idx % len(s...\n",
       "6349     [weight = nn.Parameter(torch.FloatTensor(in_fe...\n",
       "6350     [# Device on which to run the model\\r\\n# Set t...\n",
       "6352     [def random_t(img):\\r\\n    im = Image.open(img...\n",
       "6353     [Z = torch.zeros(B,N)\\r\\n\\r\\nfor i in range(B)...\n",
       "6354     [Z = torch.zeros(B,N)\\r\\n\\r\\nfor i in range(B)...\n",
       "6355     [from tensorflow.keras import Sequential\\r\\nfr...\n",
       "6356     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "6357     [net = nn.Sequential(\\r\\n\\r\\nnn.Conv2d(1, 96, ...\n",
       "6358     [        query = self.query_model(query_input_...\n",
       "6359     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "6360     [def start_training(self):\\r\\n    self.train_t...\n",
       "6361     [pytorch, DataLoader, (20000 x 1 x 28 x 28), (...\n",
       "6362     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6363     [class Baseline(nn.Module):\\r\\n    def __init_...\n",
       "6364     [class Baseline(nn.Module):\\r\\n    def __init_...\n",
       "6365     [val = int((32*32)/4)\\r\\nself.fc1 = nn.Linear(...\n",
       "6366     [torchtext, Multi30k, IWSLT2017, Multi30k, # c...\n",
       "6367     [cnn_learner, lr_find(), learn.lr_find(), lear...\n",
       "6368     [if __name__ == \"__main__\" , import torch.nn a...\n",
       "6369     [~/opt/miniconda3/lib/python3.8/site-packages/...\n",
       "6370     [    import re\\r\\n    \\r\\n    from fast_trees....\n",
       "6371     [    import re\\r\\n    \\r\\n    from fast_trees....\n",
       "6373     [Multi30k, .de, .de, FileNotFoundError: [Errno...\n",
       "6374     [# Configuration options\\r\\nk_folds = 2\\r\\nlos...\n",
       "6375     [self.encoder = nn.Sequential(\\r\\n        nn.C...\n",
       "6376     [x = torch.tensor([[1, 2, 3], [4, 5, 6]])\\r\\np...\n",
       "6377     [  File \"/code/src/bert_structure_prediction/m...\n",
       "6378     [Rs, dists_ij = torch.cdist(Rs, Rs)\\r\\n, Vs, a...\n",
       "6379     [ bert = BertForSequenceClassification.from_pr...\n",
       "6381     [import os\\r\\nimport copy\\r\\nimport torch\\r\\ni...\n",
       "6383     [for i, (inp, gt) in enumerate(test_loader):\\r...\n",
       "6384     [model(images, targets), def train(self, num_e...\n",
       "6385     [class NN1(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "6386     [AttributeError: module 'utils' has no attribu...\n",
       "6387     [data = [tensor(0.1647),tensor(0.1662),tensor(...\n",
       "6388     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "6389     [inputs = inputs.view(-1)\\r\\ntargets = targets...\n",
       "6390     [inputs = inputs.view(-1)\\r\\ntargets = targets...\n",
       "6391     [\\r\\n  def conv_block(in_channels, out_channel...\n",
       "6392     [x, y, self.final = nn.Sequential(\\r\\n    nn.C...\n",
       "6393     [model = torch.load('a.pth')\\r\\n  File \"/home/...\n",
       "6394     [[[0.13534, 0.32465, 0.60653, 0.8825, 1.0000, ...\n",
       "6395     [import torchvision.models as models\\r\\nvgg_mo...\n",
       "6396     [import torch\\r\\nimport numpy as np\\r\\narr = t...\n",
       "6397     [train_loader2=embeddings_train\\r\\n\\r\\ntrain_l...\n",
       "6398                 [edge_index, torch.long, torch.int32]\n",
       "6399     [import os\\r\\nimport torch\\r\\nimport torchvisi...\n",
       "6400     [import typing\\r\\nfrom collections import Coun...\n",
       "6401     [(12,12), (5,3,12,12), detach().numpy(),     f...\n",
       "6402     [import torch\\r\\n\\r\\npath = \"model.pt\"\\r\\n\\r\\n...\n",
       "6403     [libtorch, libtorch, inter-op, intra-op, inter...\n",
       "6404     [x=torch.randn((5,4,299,299))\\r\\n\\r\\nmodel_ft=...\n",
       "6405     [x=torch.randn((5,4,299,299))\\r\\n\\r\\nmodel_ft=...\n",
       "6407     [pip install --user pytorch, ERROR: Command er...\n",
       "6408     [import pandas as pd\\r\\nimport torch\\r\\nfrom t...\n",
       "6409     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "6410     [def run_fold(fold):\\r\\n    \\r\\n    df_train =...\n",
       "6412     [class ENCODER_RNN(nn.Module):\\r\\n    def __in...\n",
       "6413     [(py38) [ec2-user@ip current]$ nvidia-smi\\r\\n+...\n",
       "6414     [from dask import delayed\\r\\nfrom dask.distrib...\n",
       "6415     [arr=[1]*10, sum(arr[0:2]), sum(arr[2:3]), sum...\n",
       "6416     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6417     [from collections import Counter, OrderedDict\\...\n",
       "6418     [from collections import Counter, OrderedDict\\...\n",
       "6419     [2021-07-12 16:39:25,799 - INFO - allennlp.tra...\n",
       "6420     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6421     [def recv(connection, buffer_size=4096):\\r\\n  ...\n",
       "6422     [from detectron2.modeling import build_model\\r...\n",
       "6423     [import numpy as np\\r\\nimport sys, random\\r\\ni...\n",
       "6424     [    test_X, test_y = load_data(mode='test')\\r...\n",
       "6425     [def bayopt(neurons,learning_rate,batch_size):...\n",
       "6426     [from sentence_transformers import SentenceTra...\n",
       "6427     [from sentence_transformers import SentenceTra...\n",
       "6428     [class MyNeuralNetwork(torch.nn.Module):\\r\\n  ...\n",
       "6429     [File \"C:\\Users\\Administrator\\anaconda3\\envs\\w...\n",
       "6430     [pip3 install --pre torch torchvision torchaud...\n",
       "6432     [---------------------------------------------...\n",
       "6433     [model = torch.hub.load('facebookresearch/pyto...\n",
       "6434     [model = torch.hub.load('facebookresearch/pyto...\n",
       "6435     [import libTest\\r\\nundefined symbol: _ZN3c1019...\n",
       "6436     [pyhtorch, numpy, plot_example, def plot_examp...\n",
       "6437     [pip install torch\\r\\npip3 install torch\\r\\npi...\n",
       "6438     [#!pip install transformers\\r\\n!pip install tr...\n",
       "6440     [def build_train_loader(cls, cfg):\\r\\n    augs...\n",
       "6441     [input_dim = 1\\r\\nhidden_dim = 32\\r\\nnum_layer...\n",
       "6442     [decoder_start_token_id, forced_bos_token_id, ...\n",
       "6443     [for text in test_texts:\\r\\n    encoded_dict =...\n",
       "6444     [_load_image,  dl = DataLoader(coco, batch_siz...\n",
       "6445     [class Net(torch.nn.Module):\\r\\n    def __init...\n",
       "6446     [tensor([[1,3,2,6]])\\r\\n, tensor([[0,1,0,0,0,0...\n",
       "6447     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6448     [errors = {0: tensor(64.4072, device='cuda:0')...\n",
       "6449     [model = torch.jit.load('/content/drive/MyDriv...\n",
       "6450     [torchvision.models.segmentation.fcn_resnet50,...\n",
       "6451     [train_dataset = wds.Dataset(url), train_loade...\n",
       "6452     [train_dataset = wds.Dataset(url), train_loade...\n",
       "6453     [A, B, (n, m, k), (n, m), n, m, k, B, m, B = t...\n",
       "6455     [siren, siren, sin(), class Autoencoder(nn.Mod...\n",
       "6456     [for images, targets in metric_logger.log_ever...\n",
       "6458     [Net.act, from torch import nn\\r\\nimport torch...\n",
       "6459     [Net.act, from torch import nn\\r\\nimport torch...\n",
       "6460     [self.actor = nn.Sequential(\\r\\n              ...\n",
       "6461     [if __name__ == \"__main__\":\\r\\n        output ...\n",
       "6462     [def lowPass_Filter(signal, cutoff, fs, order)...\n",
       "6463     [self.gn1 = nn.GroupNorm(16, hidden_size)\\r\\nh...\n",
       "6464     [TypeError: can't convert cuda:0 device type t...\n",
       "6465     [TypeError: can't convert cuda:0 device type t...\n",
       "6466     [class AEGRU(nn.Module):\\r\\n    def __init__(s...\n",
       "6467     [torch.save(torch.tensor(train_loss_set), os.p...\n",
       "6468     [net= Net()\\r\\nmodel= torch.nn.DataParallel(ne...\n",
       "6469     [import easyocr \\r\\nimport numpy as np\\r\\nimpo...\n",
       "6470     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6471     [BERT -&gt; dropout -&gt; classifier -&gt; los...\n",
       "6472     [RuntimeError: CUDA error: device-side assert ...\n",
       "6473     [RuntimeError: CUDA error: device-side assert ...\n",
       "6474     [def run(dataset, model, runs, epochs, lr, wei...\n",
       "6475     [import torch\\r\\nfrom torch_geometric.datasets...\n",
       "6476     [.size(), len(), .data.size(),     print(test_...\n",
       "6477     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6478     [from fastai.vision import *\\r\\nfrom fastai.me...\n",
       "6479     [torch.scatter, a, idx, a = torch.tensor([[0, ...\n",
       "6480     [for epoch in range(0, epoch_num):\\r\\n    net....\n",
       "6481     [import math, random\\r\\nfrom sklearn.datasets ...\n",
       "6483     [python app.py, streamlit run app.py, PyCUDA, ...\n",
       "6484     [# Torch\\r\\ntorch_out = nn.PixelShuffle(2)(inp...\n",
       "6485     [(28,28), RuntimeError: mat1 and mat2 shapes c...\n",
       "6486     [dis_matrix = torch.tensor([[ 0.0000, 20.2615,...\n",
       "6487     [RuntimeError: CUDA error: out of memory, torc...\n",
       "6488     [pytorch_pretrained_bert, torch, poetry add py...\n",
       "6489     [source, nodes id, end, nodes id, DataFrame\\r\\...\n",
       "6492     [class Net( nn.Module ) :\\r\\n    def __init__(...\n",
       "6493     [import torch\\r\\n\\r\\n# create tensors to repre...\n",
       "6495     [from typing import Tuple\\r\\n\\r\\nimport torch\\...\n",
       "6497     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6498     [input_tensor, torch.size([4,4]), input_tensor...\n",
       "6499     [input_tensor, torch.size([4,4]), input_tensor...\n",
       "6501     [X_train, (torch.Size([716, 50, 50]), class CN...\n",
       "6502     [X_train, (torch.Size([716, 50, 50]), class CN...\n",
       "6503     [pip install torch===1.7.0 -f https://download...\n",
       "6504     [|-- train\\r\\n     |-- cats\\r\\n     |-- dogs\\r...\n",
       "6505     [epoch_num = 30\\r\\n\\r\\ntrain_log = []\\r\\ntest_...\n",
       "6506     [import torch as T\\r\\nimport numpy as np\\r\\n\\r...\n",
       "6507     [left_img = Image.open('image.jpg')\\r\\n...\\r\\n...\n",
       "6508     [left_img = Image.open('image.jpg')\\r\\n...\\r\\n...\n",
       "6509     [# Create boxes list\\r\\nboxes = [\\r\\n    [anno...\n",
       "6510     [git clone https://github.com/pytorch/pytorch\\...\n",
       "6512     [a, b, import torch\\r\\n\\r\\na = torch.tensor(([...\n",
       "6513     [images.shape: torch.Size([128, 3, 32, 32])\\r\\...\n",
       "6514     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "6515     [import torch \\r\\nfrom torch.autograd import F...\n",
       "6516     [UnboundLocalError: Caught UnboundLocalError i...\n",
       "6517     [import os \\r\\nimport matplotlib.pyplot as plt...\n",
       "6518     [ from transformers import pipeline\\r\\n\\r\\nNon...\n",
       "6520     [class ReactorNet(nn.Module):\\r\\n\\r\\n  def __i...\n",
       "6522     [TypeError, VGG16, FruitsDataModule, val_datal...\n",
       "6523     [for i in range(1, runs + 1):\\r\\n\\r\\n        d...\n",
       "6524     [**import torch\\r\\nimport torch.nn as nn\\r\\nim...\n",
       "6525     [**import torch\\r\\nimport torch.nn as nn\\r\\nim...\n",
       "6526     [# Pysyft needs to be hooked to PyTorch to ena...\n",
       "6527     [transform = transforms.Compose([transforms.Re...\n",
       "6528     [transform = transforms.Compose([transforms.Re...\n",
       "6529     [transform = transforms.Compose([transforms.Re...\n",
       "6530     [net, for p in net.parameters():\\r\\n    if p.d...\n",
       "6531     [                P = theano.shared(pop.astype(...\n",
       "6532     [[x1, y1, z1]\\r\\n[x2, y2, z2]\\r\\n    ...\\r\\n[x...\n",
       "6533     [(x, y), img[x, y], import torch\\r\\n\\r\\n# crea...\n",
       "6534     [#read dataset\\r\\ndf = pd.read_csv(\"data.csv\",...\n",
       "6535     [class network:\\r\\n\\r\\n    def __init__(self):...\n",
       "6536     [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "6539     [tensor1 = torch.rand((4,2,3,100))\\r\\ntensor2 ...\n",
       "6540     [rnn = nn.RNN(1, 1, 1, bias = False, batch_fir...\n",
       "6542     [RuntimeError: Error loading audio file: faile...\n",
       "6543     [class Net(torch.nn.Module):\\r\\n    def __init...\n",
       "6545     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6546     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6547     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6550     [RuntimeError: 1D target tensor expected, mult...\n",
       "6551     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6552     [attn_mask, BATCH_SIZE * NUMBER_HEADS, SEQUENC...\n",
       "6553     [rand_params = np.random.default_rng()\\r\\nrand...\n",
       "6554     [img, bx2xhxw, torch.nn.functional.interpolate...\n",
       "6555     [ for layer_index in range(0, number_of_layers...\n",
       "6556     [print(h.is_cuda),\\r\\n, File \"C:/Users/user/Ap...\n",
       "6557     [class GCN(torch.nn.Module):\\r\\ndef __init__(s...\n",
       "6558     [Ubuntu 20.04, CMake Error at modules/observer...\n",
       "6559     [IterableDataset, Dataset, DataLoader, Dataset...\n",
       "6560     [def distancing(people_coords, img, dist_thres...\n",
       "6561     [r1 = [([[[1, 2, 3], [1, 2, 3]], \\r\\n        [...\n",
       "6562     [n, d, d x d, J, n, J, n, expand(), J, n x d x...\n",
       "6563     [infering thread started\\r\\n1 1\\r\\n: cannot co...\n",
       "6566     [torch.bernoulli, torch.bernoulli([0.599, 0.08...\n",
       "6567     [import torch\\r\\nfrom torch_geometric.utils im...\n",
       "6568     [x = torch.tensor([ 0,  1,  0,  0,  2,  2,  3,...\n",
       "6569     [import torch as t\\r\\nimport torch.nn as nn\\r\\...\n",
       "6570     [arr = np.array([1, 2, 3]), tnsr = torch.zeros...\n",
       "6571     [i = 2\\r\\nj = 0\\r\\nmask = torch.randn(480, 360...\n",
       "6572     [read_video, import torch\\r\\nimport torchvisio...\n",
       "6573     [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "6574     [class Trainer(nn.Module):\\r\\n    def __init__...\n",
       "6575     [            sampler = torch.utils.data.Random...\n",
       "6576     [rgb = network1(input1)\\r\\nof = network2(input...\n",
       "6577     [y, y = torch.tensor([ 1,  0,  2])\\r\\n, y_pred...\n",
       "6579     [ results = classifier([\"We are very happy to ...\n",
       "6580     [pytorch, tf.keras, torch_layer = torch.nn.Con...\n",
       "6581     [predict_img = PIL.Image.open('./test1/test.jp...\n",
       "6582     [import torch\\r\\ncolumns = 43*22\\r\\nrows    = ...\n",
       "6583     [import torch\\r\\ncolumns = 43*22\\r\\nrows    = ...\n",
       "6584     [import torch\\r\\ncolumns = 43*22\\r\\nrows    = ...\n",
       "6585     [    precision = Precision(average=False)\\r\\n ...\n",
       "6586     [for q in range(batchSize):\\r\\n    temp=torch....\n",
       "6587     [for q in range(batchSize):\\r\\n    temp=torch....\n",
       "6588     [extended_output, [batchSize,nClass*repeat], [...\n",
       "6589     [Number of graphs: 1\\r\\nNumber of features: 14...\n",
       "6590     [ID  Target  Weight    Score   Scale_Cat   Sca...\n",
       "6591     [# Modules\\r\\nimport torch\\r\\nimport torch.nn ...\n",
       "6592     [# Modules\\r\\nimport torch\\r\\nimport torch.nn ...\n",
       "6593     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6594     [macro_model.tar.gz, macro_model.pth, requirem...\n",
       "6595     [macro_model.tar.gz, macro_model.pth, requirem...\n",
       "6596                         [torch.Tensor.unfold, unfold]\n",
       "6597                         [torch.Tensor.unfold, unfold]\n",
       "6598     [(100, 16, 16), (100), (100, 16, 16), (1, 16, ...\n",
       "6599     [....\\r\\n    return self._conv_forward(input, ...\n",
       "6600     [....\\r\\n    return self._conv_forward(input, ...\n",
       "6601     [for i in range(A.shape[0]):\\r\\n    for j in r...\n",
       "6602     [loss_fct = nn.LossFunction(), loss_fct = nn.L...\n",
       "6603     [nlp, pytorch, sklearn's, StratifiedKFold, cro...\n",
       "6605     [coeff, w_foo, w_bar, w_target, w_target = `w_...\n",
       "6606     [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "6607     [torch.jit.script, import torch\\r\\nfrom torch ...\n",
       "6608     [heroku logs --tail, 2021-06-25T13:13:01.05258...\n",
       "6609     [dataset = ImageFolder('/content/drive/MyDrive...\n",
       "6610     [import torch.nn\\r\\nfrom torch import tensor\\r...\n",
       "6611     [transform = transforms.Compose(\\r\\n[transform...\n",
       "6612     [transform = transforms.Compose(\\r\\n[transform...\n",
       "6613     [from __future__ import absolute_import, divis...\n",
       "6614     [n, n, optimizer.step(), import torch.multipro...\n",
       "6615     [class MyNNet(torch.nn.Module):\\r\\n  \\r\\n  def...\n",
       "6616     [img[i, j, k] = i+j+k, 1, 2, 3, grid_sample, 6...\n",
       "6617     [    for k in range(1, K_intermediate+1):\\r\\n\\...\n",
       "6618     [model_resnet50 = torchvision.models.resnet50(...\n",
       "6619     [indptr = [0 2 2 5 7]\\r\\nvalues = [2 4 3 2 1 1...\n",
       "6620     [indptr = [0 2 2 5 7]\\r\\nvalues = [2 4 3 2 1 1...\n",
       "6621     [x = torch.rand(10, requires_grad=True)\\r\\ny =...\n",
       "6622     [model = BertForSequenceClassification.from_pr...\n",
       "6623     [import os\\r\\nimport torch\\r\\nimport torch.dis...\n",
       "6624     [class LSTMModel(torch.nn.Module):\\r\\n        ...\n",
       "6625     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6626     [nn.RNN, nn, self.rnn = nn.RNN(input_size, hid...\n",
       "6627     [\\r\\nTraceback (most recent call last):\\r\\n  F...\n",
       "6628     [        self.net = nn.Sequential(\\r\\n        ...\n",
       "6629     [        kernel = [np.array([[0., 0., 0.], [0....\n",
       "6630     [#import blah blah\\r\\n\\r\\n#active funtion\\r\\nL...\n",
       "6632     [batch_encode_plus, pad [PAD], from transforme...\n",
       "6633     [UserWarning: CUDA initialization: CUDA unknow...\n",
       "6634     [print(f\"PyTorch version: {torch.__version__}\"...\n",
       "6635     [print(f\"PyTorch version: {torch.__version__}\"...\n",
       "6636     [# Define transformations for training and tes...\n",
       "6637     [nn.CrossEntropyLoss(), (batch_size, 1, 30, 30...\n",
       "6639     [cuda.set_device(), cuda.device(), torch.backe...\n",
       "6640     [cuda.set_device(), cuda.device(), torch.backe...\n",
       "6641     [TypeError: tensor() got an unexpected keyword...\n",
       "6642     [#importing the libraries\\r\\nimport numpy as n...\n",
       "6643     [# BERT training loop\\r\\nfor _ in trange(epoch...\n",
       "6645     [\\r\\npath_to_lge = \"flaubert/flaubert_small_ca...\n",
       "6646     [disciminator_input = torch.cat([hidden_states...\n",
       "6647     [z = x - i*y\\r\\n, u(x, y) = x\\r\\n, v(x, y) = -...\n",
       "6649     [[2021-06-23 07:13:17,592] {pod_launcher.py:14...\n",
       "6650     [Create a Detectron2-based Layout Detection Mo...\n",
       "6651     [Create a Detectron2-based Layout Detection Mo...\n",
       "6652     [Traceback (most recent call last):\\r\\n  File ...\n",
       "6653     [for idx, batch in enumerate(train_dataloader)...\n",
       "6654     [CUDA out of memory, model = XLMRobertaForCaus...\n",
       "6655     [import numpy as np\\r\\nclass Tensor:\\r\\n    de...\n",
       "6656     [torch.size([1, 25200, 11]), torch.size([1, 3,...\n",
       "6657     [torch.size([1, 25200, 11]), torch.size([1, 3,...\n",
       "6658     [---------------------------------------------...\n",
       "6659     [---------------------------------------------...\n",
       "6660     [tokenizer.pad, class DatasetTokenized(Dataset...\n",
       "6661     [TqdmKeyError                              Tra...\n",
       "6662     [tensor_x = torch.Tensor([np.array(v) for v in...\n",
       "6663     [GPT2_tokenizer = GPT2Tokenizer.from_pretraine...\n",
       "6664     [\\r\\nimport torchtext.legacy.data as ttd\\r\\nim...\n",
       "6665     [transform = transforms.Compose([transforms.To...\n",
       "6667     [Deeplabv3.onnx, #include &lt;sstream&gt;\\r\\n\\...\n",
       "6668     [data = []\\r\\nfor dir in os.listdir(root):\\r\\n...\n",
       "6669     [[X, 4], [Y, 4], X, Y, [X, Y, 4], [2 4 6 8] OP...\n",
       "6670     [torch.cuda.empty_cache()\\r\\ntorch.cuda.set_pe...\n",
       "6671     [deeplabv3_scripted.pt, python deeplabv3.py, p...\n",
       "6672     [UNet3D(\\r\\n  (encoders): ModuleList(\\r\\n    (...\n",
       "6673     [def main(args, df_train, df_dev, df_test) :\\r...\n",
       "6674     [Tensor, ndarray, a, b, a.add_(1), a, b, impor...\n",
       "6675     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "6677     [    corpus = [\\r\\n        \"We always come to ...\n",
       "6678     [model, op, psuedo-op, loss(op_i,gt_i)&lt;loss...\n",
       "6679     [(3, 256, 256), # Number of channels in the tr...\n",
       "6680     [optimizer.step, 90%, w1 -= lr * loss_value = ...\n",
       "6681     [class MSE_gradient(nn.Module):\\r\\n  def __ini...\n",
       "6682     [conv1.weight[1,1,:,:], class Cifar10CnnModel(...\n",
       "6684     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "6685     [---------------------------------------------...\n",
       "6686     [x = prediction['masks']\\r\\n, torch.squeeze(x,...\n",
       "6687     [split=('train', 'test'), torchtext.vocab.Voca...\n",
       "6691     [split=('train', 'test'), torchtext.vocab.Voca...\n",
       "6692     [def image_loader(transform, image_name):\\r\\n ...\n",
       "6693     [elif Config.MODEL_NAME == 'efficientnet-b3':\\...\n",
       "6694     [elif Config.MODEL_NAME == 'efficientnet-b3':\\...\n",
       "6695     [from torch_geometric.data import DataLoader, ...\n",
       "6696     [(i.e., -2,-1,0,1,2), self._one_hot_encode(lab...\n",
       "6697     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "6699     [dataset = Dataset(...)\\r\\nsampler = RandomSam...\n",
       "6701     [.moveaxis(), .movedim(), .permute(), import t...\n",
       "6702     [#include &lt;torch/extension.h&gt;\\r\\n\\r\\n// ...\n",
       "6703     [self.layer1 = nn.Sequential(\\r\\n    nn.Conv2d...\n",
       "6704     [3e-2, def _init_weights(m):\\r\\n    if type(m)...\n",
       "6705     [torch.det, a = torch.tensor([1.0, 1.0])\\r\\nb ...\n",
       "6706     [cudaLaunchKernel, import torch\\r\\nfrom torch....\n",
       "6707     [input, tensor([[[ 0,  1],\\r\\n         [ 2,  3...\n",
       "6708     [class NutSnackClassication(MultiLabelImageCla...\n",
       "6710     [RuntimeError: `lengths` array must be sorted ...\n",
       "6711     [transform=torchvision.transforms.Compose([\\r\\...\n",
       "6712     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "6713        [Torch.Tensor, gen_matrix([a, b, c, d, e, f])]\n",
       "6714     [train_transform = torch.nn.Sequential(\\r\\n   ...\n",
       "6715     [import numpy as np\\r\\nfrom numpy.linalg impor...\n",
       "6716     [def corr(x):\\r\\n    \"\"\"\\r\\n    x: [B, C, H, W...\n",
       "6717     [class LitClassifier(pl.LightningModule):\\r\\n ...\n",
       "6718                                  [x.unsqueeze(1) - y]\n",
       "6719     [pip install torch==1.7+cu101\\r\\n, 'SSLError(S...\n",
       "6720     [self.action_space = spaces.Box(\\r\\n    low=np...\n",
       "6721     [x = torch.tensor([[ 0,  1,  2,  3,  4,  5],\\r...\n",
       "6724     [TypeError: forward() takes 2 positional argum...\n",
       "6725     [(synthesis) miranda9@Brandos-MBP ~ % conda in...\n",
       "6727     [cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_D...\n",
       "6728     [from torch.utils.data import Dataset, DataLoa...\n",
       "6729     [mmconvert -sf keras -iw vgg.h5 -df pytorch -o...\n",
       "6730     [import numpy as np\\r\\nN = 30 # Number of data...\n",
       "6731     [import numpy as np\\r\\nN = 30 # Number of data...\n",
       "6732     [tf.nn.conv2d_transpose, np.random.seed(42)\\r\\...\n",
       "6733     [class VGGBlock(nn.Module):\\r\\n    def __init_...\n",
       "6734     [DistributedDataParallel, find_unused_paramete...\n",
       "6735     [DistributedDataParallel, find_unused_paramete...\n",
       "6736     [import multiprocessing\\r\\nimport torch\\r\\n\\r\\...\n",
       "6737     [def calculate_scores(sent, model, tokenizer, ...\n",
       "6738     [class CombineModel(nn.Module): #A multimodal ...\n",
       "6739     [gunicorn app:app,     Sudo Python app.py\\r\\n\\...\n",
       "6740     [class MaleFacesDataset(Dataset):\\r\\n\\r\\n def ...\n",
       "6741     [import pandas as pd\\r\\nimport json\\r\\nimport ...\n",
       "6742     [import torch\\r\\nK = 64\\r\\nstart_time = time.t...\n",
       "6744     [# -*- coding: utf-8 -*-\\r\\n\"\"\"\\r\\nCreated on ...\n",
       "6745     [tensor([[[    nan,     nan,     nan,  ...,   ...\n",
       "6746     [#torch == 1.8.1\\r\\n#numpy == 1.20.2\\r\\n#panda...\n",
       "6747     [class NeuralNet(nn.Module):\\r\\n    def __init...\n",
       "6748     [import torch.nn as nn\\r\\nimport torch.optim a...\n",
       "6749     [Train set - loss, Test  set - loss, loss, acc...\n",
       "6750     [Train set - loss, Test  set - loss, loss, acc...\n",
       "6751     [class AiService():\\r\\n\\r\\n    def __init__(se...\n",
       "6752     [class perceptron(nn.Module):\\r\\n  def __init_...\n",
       "6753     [train_set, import json\\r\\n\\r\\n! wget -O train...\n",
       "6754     [requires_grad = False, tensor.detach(), .deta...\n",
       "6756     [def backward_batchnorm2d(input, output, grad_...\n",
       "6757     [torch-geometric, shell.nix, { pkgs ? import &...\n",
       "6758     [torch-geometric, shell.nix, { pkgs ? import &...\n",
       "6760     [ def forward(self, x):\\r\\n        x = self.fo...\n",
       "6761     [((precision * recall)/(precision + recall)), ...\n",
       "6762     [((precision * recall)/(precision + recall)), ...\n",
       "6763     [convert_graph_to_onnx, transformers, import s...\n",
       "6764                                 [os.path.isfile(...)]\n",
       "6766         [nn.functional.upsample(mode = \"bicubic)\\r\\n]\n",
       "6767     [AssertionError                            Tra...\n",
       "6768     [&lt;pre&gt;&lt;code&gt;\\r\\n    class RBM():\\r...\n",
       "6769     [.dat, 200, 128*128*128, a, 128*128*128, [:, i...\n",
       "6770     [ids, mask, token_type_ids, targets, class Jig...\n",
       "6771     [ids, mask, token_type_ids, targets, class Jig...\n",
       "6772     [model, model.simulate(N = 10, T = 50)\\r\\n, im...\n",
       "6773     [var1 = torch.rand(128, 128, requires_grad=Tru...\n",
       "6775     [$ docker run --gpus all -it --rm -p 8000:8000...\n",
       "6776     [device = cuda:0, .to(cuda:0), class Sentiment...\n",
       "6777     [device = cuda:0, .to(cuda:0), class Sentiment...\n",
       "6778     [conv = nn.Conv2d(8, 8, 3, bias=False), bias, ...\n",
       "6779     [class DKLModel(gpytorch.Module):\\r\\n\\r\\n    d...\n",
       "6780     [t1, [a,b], t2, [c], t3, [a,b,c], t3[0, :, 0] ...\n",
       "6781     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6782     [class data_gen(torch.utils.data.Dataset):\\r\\n...\n",
       "6783     [tf.variable_scope, tf.Variable, def conv_laye...\n",
       "6784     [$ kubectl apply -f torchserve-custom.yaml\\r\\n...\n",
       "6785     [         # 0: Paper, 1: Rock, 2: Scissors\\r\\n...\n",
       "6786     [from scipy.linalg import subspace_angles as s...\n",
       "6787     [ res = torch.sum(x * y, dim=-1) - 2 * x[..., ...\n",
       "6788     [nn.BCEWithLogitsLoss(), loss_fn = nn.BCEWithL...\n",
       "6789     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "6790     [        learning_rate = 1e-1\\r\\n        num_e...\n",
       "6791     [self.task_layers[task][task_layer_key]; TaskL...\n",
       "6792     [device = 'cuda:0' if torch.cuda.is_available(...\n",
       "6793     [\\r\\nloss_fn = nn.BCELoss() ##nn.CrossEntropyL...\n",
       "6794     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6796     [from torchtext.datasets import WikiText103\\r\\...\n",
       "6797     [import pandas as pd\\r\\nimport torch\\r\\nfrom t...\n",
       "6798     [RuntimeError: nvrtc: error: failed to open li...\n",
       "6799     [vocab size = 100\\r\\nembbeding size = 50\\r\\nma...\n",
       "6800     [torch.jit.trace, RuntimeError: PyTorch conver...\n",
       "6801     [def RPC_get_parameters(data, model):\\r\\n    \"...\n",
       "6802     [tensor([[1., 2., 3., 4.]]), tensor([[1., 2., ...\n",
       "6804     [x, import numpy as np\\r\\nx = np.arange(4 * 10...\n",
       "6805     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "6806     [OrigResNet18 = None\\r\\nOrigResNet18 = torch.h...\n",
       "6807     [import torch\\r\\nimport torch.nn.functional as...\n",
       "6808     [import numpy as np\\r\\nimport torch\\r\\n\\r\\ny =...\n",
       "6809     [import numpy as np\\r\\nimport torch\\r\\n\\r\\ny =...\n",
       "6810     [[[1,0,1],\\r\\n [0,1,1],\\r\\n [0,0,0]]\\r\\n, [[[1...\n",
       "6812     [  ResNet(\\r\\n (conv1): Conv2d(3, 64, kernel_s...\n",
       "6814     [  def choose_action(self,enc_current_node,goa...\n",
       "6818     [class MLP(nn.Module):\\r\\n    def __init__(sel...\n",
       "6819     [class CNN_ForecastNet(nn.Module):\\r\\n    def ...\n",
       "6820     [# G is a generative model in line with StyleG...\n",
       "6821     [class k_armed_bandit:\\r\\n    def __init__(sel...\n",
       "6823     [model.train(), Train(), class CNN_ForecastNet...\n",
       "6824     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nn =...\n",
       "6825     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nn =...\n",
       "6826     [A: tensor([[0,0,1,1,2,3],[5,6,7,8,9,3]]), # a...\n",
       "6827     [A: tensor([[0,0,1,1,2,3],[5,6,7,8,9,3]]), # a...\n",
       "6828     [(batch_size, sequence_length, embedding_dim),...\n",
       "6829     [import torch\\r\\nimport argparse\\r\\n\\r\\nparser...\n",
       "6833     [def func1(word):\\r\\n    print(\"hello\", word)\\...\n",
       "6834     [train_df = pd.read_csv(train_path, index_col=...\n",
       "6835     [train_df = pd.read_csv(train_path, index_col=...\n",
       "6836     [Runtime, !pip install -q condacolab\\r\\n\\r\\nim...\n",
       "6837     [class QNetworkMLP(Module):\\r\\n    def __init_...\n",
       "6838     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6839     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6840     [z, (n_samples, n_features, n_views), n_sample...\n",
       "6841     [Your runtime has 27.3 gigabytes of available ...\n",
       "6842     [def forward(self, x):\\r\\n    x = self.model(x...\n",
       "6843     [A = np.array([[3, 1], [4, 1], [1, 4]])\\r\\nB =...\n",
       "6844     [A = np.array([[3, 1], [4, 1], [1, 4]])\\r\\nB =...\n",
       "6845     [transformers,  import torch  # version 1.8.1+...\n",
       "6846     [import torch\\r\\nfrom torchtext import data\\r\\...\n",
       "6847     [N, M, G, N x M x 3, N, H, M x 3, 1 x M x 3, K...\n",
       "6848     [x = torch.tensor([\\r\\n    [\\r\\n        [[0.44...\n",
       "6849     [x = torch.tensor([\\r\\n    [\\r\\n        [[0.44...\n",
       "6850     [x = torch.tensor([\\r\\n    [\\r\\n        [[0.44...\n",
       "6851     [G:\\Saadain\\Anaconda\\envs\\CSRNet\\lib\\site-pack...\n",
       "6852     [       tensor([[8.22266e-01, 1.34659e-03, 9.8...\n",
       "6853     [False, u_, s_, v_ = torch.svd(x)\\r\\nis_same =...\n",
       "6854     [criterion = nn.CrossEntropyLoss()\\r\\nfor epoc...\n",
       "6856     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "6857     [ResNet, num_features, import torch\\r\\nimport ...\n",
       "6858     [#include &lt;torch/extension.h&gt;\\r\\n#includ...\n",
       "6860     [test_dataset\\r\\n\\r\\nDataset({\\r\\n    features...\n",
       "6861     [test_dataset\\r\\n\\r\\nDataset({\\r\\n    features...\n",
       "6862     [test_dataset\\r\\n\\r\\nDataset({\\r\\n    features...\n",
       "6864     [[[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [...\n",
       "6865     [airplane :  -16.972412\\r\\nautomobile :  -18.7...\n",
       "6866     [!pip install -Uqq tqdm\\r\\n\\r\\nimport torch\\r\\...\n",
       "6868     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "6869     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "6870     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "6871     [tensor = 10, import torch\\r\\nimport torch.nn ...\n",
       "6872     [m x n, m, n, a, 100 x 3 x 3 x 5, b, 30 x 4, e...\n",
       "6874     [tensor([[2., 2., 2., 2.],\\r\\n        [2., 2.,...\n",
       "6875     [epochs = 500\\r\\nfinal_loss = []\\r\\nfor i in r...\n",
       "6876     [Accuracy: 59.4%, Avg loss: 0.693147\\r\\n[...50...\n",
       "6877     [fasterrcnn_foodtracker.pth, import torch\\r\\ni...\n",
       "6878     [fasterrcnn_foodtracker.pth, import torch\\r\\ni...\n",
       "6879     [del model\\r\\ntorch.cuda.empty_cache()\\r\\n, mo...\n",
       "6880     [class Model(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "6881     [t = w*x + b\\r\\n, class fit():\\r\\n    def __in...\n",
       "6882     [Net, net.pth, y = model(x), waitpid, def hand...\n",
       "6883     [import os\\r\\nimport pandas as pd\\r\\nimport nu...\n",
       "6884     [from torch.nn.parameter import Parameter\\r\\nf...\n",
       "6886     [ import torch\\r\\n matrix = torch.tensor([[1, ...\n",
       "6888     [pytorch, pytorch, import torchvision.models a...\n",
       "6889     [L, 3000, L=3, def OH3(x,end=2,len=3):\\r\\n  x ...\n",
       "6890     [L, 3000, L=3, def OH3(x,end=2,len=3):\\r\\n  x ...\n",
       "6891     [pad_sequence, pad_sequence, torch.Size([44]),...\n",
       "6892     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "6893     [from model.res50 import ResNet\\r\\nself.encode...\n",
       "6894     [model = torchvision.models.resnet50(pretraine...\n",
       "6895     [KeyError  Traceback (most recent call last)  ...\n",
       "6896     [KeyError  Traceback (most recent call last)  ...\n",
       "6897     [def validate_epoch(net, val_loader,loss_type=...\n",
       "6898     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "6899     [N, M, list_embd = [[M embeddings], [M embeddi...\n",
       "6900     [trainer.train()\\r\\n, [06/03 01:17:49 d2.engin...\n",
       "6901     [counts, idx, idx, i, idx, i, counts, count, i...\n",
       "6904     [ret, eval(), exec_job, ret is None; TypeError...\n",
       "6905     [learn = cnn_learner(data, \\r\\n               ...\n",
       "6906     [import torch\\r\\nfrom torch import Tensor\\r\\ni...\n",
       "6907     [class Trainer(BaseTrainer):\\r\\n    def __init...\n",
       "6908     [from torch.nn.parameter import Parameter\\r\\nf...\n",
       "6911     [10%, WeightedRandomSampler, torch.utils.data,...\n",
       "6912     [pose_pre,     # print(pose_pre) # &lt;-------...\n",
       "6913     [class MicroESDataset(Dataset):\\r\\n\\r\\n    def...\n",
       "6916     [torch.Size([128], torch.Size([256, 128, 3, 3]...\n",
       "6917     [pytorch, class SNet(nn.Module):\\r\\n    def __...\n",
       "6918     [    # get prediction\\r\\n    ypred=forward(x,w...\n",
       "6919     [Accelerator, class BERTModel(nn.Module):\\r\\n ...\n",
       "6920     [class price_dataset(Dataset):\\r\\n    def __in...\n",
       "6921     [class CNNLSTM(nn.Module):\\r\\n    def __init__...\n",
       "6922     [batch_current = Variable(torch.zeros(size, se...\n",
       "6923     [import torch\\r\\n!pip install transformers\\r\\n...\n",
       "6924     [Error:\\r\\nUserWarning: Error detected in Addm...\n",
       "6925     [tensor([0.9998, 0.9997, 0.9991, 0.9998, 0.999...\n",
       "6926     [TensorDataset(), DataLoader(), TensorDataset(...\n",
       "6927     [relative_pose = torch.multiply(A, torch.inver...\n",
       "6928     [relative_pose = torch.multiply(A, torch.inver...\n",
       "6929     [custom_loss = constrain_parameters_to_be_disc...\n",
       "6931     [trtexec --onnx=model.onnx --batch=400 --saveE...\n",
       "6932     [trtexec --onnx=model.onnx --batch=400 --saveE...\n",
       "6933     [self.fc0 = nn.Linear(120, M)\\r\\nself.fc1 = nn...\n",
       "6934     [/usr/local/lib/python3.7/dist-packages/torch/...\n",
       "6935     [apiVersion: machinelearning.seldon.io/v1\\r\\nk...\n",
       "6936     [[[0,0,0,0,0,0,0,0,1,0],\\r\\n[1,1,1,0,0,0,1,1,0...\n",
       "6937                                 [torch.nn.DropOut(p)]\n",
       "6940     [#import the nescessary libs\\r\\nimport numpy a...\n",
       "6941     [def train_dmc(loader,loss):\\r\\n\\r\\n\\r\\n \\r\\n ...\n",
       "6942     [# LPRNET model\\r\\nimport torch\\r\\nimport torc...\n",
       "6943                  [torch.nn.BatchNorm1d, num_features]\n",
       "6944     [tensor([[ 0.0141, -0.0279,  0.0623],\\r\\n     ...\n",
       "6945     [ a = torch.randn(4, 4)\\r\\n a\\r\\ntensor([[ 1.3...\n",
       "6946     [x, x.reshape(shape), x.contiguous().view(shape)]\n",
       "6948     [x.shape, torch.Size([1024, 300]), torch.Size(...\n",
       "6949     [a = torch.Tensor([0,0,0],dtype = torch.int64)...\n",
       "6950     [a = torch.Tensor([0,0,0],dtype = torch.int64)...\n",
       "6951     [ReduceLROnPlateau, learning_rate = 1e-3\\r\\nop...\n",
       "6954     [class Generator(nn.Module):\\r\\n  def __init__...\n",
       "6957     [f1(arg_tensor), f2(tensor_row_1, tensor_row_2...\n",
       "6958     [import pandas as pd\\r\\nimport datetime\\r\\nfro...\n",
       "6959     [m = nn.Conv2d(16, 16, 3, stride=1, groups=16,...\n",
       "6960     [class TuckER(torch.nn.Module):\\r\\n    def __i...\n",
       "6961     [predicted_index = torch.argmax(predictions[0,...\n",
       "6962     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6963     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "6964     [def conv_block(in_channels, out_channels, poo...\n",
       "6965     [import os\\r\\nnum_gpus = os.environ['CUDA_VISI...\n",
       "6966     [BCELoss, CrossEntropyLoss, 'weight', CE_loss ...\n",
       "6967     [BCELoss, CrossEntropyLoss, 'weight', CE_loss ...\n",
       "6968     [BCELoss, CrossEntropyLoss, 'weight', CE_loss ...\n",
       "6969     [BCELoss, CrossEntropyLoss, 'weight', CE_loss ...\n",
       "6970     [BCELoss, CrossEntropyLoss, 'weight', CE_loss ...\n",
       "6971     [#Set the random seeds for reproducibility\\r\\n...\n",
       "6972     [from torch import nn\\r\\nsigmoid = nn.Sigmoid(...\n",
       "6973     [self.embeddings_user = torch.nn.Embedding(30,...\n",
       "6974     [RuntimeError: CUDA error: invalid device ordi...\n",
       "6975     [for epoch in tqdm(range(epochs_num)):\\r\\n    ...\n",
       "6976     [#import the nescessary libs\\r\\nimport numpy a...\n",
       "6977     [gpu=False, easyocr.Reader, Failed to get conv...\n",
       "6978     [def save_to_file(model, imgs_batch):\\r\\n  img...\n",
       "6979     [class WeightedBCEWithLogitLoss(nn.Module):\\r\\...\n",
       "6980     [def proportion(text1, text2):\\r\\n  ...\\r\\n\\r\\...\n",
       "6981     [data = [[tensor([0, 0, 0]), tensor([1, 2, 3])...\n",
       "6982     [data = [[tensor([0, 0, 0]), tensor([1, 2, 3])...\n",
       "6983     [model.compile(loss=\"binary_crossentropy\", opt...\n",
       "6984     [ import pickle\\r\\n\\r\\n tensor1 = pickle.load(...\n",
       "6985     [torch.nn.init.normal_(self.layer1.weight, mea...\n",
       "6986     [torch.nn.init.normal_(self.layer1.weight, mea...\n",
       "6987     [class final_layers(nn.Module):\\r\\n    def __i...\n",
       "6988     [class DFUDataset(Dataset):\\r\\n    def __init_...\n",
       "6990     [sequence_output, all_token_mapping, initial_r...\n",
       "6991     [sequence_output, all_token_mapping, initial_r...\n",
       "6992     [sequence_output, all_token_mapping, initial_r...\n",
       "6993     [import torch\\r\\na = torch.zeros((5, 50, 5, 50...\n",
       "6994     [import torch\\r\\nimport torch.nn.functional as...\n",
       "6995     [resnet = resnet18().cuda() #a modified resnet...\n",
       "6996     [model.pt, from smart_open import open as smar...\n",
       "6997     [trained_cnnfmnist_model=net\\r\\n\\r\\nclass CNNF...\n",
       "6998     [bert_out = bert(**bert_inp)\\r\\nhidden_states ...\n",
       "6999     [if __name__ == '__main__':\\r\\n, from torch.ut...\n",
       "7000     [#Import model\\r\\npip install timm\\r\\nimport t...\n",
       "7001     [model [CycleGANModel] was created\\r\\nloading ...\n",
       "7002     [class MDN(nn.Module):\\r\\n    \"\"\"A mixture den...\n",
       "7003     [torch.empty_like(input), torch.empty(input.si...\n",
       "7004     [def train(conf):\\r\\n    batch = []\\r\\n    ste...\n",
       "7005     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "7006     [#reproduce error\\r\\nfrom transformers import ...\n",
       "7007     [def get_variation_uncertainty(prediction_scor...\n",
       "7008     [def get_variation_uncertainty(prediction_scor...\n",
       "7009     [torchvision.datasets.ImageFolder(root='/conte...\n",
       "7010     [INFO:root:Time: 05/24/21 16:24:40, Epoch: 1\\r...\n",
       "7011     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7012     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "7013     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "7014     [def bilinear_sample_noloop(image, grid):\\r\\n ...\n",
       "7015     [def feat_prototype_distance(self, feat):\\r\\n ...\n",
       "7016     [gmentation maps.\\r\\n\\r\\n# gt_seg - Ground tru...\n",
       "7017     [torch/nn/modules/module.py, torch.nn, nn.Modu...\n",
       "7018     [img = torch.rand((3,1080,1080))\\r\\nR_coeffici...\n",
       "7019     [img = torch.rand((3,1080,1080))\\r\\nR_coeffici...\n",
       "7020     [img = torch.rand((3,1080,1080))\\r\\nR_coeffici...\n",
       "7021     [0.1504615843296051\\r\\n0.10858417302370071\\r\\n...\n",
       "7022     [global_model = CNNMnist(args=args), .paramete...\n",
       "7023     [id   input (diagnoses)    elapsed_days    out...\n",
       "7024     [import torch\\r\\nimport tensorflow as tf\\r\\nfr...\n",
       "7025     [#requirements.txt\\r\\n.\\r\\n.\\r\\ntorch==1.8.1+c...\n",
       "7026     [X = [[0. 0. 0. ... 1. 1. 1.]\\r\\n [0. 0. 0. .....\n",
       "7027     [[batch_size, seq_len, n_features], axis=1, te...\n",
       "7028     [[batch_size, seq_len, n_features], axis=1, te...\n",
       "7029     [  f = [ x[r][1], ((0.5*g*m*np.sin(2*x[r][2]))...\n",
       "7030     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7031     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "7033     [clock_t start = clock();\\r\\ntorch::Tensor tra...\n",
       "7034     [pip install mmseg, (Monocular3D) root@gpu9:~/...\n",
       "7035     [pip install mmseg, (Monocular3D) root@gpu9:~/...\n",
       "7036     [import os\\r\\nfrom PIL import Image\\r\\npath='D...\n",
       "7037     [import torch, os\\r\\nimport yaml\\r\\nfrom IPyth...\n",
       "7039     [import numpy as np\\r\\nimport cv2\\r\\nimport to...\n",
       "7041     [from PIL import Image\\r\\n\\r\\nclass lakeDataSe...\n",
       "7042     [def one_hot_encoding(label):\\r\\n    for idx, ...\n",
       "7043     [def get_torch_model(model_path):\\r\\n    \"\"\"\\r...\n",
       "7044     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7045     [   INCIDENT_NUMBER           enc_rep         ...\n",
       "7046     [   INCIDENT_NUMBER           enc_rep         ...\n",
       "7049     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7050     [import torch\\r\\ntest_tensor=torch.tensor([[1,...\n",
       "7051     [training_data, {\"image\": image, \"label\": labe...\n",
       "7052     [training_data, {\"image\": image, \"label\": labe...\n",
       "7053                     [PyTorch, nn.functional, PyTorch]\n",
       "7054     [layer.get_weights(), tf.keras, gamma, beta, r...\n",
       "7055     [piq, TiffPage 1: ByteCounts tag is missing\\r\\...\n",
       "7056     [AttributeError: 'BiSeNet' object has no attri...\n",
       "7058     [retain_graph=True, backward(), #define a clas...\n",
       "7059     [def ReLU_activation_func(outputs):\\r\\n    pri...\n",
       "7060     [A40 with CUDA capability sm_86 is not compati...\n",
       "7061     [import torch \\r\\nx = torch.arange(32*512*3*2)...\n",
       "7062     [import torch \\r\\nx = torch.arange(32*512*3*2)...\n",
       "7063     [!python models/export.py\\r\\n, Namespace(batch...\n",
       "7064     [import cv2\\r\\nimport numpy as np\\r\\nimport PI...\n",
       "7065     [    self.list_1 = []\\r\\n\\r\\n    for i in rang...\n",
       "7067     [mask.putpalette([\\r\\n    0, 0, 0, # black bac...\n",
       "7069     [import torch\\r\\n\\r\\ntest_act = torch.tensor([...\n",
       "7070     [encodings = tokenizer(sentences)\\r\\n# vs\\r\\ne...\n",
       "7071     [bert, class BERTBaseUncased(nn.Module):\\r\\n  ...\n",
       "7072     [/usr/local/cuda/lib64, FAILED: bin/roi_align_...\n",
       "7073     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7074     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7075     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "7076     [inference.py, def input_fn(request_body, cont...\n",
       "7077     [if epoch % 50000 == 0:\\r\\n  #checkpoint save ...\n",
       "7078     [i = torch.LongTensor([[0, 1, 1], [2, 0, 2]])\\...\n",
       "7080     [M1 = [[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]...\n",
       "7081     [..automethod, AttributeError: '_CachedForward...\n",
       "7082     [A1 = np.zeros(10*18*40*28)\\r\\nA1[1234] = 1\\r\\...\n",
       "7083     [import pyro\\r\\nimport torch\\r\\nimport pyro.di...\n",
       "7086     [model = BertWSD.from_pretrained(model_dir)\\r\\...\n",
       "7087     [criterion = torch.nn.BCELoss()\\r\\n, Using a t...\n",
       "7088     [---&gt; 23         pt = Tensor(logpt.data.exp...\n",
       "7089     [torch._C._cuda_init()\\r\\nRuntimeError: No CUD...\n",
       "7090     [import torch\\r\\np1 = torch.tensor([1.0, 3.5])...\n",
       "7093     [        print(\"pred_Curl shape:\", np.shape(pr...\n",
       "7094     [---------------------------------------------...\n",
       "7095     [# set initial loss to infinite\\r\\nbest_valid_...\n",
       "7096     [def save_experiment_config(self):\\r\\n    with...\n",
       "7097     [    data = torch.randn(size=(1000,110)).to(de...\n",
       "7098     [def gather_feature(fmap, index):\\r\\n    # fma...\n",
       "7099     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7101     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7103     [ 1.1.0 changed this behavior in a BC-breaking...\n",
       "7104     [/tmp/ccbgkLx2.o: In function `long long* at::...\n",
       "7106     [class AugmentDataset(StereoDataset, PseudoDat...\n",
       "7107     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7108     [m × c, n × c, m × f, n × f, for i in range(B....\n",
       "7110     [criterion = nn.CrossEntropyLoss(reduction='me...\n",
       "7114     [Python builtin &lt;built-in function sum&gt; ...\n",
       "7115     [torch.autograd.grad, backward, x=torch.tensor...\n",
       "7116     [import io\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "7117     [ConvAEUnpool, class ConvAEUnpool(nn.Module): ...\n",
       "7118     [def create_model():\\r\\n  # load model from pa...\n",
       "7119     [def create_model():\\r\\n  # load model from pa...\n",
       "7120     [bert-base-multilingual-uncased, config.json, ...\n",
       "7121     [ARG PYTORCH=\"1.3\"\\r\\nARG CUDA=\"10.1\"\\r\\nARG C...\n",
       "7122     [ARG PYTORCH=\"1.3\"\\r\\nARG CUDA=\"10.1\"\\r\\nARG C...\n",
       "7123     [conda install pytorch torchvision torchaudio ...\n",
       "7124     [def load_img(filepath):\\r\\nimg = Image.open(f...\n",
       "7125                                          [torch.topk]\n",
       "7126     [torch.nn.init.sparse(tensor, sparsity=0.1), i...\n",
       "7127     [import numpy as np\\r\\nimport random\\r\\nimport...\n",
       "7128     [bert-base-mutilingual-uncased, TOKENIZER, con...\n",
       "7129     [# Load pretrained model weights\\r\\nmodel_url ...\n",
       "7130     [detectron2, BoxMode, detectron2.structures, B...\n",
       "7131     [[0.055709425,0.04365404,0.008613999,0.0022386...\n",
       "7132     [[0.055709425,0.04365404,0.008613999,0.0022386...\n",
       "7133     [tb.add_scalar(tag1, loss, it), 000 (6466.000....\n",
       "7134     [RPN,   File \"/home/f523/guazai/sdb/rsy/corner...\n",
       "7135     [from detectron2.modeling import build_model\\r...\n",
       "7136     [(H,W,6), target.min(), target.max(): 0.0, 1.0...\n",
       "7137     [__getitem__, __len__, train_loader = torch.ut...\n",
       "7139     [\\r\\nimport numpy as np\\r\\nimport torch\\r\\nimp...\n",
       "7140     [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "7141     [{\\r\\n 'eval_loss': 0.003242955543100834,\\r\\n ...\n",
       "7142     [bert-base-uncased, Some weights of the model ...\n",
       "7143     [bert-base-uncased, Some weights of the model ...\n",
       "7144     [ criterion = F.cross_entropy, Epoch [1/50]: 1...\n",
       "7145     [bert, train.py, &gt;&gt; (myenv) PS D:\\Transf...\n",
       "7147     [from torch.autograd import Variable\\r\\ntorch....\n",
       "7148     [ResNet(\\r\\n  (conv1): Conv2d(3, 64, kernel_si...\n",
       "7149     [GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrp...\n",
       "7150     [class LinearWeightedAvg(nn.Module):\\r\\n      ...\n",
       "7151               [[A,A,A,A...,A], [[A],[A],[A],...,[A]]]\n",
       "7152               [[A,A,A,A...,A], [[A],[A],[A],...,[A]]]\n",
       "7153               [[A,A,A,A...,A], [[A],[A],[A],...,[A]]]\n",
       "7154     [for n, m in self.layer3.named_modules():\\r\\n ...\n",
       "7155     [conda install pytorch=0.3.0 torchvision=0.2.0...\n",
       "7156     [import knn_cuda\\r\\n        Traceback (most re...\n",
       "7157     [image retrieval, 5 images, 75 images, 300 cla...\n",
       "7158     [image retrieval, 5 images, 75 images, 300 cla...\n",
       "7159     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "7160     [    self.criterion = nn.CrossEntropyLoss()\\r\\...\n",
       "7161     [\\r\\nclass NeuralNetwork(nn.Module):\\r\\n    de...\n",
       "7162     [model = torchvision.models.detection.fasterrc...\n",
       "7163     [data.transforms, data_transforms = {\\r\\n    '...\n",
       "7164     [data.transforms, data_transforms = {\\r\\n    '...\n",
       "7165     [data.transforms, data_transforms = {\\r\\n    '...\n",
       "7166     [data.transforms, data_transforms = {\\r\\n    '...\n",
       "7167     [data.transforms, data_transforms = {\\r\\n    '...\n",
       "7168     [import torch.nn as nn\\r\\n\\r\\n\\r\\nclass RNN(nn...\n",
       "7170     [11.1, conda install pytorch torchvision torch...\n",
       "7171     [import torch\\r\\nfrom torch.fft import rfftn, ...\n",
       "7172     [training_data_path = \"..\"\\r\\nmodel_path = \".....\n",
       "7173     [  from transformers import BertTokenizer\\r\\n\\...\n",
       "7174     [A, torch.tensor, A = \\r\\n[[1,x,y], \\r\\n [1,2,...\n",
       "7175     [l1 = layer1(input)\\r\\nl2 = layer2(l1)\\r\\nl3 =...\n",
       "7176     [torch.bool, PyTorch, gate_A, gate_B, class Ne...\n",
       "7177     [torch.bool, PyTorch, gate_A, gate_B, class Ne...\n",
       "7179     [class cows_train(Dataset):\\r\\n\\r\\n    def __i...\n",
       "7180     [train_loader = torch.utils.data.DataLoader(tr...\n",
       "7181     [python debugger, pdb.set_trace(), python -m t...\n",
       "7182     [layer normalization, AdaptiveAvgPool2d, L2 no...\n",
       "7183     [layer normalization, AdaptiveAvgPool2d, L2 no...\n",
       "7184     [layer normalization, AdaptiveAvgPool2d, L2 no...\n",
       "7185     [def __call__(self, *input, **kwargs):\\r\\n   r...\n",
       "7186     [\"remove the bias term inthe last linear layer...\n",
       "7187     [from transformers import BertTokenizer, BertF...\n",
       "7188     [from transformers import BertTokenizer, BertF...\n",
       "7189     [# set random number \\r\\nrandom.seed(0)\\r\\ntor...\n",
       "7191     [P1=[31, 22, 11, 10,  9, 9, 0, 0, 23 ....]  # ...\n",
       "7192     [P1=[31, 22, 11, 10,  9, 9, 0, 0, 23 ....]  # ...\n",
       "7193     [class CNN(torch.nn.Module):\\r\\n    @property\\...\n",
       "7194     [    \"\"\"This function prepares the datasets to...\n",
       "7195     [    \"\"\"This function prepares the datasets to...\n",
       "7196     [import torchvision\\r\\ndilated_model = torchvi...\n",
       "7197     [M, (d1, d2), V, d2, M*V, OUT, (d1, d2), M, V,...\n",
       "7198     [M, (d1, d2), V, d2, M*V, OUT, (d1, d2), M, V,...\n",
       "7199     [nn.Model, nn.Parameter, nn.Parameter, from to...\n",
       "7200     [from keras.preprocessing.text import one_hot,...\n",
       "7201     [ant, bee, 200x200, Feed Forwad NN, Conv Nets....\n",
       "7202     [nn.ModuleList, nn.Sequential, nn.Sequential, ...\n",
       "7204     [class TPS_SpatialTransformerNetwork(nn.Module...\n",
       "7205     [from transformers import BertTokenizer, BertF...\n",
       "7206     [# example tensor size 2 x 4\\r\\na = torch.Tens...\n",
       "7207     [model = models.resnet18(pretrained=True)\\r\\n\\...\n",
       "7208     [model = models.resnet18(pretrained=True)\\r\\n\\...\n",
       "7209     [class ConvNet(torch.nn.Module): \\r\\n    def _...\n",
       "7210     [.pth, model.pth, torch.load(model.pth), model...\n",
       "7211     [import torch\\r\\nimport torch.nn as nn\\r\\ninpu...\n",
       "7212     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7213     [class GCNEncoder(torch.nn.Module):\\r\\n\\r\\n   ...\n",
       "7214     [transforms.Normalize(), tf.image.per_image_st...\n",
       "7215     [    self.linear1 = Linear(d_model, dim_feedfo...\n",
       "7216     [    self.linear1 = Linear(d_model, dim_feedfo...\n",
       "7217     [def get_chunk_embeddings(encoded_dataset, bat...\n",
       "7218     [t, (3, 3, 3, 3), t[0, 1, x, y], z, x, y, t[0,...\n",
       "7219     [RunTimeError: external/org_tensorflow/tensorf...\n",
       "7220     [Current run is terminating due to exception: ...\n",
       "7222     [model_size = \"base\"\\r\\nmodel_name = f\"persian...\n",
       "7223     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7224     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7225     [A, (batch_size, width, height), A = torch.ten...\n",
       "7226     [A, (batch_size, width, height), A = torch.ten...\n",
       "7227             [N × F, N × 1, pytorch, LSTM, LSTM, LSTM]\n",
       "7228     [*2, x*2, import torch\\r\\nprint(torch.__versio...\n",
       "7229     [Flatten, DataLoader, batch_size, DataLoader, ...\n",
       "7230     [torch.nn.lstm, batch_size, month X 2-stores, ...\n",
       "7231     [class VGG16COMBO(nn.Module):\\r\\n    \\r\\n    d...\n",
       "7232     [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "7233     [f(a,b,c):\\r\\n   # a: [batchsize, n, channel]\\...\n",
       "7235     [torch.from_numpy, a = np.random.randn(100,100...\n",
       "7236     [RuntimeError: stack expects each tensor to be...\n",
       "7237     [ from torch import nn\\r\\n conv1 = nn.Conv2d(3...\n",
       "7238     [ mean_actions\\r\\ntensor([[-5.7547e-04,  1.431...\n",
       "7239     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7240     [&gt; t = torch.ones(4, 3)\\r\\n&gt; t\\r\\ntensor...\n",
       "7241     [torch.save({\\r\\n            'epoch': epoch + ...\n",
       "7242     [model.eval(), model.train(), BatchNorm, Dropo...\n",
       "7244     [torch.norm, torch.norm, x, import torch\\r\\nx ...\n",
       "7245     [# importing libraries\\r\\nimport pandas as pd\\...\n",
       "7246     [# importing libraries\\r\\nimport pandas as pd\\...\n",
       "7247     [point_net.to(device)\\r\\nfor epoch in range(10...\n",
       "7248     [from torch_sparse import coalesce, SparseTens...\n",
       "7250     [import torchvision\\r\\ntorchvision.models.resn...\n",
       "7251     [import torch\\r\\n\\r\\ntensor = torch.randn(50, ...\n",
       "7252     [(256, 256, 3), (256, 256), [32, 3, 256, 256],...\n",
       "7253     [(256, 256, 3), (256, 256), [32, 3, 256, 256],...\n",
       "7254     [import torch\\r\\nimport time\\r\\nimport torch.n...\n",
       "7255     [import torch\\r\\nimport time\\r\\nimport torch.n...\n",
       "7256     [datamodule, PyTorch Lightning, linear_model, ...\n",
       "7257     [class UNet(nn.Module):\\r\\n    def __init__(se...\n",
       "7258     [a = torch.nn.Parameter(torch.rand(7, requires...\n",
       "7259     [import os\\r\\nimport shutil\\r\\nimport random\\r...\n",
       "7260     [class Classifier(nn.Module):                 ...\n",
       "7261     [PyTorch Lightning, DataModuleClass, prepare_d...\n",
       "7262     [__getitem__, class CustomDataset:\\r\\n\\r\\n    ...\n",
       "7263     [__getitem__, class CustomDataset:\\r\\n\\r\\n    ...\n",
       "7264     [__getitem__, class CustomDataset:\\r\\n\\r\\n    ...\n",
       "7265     [mean, std, cityscapes, def compute_mean_std(d...\n",
       "7266     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "7269                     [F, F, F, F, tensorflow, pytorch]\n",
       "7270     [NumPy, prepare_data(), DataModules, setup(), ...\n",
       "7271     [NumPy, prepare_data(), DataModules, setup(), ...\n",
       "7272     [class MlpNN(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "7273     [X_train_tensor = torch.from_numpy(np.asarray(...\n",
       "7274     [def train_classifier():\\r\\n    start=0\\r\\n   ...\n",
       "7275     [setup.py, setup.py, gcc -pthread -shared -B /...\n",
       "7276     [input_t0, s_t0, s_t1, input_t1, s_t1, s_t0, s...\n",
       "7277     [model = ct.convert(\\r\\n    traced_model,\\r\\n ...\n",
       "7278     [def get_action(self, state):\\r\\n        state...\n",
       "7280     [from stable_baselines.common.policies import ...\n",
       "7281     [class iResNetBlock(nn.Module):\\r\\n    def __i...\n",
       "7282     [n, k, class PINN(torch.nn.Module):\\r\\n    def...\n",
       "7284     [!pip3 install mkl\\r\\n\\r\\n!curl https://raw.gi...\n",
       "7286     [class ae(torch.nn.Module):\\r\\n   def __init__...\n",
       "7287     [class Foo(nn.Module):\\r\\n    \"\"\"Toy class tha...\n",
       "7288     [SummaryWriter(self, log_dir=None, comment='',...\n",
       "7289     [def trySolveEquation(V, L):\\r\\n    #The equat...\n",
       "7291     [from __future__ import print_function\\r\\nimpo...\n",
       "7292     [test_transform = transforms.Compose([\\r\\n  la...\n",
       "7293     [&gt; DATASET/\\r\\n&gt; ---TRAIN/\\r\\n&gt; -----...\n",
       "7294     [Network, class whatever:\\r\\n    def __init__(...\n",
       "7295     [food, sports, science, I dont like to each mu...\n",
       "7296     [class NOWANet(nn.Module):\\r\\n    def __init__...\n",
       "7298     [1. git clone https://github.com/pytorch/pytor...\n",
       "7299     [[batch_size, sequence_length, number_of_token...\n",
       "7300     [[batch_size, sequence_length, number_of_token...\n",
       "7301     [[batch_size, sequence_length, number_of_token...\n",
       "7302     [MODEL_NAME='test_iris'\\r\\nMODEL_VERSION='v1'\\...\n",
       "7304     [.to(device=\"cuda:0\"), .cuda(), \\r\\n# %% [mark...\n",
       "7305     [\\r\\ndef save_video(filename):\\r\\n\\r\\n    fram...\n",
       "7306     [[3, 4, 5, 6, 7, 20, 31, 32, 33, 34]\\r\\n, [\\r\\...\n",
       "7307     [net_output\\r\\n# tensor([[[0.7718, 0.3856, 0.2...\n",
       "7308     [class SentencePairSimilarityBert(nn.Module):\\...\n",
       "7310     [box_a = torch.randn(1,4)\\r\\nbox_b = torch.ran...\n",
       "7311     [class ConvNet(nn.Module):\\r\\n  def __init__(s...\n",
       "7313     ['''VGG for CIFAR10. FC layers are removed.\\r\\...\n",
       "7314     [inputs = Input(shape = (64, 64, 1)). # Channe...\n",
       "7315     [        loss_fn = torch.nn.MSELoss()\\r\\n     ...\n",
       "7316     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7317     [hidden_sizes = [6336, 1000] \\r\\nclass Net(tor...\n",
       "7318     [def biencoder_training():\\r\\n    params = BiE...\n",
       "7319     [from __future__ import print_function, divisi...\n",
       "7320     [model = keras.Sequential()\\r\\nmodel.add(layer...\n",
       "7321     [ vec\\r\\ntensor([[0.2677, 0.1158, 0.5954, 0.92...\n",
       "7323     [def forward(self, input, hidden):\\r\\n\\r\\n    ...\n",
       "7324     [tokenizer.padding_side = \"left\"\\r\\ntokenizer....\n",
       "7325     [import imageio\\r\\nimport numpy as np\\r\\nimage...\n",
       "7327     [os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\\...\n",
       "7328     [import time\\r\\nfrom torchvision.models import...\n",
       "7329     [class FC(nn.Module):\\r\\n  def __init__(self, ...\n",
       "7330     [    self.lstm = nn.LSTM(\\r\\n        input_siz...\n",
       "7331     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "7332     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7333     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "7334     [torch.nn.Sequential, Sequential, class net2(n...\n",
       "7335     [torch.nn.Sequential, Sequential, class net2(n...\n",
       "7336     [img = cv2.imread(path)\\r\\narray_1 = cv2.cvtCo...\n",
       "7337     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "7338     [conda create -n tst2 python=3.7\\r\\nconda acti...\n",
       "7339     [out of memory,     src, trg = src.cuda().T, t...\n",
       "7341     [iter = 3500\\r\\ntop_labels = 5\\r\\nnum_super_pi...\n",
       "7343     [model_emo = torch_load_model('best_model.pt',...\n",
       "7344     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7346     [import os; os.environ[\"KMP_DUPLICATE_LIB_OK\"]...\n",
       "7347     [import os; os.environ[\"KMP_DUPLICATE_LIB_OK\"]...\n",
       "7348     [&lt;MapDataset shapes: {input_ids: (128,), in...\n",
       "7349     [json file\\r\\n├── \"data\"\\r\\n│   └── [i]\\r\\n│  ...\n",
       "7350     [    from transformers import AutoTokenizer, A...\n",
       "7351     [commands, allennlp train -f --include-package...\n",
       "7352     [commands, allennlp train -f --include-package...\n",
       "7353     [OH,   def OH(x,end=10,l=12):\\r\\n    x = T.Lon...\n",
       "7354     [class RONANet(nn.Module):\\r\\n  def __init__(s...\n",
       "7355     [class RONANet(nn.Module):\\r\\n  def __init__(s...\n",
       "7356     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7358     [            num_correct = 0.0\\r\\n            ...\n",
       "7360     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7361     [object_ids = [tensor([2., 3.]), tensor([2., 3...\n",
       "7362     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7363     [torch.Size([12, 10]), torch.Size([120]), torc...\n",
       "7364     [torch.Size([12, 10]), torch.Size([120]), torc...\n",
       "7365     [Pip install alennlp==2.4.0\\r\\npip install all...\n",
       "7366     [num_labels = 5\\r\\nmodel_name = \"Zaid/wav2vec2...\n",
       "7367     [lr = 0.1  # 0.1\\r\\ncriterion = nn.CrossEntrop...\n",
       "7369     [#autograd\\r\\nimport torch\\r\\nfrom torch.autog...\n",
       "7370     [state dict, state dict, state dict, EOFError ...\n",
       "7371     [class Policy(nn.Module):\\r\\n    def __init__(...\n",
       "7372     [from einops.layers.torch import Rearrange\\r\\n...\n",
       "7373     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nobs...\n",
       "7374     [+--------------------------------------------...\n",
       "7375     [+--------------------------------------------...\n",
       "7376     [+--------------------------------------------...\n",
       "7377     [[56]  model = hopenet.Hopenet(torchvision.mod...\n",
       "7378     [a = f(x,y)\\r\\nfind gradient of a with respect...\n",
       "7379     [args = TrainingArguments(\\r\\n    'cuad-robert...\n",
       "7380     [def log_softmax(x):\\r\\n    return x - x.exp()...\n",
       "7381     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "7382     [def my_func(f1, f2):\\r\\n``\\r\\nf1: torch.Float...\n",
       "7383     [allennlp train -f --include-package custom-ex...\n",
       "7384     [first_layer = torch.nn.Conv2d(in_channels=3, ...\n",
       "7385     [model = torch.hub.load('pytorch/vision:v0.9.0...\n",
       "7387     [A = np.arange(1024).reshape(8,1,128)\\r\\nB = n...\n",
       "7388     [DataParallel(\\r\\n  (module): MobileFaceNet(\\r...\n",
       "7389     [import torch\\r\\nimport torchvision\\r\\n\\r\\ndev...\n",
       "7390     [def validate(loader, model, criterion):      ...\n",
       "7391     [1 * prod(input)\\r\\n, 1 x N x C_in x H_in x W_...\n",
       "7392     [Focal loss + LS (My implementation): Train lo...\n",
       "7393     [Man   is going to write a very long novel tha...\n",
       "7394     [Man   is going to write a very long novel tha...\n",
       "7395     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "7396     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "7397     [class TestingClassifier(nn.Module):\\r\\n  def ...\n",
       "7398     [x, zzz, x_t, import torch\\r\\n\\r\\nx = torch.te...\n",
       "7399     [#imports\\r\\nimport torch\\r\\nimport torch.nn a...\n",
       "7400     [torch.long, int64, In [62]: a = torch.tensor(...\n",
       "7401     [(3072,1000), row_indices = np.random.choice(n...\n",
       "7402     [(3072,1000), row_indices = np.random.choice(n...\n",
       "7403     [  File \".\\api\\deepmatcher\\data\\dataset.py\", l...\n",
       "7404     [detect.py, python detect.py --source data/ima...\n",
       "7405     [detect.py, python detect.py --source data/ima...\n",
       "7406     [from torch.utils.data import Dataset\\r\\n\\r\\nc...\n",
       "7407     [parser = argparse.ArgumentParser(description=...\n",
       "7408     [!pip install -q -U segmentation-models-pytorc...\n",
       "7409     [import torch\\r\\nimport numpy\\r\\n\\r\\na = torch...\n",
       "7412     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "7413     [torch, def batchify(data, bsz):\\r\\n    nbatch...\n",
       "7414     [class trainer:\\r\\n    def __init__():\\r\\n    ...\n",
       "7415     [tf.browser.toPixels() tensorflowJS, matplotli...\n",
       "7416     [torch.Tensor, (2, 2, 2), [0, 1], K, 1/k, (2, ...\n",
       "7417     [https://pytorch.org/tutorials/advanced/cpp_fr...\n",
       "7419     [model = nn.Sequential(nn.Linear(2,2),nn.ReLU(...\n",
       "7420     [resnet_cnn = models.resnet18(pretrained = Tru...\n",
       "7421     [def predict_image(path):\\r\\n    print(\"Predic...\n",
       "7422     [train_data = signalDataset(train_dataset) \\r\\...\n",
       "7423     [modelMNIST.parameters()\\r\\nmodelSVHN.paramete...\n",
       "7424     [modelMNIST.parameters()\\r\\nmodelSVHN.paramete...\n",
       "7425     [rnn_cell_video_fw = tf.contrib.rnn.LSTMCell(\\...\n",
       "7426                           [(125, 3, 128, 128), [0,1]]\n",
       "7427     [def __getitem__(self,index):\\r\\n  desired_fil...\n",
       "7428     [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "7429     [```\\r\\nsize = 480\\r\\nhalf= (256, 256) \\r\\nspl...\n",
       "7430     [VERSION = \"nightly\"  #@param [\"1.5\" , \"202003...\n",
       "7431     [class MyModel(torch.nn.Module):\\r\\n   def __i...\n",
       "7433     ['example'[999:9999], 'example'[9], 'example'[...\n",
       "7434     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\n\\...\n",
       "7435     [class Mark_Predict(nn.Module):\\r\\n    def __i...\n",
       "7436     [import torch\\r\\nfrom models.bert_attention_mo...\n",
       "7437     [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "7438     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7439     [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "7440     [x = torch.Tensor([[1, 2], [3, 4]])\\r\\n, def f...\n",
       "7442     [detect.py, import torch\\r\\n    \\r\\nmodel = to...\n",
       "7443     [class ResidualBlock(nn.Module):\\r\\n    '''\\r\\...\n",
       "7444     [import torchvision.datasets as dsets\\r\\nimpor...\n",
       "7445     [def train_model(model, criterion, optimizer, ...\n",
       "7446     [def train_model(model, criterion, optimizer, ...\n",
       "7447     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "7448     [RuntimeError: cuda runtime error (59) : devic...\n",
       "7450     [B = A[:, :, 0:3, :, :]\\r\\n, B = subset(A, dim...\n",
       "7451     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "7452     [import types\\r\\n\\r\\nclass MyClass:\\r\\n    def...\n",
       "7453     [dls=CollabDataLoaders.from_df(ratings,item_na...\n",
       "7454     [r,i,j,k, r, r, tensor_1, tensor_2, r,i,j,k, t...\n",
       "7455     [r,i,j,k, r, r, tensor_1, tensor_2, r,i,j,k, t...\n",
       "7456     [beam_scorer = BeamSearchScorer(\\r\\n          ...\n",
       "7457     [def train_model(model, criterion, optimizer, ...\n",
       "7458     [z, tensor([[[[0.0908, 0.1286, 0.6942, 0.5161]...\n",
       "7459     [        self.encoder = nn.Sequential(\\r\\n    ...\n",
       "7460     [RuntimeError: Given groups=1, weight of size ...\n",
       "7461     [optimizer.param_groups, LambdaLR, net = Model...\n",
       "7462                                         [numpy.zeros]\n",
       "7463     [class GetHogData(Dataset):\\r\\n\\r\\n  def __ini...\n",
       "7464     [writer = SummaryWriter(comment=f\"_{base_model...\n",
       "7466     [O_1 = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x1...\n",
       "7467     [class VimeoDataset(Dataset):\\r\\ndef __init__(...\n",
       "7469     [myTensor.contiguous().flatten()\\r\\nmyTensor.v...\n",
       "7470     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7471     [from PIL import Image\\r\\nimport s3fs\\r\\n\\r\\nf...\n",
       "7472     [regressor.predict(), (1006,19), predictions =...\n",
       "7473     [mlflow.pytorch.autolog()\\r\\ntrainer = pl.Trai...\n",
       "7476     [RuntimeError: Couldn't open shared file mappi...\n",
       "7477     [   INCIDENT_NUMBER                      \\r\\n0...\n",
       "7478     [image_total, image_crop_[idx], image_total, [...\n",
       "7479     [ loop += 1\\r\\n        if loop % 50 == 0:\\r\\n ...\n",
       "7480     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7482     [torch.sigmoid, def sigmoid(x):\\r\\n    return ...\n",
       "7483     [torch.sigmoid, def sigmoid(x):\\r\\n    return ...\n",
       "7484     [wandb, for epoch in range(epochs):\\r\\n   outp...\n",
       "7485     [image.shape = torch.Size([128, 512])\\r\\ntext....\n",
       "7486     [image.shape = torch.Size([128, 512])\\r\\ntext....\n",
       "7487     [    input = Input(shape=(216, 1025, 1))\\r\\n  ...\n",
       "7489     [def train(model, local_rank):\\r\\n    model_pa...\n",
       "7490     [FROM nvidia/cuda:10.1-devel\\r\\n        \\r\\n# ...\n",
       "7491     [a = torch.tensor([[1,0]\\r\\n                  ...\n",
       "7492     [a = torch.tensor([[1,0]\\r\\n                  ...\n",
       "7493     [DataLoader, num_workers &gt; 1, worker_init_f...\n",
       "7494     [DataLoader, num_workers &gt; 1, worker_init_f...\n",
       "7495     [dic = [] \\r\\nfor step, batch in tqdm(enumerat...\n",
       "7496     [class DataframeDataset(torch.utils.data.Datas...\n",
       "7497     [reset_weights(self), torch.nn.init.uniform_(s...\n",
       "7498     [[1, 2, 3, 4], [[4, 3, 1, 2],\\r\\n [1, 4, 3, 2]...\n",
       "7499     [        def get_char_context(valid_embeds, wo...\n",
       "7500     [DQN, FrozenLake-v0, Pytorch, class LinearDeep...\n",
       "7501     [def Convolve(a, b):\\r\\n  conv=torch.zeros(a.s...\n",
       "7502     [from torch import utils, nn, optim, no_grad\\r...\n",
       "7503     [r = torch.tensor(1.0, requires_grad=True)\\r\\n...\n",
       "7505     [LightningModule, class MyModel(LightningModul...\n",
       "7506     [    def training_epoch_end(self, outs):\\r\\n  ...\n",
       "7507     [self.a, self.b, self.c, self.b, tanh, self.b,...\n",
       "7508     [DataLoader, num_workers &gt; 1, import numpy ...\n",
       "7509     [DataLoader, num_workers &gt; 1, import numpy ...\n",
       "7510     [(batch_size, n_time_steps, n_features), class...\n",
       "7511     [cos = nn.CosineSimilarity(dim=1)\\r\\n\\r\\nd = t...\n",
       "7512     [FFNN = feedforwardnet(20);\\r\\nFFNN_trained = ...\n",
       "7513     [output\\r\\ntensor([[[ 21.1355,  -7.5047,   2.8...\n",
       "7514     [%%capture\\r\\nresnet = models.resnet50(pretrai...\n",
       "7515     [class Net(nn.Module):\\r\\n  def __init__(self,...\n",
       "7516     [----&gt; 2 model, history = run_fold(model, c...\n",
       "7517     [#x = next batch\\r\\n\\r\\nk = torch.randint(0, 4...\n",
       "7519     [tensor([[[1.9392, -1.9266,  0.9664],\\r\\n     ...\n",
       "7520     [from google.colab import drive\\r\\ndrive.mount...\n",
       "7521     [EPOCHS = 5\\r\\nactivation_function = nn.LeakyR...\n",
       "7522     [import torch as t\\r\\nimport torch.nn as nn\\r\\...\n",
       "7523        [o = tf.reshape(o, shape=[30, 50, 32, 1])\\r\\n]\n",
       "7524     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7525     [Memory 7.8 GiB\\r\\nProcessor Intel® Core™ i5-6...\n",
       "7526     [epochs = 1\\r\\nfor epcoh in range(epochs):\\r\\n...\n",
       "7527     [image_datasets = {x: datasets.ImageFolder(os....\n",
       "7528     [sentece,label\\r\\nintent example 1,new_label\\r...\n",
       "7529     [x = torch.tensor([1,2,3,4,5])\\r\\nidx = torch....\n",
       "7531     [from fastai.vision.all import *\\r\\nfrom fasta...\n",
       "7532     [Variable(), def predict_image(image):\\r\\n    ...\n",
       "7535     [torch.cuda.current_device(), Python 3.6.6 |An...\n",
       "7536     [class Net(nn.Module): \\r\\n    def __init__(se...\n",
       "7538     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "7539     [---------------------------------------------...\n",
       "7540     [def ogp(p: Tensor, cp: Tensor, q: Tensor, cq:...\n",
       "7541     [inputDim = 1  \\r\\n, inputDim = 2  \\r\\n, Runti...\n",
       "7542     [def _register_embedding_list_hook(model, embe...\n",
       "7543     [import cv2\\r\\nimport matplotlib.pyplot as plt...\n",
       "7545                                 [D, D[i,j]=d(i-j), d]\n",
       "7546     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7548     [from typing import Callable, List, Optional, ...\n",
       "7549     [f(), t, f(x1) = y1, f(x2) = y2, loss = mse(y1...\n",
       "7550     [def build_model(data_dim, n_channels, n_cl):\\...\n",
       "7551        [nn.Module, __init__, nn.Sequential, __init__]\n",
       "7552     [for x in range(0, 3):\\r\\n    # Call function ...\n",
       "7553     [for x in range(0, 3):\\r\\n    # Call function ...\n",
       "7554     [for x in range(0, 3):\\r\\n    # Call function ...\n",
       "7555     [for x in range(0, 3):\\r\\n    # Call function ...\n",
       "7556     [for x in range(0, 3):\\r\\n    # Call function ...\n",
       "7557     [ import torch\\r\\n torch.cuda.is_available()\\r...\n",
       "7558     [df = pd.read_csv('file_name.csv')\\r\\n,       ...\n",
       "7559     [df = pd.read_csv('file_name.csv')\\r\\n,       ...\n",
       "7561     [tensor([[[1, 2],\\r\\n         [3, 4]],\\r\\n    ...\n",
       "7562     [torchvision.utils.save_image(genarated_image,...\n",
       "7563     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7564     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7565     [from PIL import Image\\r\\nimport matplotlib.py...\n",
       "7566     [:/data/data/com.example.asl/files/flutter_ass...\n",
       "7567     [(frank) mona@goku:~/research/code/frankmocap$...\n",
       "7568     [(frank) mona@goku:~/research/code/frankmocap$...\n",
       "7569     [(frank) mona@goku:~/research/code/frankmocap$...\n",
       "7570     [x3, x = torch.tensor([0, 0, 0, 0, 1, 0, 0, 0,...\n",
       "7571     [def loss_loglik(y_mean, y_logvar, x):\\r\\n    ...\n",
       "7572     [import pandas\\r\\nimport torch\\r\\nimport matpl...\n",
       "7573     [import numpy as np\\r\\n\\r\\narr = np.linspace(0...\n",
       "7574     [pytorch helloworld, pod install, Process:    ...\n",
       "7575     [pytorch helloworld, pod install, Process:    ...\n",
       "7576     [output_size = torch.nn.Conv2d(3, 5, 5,stride=...\n",
       "7577     [class MyData(Dataset):\\r\\n    def _init_(self...\n",
       "7578     [ОТДЕЛЕНИЕ СТД РФ (ВТО) - СТД РЕСПУБЛИКИ АДЫГЕ...\n",
       "7579     [class CRNN(nn.Module):\\r\\ndef __init__(self, ...\n",
       "7580     [patch_width = 3\\r\\npatches = image.permute(0,...\n",
       "7581     [patch_width = 3\\r\\npatches = image.permute(0,...\n",
       "7582     [.astype(np.double), Tensor, .double(), import...\n",
       "7583     [.astype(np.double), Tensor, .double(), import...\n",
       "7584     [!mv -v ./datasets/dataset.json ./datasets/aud...\n",
       "7585     [    def __init__(self):\\r\\n    super(enhance_...\n",
       "7586     [Epoch [1/30]:   1%|▍                         ...\n",
       "7587     [TransformerWordEmbeddings('emilyalsentzer/Bio...\n",
       "7588     [def get_model():\\r\\n\\r\\n    model = keras.mod...\n",
       "7589     [              x_i (if x_i is one of the top k...\n",
       "7591     [#\\r\\n# Name                    Version       ...\n",
       "7592     [Conv2dTranspose(1024, 512, kernel_size=3, str...\n",
       "7593     [!python TransCoder/translate.py --src_lang ja...\n",
       "7594     [Conv1d, RuntimeError                         ...\n",
       "7595     [self.main = nn.Sequential(\\r\\n           \\r\\n...\n",
       "7597     [def get_nnet_model(module_list=nn.ModuleList(...\n",
       "7598     [def precision(outputs, labels):\\r\\nop = outpu...\n",
       "7599     [{\\r\\n    \"imgX\": [{\\r\\n        \"key\": \"x\",\\r\\...\n",
       "7600     [import inspect\\r\\nimport torch\\r\\n\\r\\ninspect...\n",
       "7601     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "7603     [def save_checkpoint(state, file=checkpoint_fi...\n",
       "7604     [output_1, output_2 = model(x)\\r\\nloss = cross...\n",
       "7605     [@app.route('/get_keywords')\\r\\ndef get_keywor...\n",
       "7606     [    omniglot_dataset = torchvision.datasets.O...\n",
       "7608     [model = nn.Sequential(\\r\\n    bnn.BayesLinear...\n",
       "7609     [@Throws(IOException::class, ModelException::c...\n",
       "7610     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7611     [input_tensor.shape = tensor([1, 256, 225332])...\n",
       "7612     [AttributeError: module 'torch_geometric.trans...\n",
       "7614     [self.bridge = Bridge(512, 512)\\r\\n\\r\\nup_bloc...\n",
       "7615     [https://github.com/gjy3035/NWPU-Crowd-Sample-...\n",
       "7616     [requires_grad=False, requires_grad, def fix_t...\n",
       "7619     [convtraining.zero_grad(), loss.sum().backward...\n",
       "7620     [convtraining.zero_grad(), loss.sum().backward...\n",
       "7621     [df, objects, ValueError: cannot set using a m...\n",
       "7622     [df, objects, ValueError: cannot set using a m...\n",
       "7623     [    if len(i) &lt; 1: continue;\\r\\n    print(...\n",
       "7624     [e1, v1 = torch.eig(A)\\r\\ne2, v2 = torch.eig(B...\n",
       "7625     [class VimeoDataset(Dataset):\\r\\ndef __init__(...\n",
       "7626     [[18, 512, 512], [512, 4, 4], class HeatmapEnc...\n",
       "7627     [self.face_decoder_blocks = nn.ModuleList([\\r\\...\n",
       "7628     [    def learning_rate_adjust(self, args):\\r\\n...\n",
       "7630     [y = tensor([[10.3, -1, -1, 4.5, 6.7, -1]])\\r\\...\n",
       "7631     [LambdaLR, import torch\\r\\nimport torch.nn as ...\n",
       "7632     [class TrainingDataset(data.Dataset):\\r\\n  def...\n",
       "7633     [mean = [max, min], std = [max, min],     def ...\n",
       "7635     [array([[1,2], [3,4], [5,6]],\\r\\n[[7,8], [9,0]...\n",
       "7636     [y.shape, torch.Size([64]), (64,), ##### IMPOR...\n",
       "7637     [BaseFeaturesExtractor, policy_kwarg.features_...\n",
       "7638     [cfg = get_cfg()\\r\\n\\r\\ncfg.merge_from_file(mo...\n",
       "7639     [Counter({'O': 16348, 'B-PER': 980, 'B-ORG': 4...\n",
       "7640     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "7641     [model = models.resnet50(pretrained=True)\\r\\n\\...\n",
       "7642     [Dataset.py, class MyDataset(Dataset):\\r\\n    ...\n",
       "7643     [writer_train = SummaryWriter('runs/training')...\n",
       "7644     [torch v1.8.0, v1.8.1, v1.7.1, v1.8.0, install...\n",
       "7645     [ train_set = tv.datasets.MNIST(root = \"./data...\n",
       "7646     [    checkpoint_callback = ModelCheckpoint(\\r\\...\n",
       "7647     [    checkpoint_callback = ModelCheckpoint(\\r\\...\n",
       "7648     [1 2 3\\r\\n4 5 6\\r\\n7 8 9\\r\\n, 1 0 3\\r\\n0 5 0\\r...\n",
       "7649     [1 2 3\\r\\n4 5 6\\r\\n7 8 9\\r\\n, 1 0 3\\r\\n0 5 0\\r...\n",
       "7650     [1 2 3\\r\\n4 5 6\\r\\n7 8 9\\r\\n, 1 0 3\\r\\n0 5 0\\r...\n",
       "7651     [1 2 3\\r\\n4 5 6\\r\\n7 8 9\\r\\n, 1 0 3\\r\\n0 5 0\\r...\n",
       "7652     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7653     [|dataset:      |   train   |     test   |\\r\\n...\n",
       "7654     [|dataset:      |   train   |     test   |\\r\\n...\n",
       "7655     [f(), def f(x,y):\\r\\n    return np.cos(x)+y\\r\\...\n",
       "7656     [layer = torch.nn.Conv2d(in_channels=1, out_ch...\n",
       "7657     [FashionClassify, from FashionClassify import ...\n",
       "7659     [alexnet = models.alexnet(pretrained=True)\\r\\n...\n",
       "7660     [torch.nn, requires_grad, False, True, From to...\n",
       "7661     [class LinearRegression(nn.Module):\\r\\ndef __i...\n",
       "7662     [nn.Linear(in_features, out_features), (N_batc...\n",
       "7663     [predicted, 4 x 4411, labels,     def __init__...\n",
       "7664     [import numpy as np\\r\\nfrom torch import nn\\r\\...\n",
       "7665     [import numpy as np\\r\\nfrom torch import nn\\r\\...\n",
       "7666     [RuntimeError: Found dtype Double but expected...\n",
       "7667     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "7668     [/output, .savefig(), import torch\\r\\nimport m...\n",
       "7669     [CrossEntropyLoss, log_probs, (150, 3), label_...\n",
       "7670     [\\r\\n\\r\\nimport io\\r\\nimport os\\r\\nimport logg...\n",
       "7671     [forward,  def forward(self, inputs): \\r\\n    ...\n",
       "7672     [I am trying to check the GPU device name but ...\n",
       "7673     [x = tensor([ 0.3018, -0.0079,  1.4995, -1.442...\n",
       "7674     [(my_env) crigano@crigano-desktop:~$ python3.8...\n",
       "7675     [train_loader = DataLoader(train_set, batch_si...\n",
       "7676     [| NVIDIA-SMI 460.67       Driver Version: 460...\n",
       "7677     [RuntimeError: One of the differentiated Tenso...\n",
       "7678     [tensor([[[-1.8588,  0.3776],\\r\\n         [ 0....\n",
       "7679     [torch.conv1d, vitis-ai 1.3, nn.conv2d, nn.con...\n",
       "7681     [import torch\\r\\nx = torch.tensor([0, 1, 2, 3,...\n",
       "7682     [---&gt; backend='nccl'\\r\\n/home/miranda9/mini...\n",
       "7683     [---&gt; backend='nccl'\\r\\n/home/miranda9/mini...\n",
       "7684     [---&gt; backend='nccl'\\r\\n/home/miranda9/mini...\n",
       "7685     [---&gt; backend='nccl'\\r\\n/home/miranda9/mini...\n",
       "7686     [---&gt; backend='nccl'\\r\\n/home/miranda9/mini...\n",
       "7687     [nn.functional, class Weight_classifier(nn.Mod...\n",
       "7688     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "7689     [torch.nn.utils.prune, state_dict, state_dict,...\n",
       "7690     [import torch\\r\\na = torch.ones(4)\\r\\nb = torc...\n",
       "7691     [import torch\\r\\na = torch.ones(4)\\r\\nb = torc...\n",
       "7692     [\\r\\nimport torch\\r\\nimport torch.nn as nn\\r\\n...\n",
       "7693     [0.1m x 0.1m x 0.2m(height), 1408 x 1024, 176 ...\n",
       "7694     [Target: (N, C)(N,C) , label targets padded by...\n",
       "7695     [image-folders/\\r\\n   ├── class_0/\\r\\n   |   ├...\n",
       "7697     [ValueError: Target size (torch.Size([64])) mu...\n",
       "7698     [  **~\\anaconda3\\lib\\site-packages\\torch\\cuda\\...\n",
       "7699     [ERROR: Could not find a version that satisfie...\n",
       "7700     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7701     [#action_mean_, action_std_ = action_norm\\r\\n#...\n",
       "7702     [index_put_, RuntimeError: the derivative for ...\n",
       "7703     [unlabeled_set = DatasetFolder(\"food-11/traini...\n",
       "7704     [import torch\\r\\nimport matplotlib.pyplot as p...\n",
       "7705     [train_df = chin_mnist_df.groupby('value').app...\n",
       "7707     [Tue Apr  6 20:03:13 2021       \\r\\n+---------...\n",
       "7708     [torch, 1.8.1+cu102, transformers, 4.4.2, impo...\n",
       "7709     [x, x_lowerthanzero = x.lt(0)\\r\\n, x_lowerthan...\n",
       "7711     [train_loader = torchtext.legacy.data.BucketIt...\n",
       "7712     [import torch\\r\\n\\r\\nclass GRU_model(torch.nn....\n",
       "7713     [import torch\\r\\n\\r\\nclass GRU_model(torch.nn....\n",
       "7715     [transform, torchvision, trans = transforms.Co...\n",
       "7716     [torch::Tensor x = torch::linspace(-1, 1, 100)...\n",
       "7717     [ConvNN_model = models.Sequential()\\r\\nConvNN_...\n",
       "7718     [torch.save(model.state_dict(), \"model1_stated...\n",
       "7720     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7721     [def __init__(self) :\\r\\n    super(Net, self)....\n",
       "7722     [class BertBinaryClassifier(nn.Module):\\r\\n   ...\n",
       "7723     [class CLIP(nn.module):\\r\\n   ...\\r\\n   def en...\n",
       "7724     [a = torch.randn(1000000,10)\\r\\na = a.to(devic...\n",
       "7725     [import torchtext\\r\\n\\r\\nENGLISH = torchtext.d...\n",
       "7726     [class MyLightningModel(pl.LightningModule):\\r...\n",
       "7727     [tensors / ndarrays, a_intents, (b, n_i), ij, ...\n",
       "7728     [torchvision, MNIST, transform,     if self.tr...\n",
       "7729     [Name    Self CPU %      Self CPU   CPU total ...\n",
       "7730     [CustomMNISTDataset, import torchvision.datase...\n",
       "7731     [OUTPUT_DIM = 15, 'hi my name is' =&gt; [1,43,...\n",
       "7732     [import tqdm.notebook as tq\\r\\nimport sys\\r\\n\\...\n",
       "7735     [for epoch in range(1, config.general['epochs'...\n",
       "7736     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7737     [import torch\\r\\n\\r\\nx = torch.rand(3, require...\n",
       "7739     [a = torch.Tensor([[0, 1, 1],\\r\\n             ...\n",
       "7740     [assert filled_target[:, -forecast_length:, :]...\n",
       "7741     [  File \"c:/Users/supre/Documents/Python Progr...\n",
       "7742     [a = torch.Tensor([[1, 2, 3, 4],\\r\\n          ...\n",
       "7743     [RuntimeError: the feature number of src and t...\n",
       "7744     [import torch\\r\\n\\r\\na = torch.tensor([3,2,3,4...\n",
       "7745     [a = torch.Tensor([1, 0, 0, 0])\\r\\nb = torch.T...\n",
       "7746     [class MLP(nn.Module):\\r\\n  #def __init__(self...\n",
       "7748     [class CPC(nn.Module):\\r\\n    def __init__(sel...\n",
       "7749     [.pth, t = time.time(), #!/usr/bin/env python\\...\n",
       "7750     [class Policy(nn.Module):\\r\\n    def __init__(...\n",
       "7751     [class Policy(nn.Module):\\r\\n    def __init__(...\n",
       "7752     [BCEWithLogitsLoss(), BCEWithLogitsLoss(), red...\n",
       "7754     [inp = tensor([[[ 0.0000e+00,  5.7100e+02, -6....\n",
       "7755     [inp = tensor([[[ 0.0000e+00,  5.7100e+02, -6....\n",
       "7756     [Net=FCN.Net(CatDic.CatNum) \\r\\nNet.load_state...\n",
       "7757     [TypeError: only size-1 arrays can be converte...\n",
       "7758     [2, training loss, nan, data, (15958, 4), Spli...\n",
       "7759     [arr = np.array([[[0,1,2],\\r\\n                ...\n",
       "7760     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7761     [def __init__(self, config, n_classes, datamod...\n",
       "7762     [blah[:, :, C]\\r\\n\\r\\nfor i in range(M):\\r\\n  ...\n",
       "7763     [blah[:, :, C]\\r\\n\\r\\nfor i in range(M):\\r\\n  ...\n",
       "7765     [for data in tqdm(train_loader):\\r\\n    traine...\n",
       "7766     [\"gloo\", \"nccl\", \"gloo\", $ time python test_dd...\n",
       "7767     [env.reset()\\r\\n# In case you're running this ...\n",
       "7768     [import argparse\\r\\nimport torch\\r\\nfrom model...\n",
       "7769     [import torch\\r\\ntorch.manual_seed(0)\\r\\n\\r\\na...\n",
       "7770     [self.cnn, nn.Flatten(), F.linear, x = self.cn...\n",
       "7771     [### TODO: Write data loaders for training, va...\n",
       "7772     [best_valid_loss = float('inf')\\r\\ntrain_losse...\n",
       "7773     [idx = tensor([[0,1,2,0],\\r\\n        [0,3,2,2]...\n",
       "7774     [idx = tensor([[0,1,2,0],\\r\\n        [0,3,2,2]...\n",
       "7775     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7778     [train = pd.read_csv('datatrain.csv')   # load...\n",
       "7779     [tensor([0,1,2,0])\\r\\n, tensor([[[0, 9],\\r\\n  ...\n",
       "7780     [torchvision.io cannot find reference 'read_im...\n",
       "7781     [torchvision.io cannot find reference 'read_im...\n",
       "7782     [x = torch.autograd.Variable(image, requires_g...\n",
       "7783     [from autograd import elementwise_grad as egra...\n",
       "7784     [from autograd import elementwise_grad as egra...\n",
       "7785     [torch, torchvision, transformed_cifar10, tran...\n",
       "7786     [from __future__ import print_function\\r\\n\\r\\n...\n",
       "7787     [&lt;&lt;&lt; time 0 and agent 0:\\r\\ncurrent_s...\n",
       "7790     [My = MyNet(data)\\r\\nMy = torch.load(\"model_pa...\n",
       "7791     [class MyModel(pl.LightningModule):\\r\\n    def...\n",
       "7792     [encoder = TFBertModel.from_pretrained(\"bert-b...\n",
       "7794     [state_dict, state_dict, import binascii\\r\\nim...\n",
       "7798     [def test_setup():\\r\\n    print('test_setup')\\...\n",
       "7799     [collect_env.py, PyTorch version: 1.7.1+cu101\\...\n",
       "7800     [collect_env.py, PyTorch version: 1.7.1+cu101\\...\n",
       "7802     [# read images\\r\\n# --------------------------...\n",
       "7803     [validation_epoch_end, validation_epoch_end, v...\n",
       "7804     [class A(nn.Module):\\r\\n    def __init__(self,...\n",
       "7805     [from collections import Iterable\\r\\n\\r\\ndef c...\n",
       "7806     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "7807     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "7808     [(7,), (), (6,), (14,), arr1= [1, 2, 3], arr2=...\n",
       "7809     [copy.deepcopy(), def train_model(model, num_c...\n",
       "7810     [Conv2d, import torch.nn as nn\\r\\nimport torch...\n",
       "7812     [batchsize, batchsize, import torch\\r\\nfrom to...\n",
       "7813     [RuntimeError: CUDA error: CUBLAS_STATUS_EXECU...\n",
       "7814     [torch.randperm(n)\\r\\n, K = 10  # should be po...\n",
       "7815     [class _netD(nn.Module):\\r\\n    def __init__(s...\n",
       "7816     [# convert class weights to tensor\\r\\nweights=...\n",
       "7817     [import torch\\r\\nimport torch.onnx\\r\\nfrom det...\n",
       "7818     [class Alexnet(nn.Module):\\r\\n  def __init__(s...\n",
       "7820     [transform_list={'train':transforms.Compose([t...\n",
       "7821     [Signature: learn.predict(item, rm_type_tfms=N...\n",
       "7822     [def forward(self, x):\\r\\n    x = self.relu1(s...\n",
       "7823     [GPT2LMHeadModel, DataCollatorForLanguageModel...\n",
       "7825     [[x, y, z], P: [2, 0, 1], [z, x, y], P^-1: [1,...\n",
       "7826     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "7827     [model = torch.load('/content/gdrive/model.pth...\n",
       "7828     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "7829     [# MNIST Test dataset and dataloader declarati...\n",
       "7830     [x, y, x = torch.Tensor([[1,2,3],[4,5,6],[7,8,...\n",
       "7831     [def func(list):\\r\\n    #os.system('cp /code/p...\n",
       "7832     [WordLevel, BPE, from transformers import Data...\n",
       "7834     [[[[1, 2, 3]\\r\\n  [4, 5, 6]\\r\\n  [7, 8, 9]\\r\\n...\n",
       "7835     [mnist_train = MNIST('../data/MNIST', download...\n",
       "7836     [backend='nccl'\\r\\nrank=1\\r\\nmp.current_proces...\n",
       "7837     [class _ScaleGradient(Function):\\r\\n    @stati...\n",
       "7838     [class integrated(nn.Module):\\r\\n    def __ini...\n",
       "7839     [# here is a one-hot encoded vector for the mu...\n",
       "7840     [dataset = gdal.Open(dir)\\r\\n\\r\\nprint(dataset...\n",
       "7841     [psutil, tracemalloc, Epoch     25/  1000 Loss...\n",
       "7842     [def _block(self, in_channels, out_channels, k...\n",
       "7843     [P.shape=[N,k], ind.shape=[L,N], ind[i,j], P[j...\n",
       "7844     [class GradReverse(Function):\\r\\n    def forwa...\n",
       "7845     [q = D.Independent(D.Gamma(alpha, beta), 1), a...\n",
       "7847     [import transformers\\r\\nfrom torch.utils.data ...\n",
       "7848     [loss.backward(), loss, class test_net_1(nn.Mo...\n",
       "7849     [class LSTM(nn.Module):\\r\\n  def __init__(self...\n",
       "7850     [import torch\\r\\na = torch.tensor([10.,10.],re...\n",
       "7851     [learning_rate = 0.001\\r\\noptimizer = torch.op...\n",
       "7852     [#include &lt;stdio.h&gt;\\r\\n#include &lt;cuda...\n",
       "7854     [RuntimeError: NCCL error in: /opt/conda/conda...\n",
       "7855     [RuntimeError: NCCL error in: /opt/conda/conda...\n",
       "7856     [RuntimeError: NCCL error in: /opt/conda/conda...\n",
       "7859     [import torch\\r\\n\\r\\nA = torch.rand(600, 600, ...\n",
       "7860     [def main():\\r\\n    config = Config()\\r\\n\\r\\n ...\n",
       "7861     [from transformers import AutoTokenizer, AutoM...\n",
       "7862     [from transformers import AutoTokenizer, AutoM...\n",
       "7863     [Generator(\\r\\n  (main): Sequential(\\r\\n    (0...\n",
       "7864     [        self.features = nn.Sequential(\\r\\n   ...\n",
       "7865     [        self.features = nn.Sequential(\\r\\n   ...\n",
       "7866     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "7867     [ a = torch.arange(12).reshape(2, 6)\\r\\n a\\r\\n...\n",
       "7868     [class Generator(nn.Module):\\r\\n    def __init...\n",
       "7875     [X1 (X[0]): tensor([[1408, 1413,   43,  ...,  ...\n",
       "7876     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7877     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7878     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7879     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7880     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7881     [import torch\\r\\n\\r\\na = torch.tensor([[1,2],[...\n",
       "7882     [import torch\\r\\nimport torchvision.transforms...\n",
       "7883     [import requests\\r\\nimport json\\r\\nimport torc...\n",
       "7884     [fill_diagonal_,  data = torch.ones(3,4,4)\\r\\n...\n",
       "7885     [def loss_fn(self, pred, truth):        \\r\\n  ...\n",
       "7886     [(classifier): Linear(in_features=768, out_fea...\n",
       "7888     [class VGG16(torch.nn.Module):\\r\\n    def __in...\n",
       "7889     [class SimpleAgeRegrNet3D(nn.Module):\\r\\n    d...\n",
       "7890     [A, A = tensor([[3,2,1],[1,0,2],[2,2,0]])\\r\\n,...\n",
       "7891     [A, A = tensor([[3,2,1],[1,0,2],[2,2,0]])\\r\\n,...\n",
       "7892     [RuntimeError                              Tra...\n",
       "7893     [a= torch.randperm(len(l-1)) #where l is total...\n",
       "7894     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7895     [from fastai.vision.all import *\\r\\npath = unt...\n",
       "7896     [class GradCAM(object):\\r\\n    \"\"\"\\r\\n    1: t...\n",
       "7897     [def show_result(G_net, z_, num_epoch, show=Fa...\n",
       "7898     [max_q_len = 128\\r\\nmax_a_len = 64    \\r\\ntrai...\n",
       "7899     [def train_during_validation():\\r\\n    for epo...\n",
       "7900     [[B,N,F], [B,k], index[i][j], source[i][j], ou...\n",
       "7901     [Traceback (most recent call last):\\r\\n  File ...\n",
       "7902     [dummy_input, TracerWarning: Converting a tens...\n",
       "7903     [Onnx2Keras, TF2.3, Onnx2Keras, Conv3x3, ConvB...\n",
       "7905     [model = nn.Sequential(\\r\\n    nn.Conv2d(3,16,...\n",
       "7906     [RUN python3.8 -m pip install -r requirements....\n",
       "7908     [return_sequences=True, return_state=True, inp...\n",
       "7910     [class SimpleResidualBlock(nn.Module):\\r\\n    ...\n",
       "7912     [t = torch.tensor([1,2,3,4,5])\\r\\n, indices = ...\n",
       "7914     [t = torch.tensor([1,2,3,4,5])\\r\\n, indices = ...\n",
       "7915     [(...)\\r\\nfor epoch in range(round):\\r\\n      ...\n",
       "7916     [total_v=0\\r\\ncorrect_v=0\\r\\n\\r\\nwith torch.no...\n",
       "7917     [ torch.set_printoptions(precision=30)\\r\\n y\\r...\n",
       "7918     [# Name                    Version            ...\n",
       "7919     [for i, (inputs, labels) in enumerate(training...\n",
       "7920     [for epoch in range(epochs):\\r\\n    traininglo...\n",
       "7921     [for epoch in range(epochs):\\r\\n    traininglo...\n",
       "7922     [torch.nn.functional.grid_sample, torchscript,...\n",
       "7923     [torch.nn.functional.grid_sample, torchscript,...\n",
       "7924     [import torch\\r\\nimport numpy as np\\r\\nfrom sc...\n",
       "7925     [class LeNet300(nn.Module):\\r\\n    def __init_...\n",
       "7926     [class LeNet300(nn.Module):\\r\\n    def __init_...\n",
       "7927     [torch.FloatTensor, a = torch.FloatTensor(3,3)...\n",
       "7928     [torch.tensor, (n,m), t1 = torch.tensor([[1, 2...\n",
       "7929     [class BertAutoEncoder(nn.Module):\\r\\n    def ...\n",
       "7930     [  self.downsample = nn.AvgPool2d(3, stride=2,...\n",
       "7931     [[400,3], [400],     def sigmoid(z):\\r\\n      ...\n",
       "7932     [[400,3], [400],     def sigmoid(z):\\r\\n      ...\n",
       "7933     [loss = criterion(outputs, data_y), def run(mo...\n",
       "7934     [torch, # first time save and the loss  \\r\\nep...\n",
       "7935     [SubsetRandomSampler,  print('len(train_data):...\n",
       "7936     [onnx2keras, pytorch2keras, set_weights, 'enco...\n",
       "7938     [trained_model.pt, import torch\\r\\nfrom pytorc...\n",
       "7939     [    =&gt; loading model from models/pytorch/p...\n",
       "7940     [    =&gt; loading model from models/pytorch/p...\n",
       "7941     [  optimizer = optim.SGD([\\r\\n          {'para...\n",
       "7943     [u(x,t), 2X50, 50X50, 50X1, x,t, [100,2], u, x...\n",
       "7944     [tensor(0, device='cuda:0')\\r\\ntensor(6, devic...\n",
       "7945     [.pt, model = BertModel.from_pretrained('train...\n",
       "7946     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7947     [--data\\r\\n-----mars\\r\\n---------bbox_train\\r\\...\n",
       "7948     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "7950     [\\r\\ncurrent_grad = 0\\r\\nl_rate = 10**-4\\r\\nx=...\n",
       "7951     [from fastT5 import export_and_get_onnx_model\\...\n",
       "7952     [RuntimeError: fft: ATen not compiled with MKL...\n",
       "7953     [img = [[c1,c2], [c3, c4]] where c is a RGB co...\n",
       "7954     [img = [[c1,c2], [c3, c4]] where c is a RGB co...\n",
       "7955     [import torch.nn.functional as F\\r\\nimport tor...\n",
       "7956     [torch.save(models[0].save_dict(), \"test.pth\",...\n",
       "7957     [    prob = torch.rand(trgs.shape, dtype=torch...\n",
       "7958     [    while total_timesteps &lt; episodes:\\r\\n ...\n",
       "7959     [class AverageMeter(object):\\r\\n    \"\"\"Compute...\n",
       "7960     [np.arange(12).reshape(4,3)\\r\\nOut[119]: \\r\\na...\n",
       "7961     [np.arange(12).reshape(4,3)\\r\\nOut[119]: \\r\\na...\n",
       "7962     [np.arange(12).reshape(4,3)\\r\\nOut[119]: \\r\\na...\n",
       "7963     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7964     [list = [tensor([1,2]), tensor([3, 4, 5])], li...\n",
       "7965     [model = model.cuda(), model = model.to(device...\n",
       "7966     [model = model.cuda(), model = model.to(device...\n",
       "7967     [class SiameseNetwork(torch.nn.Module):\\r\\n   ...\n",
       "7969     [retain_graph=True, loss_actor.backward(retain...\n",
       "7970     [import torch\\r\\na = torch.rand(100,100)\\r\\nb ...\n",
       "7974     [data_loader = torch.utils.data.DataLoader('/c...\n",
       "7975     [import torch\\r\\nimport torchvision as tv\\r\\ni...\n",
       "7976     [import torch\\r\\nimport torchvision as tv\\r\\ni...\n",
       "7978     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "7979     [losses_batch_list = []\\r\\nbatch_size = log_pr...\n",
       "7980     [if performance_metric.item()&gt;max_performan...\n",
       "7982     [nn.Conv1d, h=nn.Conv1d(in, out, k), x=torch.t...\n",
       "7983     [pos_weight, BCEWithLogitsLoss, pos_weight, po...\n",
       "7984     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "7985     [def conv_nd_inverse(self, m, relevance_in):\\r...\n",
       "7986     [Jane Smith is walking in the park, B-PER I-PE...\n",
       "7987     [import torch\\r\\nfrom transformers import Long...\n",
       "7988     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "7989     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "7990     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "7991     [X = d * Kinverse @ [u, v, 1]   #therefore X i...\n",
       "7992     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7993     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7994     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7995     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7996     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7997     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7998     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "7999     [epoch = 100\\r\\nlearning_rate = 0.01\\r\\nN = 1\\...\n",
       "8000     [#data_loader = utils.get_data_loader(dataset,...\n",
       "8001     [RuntimeError: cuDNN error: CUDNN_STATUS_NOT_I...\n",
       "8003     [nn.AdaptiveAvgPool2d, class LeNet5(nn.Module)...\n",
       "8004     [model = nn.Sequential(\\r\\n    nn.Linear(58,64...\n",
       "8005     [model = nn.Sequential(\\r\\n    nn.Linear(58,64...\n",
       "8006     [device = torch.device('cpu')\\r\\n\\r\\ntrained_m...\n",
       "8007     [\\r\\nfrom effdet import get_efficientdet_confi...\n",
       "8008     [for x in range(81):\\r\\n    torch.cuda.empty_c...\n",
       "8009     [from transformers import EncoderDecoderModel,...\n",
       "8010     [from transformers import EncoderDecoderModel,...\n",
       "8011     [class loss_e(nn.Module):\\r\\n\\r\\ndef __init__(...\n",
       "8012     [import torch\\r\\ntorch.manual_seed(42)\\r\\nlogi...\n",
       "8013     [transforms.Normalize((0.485, 0.456, 0.406), (...\n",
       "8014     [transforms.Normalize((0.485, 0.456, 0.406), (...\n",
       "8015     [lst = [torch.rand(4).reshape(1,-1) for _ in r...\n",
       "8016     [@torch.jit.script, OSError: Can't get source ...\n",
       "8018     [def valid_sequence_output(sequence_output, va...\n",
       "8021     [import torch\\r\\nfrom torch import Tensor\\r\\ni...\n",
       "8022     [import torch\\r\\nfrom torch.nn.utils.rnn impor...\n",
       "8023     [onnx, torch.onnx.export(model,(example_query_...\n",
       "8024     [ValueError: optimizer got an empty parameter ...\n",
       "8025     [# Importing Dependencies\\r\\n\\r\\nimport os\\r\\n...\n",
       "8026     [    Running setup.py install for neural-rende...\n",
       "8027     [model &lt;- convlstm(input_dim = 1, hidden_di...\n",
       "8028     [# sample neural network\\r\\n\\r\\n# importing li...\n",
       "8029     [model = torch.nn.DataParallel(model, device_i...\n",
       "8030     [meta_batch_size, qry_loss.backward()\\r\\n, met...\n",
       "8031     [number_batches_in = int(len(dataset_in)/batch...\n",
       "8032     [connectionError: HTTPConnectionPool(host='www...\n",
       "8033     [A = torch.tensor([[[ 1.,  2.,  3.],\\r\\n     [...\n",
       "8035     [y_true = torch.tensor([])\\r\\ny_pred = torch.t...\n",
       "8036     [class ROCKET(nn.Module):\\r\\n    def __init__(...\n",
       "8037     [os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\", Run...\n",
       "8038     [os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\", Run...\n",
       "8039     [def main():\\r\\n    output_format = Pupils()\\r...\n",
       "8040     [torch.roll, [[1,2,3],\\r\\n [4,5,6],\\r\\n [7,8,9...\n",
       "8041     [torch.roll, [[1,2,3],\\r\\n [4,5,6],\\r\\n [7,8,9...\n",
       "8042     [    model = models.resnet18(pretrained=True, ...\n",
       "8043     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "8044     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8045     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8046     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8048     [bert-base-uncased, {\\r\\n  \"architectures\": [\\...\n",
       "8049     [upper_bound = torch.tensor([1,5,10], requires...\n",
       "8050                [[-0.8423,  0.3778][-3.1070, -2.6518]]\n",
       "8052     [class Autoencoder(nn.Module):\\r\\n    def __in...\n",
       "8054     [# MNIST dataset statistics:\\r\\n# mean = tenso...\n",
       "8055     [a = torch.tensor([[[1], [2], [3]],\\r\\n       ...\n",
       "8056     [import torch.tensor as T\\r\\n, T, extensions =...\n",
       "8057     [ModuleNotFoundError: No module named 'soft_re...\n",
       "8058     [nn.Module, class Actor(nn.Module):\\r\\n    def...\n",
       "8059     [import torch\\r\\n\\r\\nz = torch.rand((1,6))\\r\\n...\n",
       "8060     [import torch\\r\\n\\r\\nz = torch.rand((1,6))\\r\\n...\n",
       "8061     [import torch\\r\\n\\r\\nz = torch.rand((1,6))\\r\\n...\n",
       "8062     [    class BertClassifier(nn.Module):\\r\\n    #...\n",
       "8064     [f = h5py.File('./Train.h5', 'r')\\r\\ninput_tra...\n",
       "8065     [class Elementwise(nn.ModuleList):\\r\\n    \"\"\"\\...\n",
       "8066     [inp = torch.eye(5, requires_grad=True)\\r\\nout...\n",
       "8067     [class CustomMnistDataset_OL(Dataset):\\r\\n\\r\\n...\n",
       "8068     [conda create --name pytorch-yolo, conda insta...\n",
       "8069     [`newstudent@snail-System-Product-Name:~$ cond...\n",
       "8070     [Installing collected packages: torch\\r\\nERROR...\n",
       "8072     [tensor([[0., 1., 2.],\\r\\n        [3., 4., 5.]...\n",
       "8073     [import torch\\r\\ntorch.__version__\\r\\n'1.4.0'\\...\n",
       "8075     [conda env create -n test -f test-env.yaml, te...\n",
       "8076     [FROM ubuntu:18.04\\r\\nENV TZ=Asia/Shanghai\\r\\n...\n",
       "8077     [  File \"train.py\", line 98, in validation_epo...\n",
       "8078     [tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4...\n",
       "8080     [wandb, train.py , !WANDB_MODE=\"dryrun\" python...\n",
       "8081     [import random\\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "8082     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8083     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8084     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8085     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8086     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8087     [!pip install pytorch_lightning -qqq\\r\\nimport...\n",
       "8088     [img = mmcv.imread('/content/mmdetection/20210...\n",
       "8089     [tensor([[[[1., 1., 1.],\\r\\n          [1., 1.,...\n",
       "8092     [import pickle\\r\\n\\r\\nfile_name = \"trainData.p...\n",
       "8093     [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "8094     [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "8095     [for i, x in enumerate(target):\\r\\n  if target...\n",
       "8096     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "8098     [model1.weights = model2.weights\\r\\n, variable...\n",
       "8099     [test_t = torch.zeros(2, 1, 1, 1)\\r\\n\\r\\noutpu...\n",
       "8100     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "8101     [torch.mean, import torch\\r\\n\\r\\na = torch.ara...\n",
       "8102     [PyTorch-Lightning,  import pytorch_lightning ...\n",
       "8103     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8104     [  File \"main.py\", line 60, in &lt;module&gt;\\...\n",
       "8105     [  File \"main.py\", line 60, in &lt;module&gt;\\...\n",
       "8106     [python -m spacy train, roberta-large, albert-...\n",
       "8107     [runs\\r\\n├── test_1\\r\\n│   └── events.out.tfev...\n",
       "8110     [test_ds = ImageFolder(root=\"./test\", transfor...\n",
       "8111     [\\r\\nclass MyModel():\\r\\n  init\\r\\n  self.netw...\n",
       "8112     [def resnet_block(input_channels, num_channels...\n",
       "8113     [def find_free_port():\\r\\n    \"\"\" https://stac...\n",
       "8114     [ import numpy as np\\r\\n predictors = np.array...\n",
       "8115     [def _train_users_locally(self):\\r\\n        fo...\n",
       "8116     [base_model.py, import torch\\r\\nfrom torch imp...\n",
       "8117     [x = torch.tensor([[[0],[1],[2]],[[3],[4],[5]]...\n",
       "8118     [x = torch.tensor([[[0],[1],[2]],[[3],[4],[5]]...\n",
       "8119     [# Autoencoder class\\r\\n#https://medium.com/py...\n",
       "8120     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8121     [\"\"\"\\r\\ninput:              result:\\r\\ntensor(...\n",
       "8122     [TypeError: __init__() got an unexpected keywo...\n",
       "8123     [TypeError: __init__() got an unexpected keywo...\n",
       "8124           [model.input_shape\\r\\n, print(), summary()]\n",
       "8126           [model.input_shape\\r\\n, print(), summary()]\n",
       "8127     [a, b, (S, M), (S, M, H), M, (M, H), s, a[s] *...\n",
       "8130     [class VM(nn.Module):\\r\\n    def __init__(self...\n",
       "8131     [tokenizer = BertTokenizer.from_pretrained(r'C...\n",
       "8132     ['LSTM' object has no attribute '_flat_weights...\n",
       "8133     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "8134     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "8135     [from sklearn.preprocessing import LabelEncode...\n",
       "8136     [\\r\\n    from torchvision.models.detection.fas...\n",
       "8137     [def __init__():\\r\\n    ...\\r\\n    self.val_ac...\n",
       "8138     [training_set = Dataset(\"train_data.txt\",\"trai...\n",
       "8139     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8141     [timestamps                                  d...\n",
       "8143     [from torchvision import datasets, transforms\\...\n",
       "8144     [add_graph(), enumerate(), train(), for i, sam...\n",
       "8145     [class CNN(nn.Module):\\r\\n  def __init__(self,...\n",
       "8146     [dataset = MNIST(root='data/', download=True)\\...\n",
       "8147     [class WassersteinLoss(nn.Module): \\r\\n  def _...\n",
       "8148     [from fastapi import Depends, FastAPI\\r\\nfrom ...\n",
       "8149     [class CAE(nn.Module):\\r\\n    def __init__(sel...\n",
       "8151     [Q_pred = self.Q_1.forward(s_now)[T.arange(bat...\n",
       "8152     [map : (Numeric -&gt; Numeric) -&gt; Tensor -&...\n",
       "8153     [FullDataset, torch.utils.data.DataLoader(full...\n",
       "8154     [input_val &gt;= zero &amp;&amp; input_val &lt...\n",
       "8155     [&lt;form method ='post' enctype=multipart/for...\n",
       "8156     [normalize = transforms.Normalize(\\r\\n    mean...\n",
       "8157     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8158     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8159     [DataLoader, DistributedDataParallel, def get_...\n",
       "8160     [x  y    cluster\\r\\n0  112  4\\r\\n0  113  4\\r\\n...\n",
       "8161     [images.shape\\r\\n\\r\\ntorch.Size([32, 3, 244, 2...\n",
       "8163     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8164     [def train_and_test(e):\\r\\n    epochs = e\\r\\n ...\n",
       "8165     [model.save_pretrained(save_location), torch.s...\n",
       "8166     [&lt;starting time&gt; &lt;note pitch&gt; &lt;...\n",
       "8168     [{0.0, 0.5, 1.0}, [0.1, 0.1, 0.9, 0.8, 0.6, 0....\n",
       "8169     [Dataset not found error., import horovod.torc...\n",
       "8170     [Dataset not found error., import horovod.torc...\n",
       "8171     [x = torch.zeros(2, 2), item = torch.tensor([[...\n",
       "8172     [x = torch.zeros(2, 2), item = torch.tensor([[...\n",
       "8173     [x = torch.zeros(2, 2), item = torch.tensor([[...\n",
       "8174     [y_pred=loaded_model(Variable(featuresTest)), ...\n",
       "8175     [checkpoint_callback = ModelCheckpoint(\\r\\n   ...\n",
       "8176     [        # I DONT THINK THIS IS NEEDED, since ...\n",
       "8177     [import os\\r\\nimport copy\\r\\nimport time\\r\\nim...\n",
       "8178     [import os\\r\\nimport copy\\r\\nimport time\\r\\nim...\n",
       "8179     [torch, torch, torch, def _lazy_import_torch()...\n",
       "8180     [torch, torch, torch, def _lazy_import_torch()...\n",
       "8181     [print(a.size)\\r\\ntorch.Size([10, 5])\\r\\n, # a...\n",
       "8182     [print(a.size)\\r\\ntorch.Size([10, 5])\\r\\n, # a...\n",
       "8183     [int64, image = np.array([[1, 2], [3, 4]], dty...\n",
       "8184     [int64, image = np.array([[1, 2], [3, 4]], dty...\n",
       "8186     [torch.randn(1,5), torch.randn(1,5), torch.ran...\n",
       "8187     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "8188     [self.loss_fn = nn.MSELoss()\\r\\n\\r\\n#### -- Sn...\n",
       "8189     [t_1d = torch.Tensor([9, 3, 0, 3, 5, 7, 3, 3, ...\n",
       "8190     [t_1d = torch.Tensor([6, 5, 1, 7, 8, 4, 7, 1, ...\n",
       "8191     [|batch|index|loss|\\r\\n8 0 0.6232748031616211\\...\n",
       "8192     [torch.nn.functional.interpolate(), transforms...\n",
       "8193     [import torch\\r\\nimport matplotlib.pyplot as p...\n",
       "8194     [def fit(num_epochs, model, loss_fn, opt, trai...\n",
       "8197     [def _run():\\r\\n    MAX_LEN = 192 # maximum te...\n",
       "8198     [RuntimeError: Tensor for 'out' is on CPU, Ten...\n",
       "8200     [class LSTM_Model(nn.Module):\\r\\n    def __ini...\n",
       "8201     [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "8202     [shape of X_train (891, 7)\\r\\nShape of Y_train...\n",
       "8204     [torch.tensor([x], dtype=torch.double), x_tens...\n",
       "8205     [ assert self.head_dim * num_heads == self.emb...\n",
       "8207     [import tensorflow as tf\\r\\na=tf.convert_to_te...\n",
       "8208     [# This is the value I am trying to estimate\\r...\n",
       "8209     [a = torch.randn((5,5))\\r\\n a\\r\\ntensor([[ 0.0...\n",
       "8210     [int main()\\r\\n{\\r\\n\\r\\n  auto tensor_create_o...\n",
       "8211     [(one hot encoded vector) * matrix, e = Embedd...\n",
       "8213     [a = torch.full([2, 2], 9)\\r\\n\\r\\nb = a.sqrt()...\n",
       "8214     [a = torch.tensor([[[1., 0., 0., 0.]],\\r\\n    ...\n",
       "8215     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "8218     ['num_epochs = 500\\r\\ntrain_loss = []\\r\\ntest_...\n",
       "8219     [import torch\\r\\nfrom torch.utils.data.dataset...\n",
       "8220     [feature= [tensor(indices=tensor([[   0,    1,...\n",
       "8221     [UserWarning: CUDA initialization: Unexpected ...\n",
       "8223     [__getitem__(), def __getitem__(self, idx):\\r\\...\n",
       "8224     [__getitem__(), def __getitem__(self, idx):\\r\\...\n",
       "8225     [transforms.Compose, center_crop, def center_c...\n",
       "8226     [        FP = confusion_matrix.sum(axis=0) - n...\n",
       "8227     [x, import torch\\r\\n\\r\\nx = torch.randn(1000, ...\n",
       "8228     [x, import torch\\r\\n\\r\\nx = torch.randn(1000, ...\n",
       "8229     [class Net(nn.Module):\\r\\n  def __init__(self)...\n",
       "8230     [cProfile, Profile.enable() ... Profile.disabl...\n",
       "8231     [import os \\r\\nimport warnings\\r\\nwarnings.fil...\n",
       "8232     [theta = torch.ones([3], requires_grad=True, d...\n",
       "8233     [\\r\\nPclass  Sex Age SibSp   Parch   Fare    E...\n",
       "8234     [augment_img = []\\r\\naugment_label = []\\r\\naug...\n",
       "8235     [3,3,3, 5,5,5, x = torch.from_numpy(np.arange(...\n",
       "8236     [api.py, api.py, def load_model_weights(model_...\n",
       "8237     [mat1 and mat2 shapes cannot be multiplied (48...\n",
       "8238     [a = torch.rand(2,3,5)\\r\\n, tensor([[[0.2764, ...\n",
       "8239     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "8240     [from __future__ import print_function\\r\\nfrom...\n",
       "8241     [#LeNet-5 class\\r\\nclass Model(nn.Module):\\r\\n...\n",
       "8242     [from __future__ import print_function, divisi...\n",
       "8244     [matplotlib.use('TkAgg'), ImportError: Cannot ...\n",
       "8245     [unique_consecutive(), input = tensor([[3, 3, ...\n",
       "8246     [import os\\r\\nimport pydicom\\r\\nimport cv2\\r\\n...\n",
       "8247     [iter(train_loader).next(), train_loader = tor...\n",
       "8248     [&gt; def partial_f_x:\\r\\n\\r\\n      return 2*x...\n",
       "8249     [ correct += (predicted == labels).sum(), clas...\n",
       "8250     [ File \"/usr/lib/python3.7/multiprocessing/uti...\n",
       "8251     [predictions = None\\r\\n\\r\\nfor i, batch in enu...\n",
       "8252     [    for batch_x, batch_y, len_batch in val_lo...\n",
       "8253     [shape '[-1, 1031]' is invalid for input of si...\n",
       "8255     [def forward(self, x): #, paddingBottom, paddi...\n",
       "8256     [[[0, 107], [0, 108], [0, 109], [0, 115], [0, ...\n",
       "8257     [# prepare torch data set\\r\\nclass MSRH5Proces...\n",
       "8258     [Code:\\r\\n\"\"\"\\r\\nMain file for training Yolo m...\n",
       "8259     [index       target      d1  d2  d3  d4  d5  d...\n",
       "8260     [TEXT = data.Field(\\r\\n    sequential=True,\\r\\...\n",
       "8261     [import onnx\\r\\nfrom onnx2pytorch import Conve...\n",
       "8262     [model_final.pth, model_final.pth, model_final...\n",
       "8263     [model_final.pth, model_final.pth, model_final...\n",
       "8264     [#Transformation for image\\r\\ntransform_ori = ...\n",
       "8266     [    X = torch.randint(100, (100,5))\\r\\n    x1...\n",
       "8268     [x, y, import torch\\r\\n\\r\\nx = torch.randn(3, ...\n",
       "8272     [self.e_conv_1 = nn.Sequential(\\r\\n    nn.Zero...\n",
       "8273     [cout &lt;&lt; in_img &lt;&lt; endl;\\r\\n\\r\\n a...\n",
       "8274     [net = timm.create_model(model_name='regnetx_0...\n",
       "8275     [b[0], import numpy as np\\r\\nimport torch\\r\\ni...\n",
       "8276     [b[0], import numpy as np\\r\\nimport torch\\r\\ni...\n",
       "8277     [torch.nn.Sequential(\\r\\n    # other layers......\n",
       "8278     [    import torch.nn as nn\\r\\n    class learn_...\n",
       "8279     [    import torch.nn as nn\\r\\n    class learn_...\n",
       "8280     [transforms.Compose(), train_transform = trans...\n",
       "8281     [transforms.Compose(), train_transform = trans...\n",
       "8282     [transforms.Compose(), train_transform = trans...\n",
       "8283     [sudo, $ git clone https://github.com/torch/di...\n",
       "8284     [input_size = len(input_columns)\\r\\nhidden_siz...\n",
       "8285     [{\\r\\n  \"_name_or_path\": \"gpt2\",\\r\\n  \"activat...\n",
       "8286     [train_data = MyDataset(int(1e3), length=50)\\r...\n",
       "8287     [ def forward(self, features):\\r\\n     #print(...\n",
       "8288     [ def forward(self, features):\\r\\n     #print(...\n",
       "8289     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "8290     [        rnn_cell_basic = tf.nn.rnn_cell.Basic...\n",
       "8291     [import torch\\r\\nx = torch.tensor([[10, 11], [...\n",
       "8292     [&lt;&lt;, torch::Tensor, #include &lt;torch/s...\n",
       "8293     [&lt;&lt;, torch::Tensor, #include &lt;torch/s...\n",
       "8294     [&lt;&lt;, torch::Tensor, #include &lt;torch/s...\n",
       "8295     [Exception: process 0 terminated with signal S...\n",
       "8296     [Exception: process 0 terminated with signal S...\n",
       "8297     [class CustomSciBERTModel(nn.Module):\\r\\n    d...\n",
       "8298     [ValueError: Expected input batch_size (4) to ...\n",
       "8299     [torch.onnx.export(\\r\\n  model=modnet.module,\\...\n",
       "8300     [max_norm=1, x = Embedding(num_embeddings=10, ...\n",
       "8301     [tensor([[False, False, False,  ..., False, Fa...\n",
       "8303     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8304     [CrossEntropyLoss, BCEWithLogitsLoss, BCEWithL...\n",
       "8305     [torch.tensor, X_tensor = torch.from_numpy(X_b...\n",
       "8306                         [my_matrix = [:,:,C,:,:]\\r\\n]\n",
       "8307     [torch.einsum, import torch\\r\\n\\r\\na = torch.r...\n",
       "8308     [import torch.multiprocessing as mp\\r\\nimport ...\n",
       "8309     [std ::shared_ptr&lt;torch::jit::script::Modul...\n",
       "8310     [{key: Tensor}, torch.nn.DataParallel, chunk e...\n",
       "8311     [#Model training\\r\\n\\r\\nepochs = 2\\r\\n\\r\\nfor ...\n",
       "8313     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8314     [    def __init__(self,learning_rate,beta_para...\n",
       "8315     [array([ 57, 58, 59, 60, 61, 78, 79, 80, 81, 8...\n",
       "8316     [array([ 57, 58, 59, 60, 61, 78, 79, 80, 81, 8...\n",
       "8317     [def camera(transform):\\r\\n    capture = cv2.V...\n",
       "8318     [RuntimeError: Failed to run torchinfo. See ab...\n",
       "8319     [001101000010010, False\\r\\n111001001000000, Fa...\n",
       "8320     [UnsatisfiableError: The following specificati...\n",
       "8321     [d_in &lt;- 3\\r\\nd_out &lt;- 1\\r\\nn &lt;- 100\\...\n",
       "8322     [torch::kHalf, torch::kFloat16, update(), #def...\n",
       "8325     [tag1, tag2, batch_size=1, tag1, tag2, batch_s...\n",
       "8326     [class myDataset(T.utils.data.Dataset):\\r\\n# W...\n",
       "8327     [import pydicom as dicom\\r\\nimport cv2 \\r\\n\\r\\...\n",
       "8328     [import pydicom as dicom\\r\\nimport cv2 \\r\\n\\r\\...\n",
       "8331     [Dimension out of range (expected to be in ran...\n",
       "8332     [1992 regular unleaded 172 6 MANUAL all wheel ...\n",
       "8333     [python setup.py install, Traceback (most rece...\n",
       "8334     [import torch\\r\\nx = torch.tensor([1, 2, 3])\\r...\n",
       "8335     [class Block(nn.Module):\\r\\n   def __init__(se...\n",
       "8336     [class LBCBlock(nn.Module):\\r\\n    def __init_...\n",
       "8337     [for i, (x, y) in batch_iter:\\r\\n    input, ta...\n",
       "8338     [conda install numpy\\r\\nconda install matplotl...\n",
       "8339     [The size of tensor a (296) must match the siz...\n",
       "8340     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\n#...\n",
       "8341     [ def __init__(self, M=1):\\r\\n        super(PP...\n",
       "8342     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8344     [class Encoder(nn.Module):\\r\\ndef __init__(sel...\n",
       "8345     [y = ax + b, a, b, x, y, a, probability_networ...\n",
       "8348     [# downloaded torchlib\\r\\nexport Torch_DIR=/ho...\n",
       "8349     [self.word_embedding = nn.Embedding(\\r\\n      ...\n",
       "8350     [import torch.nn.functional as F\\r\\n\\r\\nclass ...\n",
       "8351     [Loss is nan, stopping training\\r\\n{'loss_clas...\n",
       "8352     [        \"\"\"\\r\\n        if type(json_data) is ...\n",
       "8353     [def binary_focal_loss(pred, truth, gamma=2., ...\n",
       "8354     [self.policy.optimizer.zero_grad()\\r\\nG = T.te...\n",
       "8356     [import boto3\\r\\n\\r\\ns3 = boto3.client('s3')\\r...\n",
       "8357     [import boto3\\r\\n\\r\\ns3 = boto3.client('s3')\\r...\n",
       "8358     [import boto3\\r\\n\\r\\ns3 = boto3.client('s3')\\r...\n",
       "8359     [eg6 = torch.tensor([\\r\\n    [ 1.,  7., 13., 1...\n",
       "8360     [\\r\\ndef train_net(net,\\r\\n              devic...\n",
       "8361     [class Individual(nn.Module):\\r\\n    def __ini...\n",
       "8362     [Tensor = torch.cuda.FloatTensor\\r\\n\\r\\n\\r\\n# ...\n",
       "8363     [class_names = ['airplane', 'automobile', 'bir...\n",
       "8364     [torch.nn.conv2d, channels_last, conv2d, impor...\n",
       "8365     [img_c, img_h, img_w = img.shape[-3], img.shap...\n",
       "8367     [def main():\\r\\n    device = 'cuda:0' if torch...\n",
       "8368     [for name, param in model.named_parameters():\\...\n",
       "8369     [TokenClassification, label2id = {\\r\\n    \"B-A...\n",
       "8370     [TokenClassification, label2id = {\\r\\n    \"B-A...\n",
       "8371            [RandomHorizontalFlip, RandomVerticalFlip]\n",
       "8373     [import torch.nn as nn\\r\\nimport torch.optim a...\n",
       "8374     [class UNET(nn.Module):\\r\\n    def __init__(se...\n",
       "8375     [import torch\\r\\n\\r\\n# init\\r\\nx = torch.tenso...\n",
       "8376     [Dataset, transformers, tokenizing_UDF, Datase...\n",
       "8377     [OrderedDict([('quant.scale', tensor([0.0058])...\n",
       "8378     [buf = numpy.fromfile( dataFile, dtype=np.uint...\n",
       "8379     [Hyperparameter, Hyperparameter, zero_grad(), ...\n",
       "8380     [    path = \"new_z_axis\"\\r\\n    device = \"cuda...\n",
       "8381     [furrr, library(rTorch)\\r\\ntorch_it &lt;- func...\n",
       "8382     [CrossEntropyLoss, ValueError: Expected target...\n",
       "8384     [enumerate(dataset), class TrainImageFolder(Da...\n",
       "8385     [Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2...\n",
       "8386                                   [ReduceLROnPlateau]\n",
       "8387     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "8388     [y = q(x)\\r\\n\\r\\nfor f in functions\\r\\n    res...\n",
       "8389     [import netron\\r\\n\\r\\nenable_netron = True\\r\\n...\n",
       "8390     [class LSTMRating(nn.Module):\\r\\n\\r\\ndef __ini...\n",
       "8392     [INPUT --&gt; | NETWORK 1 | --&gt; FILTERED OU...\n",
       "8395     [def binary_focal_loss(pred, truth, gamma=2., ...\n",
       "8396     [!rm -rf onnx/\\r\\nfrom pathlib import Path\\r\\n...\n",
       "8397     [pip show torch\\r\\nVersion: 1.7.1\\r\\n\\r\\npytho...\n",
       "8398     [import torch\\r\\n# import numpy as np\\r\\n\\r\\nc...\n",
       "8399     [RuntimeError: CUDA error: no kernel image is ...\n",
       "8400     [i = torch.tensor([[2, 2, 1], [2, 0, 2]])\\r\\nv...\n",
       "8402     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "8403     [Class A(nn.Module):\\r\\n      # MY CODE\\r\\n\\r\\...\n",
       "8404     [def add_trace(arrInd, arr):\\r\\n    \"\"\" Add on...\n",
       "8405     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8406     [python3 -q -X faulthandler test.py --model.ba...\n",
       "8407     [[{\"text\":[[\"i\", \"feel\", \"sad\"], [\"not\", \"sure...\n",
       "8408     [[{\"text\":[[\"i\", \"feel\", \"sad\"], [\"not\", \"sure...\n",
       "8409     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8410     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8411     [TypeError: unsupported operand type(s) for +:...\n",
       "8412     [class MyFunc(torch.autograd.Function):\\r\\n@st...\n",
       "8413     [class MyFunc(torch.autograd.Function):\\r\\n@st...\n",
       "8414     [nn.Linear(9,9), nn.functional.conv2d(input,we...\n",
       "8415     [padding=SAME, S=Stride\\r\\nP=Padding\\r\\nW=Widt...\n",
       "8416     [class model_dnn_2(nn.Module):\\r\\n    def __in...\n",
       "8417     [conda install tensorflow-gpu\\r\\nCollecting pa...\n",
       "8418     [\\r\\nimport torch\\r\\nimport torch.nn as nn\\r\\n...\n",
       "8419     [test_dataset = ImageFolderWithPaths('/Users/d...\n",
       "8420     [!pip install torch torchvision\\r\\nimport torc...\n",
       "8421     [class MatrixFactorization(nn.Module):\\r\\n\\r\\n...\n",
       "8422     [index = 0\\r\\nrunning_loss = 0\\r\\navg_loss = 0...\n",
       "8423     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "8424     [[3360, 3, 224, 224], dataset(torch.utils.data...\n",
       "8425     [from transformers import BertTokenizer, BertF...\n",
       "8426     [torch.Size([256, 3, 28, 28])\\r\\n, class Model...\n",
       "8427     [lb = joblib.load('/content/drive/MyDrive/Cola...\n",
       "8428     [import torch\\r\\ndevice = torch.device('cpu')\\...\n",
       "8429     [`class CustomDataset(torch.utils.data.Dataset...\n",
       "8430     [model = ModelLSTM(m, k).to(device)\\r\\n\\r\\nmod...\n",
       "8431     [Expected target boxes to be a tensor of shape...\n",
       "8432     [resized_image4D = np.reshape(image_noisy, (1,...\n",
       "8433     [t, (t.numel() % x) == 0, def pad_minimally(t,...\n",
       "8434     [import pandas as pd\\r\\nimport torch\\r\\nfrom t...\n",
       "8435     [torch.nn.BCEWithLogitsLoss(), ~\\Anaconda3\\env...\n",
       "8436     [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "8437     [from keras.applications.vgg16 import VGG16\\r\\...\n",
       "8438     [predict,     def predict(self, x):\\r\\n       ...\n",
       "8439     [train_loader = torch.utils.data.DataLoader(\\r...\n",
       "8440     [class Autoencoder(torch.nn.Module):\\r\\n\\r\\n  ...\n",
       "8441     [class Autoencoder(torch.nn.Module):\\r\\n\\r\\n  ...\n",
       "8442     [torchvision.dataset, ImageFolder, dataset = v...\n",
       "8443     [cfg = get_cfg()\\r\\ncfg.merge_from_file(model_...\n",
       "8444     [cfg = get_cfg()\\r\\ncfg.merge_from_file(model_...\n",
       "8446     [a = torch.tensor([[1,2], [2,3],[3,4]])\\r\\nb =...\n",
       "8448     [a = torch.tensor([[1,2], [2,3],[3,4]])\\r\\nb =...\n",
       "8449     [class BertTransformer(BaseEstimator, Transfor...\n",
       "8450     [256x256, 1920x1080, 1920x1080, 240x135, 120x6...\n",
       "8451     [pytorch 1.7, data_loader = torch.utils.data.D...\n",
       "8452     [pytorch 1.7, data_loader = torch.utils.data.D...\n",
       "8453     [Figure 1, batch_size = 1  pytorch\\r\\nFigure 2...\n",
       "8454     [model = Network()\\r\\nmodel.cuda()\\r\\n#loss = ...\n",
       "8455     [s = pc()\\r\\nfor _ in trange(max_length):\\r\\n ...\n",
       "8456     [py::dict quantize(py::dict target) {\\r\\n    ....\n",
       "8457     [MLP, from keras.models import Sequential\\r\\nf...\n",
       "8458     [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "8459     [fake_images[0] = fake_images[0].numpy(), Type...\n",
       "8460     [def predict_all(predictor, data):\\r\\n    for ...\n",
       "8461     [def predict_all(predictor, data):\\r\\n    for ...\n",
       "8462     [nn.ModuleDict, class Net(nn.Module):\\r\\n    d...\n",
       "8463     [torch, import torch\\r\\na=torch.randn(3,100)\\r...\n",
       "8464     [torch, import torch\\r\\na=torch.randn(3,100)\\r...\n",
       "8465     [import numpy as np  \\r\\nimport torch\\r\\nimpor...\n",
       "8466     [class summation: \\r\\n    def __init__(self, f...\n",
       "8467     [torch.stack, import torch\\r\\n\\r\\nqx = torch.r...\n",
       "8468     [class Net1(nn.Module):\\r\\n    \\r\\n    def __i...\n",
       "8469     [https://docs.cupy.dev/en/stable/install.html,...\n",
       "8470     [train.py, \\r\\nrunfile('C:/Users/Sylvain ARD/D...\n",
       "8471     [def shift_matrix(a, distances) -&gt; Tensor:\\...\n",
       "8472     [pytorch_model.bin, BertModel.from_pretrained(...\n",
       "8473     [pytorch_model.bin, BertModel.from_pretrained(...\n",
       "8474     [Model, output_sequence, trajectory_length, cl...\n",
       "8475     [print(torch.__version__)\\r\\nprint(torchvision...\n",
       "8476     [$ pip install neuralprophet\\r\\nCollecting neu...\n",
       "8477     [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "8478     [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "8479     [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "8480     [class Net(torch.nn.Module):\\r\\n    def __init...\n",
       "8481     [def save(self, folder_to_save='./'):\\r\\n    i...\n",
       "8482     [torch.cat, squeeze(), &lt;ipython-input-51-cd...\n",
       "8484                 [torch.flatten(), torch.nn.Flatten()]\n",
       "8485     [bert, pytorch_model.bin, config.json, import ...\n",
       "8486     [.pt, zip, import torch\\r\\nimport torchvision\\...\n",
       "8488     [Numpy, npy_p = np.random.randn(4,6)\\r\\nquant ...\n",
       "8489     [training_args = TrainingArguments(\\r\\n       ...\n",
       "8490     [w, torch.Size([64, 3, 7, 7]), p, 64x64, torch...\n",
       "8491     [torch.Tensor, [batch_size, ..., num_classes],...\n",
       "8492     [ torchvision.models.segmentation.deeplabv3_re...\n",
       "8493     [# Translate fixed images for debugging.\\r\\nif...\n",
       "8495     [T, (batch_size, window_size, filters, 3, 3), ...\n",
       "8496     [epoch: 1, loss= -16.0369\\r\\nepoch: 2, loss= -...\n",
       "8497     [class Net(Module):   \\r\\n    def __init__(sel...\n",
       "8498     [class Net(Module):   \\r\\n    def __init__(sel...\n",
       "8499     [class SelfAttention(nn.Module):\\r\\n    def __...\n",
       "8500     [Traceback (most recent call last):\\r\\nFile \"C...\n",
       "8501     [Pip, pip install torch===1.7.1 torchvision===...\n",
       "8502     [Data_A, Data_X, Data_A, Data_X, Data_B, Data_...\n",
       "8503     [def preprocess(string):\\r\\n    return torch.F...\n",
       "8504     [def preprocess(string):\\r\\n    return torch.F...\n",
       "8505     [__getitem__(),     def __getitem__(self, idx)...\n",
       "8506     [---------------------------------------------...\n",
       "8507     [def server_aggregate(server_model, client_mod...\n",
       "8508     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "8509     [criterion = nn.CrossEntropyLoss()\\r\\nif CUDA:...\n",
       "8510     [LR = 0.0001 \\r\\nclass LSTM(nn.Module):\\r\\n   ...\n",
       "8511     [AttributeError: 'Image' object has no attribu...\n",
       "8512     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "8513     [cuda.is_available, false, conda install pytor...\n",
       "8514     [evaluate(model, valid_dl), self.classifier, -...\n",
       "8515     [import torch.nn.functional as F\\r\\nimport tor...\n",
       "8516     [x -&gt; [batch_size, query_len, embedding_siz...\n",
       "8517     [model = model.UNet_ConvLSTM(config.img_channe...\n",
       "8518     [    class LSTMTagger(nn.Module):\\r\\n\\r\\n     ...\n",
       "8519     [.ipynb, .py, unresolved import 'MLutils, MLut...\n",
       "8520     [loss = criterion(outputs, stat_batch), output...\n",
       "8521     [pip install torchaudio\\r\\n,  ERROR: Could not...\n",
       "8522     [pip install torchaudio\\r\\n,  ERROR: Could not...\n",
       "8524     [ImportError: torch.utils.ffi is deprecated. P...\n",
       "8526     [1D target tensor expected, multi-target not s...\n",
       "8527     [images = Variable(images.cuda())\\r\\ntargets =...\n",
       "8528     [class LR(nn.Module):\\r\\n    def ___init___(se...\n",
       "8529     [backward, backward, import torch\\r\\nimport to...\n",
       "8530     [output =[node.name for node in model.graph.ou...\n",
       "8531     [class Simple1DCNN(torch.nn.Module):\\r\\n    de...\n",
       "8532     [import torch\\r\\n\\r\\na = torch.tensor([\\r\\n   ...\n",
       "8534     [#############################################...\n",
       "8537     [(63,32,1,600,600), torch.stack(matrices).cpu(...\n",
       "8539     [conda install pytorch torchvision torchaudio ...\n",
       "8541     [e, v, e, v, [[9, 6, 5, 4, 10],\\r\\n [8, 7, 3, ...\n",
       "8542     [torch.rfft(), def dft_amp(img):\\r\\n    fft_im...\n",
       "8543     [Dataset, Dataloader, .to(), .cuda(), from tor...\n",
       "8544     [  !pip install torch \\r\\n, pip install torch ...\n",
       "8545     [B*C*T*H*W, H*W, B*C*T*H*W, data = raw_data.tr...\n",
       "8546     [dataset = pd.read_csv('augmented_data.csv')\\r...\n",
       "8547     [cat /etc/lsb-release, DISTRIB_ID=Ubuntu\\r\\nDI...\n",
       "8548     [vs = 200\\r\\nnt = 12\\r\\nb = torch.ones(vs)/vs\\...\n",
       "8549     [TensorDataset, transform_train = transforms.C...\n",
       "8551     [     def trained_model(criterion, optimizer, ...\n",
       "8552     [# Convert data to tensors\\r\\nX_train = torch....\n",
       "8553     [# Convert data to tensors\\r\\nX_train = torch....\n",
       "8554     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "8555     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "8556     [os.listdir(r'C:\\Users\\hafizurr\\Documents\\clas...\n",
       "8557     [CMake Error at CMakeLists.txt:4 (add_executab...\n",
       "8558     [seq_A.size()\\r\\nOut[1]: torch.Size([20, 300, ...\n",
       "8559     [google/bert_uncased_L-2_H-128_A-2, def pre_en...\n",
       "8560     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8561     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8562     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "8563     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "8564     [class Network(nn.Module):\\r\\n    def __init__...\n",
       "8565     [class MLP(nn.Module):  \\r\\n    def __ini__(se...\n",
       "8566     [import torch\\r\\nx = torch.randn(20,1)\\r\\ny = ...\n",
       "8568     [vp_sa_s=mdp_data['sa_s'].detach().clone()\\r\\n...\n",
       "8570     [def get_dls(bs, size):\\r\\n    dblock = DataBl...\n",
       "8571     [def communicate_to_server(*, local_data, prev...\n",
       "8572     [copy.deepcopy, torch.tensor.contiguous(), src...\n",
       "8573     [t0, bs = 4\\r\\nseq = 10\\r\\nv = 16\\r\\nt0 = torc...\n",
       "8574     [t0, bs = 4\\r\\nseq = 10\\r\\nv = 16\\r\\nt0 = torc...\n",
       "8575     [TypeError: Cannot interpret 'torch.uint8' as ...\n",
       "8576     [pip install torch==1.7.1+cpu torchvision==0.8...\n",
       "8577     [##% first ,I set a model:\\r\\n\\r\\nclass net(nn...\n",
       "8578     [for p in model.input.parameters():\\r\\n       ...\n",
       "8579     [##% first I set a model\\r\\nclass net(nn.Modul...\n",
       "8580     [##% first I set a model\\r\\nclass net(nn.Modul...\n",
       "8581     [##% first I set a model\\r\\nclass net(nn.Modul...\n",
       "8584     [transform=transforms.Compose([\\r\\n        tra...\n",
       "8586     [print(\"Device resnet\", torch.cuda.current_dev...\n",
       "8587     [[batch_size, timesteps, features_of_timesteps...\n",
       "8588     [param.grad, model.parameters(), def add_error...\n",
       "8589     [from torch import nn\\r\\n#DEFINE THE REQUIRED ...\n",
       "8590     [from torch import nn\\r\\n#DEFINE THE REQUIRED ...\n",
       "8591     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "8592     [class ResNet9(ImageClassificationBase):\\r\\nde...\n",
       "8593     [transform_train = transforms.Compose([\\r\\n   ...\n",
       "8594     [for epoch in range(EPOCHS):\\r\\nrunning_loss =...\n",
       "8595     [input_data = block_reduce(input_data, block_s...\n",
       "8597     [RuntimeError: Detected that PyTorch and torch...\n",
       "8598     [RuntimeError: Detected that PyTorch and torch...\n",
       "8599     [P, Q, L(X-PQ), X, x, X, X, x, L(X' - P'Q) = L...\n",
       "8601     [from torchvision import models\\r\\n\\r\\nmodel =...\n",
       "8602     [f(x,y), R^d x R^d, X = [x1,x2,...,xm] , Y = [...\n",
       "8603     [torch_geometric, pip install torch-sparse, to...\n",
       "8604     [tensor2, tensor1, copy_ind = torch.tensor([0,...\n",
       "8605     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "8606     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "8607     [class Darknet(nn.Module):\\r\\n    def __init__...\n",
       "8609     [class SaveOutput:\\r\\n  #Callable object for s...\n",
       "8610     [#creating a BERT tokenizer\\r\\ntokenizer = Ber...\n",
       "8611     [shuffle=True, fnames = [fnames[i] for i in to...\n",
       "8612     [---------------------------------------------...\n",
       "8613     [# instantiate the quantized net (not shown he...\n",
       "8614     [map, map, if tensor_a * tensor_b.matmul(tenso...\n",
       "8615     [[1, 24, 768], [1, 1, 768], [1, 1, 24*768], li...\n",
       "8616     [RCNN(\\r\\n  (embeddings): Embedding(10661, 300...\n",
       "8617     [\\r\\nclass model(nn.Module):\\r\\n    def __init...\n",
       "8618     [def test_model(size):\\r\\n    model = Sequenti...\n",
       "8619     [train_one_epoch, loss_dict = model(images, ta...\n",
       "8620     [def classify_sentence(self, sentence):\\r\\n\\r\\...\n",
       "8621     [for i in range(len(loss_per_layer)):\\r\\n    l...\n",
       "8622     [for i in range(len(loss_per_layer)):\\r\\n    l...\n",
       "8623     [find_package, [cmake] CMake Warning at libtor...\n",
       "8624     [i = [[0,2]]\\r\\nv = [np.array([1,2,3,4]),[5,6,...\n",
       "8625     [def __init__(self, num_out, kernel_size, num_...\n",
       "8627     [scaler = GradScaler()\\r\\n\\r\\nfor epoch in epo...\n",
       "8628     [scaler = GradScaler()\\r\\n\\r\\nfor epoch in epo...\n",
       "8629     [args = parser.parse_args()\\r\\n\\r\\nuse_cuda = ...\n",
       "8630     [train_sampler = RandomClipSampler(dataset.vid...\n",
       "8631     [indices, (2, 5, 2), value, (2, 5, 2, 16, 16),...\n",
       "8632     [indices, (2, 5, 2), value, (2, 5, 2, 16, 16),...\n",
       "8633     [C:\\Users\\myself&gt;pip install torch\\r\\nColle...\n",
       "8634     [self.actor = Actor().to(device)\\r\\nself.actor...\n",
       "8635     [torch.sparse_coo_tensor, array([[1, 0, 5, 0],...\n",
       "8636                        [Dropout= [0.1, 0.2, 0.3]\\r\\n]\n",
       "8637                        [Dropout= [0.1, 0.2, 0.3]\\r\\n]\n",
       "8638     [t,x,y\\r\\n0.0,-,0.5759052335487023\\r\\n0.01,-,-...\n",
       "8639     [import torch\\r\\nfrom torch import nn\\r\\n#\\r\\n...\n",
       "8640     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8641     [(bn, c * k, 32, 32), (bn, k, 1, 2), out, (bn,...\n",
       "8642     [(bn, c * k, 32, 32), (bn, k, 1, 2), out, (bn,...\n",
       "8643     [dataset = Dataset(train_tensor)\\r\\nval_datase...\n",
       "8644     [dataset = Dataset(train_tensor)\\r\\nval_datase...\n",
       "8645     [dataset = Dataset(train_tensor)\\r\\nval_datase...\n",
       "8646     [dataset = Dataset(train_tensor)\\r\\nval_datase...\n",
       "8647     [def Myloss1(source, target):\\r\\n    loss = to...\n",
       "8648     [    BERTmodel = AutoModel.from_pretrained('be...\n",
       "8649     [\"ValueError: can't optimize a non-leaf Tensor...\n",
       "8650     [import torch\\r\\ntest_tensor = tensor([1,-2,3]...\n",
       "8652     [A, (100, 80000, 4), B, (1, 80000, 1), i, 0, 7...\n",
       "8653     [Traceback (most recent call last):\\r\\n  File ...\n",
       "8654     [nn.parameter.Parameter(data=torch.Tensor((13,...\n",
       "8655     [# -*- mode: python ; coding: utf-8 -*-\\r\\nblo...\n",
       "8656     [image.convert('RGB'), Traceback (most recent ...\n",
       "8657     [from setuptools import setup\\r\\nfrom pathlib ...\n",
       "8661     [BxCxHxW, B, l1_loss = torch.nn.L1Loss()\\r\\nlo...\n",
       "8662     [BxCxHxW, B, l1_loss = torch.nn.L1Loss()\\r\\nlo...\n",
       "8666     [def __init__(self, input_size, output_size):\\...\n",
       "8667     [predict(), forward(), LightningDataModule, se...\n",
       "8668     [A = torch.FloatTensor([[1,2],[3,4]])\\r\\nB = t...\n",
       "8669     [class getSequence(nn.Module):\\r\\n    def forw...\n",
       "8670     [def init_process_group(rank, world_size):\\r\\n...\n",
       "8671     [#include &lt;pybind11/pybind11.h&gt;\\r\\n#incl...\n",
       "8674     [batch['input_ids'] = [[[101, 2014, 2353, 2201...\n",
       "8676     [tokenizer = BertTokenizer.from_pretrained(mod...\n",
       "8679     [[\"Mild\", \"Moderate\", \"No DR\", \"Proliferative ...\n",
       "8681     [   class CNN(nn.Module):\\r\\n        def __ini...\n",
       "8682     [import pandas as pd\\r\\nfrom pandas import rea...\n",
       "8683     [target_mac_out[avail_actions[:, 1:] == 0] = -...\n",
       "8684     [target_mac_out[avail_actions[:, 1:] == 0] = -...\n",
       "8685     [CUDA out of memory, import torch\\r\\nfrom torc...\n",
       "8686     [class Arguments:\\r\\n        def __init__(self...\n",
       "8687     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "8688     [class LSTM(nn.Module):\\r\\n    def __init__(*a...\n",
       "8689     [import torch\\r\\nimport math\\r\\n\\r\\n\\r\\n# Crea...\n",
       "8690     [StopIteration: Caught StopIteration in replic...\n",
       "8691     [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "8692     [e1, e2, ax, ay, az, F(p) - 1, def eval_inout_...\n",
       "8693     [import torch\\r\\nimport matplotlib.pyplot as p...\n",
       "8694     [tensor([[2.7183, 0.4005, 2.7183, 0.5236],\\r\\n...\n",
       "8695     [tensor([[2.7183, 0.4005, 2.7183, 0.5236],\\r\\n...\n",
       "8696     [java.io.IOException: Failed to bind\\r\\n      ...\n",
       "8697     [def create_latent_batch_vectors(batch_size, l...\n",
       "8698     [def res(t):\\r\\n    n = np.zeros((3,32,32))\\r\\...\n",
       "8700     [import torch\\r\\nimport sys\\r\\nprint('A', sys....\n",
       "8701     [distilgpt2, setup.py, from setuptools import ...\n",
       "8703     [import torch.nn as nn\\r\\nimport torch.optim a...\n",
       "8704     [I tensorflow/stream_executor/platform/default...\n",
       "8705     [usage: main.py [-h] [--self_host SELF_HOST] [...\n",
       "8706     [class NeuralNetwork(nn.Module):\\r\\n\\r\\ndef __...\n",
       "8707     [!pip install balanced_kmeans\\r\\n, from google...\n",
       "8708        [torch.utils.data.dataset.Subset, num_classes]\n",
       "8710     [vector = torch.tensor([[1,5,3], [2,3,4]])\\r\\n...\n",
       "8711     [class question_lstm(nn.Module):\\r\\n\\r\\n    de...\n",
       "8712     [    org_x = train_csv.drop(['id', 'digit', 'l...\n",
       "8713     [    org_x = train_csv.drop(['id', 'digit', 'l...\n",
       "8714     [torch.Normal(loc, scale), import torch as pt\\...\n",
       "8715     [import logging\\r\\n\\r\\nimport pandas as pd\\r\\n...\n",
       "8716     [(256, 237, 1, 21), (256, 237, 1, 1024), impor...\n",
       "8717     [(256, 237, 1, 21), (256, 237, 1, 1024), impor...\n",
       "8718     [gd_loss = tf.reduce_sum(tf.square(tf.abs(dx_r...\n",
       "8719     [gd_loss = tf.reduce_sum(tf.square(tf.abs(dx_r...\n",
       "8720     [key = os.environ.get('AZURE_SEARCH_KEY', 'XXX...\n",
       "8721     [DataLoader, import pymongo\\r\\nfrom pymongo im...\n",
       "8722     [import torch\\r\\nimport torch.sparse\\r\\n\\r\\nnb...\n",
       "8723     [# Python program to display all the prime num...\n",
       "8724     [# Python program to display all the prime num...\n",
       "8725     [# Python program to display all the prime num...\n",
       "8726     [class Logits(nn.Sequential):\\r\\n    def __ini...\n",
       "8727     [class Logits(nn.Sequential):\\r\\n    def __ini...\n",
       "8728     [1*1*29*29, \\r\\nclass autoencoder(nn.Module):\\...\n",
       "8729     [numpy.core.multiarray, python3               ...\n",
       "8731     [can't convert np.ndarray of type numpy.object...\n",
       "8732     [can't convert np.ndarray of type numpy.object...\n",
       "8733     [import torch\\r\\ntorch.cuda.is_available()\\r\\n...\n",
       "8734     [import torch\\r\\ntorch.cuda.is_available()\\r\\n...\n",
       "8735     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "8736     [class img_CNN(nn.Module):\\r\\n  def __init__(s...\n",
       "8737     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "8738     [smile_ids = attrs['Smiling'].sort_values(asce...\n",
       "8739     [class LSTM_model(nn.Module):\\r\\n    def __ini...\n",
       "8740     [BatchNorm3d(C), (1, C, 1, 1, 1), BatchNorm, I...\n",
       "8741     [head, tail, children, import torch\\r\\nimport ...\n",
       "8742     [head, tail, children, import torch\\r\\nimport ...\n",
       "8743     [Loading Synthesis Network\\r\\nLoading Mapping ...\n",
       "8744     [batch x channel x height x width, amp_ip, pha...\n",
       "8745     [import torch\\r\\ntorch.cuda.is_available()\\r\\n...\n",
       "8747     [A, &gt;&gt; A.shape\\r\\ntorch.Size([60, 10, 16...\n",
       "8748     [Pytorch, 0, 1, x, (2, 2, 3),  x = torch.tenso...\n",
       "8749     [Pytorch, 0, 1, x, (2, 2, 3),  x = torch.tenso...\n",
       "8750     [dat0 = [np.array(...)], dat1 = [np.array(...)...\n",
       "8751     [from dataloader import bAbi_Dataset\\r\\nimport...\n",
       "8752     [x, y, edge_index, edge_attr, data, Data(edge_...\n",
       "8753     [x, y, edge_index, edge_attr, data, Data(edge_...\n",
       "8755     [Epoch: [14][5000/5005]  Time 1.910 (2.018)  D...\n",
       "8756     [ . . .\\. . .\\. . . .\\r\\n       |\\r\\n\\0 0 0 0\\...\n",
       "8757     [conda install pytorch==1.6.0 torchvision==0.7...\n",
       "8758     [def main():\\r\\n  args.world_size=2\\r\\n  args....\n",
       "8759     [y_hat[:, torch.arange(N), torch.arange(N)] = ...\n",
       "8760     [class LeNet5(nn.Module):\\r\\n\\r\\ndef __init__(...\n",
       "8762     [Dataset, Dataloader, for i,batch in enumerate...\n",
       "8764     [import numpy as np\\r\\nfrom time import time\\r...\n",
       "8765     [img = torch.from_numpy(img).to(device), pred ...\n",
       "8766           [(batch_size, height, width, channel_size)]\n",
       "8767     [running_loss = 0.0\\r\\nfor i, data in enumerat...\n",
       "8768     [[batch_size,1], [batch_size,5000], t1=[[3],[5...\n",
       "8770     [-, ~, $ cat fit.sh\\r\\nexport CUDA_VISIBLE_DEV...\n",
       "8771     [-, ~, $ cat fit.sh\\r\\nexport CUDA_VISIBLE_DEV...\n",
       "8772     [seg, [batch, channels, imsize, imgsize], [16,...\n",
       "8773     [pytorch, from torch.utils.data import Dataset...\n",
       "8774     [sentence_transformers(\"distilbert-base-nli-st...\n",
       "8775     [sentence_transformers(\"distilbert-base-nli-st...\n",
       "8776     [OSError: [WinError 127] The specified procedu...\n",
       "8777     [DataLoader, simple_linear = torch.nn.Linear(7...\n",
       "8778     [DataLoader, simple_linear = torch.nn.Linear(7...\n",
       "8779     [import sys\\r\\nimport os\\r\\nimport torch\\r\\nim...\n",
       "8780     [x = [1, 2, 3, 4, 5], stride = 3, step = 1, re...\n",
       "8781     [class NewModel(nn.Module):\\r\\n    def __init_...\n",
       "8782     [    RuntimeError                             ...\n",
       "8783     [class CCLModel(nn.Module):\\r\\n    def __init_...\n",
       "8784     [# Testing-\\r\\nconv1 = nn.Conv2d(\\r\\n    in_ch...\n",
       "8785     [# Testing-\\r\\nconv1 = nn.Conv2d(\\r\\n    in_ch...\n",
       "8786     [# B: the batch size\\r\\n# N: the number of tra...\n",
       "8787     [# B: the batch size\\r\\n# N: the number of tra...\n",
       "8788     [train_loader = DataLoader(train_dataset, batc...\n",
       "8789     [train_loader = DataLoader(train_dataset, batc...\n",
       "8790     [train_loader = DataLoader(train_dataset, batc...\n",
       "8791     [add_module(), self._other module = other_module]\n",
       "8794     [class ManyToManyRNN(nn.Module):\\r\\n    def __...\n",
       "8795     [cv2.normalize, cv2.dnn.blobFromImage, net.set...\n",
       "8796     [cv2.normalize, cv2.dnn.blobFromImage, net.set...\n",
       "8797     [cv2.normalize, cv2.dnn.blobFromImage, net.set...\n",
       "8798     [cv2.normalize, cv2.dnn.blobFromImage, net.set...\n",
       "8799     [cv2.normalize, cv2.dnn.blobFromImage, net.set...\n",
       "8800     [grid, 3,28,280, 28, 280, plt.imshow(), 28x280...\n",
       "8801     [array([[[[0.35980392, 0.26078431, 0.14313725]...\n",
       "8802     [import pandas as pd\\r\\nfrom sklearn.model_sel...\n",
       "8803     [def __len__(self):\\r\\n        return len(self...\n",
       "8804     [stem=BasicStem, class BasicStemModified(nn.Se...\n",
       "8805     [model.load_state_dict(torch.load(MODEL_PATH))...\n",
       "8806     [mask = targets &gt;= 0\\r\\ntargets = targets[m...\n",
       "8807     [mask = targets &gt;= 0\\r\\ntargets = targets[m...\n",
       "8808     [def train(...):\\r\\n  ...\\r\\n  assert False\\r\\...\n",
       "8809     [# X_train\\r\\n             weekday    monthday...\n",
       "8810     [A = torch.tensor([[0., 0., 0., 0., 1., 5., 1....\n",
       "8812           [pip, torch-1.1.0-cp37-cp37m-win_amd64.whl]\n",
       "8813     [import os\\r\\nfrom pytorch_lightning import Li...\n",
       "8814     [array([[[[0.35980392, 0.26078431, 0.14313725]...\n",
       "8815     [array([[[[0.35980392, 0.26078431, 0.14313725]...\n",
       "8816     [external_grad = torch.tensor([1., 1.])\\r\\nQ.b...\n",
       "8817     [tensor([[ 0.0000, 23.2000, 25.4000, 30.0000, ...\n",
       "8819     [BasicBlock, torchvision.models.resnet, from t...\n",
       "8820     [C, 3x4, requires_grad = True, C, 3x5, C = [C,...\n",
       "8821     [    k = k.contiguous().view(-1, bsz * num_hea...\n",
       "8822     [     def __init__(self, real_frames_dataframe...\n",
       "8823     [torch.onnx.export, blobFromImage, setInput, f...\n",
       "8825     [import torch\\r\\nimage = torch.tensor([[246,  ...\n",
       "8826     [layoutlm, python 3.6, transformer 2.9.0, cond...\n",
       "8828     [ValueError: node input.2 (max) got 2 input(s)...\n",
       "8829     [import io\\r\\nimport torch\\r\\nfrom torchtext.u...\n",
       "8830     [import io\\r\\nimport torch\\r\\nfrom torchtext.u...\n",
       "8831     [import io\\r\\nimport torch\\r\\nfrom torchtext.u...\n",
       "8832     [import io\\r\\nimport torch\\r\\nfrom torchtext.u...\n",
       "8833     [class LogisticRegression(nn.Module):\\r\\n\\r\\n\\...\n",
       "8834     [for experiment_name in experiments:\\r\\n    lo...\n",
       "8835     [for experiment_name in experiments:\\r\\n    lo...\n",
       "8836     [class NetConv(nn.Module):\\r\\n    def __init__...\n",
       "8837     [topv, topi = outline.topk(beam_size)  # beam_...\n",
       "8838     [permute,     def forward(self, x):\\r\\n       ...\n",
       "8839     [permute,     def forward(self, x):\\r\\n       ...\n",
       "8840     [indx = torch.LongTensor([\\r\\n    [ 0,  2,  0]...\n",
       "8841     [RuntimeError: element 0 of tensors does not r...\n",
       "8842     [optimizer.zero_grad(), nb_epochs = 20\\r\\n    ...\n",
       "8843     [import torch\\r\\n\\r\\ndef describe(x):\\r\\n  pri...\n",
       "8844     [A = torch.tensor([2., 3., 4., 5., 6., 7.])\\r\\...\n",
       "8845     [A = torch.tensor([2., 3., 4., 5., 6., 7.])\\r\\...\n",
       "8846     [A = torch.tensor([2., 3., 4., 5., 6., 7.])\\r\\...\n",
       "8847     [trafo = transforms.Compose(\\r\\n              ...\n",
       "8848     [trafo = transforms.Compose(\\r\\n              ...\n",
       "8849     [repo:\\r\\n   model:\\r\\n         fasterrcnn.pth...\n",
       "8850     [\\r\\n    def evaluate(self):\\r\\n        self.m...\n",
       "8851     [class net(nn.Module):\\r\\ndef __init__(self, i...\n",
       "8852     [class net(nn.Module):\\r\\ndef __init__(self, i...\n",
       "8853                                          [256x256x32]\n",
       "8854                                          [256x256x32]\n",
       "8855     [tensor([[0.0000,0.1537],...],grad_fn=&lt;Relu...\n",
       "8856     [plt.scatter, def grid_torch(x_coords, y_coord...\n",
       "8858     [nn.Sequential, layernum, seed = 0\\r\\ntorch.ma...\n",
       "8859     [UnpicklingError: invalid load key, 'v'.\\r\\nTr...\n",
       "8860     [import torch.nn.functional as f\\r\\ntrain_on_g...\n",
       "8861     [CLS, Cosine Similarity/JAccard/MAnhattan/Eucl...\n",
       "8862     [weight = torch.FloatTensor([[1, 2, 3], [4, 5,...\n",
       "8863     [weight = torch.FloatTensor([[1, 2, 3], [4, 5,...\n",
       "8864     [t1, (2*n, 2*n), t2, (2*n), t1, [i,(i+n) mod 2...\n",
       "8865     [from torch.utils.data import TensorDataset, D...\n",
       "8866     [from torch.utils.data import TensorDataset, D...\n",
       "8867     [model = TransformerModel.from_pretrained(...)...\n",
       "8868     [from torchvision import models\\r\\nmodel = mod...\n",
       "8869     [# Name                    Version            ...\n",
       "8870     [def set_parameter_requires_grad(model, featur...\n",
       "8871     [#include &lt;torch/script.h&gt;\\r\\n#include &...\n",
       "8872     [ModuleNotFoundError: No module named 'utils'\\...\n",
       "8873     [ModuleNotFoundError: No module named 'utils'\\...\n",
       "8874     [ValueError: Target size (torch.Size([1000])) ...\n",
       "8875     [ValueError: Target size (torch.Size([1000])) ...\n",
       "8876     [libtorch 1.7.1, libtorch, QT -= gui\\r\\nCONFIG...\n",
       "8877     [class HDF5Dataset(Dataset):\\r\\n    # load the...\n",
       "8878     [import torch\\r\\nimport numpy as np\\r\\n\\r\\nz =...\n",
       "8879     [import torch\\r\\nimport numpy as np\\r\\n\\r\\nz =...\n",
       "8880     [(64,64,1), means = {'notredame': 0.4854, 'yos...\n",
       "8881     [def batch_data(feature1, sequence_length, bat...\n",
       "8882     [def batch_data(feature1, sequence_length, bat...\n",
       "8883     [print(h0.shape)\\r\\nprint(x.shape)\\r\\n\\r\\ntorc...\n",
       "8885     [GPT2, run_clm.py, !python3 run_clm.py \\\\r\\n  ...\n",
       "8886     [GPT2, run_clm.py, !python3 run_clm.py \\\\r\\n  ...\n",
       "8887     [classes = ('T-shirt/top', 'Trouser', 'Pullove...\n",
       "8888     [# Root directory for the dataset\\r\\ndata_root...\n",
       "8889     [# Root directory for the dataset\\r\\ndata_root...\n",
       "8890     [from dataset import AdultDataset, ImportError...\n",
       "8891     [(x,y), (z), TypeError: Input z must be at lea...\n",
       "8892     [( (tensor(weights), tensor(values), tensor(to...\n",
       "8893     [import torch \\r\\nfrom ortools.algorithms impo...\n",
       "8894     [def accuracy(outputs, labels):\\r\\n    _, pred...\n",
       "8895     [N*D, N, D, N*N, 1, [i, j], sentence[i], sente...\n",
       "8896     [torch.jit.trace, RuntimeError: Could not run ...\n",
       "8897     [P(B,N,k), W(B,N,N), A(B,N,N), for i in range(...\n",
       "8898     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8899     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8900     [EfficientNets,     class CustomEfficientNet(n...\n",
       "8901     [ListA = tensor([ [1.0,2.0], [1.0,3.0], [4.0,8...\n",
       "8902     [for batch in iterator:\\r\\n        optimizer.z...\n",
       "8903     [####################################\\r\\n#####...\n",
       "8904     [class Dataset(torch.utils.data.Dataset):\\r\\n'...\n",
       "8905     [selective_max, mask, x [batch_size , dim, num...\n",
       "8906     [def conv_bn(in_channels, out_channels, conv, ...\n",
       "8907     [n, label\\r\\n1, 2\\r\\n2, 3\\r\\n3, 6\\r\\n4, 9\\r\\n....\n",
       "8908     [class BloodDataset(Dataset):\\r\\n    \"\"\"MIMIC ...\n",
       "8909     [testset = torchvision.datasets.FashionMNIST(M...\n",
       "8910     [torch.Size([1, 512, 14, 14]), torch.Size([512])]\n",
       "8911     [grads = torch.autograd.grad(loss, net.paramet...\n",
       "8912     [model = Model(input_size = 30,hidden_size = 2...\n",
       "8913     [https://download.pytorch.org/whl/cpu/torch-1....\n",
       "8914     [Detected that PyTorch and torchvision were co...\n",
       "8915     [(1, 740), (1, 740), self.conv1 = torch.nn.Con...\n",
       "8916     [(1, 740), (1, 740), self.conv1 = torch.nn.Con...\n",
       "8917     [# Create custom dataset that accepts 4 channe...\n",
       "8918     [#Train the model for 4 epochs\\r\\nfrom collect...\n",
       "8919                [(1, 512, 14, 14), (1, k, 1, 1), (k,)]\n",
       "8920     [return {\"val_loss\": loss, \"recon_batch\": reco...\n",
       "8921     [class LSTMClassifier(nn.Module):\\r\\n    def _...\n",
       "8923     [a = np.zeros((4, 5, 6))\\r\\na = a[:, :, np.new...\n",
       "8925     [inputs dimension: (batch_size,sequence length...\n",
       "8926     [def build_model(self):\\r\\n        \"\"\" DataLoa...\n",
       "8927     [def build_model(self):\\r\\n        \"\"\" DataLoa...\n",
       "8928     [X, B x 9 x C x H x W, Y, B x 9C x H x W, a = ...\n",
       "8929     [X, B x 9 x C x H x W, Y, B x 9C x H x W, a = ...\n",
       "8930     [  logits_real_loss = bce_loss(logits_real, to...\n",
       "8931     [x = torch.tensor([[0, 2, 8, 12],\\r\\n         ...\n",
       "8932     [x = torch.tensor([[0, 2, 8, 12],\\r\\n         ...\n",
       "8933     [torch.Size([10, 512, 512, 3]), torch.Size([10...\n",
       "8934     [class VAE(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "8936     [decoder = GLOGenerator()\\r\\ng_optimizer = tf....\n",
       "8937     [IndexError Traceback (most recent call last)\\...\n",
       "8938     [---------------------------------------------...\n",
       "8939     [tf.nn.softmax_cross_entropy_with_logits, Tens...\n",
       "8940     [tf.nn.softmax_cross_entropy_with_logits, Tens...\n",
       "8941     [def run_a_gan(D, G, D_solver, G_solver, discr...\n",
       "8942     [output = previous_layer(previous_input)\\r\\nfi...\n",
       "8943     [if self.transforms:\\r\\n            data = sel...\n",
       "8944     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "8945     [loss = criterion(outputs, labels), input_size...\n",
       "8946     [batch[:, 0], batch[:, 1], if self._current_ep...\n",
       "8947     [sigmoid(WX+b), Wx+b, 𝑦̂ =𝜎(𝑤1𝑥1+𝑤2𝑥2+𝑏)\\r\\n, ...\n",
       "8948     [sigmoid(WX+b), Wx+b, 𝑦̂ =𝜎(𝑤1𝑥1+𝑤2𝑥2+𝑏)\\r\\n, ...\n",
       "8951     [ResNet, k, 1000, k, k, param_grads = [param.g...\n",
       "8952     [hp_metric, self.logger.experiment.add_scalars...\n",
       "8953     [hp_metric, self.logger.experiment.add_scalars...\n",
       "8954     [data, mask, data, 1x2x24x2, mask, 1x2x24, mas...\n",
       "8955     [A, B, A, B, A, C, D, A, B, C, D, import rando...\n",
       "8956     [A, B, A, B, A, C, D, A, B, C, D, import rando...\n",
       "8957     [A, B, A, B, A, C, D, A, B, C, D, import rando...\n",
       "8958     [A, B, A, B, A, C, D, A, B, C, D, import rando...\n",
       "8959     [A, B, A, B, A, C, D, A, B, C, D, import rando...\n",
       "8960     [class BERT_Arch(nn.Module):\\r\\n\\r\\n    def __...\n",
       "8962     [inputs, trade_quantity, trade_value, targets,...\n",
       "8963     [class DotProduct(Module):\\r\\n    def __init__...\n",
       "8964     [import os\\r\\nimport torch\\r\\nimport tqdm\\r\\nf...\n",
       "8965     [x, z.grad\\r\\n, Tensorflow 2, if z.grad &gt; 1...\n",
       "8966     [criterion = nn.CosineSimilarity() \\r\\nloss = ...\n",
       "8967     [class Net(BaseFeaturesExtractor):\\r\\n    def ...\n",
       "8968     [class Net(nn.Module):\\r\\n        def __init__...\n",
       "8972     [def __init__(self, n_tasks, \\r\\n             ...\n",
       "8974     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8975     [import torch\\r\\na = torch.rand(5,3)\\r\\nprint ...\n",
       "8976     [import torch\\r\\na = torch.rand(5,3)\\r\\nprint ...\n",
       "8977     [def replace_max_pooling(model):\\r\\n '''\\r\\n T...\n",
       "8978     [BxCxd,  [[[1,0,0],[0,1,0],[0,0,1]]] -&gt; [[[...\n",
       "8979     [torch, class MyModelClass(torch.nn.Module), r...\n",
       "8980     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "8981     [nn.TransformerEncoder, batch-size, seq-len, e...\n",
       "8982     [names = ['class A', 'class B', 'class C']\\r\\n...\n",
       "8983                                     [padding_mode, 0]\n",
       "8984     [arr = np.array([[ 1, 2, 3, 4, 5], [5, 6, 7, 8...\n",
       "8985     [torch.normal, torch.normal(mean=0,std=1,size=...\n",
       "8986     [import numpy as np\\r\\nimport csv\\r\\nimport pa...\n",
       "8987     [import numpy as np\\r\\nimport csv\\r\\nimport pa...\n",
       "8989     [print(pred)\\r\\noutput: [tensor([[176.64380, 1...\n",
       "8990     [torch.eig(), tp1 = torch.tensor([[123., 43, 4...\n",
       "8991     [average_loss = loss_func(prediction, labels)\\...\n",
       "8992     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "8993     [import torch\\r\\nimport torch.utils.data\\r\\n\\r...\n",
       "8994            [nn.CrossEntropyLoss(), nn.Linear(84, 10)]\n",
       "8995     [def show_images(image_tensor, num_images=9, s...\n",
       "8996     [def fun():\\r\\n   print(1)\\r\\nif __name__==\"__...\n",
       "8998     [criterion = nn.MSELoss()\\r\\n, outputs = model...\n",
       "8999     [criterion = nn.MSELoss()\\r\\n, outputs = model...\n",
       "9000     [Epoch 1/4    loss=0.8802     val_loss=0.8202 ...\n",
       "9001     [# sklearn's dataloader, useful for large data...\n",
       "9002     [imsize = 512 if torch.cuda.is_available() els...\n",
       "9003     [RuntimeError: CUDA error: unspecified launch ...\n",
       "9005     [class Net(nn.Module):\\r\\ndef __init__(self, s...\n",
       "9006     [RuntimeError: Given groups=1, weight of size ...\n",
       "9007     [idxlist = []\\r\\n\\r\\nfor x in range (0, len(in...\n",
       "9008     [print('Prediction started on test data')\\r\\nm...\n",
       "9009     [train_losses=[]\\r\\nval_losses=[]\\r\\n\\r\\nfor e...\n",
       "9010     [ERROR: Failed building wheel for pytorch3d, !...\n",
       "9011     [ERROR: Failed building wheel for pytorch3d, !...\n",
       "9012     [[bn, k, 2], [:, :, 0], import torch\\r\\na = to...\n",
       "9014     [mxnet, codelab, import torch\\r\\nimport torch....\n",
       "9015     [pad_packed_sequence, MAX_LEN, [12, 384, 768],...\n",
       "9016     [import torch\\r\\n\\r\\n# Test tensor with NCHW d...\n",
       "9017                          [t = torch.zeros((4, 5, 6))]\n",
       "9018     [class FFModel(nn.Module):\\r\\n    def __init__...\n",
       "9019     [a, (n, d, l), indices, (n, 1), a, indices, (n...\n",
       "9020     [a, (n, d, l), indices, (n, 1), a, indices, (n...\n",
       "9021     [a, (n, d, l), indices, (n, 1), a, indices, (n...\n",
       "9022     [Dataset:\\r\\n      train:\\r\\n           1.png\\...\n",
       "9023     [    self.layer0 = nn.Sequential(\\r\\n         ...\n",
       "9024     [def process_image(pdf_path, page_dimensions):...\n",
       "9026     [Average Precision  (AP) @[ IoU=0.50:0.95 | ar...\n",
       "9027     [a, bin_indices, n, bins, i, a[bins_indices ==...\n",
       "9028     [a, bin_indices, n, bins, i, a[bins_indices ==...\n",
       "9029     [a, bin_indices, n, bins, i, a[bins_indices ==...\n",
       "9030     [#we do the spatial transformations first, and...\n",
       "9032     [firstData, torch.Size([128, 1, 28, 28]), firs...\n",
       "9034     [model = torchvision.models.detection.maskrcnn...\n",
       "9035     [import os\\r\\nos.getcwd()\\r\\nfrom PIL import I...\n",
       "9036     [import os\\r\\nos.getcwd()\\r\\nfrom PIL import I...\n",
       "9037     [self.transforms_list = [transforms.ColorJitte...\n",
       "9038     [  import tensorflow.compat.v2 as tf\\r\\n\\r\\n  ...\n",
       "9039     [gather, select_index, [[[1,2,3,4],\\r\\n  [5,6,...\n",
       "9040     [gather, select_index, [[[1,2,3,4],\\r\\n  [5,6,...\n",
       "9041     [class CNN(torch.nn.Module):\\r\\n    \\r\\n      ...\n",
       "9043     [a = torch.tensor([[1,1],[2,2]])\\r\\n, tensor([...\n",
       "9046     [class RealOrFakeLSTM(nn.Module):\\r\\n    \\r\\n ...\n",
       "9047     [    self.query_projection = nn.Linear(input_d...\n",
       "9048     [for name,module in model.named_modules():\\r\\n...\n",
       "9049     [pip install pytorch==1.2.0 torchvision==0.4.0...\n",
       "9050     [from hardnet import hardnet\\r\\nimport torch\\r...\n",
       "9051     [device  = torch.device(\"cuda\" if torch.cuda.i...\n",
       "9052     [train_load, val_load = SRD.load_sr_st_dataset...\n",
       "9053     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9054     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "9055     [ynie/roberta-large-snli_mnli_fever_anli_R1_R2...\n",
       "9056     [X, Y, (batch_size, d), (batch_size x 1), [X[0...\n",
       "9057     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "9058     [torch.Size([1, 63840]), inp_unfolded = inp_se...\n",
       "9059     [torch.Size([1, 63840]), inp_unfolded = inp_se...\n",
       "9060     [torch.utils.data.Dataloader, CTX = torch.devi...\n",
       "9061     [torch.utils.data.Dataloader, CTX = torch.devi...\n",
       "9062     [#include &lt;torch/torch.h&gt;\\r\\n#include &l...\n",
       "9063     [tensor_input=[[[1,2],[1,3],[1,4]],[[2,5],[0,3...\n",
       "9064     [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "9065     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9066     [    return self.X[index], self.start[index], ...\n",
       "9067     [criterion = nn.BCELoss()\\r\\npreds = model(inp...\n",
       "9068     [import time\\r\\nimport os\\r\\nimport argparse\\r...\n",
       "9069     [RandomRotation, def __getitem__(self, idx):\\r...\n",
       "9070     [def focal_loss(y_real, y_pred, gamma = 2):\\r\\...\n",
       "9071     [def focal_loss(y_real, y_pred, gamma = 2):\\r\\...\n",
       "9072     [class VAE(nn.Module):\\r\\n    def __init__(sel...\n",
       "9073     [torchvision, plain_backbone = fasterrcnn_resn...\n",
       "9074     [transform = transforms.Compose([\\r\\n         ...\n",
       "9075     [transform = transforms.Compose([\\r\\n         ...\n",
       "9076     [b = torch.rand(10, requires_grad=True).cuda()...\n",
       "9077     [&gt; poetry add torchvision==0.8.2\\r\\n\\r\\nUpd...\n",
       "9078     [class ConvolutionalNetwork(nn.Module):\\r\\n   ...\n",
       "9079     [class UNet(nn.Module):\\r\\n    def __init__(se...\n",
       "9080     [def deconv3d(cin,cout,k=4,s=2,pad=-1):\\r\\n   ...\n",
       "9081     [deepcopy, network_cp=deepcopy(network), optim...\n",
       "9084     [import tensorflow as tf\\r\\n\\r\\nimport numpy a...\n",
       "9085     [* Epoch 1/20\\r\\n-----------------------------...\n",
       "9086     [model = nn.Sequential(\\r\\n    nn.Linear(784, ...\n",
       "9087     [model = nn.Sequential(\\r\\n    nn.Linear(784, ...\n",
       "9088     [cdd_doc_embeddings, [batch_size, cdd_size, si...\n",
       "9089     [\\r\\n# noinspection PyUnresolvedReferences\\r\\n...\n",
       "9090     [.pt, Traceback (most recent call last):\\r\\n  ...\n",
       "9091     [.pt, Traceback (most recent call last):\\r\\n  ...\n",
       "9092     [   model = BertForSequenceClassification.from...\n",
       "9093     [prediction, ground_truth,     for i in range ...\n",
       "9094     [ERROR: Command errored out with exit status 1...\n",
       "9095     [from torch.utils.data import TensorDataset, D...\n",
       "9096     [Predictions =[...x,y,z,...]\\r\\n, prediction_r...\n",
       "9097     [# make splits for data\\r\\ntrain, test = datas...\n",
       "9098     [tokenizer = RobertaTokenizer.from_pretrained(...\n",
       "9099                   [out = torch.unique(my_tensor)\\r\\n]\n",
       "9100     [RuntimeError: Trying to backward through the ...\n",
       "9101     [x1 = torch.tensor([1, 2, 3])  # single bracke...\n",
       "9102     [if torch.cuda.is_available():\\r\\n        inde...\n",
       "9103     [class LSTM_Model(nn.Module):\\r\\n    def __ini...\n",
       "9104     [import horovod.torch as hvd\\r\\nfrom sparkdl i...\n",
       "9106     [torch.randn(layers/depth, rows, columns), tor...\n",
       "9107     [UnpicklingError                           Tra...\n",
       "9108     [sparse_adj = torch.tensor([[0, 1, 2, 1, 0], [...\n",
       "9109     [BATCH_SIZE = 1000\\r\\nGAMMA = 0.999\\r\\nEPS_STA...\n",
       "9110     [def prepare_dataloaders(hparams):\\r\\n    # Ge...\n",
       "9112     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "9114     [x=torch.rand(100,64,22,3,3)\\r\\nx_sorted=torch...\n",
       "9115     [def Fill2DCountTable(arraysList):\\r\\n    '''\\...\n",
       "9116     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9117     [fastai, fastai, TabularModel(\\r\\n  (embeds): ...\n",
       "9118     [OSError - Not Found - No such file or directo...\n",
       "9119     ['My name is slim shade and I am an aspiring A...\n",
       "9120     [def train_dataloader(self):\\r\\n        transf...\n",
       "9121     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9122     [estimate = alpha * torch.std(list(param.grad ...\n",
       "9123     [BertForSequenceClassification, from_pretraine...\n",
       "9124     [File \"&lt;ipython-input-16-7fe0e9e30e5d&gt;\",...\n",
       "9125     [x_train = torch.FloatTensor([[1, 2, 1, 1],\\r\\...\n",
       "9126     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9127     [[0, 1], [0, 0.2), [0.2, 0.4), [0.4, 0.9), [0....\n",
       "9128     [[0, 1], [0, 0.2), [0.2, 0.4), [0.4, 0.9), [0....\n",
       "9129     [class SyNet(sy.Module):\\r\\n  def __init__(sel...\n",
       "9130     [x, [1,5], y, y[i:i+1,:], x, x, y = x.expand(1...\n",
       "9131     [x, [1,5], y, y[i:i+1,:], x, x, y = x.expand(1...\n",
       "9132     [x, [1,5], y, y[i:i+1,:], x, x, y = x.expand(1...\n",
       "9133     [a = torch.rand(2, 3, 4)\\r\\n, tensor([[[0.2410...\n",
       "9134     [momentum, 0.1, 0.001, momentum, 0.9, 0.999, #...\n",
       "9135     [ def get_nll(x, parzen, batch_size=10):\\r\\n  ...\n",
       "9136     [torch.optim.Optimizer, import torch.optim as ...\n",
       "9137     [(vibe-env) mona@mona:~/research/VIBE$ pip ins...\n",
       "9138     [(vibe-env) mona@mona:~/research/VIBE$ pip ins...\n",
       "9140     [class_names = ['normal', 'viral', 'covid']\\r\\...\n",
       "9141     [from transformers import RobertaTokenizer, Ro...\n",
       "9142     [.backward(), retain_graph=True, a = torch.ten...\n",
       "9143     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9144     [from transformers import BertTokenizerFast, B...\n",
       "9145     [from transformers import BertTokenizerFast, B...\n",
       "9146     [class MyModelA(nn.Module):\\r\\n    def __init_...\n",
       "9147     [class MyModelA(nn.Module):\\r\\n    def __init_...\n",
       "9148     [from detecto import core, utils, visualize\\r\\...\n",
       "9149     [class CNN(Module):\\r\\n# define model elements...\n",
       "9150     [boundary = torch.tensor([[0, 3, 4, 8, 0]\\r\\n ...\n",
       "9151     [from modAL.models import ActiveLearner\\r\\nimp...\n",
       "9152     [ n = 128 m = 1024 p = 512 \\r\\n t = []\\r\\nring...\n",
       "9153     [torch.Tensor t, (8, 3, 32, 32), t, idx_last =...\n",
       "9154     [[I 2020-12-09 09:15:49,277] Trial 2 finished ...\n",
       "9155     [import torch \\r\\nimport numpy as np\\r\\nimport...\n",
       "9156     [dataset = tf.data.experimental.sample_from_da...\n",
       "9157     [bert = BertForSequenceClassification.from_pre...\n",
       "9158     [x[N], N, hs[N], x[N]= w.dot(hs[N]) + b, x[i]=...\n",
       "9159     [w = torch.tensor([1.], requires_grad=True)\\r\\...\n",
       "9163     [    # import relevant libraries   \\r\\n    fro...\n",
       "9164     [runfile('C:/Summer2020/computer_vision/final_...\n",
       "9165     [# Dump list of operators used by MobileNetV2:...\n",
       "9167     [input_3d = (1, 64, 96, 96)\\r\\npool_3d = (2, 2...\n",
       "9169     [n x n, m, nm x nm, 2 x 2, 4 x 4, 4 x 4, torch...\n",
       "9170     [from google.colab import drive\\r\\ndrive.mount...\n",
       "9171     [cat,  x = torch.randn(2, 3)\\r\\n x\\r\\ntensor([...\n",
       "9172     [return_sequence, model = Sequential()\\r\\nmode...\n",
       "9174     [    trainset = torch.utils.data.Dataloader(tr...\n",
       "9175     [CutMix, MixUp, beta, np.random.beta, scipy.st...\n",
       "9176     [CutMix, MixUp, beta, np.random.beta, scipy.st...\n",
       "9177     [ import torch\\r\\n import torch.nn as nn\\r\\n c...\n",
       "9178     [# extract data from torch Variable, move to c...\n",
       "9180     [1, x = torch.Tensor([5, 4, 1, 3, 6, 2]), segm...\n",
       "9181     [torchvision.models, vgg16 = models.vgg16(pret...\n",
       "9183     [(base) mona@mona:~/research$ cd phosa/\\r\\n(ba...\n",
       "9184     [def cycle(iterable):\\r\\n    while True:\\r\\n  ...\n",
       "9185     [class Autoencoder(nn.Module):\\r\\n    def __in...\n",
       "9186     [class HeadNet(nn.Module):\\r\\n    def __init__...\n",
       "9187     [nn.Embedding, N-d, M-d, M &lt; N, nn.Embeddin...\n",
       "9188     [result = tune.run(\\r\\n    train,\\r\\n    resou...\n",
       "9189     [model.generate(), tokenizer.decode(), encoder...\n",
       "9190     [[batch_size, seq_length, hidden_dim], [batch_...\n",
       "9191     [tf.keras.layers.Embedding, embeddings_regular...\n",
       "9192     [class MoneyGraph(Dataset):\\r\\n    def __init_...\n",
       "9193     [class Decoder(tf.keras.Model):\\r\\n  def __ini...\n",
       "9194     [class EncoderRNN(nn.Module):\\r\\n    def __ini...\n",
       "9195     [(64,100), t = torch.randn((64,100))\\r\\n, 6400...\n",
       "9196     [(64,100), t = torch.randn((64,100))\\r\\n, 6400...\n",
       "9197     [num_workers = 1\\r\\n\\r\\nclasses = ('plane', 'c...\n",
       "9198     [padding = 'same', from tensorflow.keras.layer...\n",
       "9199     ['torch/torch.h' file not found [clang: pp_fil...\n",
       "9200     [loss = loss_function(output, y), import matpl...\n",
       "9201     [loss = loss_function(output, y), import matpl...\n",
       "9202     [loss = loss_function(output, y), import matpl...\n",
       "9203     [backward, x1 = tensor(2.).requires_grad_()\\r\\...\n",
       "9204     [git clone https://github.com/NVIDIA-AI-IOT/to...\n",
       "9205     [data_dir = \"C:\\\\Users\\\\Lyn\\\\Desktop\\\\UTKFaceD...\n",
       "9206     [GeomLoss, import torch\\r\\nimport geomloss  # ...\n",
       "9207     [def get_transform(train):\\r\\n    transforms =...\n",
       "9208     [def Log(A):\\r\\n    '''\\r\\n    theta = arccos(...\n",
       "9209     [# define the NN architecture\\r\\nclass ConvAut...\n",
       "9210     [# define the NN architecture\\r\\nclass ConvAut...\n",
       "9211     [def forward_res(model, conv_layer, x): \\r\\n  ...\n",
       "9212     [&lt;|startoftext|&gt;\\r\\npublic class FindCit...\n",
       "9213     [lrel_w, lrel_w = torch.zeros(\\r\\n  input_size...\n",
       "9214     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "9215     [# Transfers gradients from thread-specific mo...\n",
       "9216     [def load_array(data_arrays, batch_size, is_tr...\n",
       "9218     [x, xs, def load_data():\\r\\n    pokemon = []\\r...\n",
       "9219     [class Neural_Network:\\r\\n    def __init__(sel...\n",
       "9220     [ValueError: Using a target size (torch.Size([...\n",
       "9221     [ABC_lst, import numpy as np\\r\\nimport torch\\r...\n",
       "9223     [def dice_score_reduced_over_batch(x, y, smoot...\n",
       "9224     [A = torch.tensor(np.array([40, 42, 38]), dtyp...\n",
       "9227                                   [numpy.corrcoef ()]\n",
       "9229     [class network(nn.Module):\\r\\n    def __init__...\n",
       "9230     [class BERTModel(nn.Module):\\r\\n    def __init...\n",
       "9232     [The shop is open\\r\\n, nn.Embedding, [The, sho...\n",
       "9233     [pytorch.org, - name: EXTRA_CONDA_PACKAGES\\r\\n...\n",
       "9234     [class InferenceSiameseNetworkDataset(Dataset)...\n",
       "9235     [mat1 dim1 must match mat1 dim0, class Net(Mod...\n",
       "9236     [X_train, X_test, y_train, y_test = train_test...\n",
       "9237     [class FCN(nn.Module):\\r\\n    def __init__(sel...\n",
       "9238     [        [[595.00000, 179.62500, 628.00000, 28...\n",
       "9239     [        [[595.00000, 179.62500, 628.00000, 28...\n",
       "9240     [torch.fft, import cv2 as cv\\r\\nimport numpy a...\n",
       "9242     [def GeneralizedNabla(self, image):\\r\\n       ...\n",
       "9243     [conv3d(in, out, kernel_size(1,3,3))\\r\\n, conv...\n",
       "9244     [torch.Size([24047])\\r\\ntensor([1315, 1318, 14...\n",
       "9245     [model_fn, input_fn, predict_fn, output_fn, to...\n",
       "9246     [$ pip3 install torch==1.6.0\\r\\nCollecting tor...\n",
       "9247     [# function to train the model\\r\\ndef train():...\n",
       "9248     [RealPhotos, jpg, ls RealPhotos/\\r\\n2007_00002...\n",
       "9249     [/opt/conda/lib/python3.7/site-packages/ipyker...\n",
       "9250     [class MancalaModel(nn.Module):\\r\\n\\r\\n    def...\n",
       "9252     [alpha_cumsum = tf.cumsum(alpha, axis = 1)\\r\\n...\n",
       "9253     [# split the dataset into validation and test ...\n",
       "9254     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9256     [BERT, HuggingFace, PyTorch, DataLoader, Seria...\n",
       "9260     [mean, max, [PAD], BertTokenizer, BertModel, i...\n",
       "9261     [mean, max, [PAD], BertTokenizer, BertModel, i...\n",
       "9262     [mean, max, [PAD], BertTokenizer, BertModel, i...\n",
       "9263     [[[[0 0 0 0 0 0 0]\\r\\n  [0 0 0 0 0 0 0]\\r\\n  [...\n",
       "9264     [PS C:\\windows\\system32&gt; pip install torch=...\n",
       "9266     [Ux, Uy, Uz, Ux, Uy, Uz, .npy, case_1 &gt;\\r\\n...\n",
       "9267     [import torch\\r\\nTraceback (most recent call l...\n",
       "9268     [ValueError: Expected target size (2, 13), got...\n",
       "9269     [torch.nn.modules.module.ModuleAttributeError:...\n",
       "9270     [python mmdetection/tools/train.py config/yolo...\n",
       "9271     [layers = nn.ModuleList()\\r\\nq = nn.ModuleList...\n",
       "9273     [CategoricalCrossEntropyLoss, targets = [0, 0,...\n",
       "9274     [weights = list(1.0 / np.array([1865, 2677, 36...\n",
       "9275     [from pathlib import Path\\r\\n\\r\\nimport numpy\\...\n",
       "9277     [&lt;class 'numpy.ndarray'&gt;\\r\\n[[[0 0 0 0 0...\n",
       "9278     [X, y = make_moons(200, noise=0.2, random_stat...\n",
       "9279     [X, y = make_moons(200, noise=0.2, random_stat...\n",
       "9280     [tensor_4d = torch.tensor([[[[1., 0., 0., 0.],...\n",
       "9281     [for epoch in range(opt.epoch, opt.n_epochs):\\...\n",
       "9282     [Fastai\\r\\nepoch     train_loss  valid_loss  a...\n",
       "9284     [import torch\\r\\nprint(torch.cuda.is_available...\n",
       "9286     [x = torch.ones(3,4,64,64)\\r\\n\\r\\nx = F.interp...\n",
       "9287     [image, warped_image, ix,iy, image, warped_ima...\n",
       "9288     [from scipy.special import softmax\\r\\nprobs = ...\n",
       "9289     [from scipy.special import softmax\\r\\nprobs = ...\n",
       "9290     [import torch\\r\\nimport torchvision.transforms...\n",
       "9292     [import transformers\\r\\nimport pandas as pd\\r\\...\n",
       "9293     [ 16   # text2tensor\\r\\n---&gt; 17   train_seq...\n",
       "9294     [tr_logits = tr_logits.detach().cpu().numpy()\\...\n",
       "9295     [def warp_frame_04(frame1: numpy.ndarray, dept...\n",
       "9296                [np.einsum('bijc,bijd-&gt;bcd', x, x)]\n",
       "9297     [n_epochs = 20\\r\\nbatch_size_train = 64\\r\\nbat...\n",
       "9298     [class Model(object):\\r\\n\\r\\n    def __init__(...\n",
       "9299     [def Gaussian_Kernal(x, mu, sigma):\\r\\n  p = (...\n",
       "9300     [self.beta = Parameter(torch.Tensor(1))\\r\\n#in...\n",
       "9301     [Darknet, .txt, .txt, bounded boxes, &lt;objec...\n",
       "9302     [encoder -&gt; 12 BertLayer -&gt; Pooling, # f...\n",
       "9303     [class generator(nn.Module):\\r\\ndef __init__(s...\n",
       "9304     [class generator(nn.Module):\\r\\ndef __init__(s...\n",
       "9305     [class generator(nn.Module):\\r\\ndef __init__(s...\n",
       "9306     [$ git clone https://github.com/Cadene/pretrai...\n",
       "9307     [optimizer.zero_grad()\\r\\nloss_G_D = BCELoss(d...\n",
       "9309     [model = CNN(height=96, width=96, channels=3)\\...\n",
       "9310         [(1,3), C = b1 * A + b2 * A^2 + b3 * A^3, ^n]\n",
       "9311     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "9312     [PytorchStreamReader failed reading zip archiv...\n",
       "9314     [    ids = ids.to(device, dtype=torch.long)\\r\\...\n",
       "9315     [if __name__ == \"__main__\", # -*- coding: utf-...\n",
       "9316     [t1=torch.Size([400, 32, 400])\\r\\nt2= torch.Si...\n",
       "9317     [const pythonProcess = spawn('python',[\"./test...\n",
       "9318     [class Discriminator(nn.Module):\\r\\ndef __init...\n",
       "9319     [trainer = Trainer(gpus=None)\\r\\n, trainer = T...\n",
       "9320     [# Create empty VGG16 model (random weights)\\r...\n",
       "9321     [# Create empty VGG16 model (random weights)\\r...\n",
       "9322     [# Create empty VGG16 model (random weights)\\r...\n",
       "9323     [# Create empty VGG16 model (random weights)\\r...\n",
       "9324     [optimizer.zero_grad()\\r\\nloss_G_D = loss_func...\n",
       "9325     [requires_grad, env_grads, env_grads[0], grad,...\n",
       "9326     [requires_grad, env_grads, env_grads[0], grad,...\n",
       "9327     [model.compile(..., loss='binary_crossentropy'...\n",
       "9328     [! fairseq-train data-bin/iwslt14.tokenized.de...\n",
       "9329     [! fairseq-train data-bin/iwslt14.tokenized.de...\n",
       "9333     [y = model(x)\\r\\n\\r\\nfor i in range(len(y)): #...\n",
       "9334     [forward, loss, forward(), sigmoid(), softmax(...\n",
       "9335     [model_name = 'kuisailab/albert-large-arabic' ...\n",
       "9336     [x = torch.cat([x1,x2],1) RuntimeError: Sizes ...\n",
       "9337     [criterion = nn.CrossEntropyLoss()\\r\\n, label ...\n",
       "9338     [criterion = nn.CrossEntropyLoss()\\r\\n, label ...\n",
       "9339     [criterion = nn.CrossEntropyLoss()\\r\\n, label ...\n",
       "9340     [ pip3 install opencv-python\\r\\n, Defaulting t...\n",
       "9342     [nn.Linear, def __init__, def forward(), class...\n",
       "9343     [u, x, import torch\\r\\nimport torch.nn as nn\\r...\n",
       "9344     [u, x, import torch\\r\\nimport torch.nn as nn\\r...\n",
       "9345     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9346     [class NeuralNet(nn.Module):\\r\\n    def __init...\n",
       "9347     [pip install torch==1.2.0+cpu torchvision==0.4...\n",
       "9348     [nn.Module,     def conv_module(x, K, kX, kY, ...\n",
       "9349     [nn.Module,     def conv_module(x, K, kX, kY, ...\n",
       "9350     [device = torch.device('cuda') if torch.cuda.i...\n",
       "9351     [import pandas as pd\\r\\nimport sqlite3 as sq\\r...\n",
       "9352     [class LSTMClassifier(nn.Module):\\r\\n\\r\\n   de...\n",
       "9353     [import torchvision.transforms as tt\\r\\nfrom t...\n",
       "9354     [# Preprocessing\\r\\nimages = predictor.model.p...\n",
       "9355     [class Net(BaseFeaturesExtractor):\\r\\n\\r\\n    ...\n",
       "9356     [x1 = (max-min)*torch.rand(1, 21, dtype=torch....\n",
       "9357     [ import torch\\r\\n import torch.nn as nn\\r\\n i...\n",
       "9358     [x1 = (max-min)*torch.rand(1, 21) + min\\r\\nx2 ...\n",
       "9359     [x1 = (max-min)*torch.rand(1, 21) + min\\r\\nx2 ...\n",
       "9360     [class GRU(nn.Module):\\r\\n    def __init__(sel...\n",
       "9361     [requirements.txt, pip install NAME_OF_THE_PAC...\n",
       "9362     [training_sampler = DistributedSampler(trainin...\n",
       "9363     [training_sampler = DistributedSampler(trainin...\n",
       "9364     [EfficientNetB3, y_preds = model(images), Data...\n",
       "9365     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "9369     [....\\r\\n\\r\\nself.G_loss.backward(retain_graph...\n",
       "9370     [import torchvision\\r\\nfrom torchvision.models...\n",
       "9371     [    42  feats = self.node_features[self.train...\n",
       "9373     [import torch\\r\\nN, C, H, W = 10, 3, 32, 32\\r\\...\n",
       "9374     [import torch\\r\\nN, C, H, W = 10, 3, 32, 32\\r\\...\n",
       "9376     [def set_tracking_running_stats(model):\\r\\n   ...\n",
       "9377     [def set_tracking_running_stats(model):\\r\\n   ...\n",
       "9379     [class MLP(torch.nn.Module):\\r\\ndef __init__(s...\n",
       "9380     [class LSTMnetwork(nn.Module):\\r\\ndef __init__...\n",
       "9381     [import csv\\r\\nimport os\\r\\nimport pandas as p...\n",
       "9383     [for epoch in tqdm(range(1, epochs+1)):\\r\\n   ...\n",
       "9384     [pytorch, [[[a,b],[c,d]], [[e,f], [g,h]], [[k,...\n",
       "9385     [import torch\\r\\nimport torch.nn.functional as...\n",
       "9386     [import numpy as np\\r\\nimport torch\\r\\n\\r\\n# R...\n",
       "9387     [Meshed-Memory Transformer Training\\r\\nLet's u...\n",
       "9388     [__getitem__, if self.transforms is not None:\\...\n",
       "9389     [decoder_start_token_id, decoder_start_token_i...\n",
       "9390     [images = torch.zeros(64, 3, 1024, 1024)\\r\\n, ...\n",
       "9391     [ preds = np.random.random_integers(0,500,(1,1...\n",
       "9392     [CUDA out of memory, try:\\r\\n    result = mode...\n",
       "9393     [CUDA out of memory, try:\\r\\n    result = mode...\n",
       "9396     [torchscript, C++, $ ./example-app ../turb_nn....\n",
       "9397     [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndim...\n",
       "9398     [list_labels = [ 0, 1, 0]\\r\\n\\r\\n# List of sen...\n",
       "9399     [list_labels = [ 0, 1, 0]\\r\\n\\r\\n# List of sen...\n",
       "9400     [import torch.nn as nn\\r\\n\\r\\nBLSTM = nn.LSTM(...\n",
       "9401     [Name                       Self CPU total %  ...\n",
       "9402     [from torch.nn import Transformer\\r\\nclass Tra...\n",
       "9404     [A=[[3,2],[1,-3]], B=[[3],[-10]], AX=B, torch....\n",
       "9405     [len(dict) = #number of separate pixels groups...\n",
       "9406     [pip install torch==1.7.0+cpu torchvision==0.8...\n",
       "9407     [pip install torch==1.7.0+cpu torchvision==0.8...\n",
       "9408     [ import torch\\r\\n from torch import nn\\r\\n im...\n",
       "9409     [    def __init__(self):\\r\\n        super().__...\n",
       "9410     [    def __init__(self):\\r\\n        super().__...\n",
       "9412     [nvcc --version, conda install pytorch torchvi...\n",
       "9413     [autograd, tape-based autograd, Pytorch, Gradi...\n",
       "9414     [image_set = torch.rand([10000, 28, 28], dtype...\n",
       "9415     [cuda-cublas-dev-10-2, libcublas-dev, [ 67%] B...\n",
       "9418     [for index_x,x in enumerate(unique_cusip_list)...\n",
       "9419     [class classification(nn.Module):\\r\\ndef __ini...\n",
       "9420     [import torch\\r\\n# t1.shape = (4,1,3)\\r\\nt1 = ...\n",
       "9421     [import pandas as pd\\r\\n_df = pd.DataFrame({'i...\n",
       "9422     [enumerate(data loader), while, StopIteration,...\n",
       "9424     [from subprocess import Popen\\r\\nimport sys\\r\\...\n",
       "9425     [from subprocess import Popen\\r\\nimport sys\\r\\...\n",
       "9426     [from subprocess import Popen\\r\\nimport sys\\r\\...\n",
       "9427     [from subprocess import Popen\\r\\nimport sys\\r\\...\n",
       "9428     [grid_sample, N, D, H, W, d, (N,2,H,W), (N,3,D...\n",
       "9429     [grid_sample, N, D, H, W, d, (N,2,H,W), (N,3,D...\n",
       "9430     [from torch.utils.tensorboard import SummaryWr...\n",
       "9431     [from torch.utils.cpp_extension import load\\r\\...\n",
       "9432     [tf.keras.constraints.NonNeg()\\r\\n, class Clas...\n",
       "9433     [tf.keras.constraints.NonNeg()\\r\\n, class Clas...\n",
       "9434     [torch.set_printoptions(precision=20) \\r\\n, be...\n",
       "9436     [from transformers import pipeline\\r\\n\\r\\nnlp ...\n",
       "9437     [# l: the pixel length of each tile\\r\\nimg_res...\n",
       "9438     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "9439     [resnet18, torchvision, nn.Linear(512, 1), BCE...\n",
       "9440     [isinstance, torch.Tensor's, dtype,     assert...\n",
       "9441     [LoadData(Dataset):\\r\\n    def __init__(self, ...\n",
       "9442     [model = models.resnet18(pretrained=True)\\r\\nm...\n",
       "9443     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9444     [def fine_tuning(self, data, labels, num_epoch...\n",
       "9445     [MelSpectrogram, eval_seq_specgram = torchaudi...\n",
       "9446     [MelSpectrogram, eval_seq_specgram = torchaudi...\n",
       "9447     [MelSpectrogram, eval_seq_specgram = torchaudi...\n",
       "9448     [matplotlib  3.3.3\\r\\ntorch       1.7.0\\r\\npan...\n",
       "9449     [import torch\\r\\n\\r\\na = torch.tensor([[1,2], ...\n",
       "9450     [torch.Size([3, 320, 480]), tensor([[[0.2980, ...\n",
       "9451     [torch.Size([3, 320, 480]), tensor([[[0.2980, ...\n",
       "9452     [import keras.backend as K\\r\\n\\r\\ndef single_c...\n",
       "9453                             [(X, Y, Z, C), (X, Y, Z)]\n",
       "9454     [Lorem &lt;NP&gt; Ipsum &lt;NP&gt; dummy &lt;N...\n",
       "9455     [TypeError: tuple indices must be integers or ...\n",
       "9456     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9457     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9458     [class NN(nn.Module):\\r\\n    def __init__(\\r\\n...\n",
       "9459     [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "9460     [Linear, class TransformerReconstruct(nn.Modul...\n",
       "9461     [Linear, class TransformerReconstruct(nn.Modul...\n",
       "9462         [[batch_size,num_variants,1,height,width], 1]\n",
       "9463     [PATH = './net.pth'\\r\\nmodel_ft = models.resne...\n",
       "9464     [PATH = './net.pth'\\r\\nmodel_ft = models.resne...\n",
       "9465     [Softmax Regression, Pytorch, Implement Softma...\n",
       "9466     [class ConvolutionalNetwork(nn.Module):\\r\\n   ...\n",
       "9467     [def autotune(trial):\\r\\n\\r\\n      cfg= { 'dev...\n",
       "9468     [loss.backward(), class Neg_Pearson(nn.Module)...\n",
       "9469     [#1. Inference the model\\r\\nmodel = PhysNet_pa...\n",
       "9470     [start_time = time.time()\\r\\n\\r\\nwith torch.no...\n",
       "9471     [class MyFunc(torch.autograd.Function):\\r\\n\\r\\...\n",
       "9472     [x**(k-1), x, x**k, p, evaluate, x, def evalua...\n",
       "9473     [x**(k-1), x, x**k, p, evaluate, x, def evalua...\n",
       "9476     [[1,1,9,4,6,5,1,2,9,9,11,4,3,6,5,2,3,4], [0,0,...\n",
       "9477     [1, 100, 100, def stress_plot(y, y_hat):\\r\\n \\...\n",
       "9478     [  train_set = Database_load(root = \"C:\\\\Users...\n",
       "9479     [pip install torch===1.7.0 torchvision===0.8.1...\n",
       "9480     [pip install torch===1.7.0 torchvision===0.8.1...\n",
       "9481     [[-0.76797587, 0.0713816], X = [[[-0.11675862,...\n",
       "9483     [#!/usr/bin/python\\r\\n\\r\\nimport os, logging\\r...\n",
       "9484     [#!/usr/bin/python\\r\\n\\r\\nimport os, logging\\r...\n",
       "9485     [x = torch.tensor([[[1, 2],\\r\\n               ...\n",
       "9486     [class ExNet(nn.Module):\\r\\n    def __init__(s...\n",
       "9487     [nn.LogSoftmax(dim=1), sklearn.utils.class_wei...\n",
       "9488     [nn.LogSoftmax(dim=1), sklearn.utils.class_wei...\n",
       "9489     [a = th.from_numpy(np.array([ [1, 0], [0, 1], ...\n",
       "9490     [gen.state_dict(), import torch\\r\\nimport torc...\n",
       "9492     [component, None, import torch\\r\\n\\r\\nclass Li...\n",
       "9494     [import numpy as np\\r\\n\\r\\npoint1 = np.random....\n",
       "9495     [def huber(a, b): \\r\\n   res = (((a-b)[abs(a-b...\n",
       "9497     [print(model.layer1[0].weight.grad), tensor([[...\n",
       "9498     [import torch\\r\\nimport transformers\\r\\ntokeni...\n",
       "9499     [import torch \\r\\ntorch.randint(low=0, high=2,...\n",
       "9502     [Inception_v3, model = models.inception_v3(pre...\n",
       "9504     [xt = tensor(3.).requires_grad_()\\r\\nxt\\r\\n[ou...\n",
       "9506     [transform = transforms.Compose([transforms.Re...\n",
       "9507     [import h5py\\r\\nimport torch\\r\\nimport numpy a...\n",
       "9508     [def forward(self, inputs, future=0, teacher_f...\n",
       "9509     [!pip install cv3\\r\\n, ERROR: Could not find a...\n",
       "9510     [for i, (train_index, val_index) in enumerate(...\n",
       "9511     [ElasticWeightConsolidation, torch.autograd.fu...\n",
       "9512     [SRC = Field(tokenize=tokenize_en,\\r\\n        ...\n",
       "9513     [class MyTestDataset(torchvision.datasets.visi...\n",
       "9514     [    for batch_id, (data, target) in enumerate...\n",
       "9515     [convolution_backward, convolution_backward_ov...\n",
       "9516     [import torchvision\\r\\nfrom torch.utils.data i...\n",
       "9517     [id1 = ttd.LabelField(use_vocab =False)\\r\\ntes...\n",
       "9518     [class RBM(nn.Module):\\r\\n    '''\\r\\n    This ...\n",
       "9519     [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "9520     [from transformers import DistilBertForTokenCl...\n",
       "9521     [from transformers import DistilBertForTokenCl...\n",
       "9522     [RuntimeError: PyTorch was compiled without Nu...\n",
       "9523     [   class DownSampleModule(nn.Module):\\r\\n   d...\n",
       "9525     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9526     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9527     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9528     [cmake_minimum_required (VERSION 3.8)\\r\\n\\r\\np...\n",
       "9529     [X = np.array([[1,2],[3,4],[5,6],[6,7]])\\r\\n\\r...\n",
       "9531     [class Inception(nn.Module):\\r\\ndef __init__(s...\n",
       "9532     [import torch.nn as nn\\r\\nfrom torch import op...\n",
       "9533     [ppms = []\\r\\nfor ii in [1, 3, 5]:\\r\\n    ppms...\n",
       "9534     [class Context:\\r\\n\\r\\n    def __init__(self):...\n",
       "9536     [class Net(torch.nn.Module):\\r\\n    def __init...\n",
       "9537     [rPPG = (shape(torch.Size([4, 128])), BVP_labe...\n",
       "9538     [rPPG = (shape(torch.Size([4, 128])), BVP_labe...\n",
       "9539     [train.txt, class DigitDataset(Dataset):\\r\\n  ...\n",
       "9540     [train.txt, class DigitDataset(Dataset):\\r\\n  ...\n",
       "9541     [train.txt, class DigitDataset(Dataset):\\r\\n  ...\n",
       "9542     [|-------------|----------|              |----...\n",
       "9544     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "9545     [RobertaForMaskedLM, ByteLevelBPETokenizer, to...\n",
       "9546     [Keras, VGG19, include_top = False, model = ke...\n",
       "9547     [Keras, VGG19, include_top = False, model = ke...\n",
       "9548     [torchvision.transforms.ToTensor(), trans = tr...\n",
       "9549     [class ImageLSTM(nn.Module):\\r\\ndef __init__(s...\n",
       "9552     [Pytorch, val1, val1, 1/var1, 1-var1, def loss...\n",
       "9553     [.pth model to onnx, import io\\r\\nimport numpy...\n",
       "9554     [def forward(self, x):\\r\\n        x = T.tensor...\n",
       "9555     [def forward(self, x):\\r\\n        x = T.tensor...\n",
       "9556     [torch.optim.Adam(weight_decay=0.01), torch.op...\n",
       "9557     [import pandas as pd\\r\\n\\r\\nData=pd.read_csv(\"...\n",
       "9559     [def init_hidden(self, x, device=None): # inpu...\n",
       "9560     [# import the necessary packages\\r\\nfrom tenso...\n",
       "9561     [pip install easyocr\\r\\n, ERROR: torchvision 0...\n",
       "9562     [    def __init__(self):\\r\\n        super(CNNM...\n",
       "9563     [loss = nn.CrossEntropyLoss()\\r\\ninput = torch...\n",
       "9564     [N x M x D, N x D x 1, N x M x 1, N, M x D, D ...\n",
       "9565     [A = torch.tensor([1,2,3,4,5,6])\\r\\n, [1, 1*2,...\n",
       "9566     [from transformers import BertForTokenClassifi...\n",
       "9567     [from transformers import BertForTokenClassifi...\n",
       "9568     [.cov(), def get_covariance(tensor):\\r\\n    bn...\n",
       "9569     [Traceback (most recent call last):\\r\\n  File ...\n",
       "9570     [Scaling parameters by 0.12 to account for a b...\n",
       "9571     [x, [N, N_g, 2], N * N_g, x[i, j, :], j, i, x_...\n",
       "9572     [+-----------------------------+\\r\\n| Filepath...\n",
       "9573     [ def train(epoch):\\r\\n      model.train()\\r\\n...\n",
       "9574     [conv1, model = nn.DataParallel(model), class ...\n",
       "9575     [from transformers import BertForSequenceClass...\n",
       "9576     [np.nan, import torch\\r\\n\\r\\ntensor = torch.Te...\n",
       "9577     [from torch.nn.functional import hardtanh, sig...\n",
       "9578     [t, index, t, index, t, t = torch.randn([3, 5,...\n",
       "9579     [def diffMask(img1=None, img2=None, opt=None, ...\n",
       "9580     [class QueryDataset(torch.utils.data.Dataset):...\n",
       "9581     [class QueryDataset(torch.utils.data.Dataset):...\n",
       "9583     [class GRUNet(nn.Module):\\r\\n    def __init__(...\n",
       "9584     [criterion = nn.NLLLoss(), loss = criterion(ou...\n",
       "9585     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "9586     [cls_tokens = output_tokens[:, 0, :]  # CLS to...\n",
       "9587     [weights = torch.randn(784, 10) / math.sqrt(78...\n",
       "9588     [class FirstModel(nn.Module):\\r\\n    def __ini...\n",
       "9589     [from PIL import Image\\r\\n\\r\\nimg_list = []\\r\\...\n",
       "9590     [class ImageLSTM(nn.Module):\\r\\ndef __init__(s...\n",
       "9591     [tensor([[[ 0.,  1.,  2.],\\r\\n         [ 3.,  ...\n",
       "9592     [tensor([[[ 0.,  1.,  2.],\\r\\n         [ 3.,  ...\n",
       "9593     [import torch\\r\\nimport time\\r\\n\\r\\nprint(torc...\n",
       "9594     [Y, T, X, g, Y=g(T, X), L, f, Y=L(T)f(X), L, f...\n",
       "9595     [[0, 1], torch.cov(), def get_covariance(tenso...\n",
       "9596     [third_model = torch.nn.ModuleDict({\\r\\n'flatt...\n",
       "9597     [import torch\\r\\n\\r\\n# create indices\\r\\ni = t...\n",
       "9598     [    sm = torch.jit.script(net)\\r\\n    sm.save...\n",
       "9599     [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "9600     [root - WARNING - Loss: 203.81146240234375\\r\\n...\n",
       "9601     [input = torch.rand((n,3),requires_grad=True)\\...\n",
       "9602     [   Traceback (most recent call last):\\r\\n  Fi...\n",
       "9603     [MTLWrapper, BaseModel, model.zero_grad(), ret...\n",
       "9604     [def vec_datastr(vector):\\r\\n\\r\\n    vector = ...\n",
       "9605                [nn.Embedding, embedding.parameters()]\n",
       "9606     [torch.matmul, torch.mm, A = [a_1, a_2, ..., a...\n",
       "9607     [torch.matmul, torch.mm, A = [a_1, a_2, ..., a...\n",
       "9608     [model = transformers.BertForSequenceClassific...\n",
       "9609     [model = transformers.BertForSequenceClassific...\n",
       "9610     [import tvm, torch, os\\r\\nfrom tvm import rela...\n",
       "9611                       [torch.nn.Embedding, Embedding]\n",
       "9612     [torch.nn.functional.unfold, #input x:[16, 1, ...\n",
       "9613     [from torch.nn.parameter import Parameter\\r\\nf...\n",
       "9614     [x_train_tensor = torch.tensor(x_train.values....\n",
       "9615     [numpy.linalg.multi_dot(), import numpy as np\\...\n",
       "9616     [numpy.linalg.multi_dot(), import numpy as np\\...\n",
       "9617     [def init_hidden(self, batch_size):\\r\\n    '''...\n",
       "9618     [def init_hidden(self, batch_size):\\r\\n    '''...\n",
       "9619     [58/69: Converting Node Type Add\\r\\n59/69: Con...\n",
       "9620     [class Generator(nn.Module):\\r\\n    def __init...\n",
       "9621     [torch.autograd.Function, z(x, t), y, x, t, ba...\n",
       "9622     [in __init__\\r\\n    super(_open_zipfile_reader...\n",
       "9623     [  def forward(self, input_tokens, output_toke...\n",
       "9624     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "9625     [A(1x16x5x5)---\\\\r\\n                 -&gt; con...\n",
       "9626     [fit(X, y=None, *, groups=None, **fit_params)[...\n",
       "9627     [def get_model():\\r\\n    model = models.vgg16(...\n",
       "9628     [class My_layer(torch.nn.Module):\\r\\n    def _...\n",
       "9629     [@register_torch_op, from coremltools.converte...\n",
       "9630     [quant, np.uint8, import torch\\r\\n\\r\\nquant = ...\n",
       "9631     [ddp, validation_epoch_end, num_gpus, 1/num_gp...\n",
       "9632     [ddp, validation_epoch_end, num_gpus, 1/num_gp...\n",
       "9633     [self.linear_pre = nn.Linear(input_dim, featur...\n",
       "9634     [class SimpleLayer(tf.keras.layers.Layer):\\r\\n...\n",
       "9635     [class SimpleLayer(tf.keras.layers.Layer):\\r\\n...\n",
       "9636     [show_memory('before call')\\r\\noutputs = model...\n",
       "9637     [epoch, StepLR, optimizer.set_lr(lr), optimize...\n",
       "9638     [StepLR, Adam,     optimizer = torch.optim.Ada...\n",
       "9639     [(base) C:\\User\\r\\ntorch.cuda.is_available()\\r...\n",
       "9640     [(base) C:\\User\\r\\ntorch.cuda.is_available()\\r...\n",
       "9641     [batch_edges, past_trained_nodes, import os\\r\\...\n",
       "9642     [map_location = lambda storage, loc: storage\\r...\n",
       "9643     [torch.linspace(0, 10, 10), reduced_tensor = t...\n",
       "9644     [torch.jit.script, torch.jit.trace, torch_tvm,...\n",
       "9645     [unfold, as_stride, import torch\\r\\nimport tor...\n",
       "9646     [docker build -t test .\\Desktop\\Docker\\Docker_...\n",
       "9647     [import torch_tvm\\r\\ntorch_tvm.enable()\\r\\n, i...\n",
       "9648     [M, x, x, # Given something like:\\r\\nM = torch...\n",
       "9649     [CrossEntropyLoss, from  torch  import Tensor ...\n",
       "9650     [NDArray, requires_grad, x.grad, None, import ...\n",
       "9651     [r =0.5\\r\\n#Sample 3D space\\r\\nmin = -10\\r\\nma...\n",
       "9653     [def my_loss_func(logits, sigma, labels, num_p...\n",
       "9655                                     [view_as_windows]\n",
       "9656     [class Encoder(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "9657     [First diverging operator:\\r\\n    Node diff:\\r...\n",
       "9658     [import torch\\r\\n\\r\\nclass MyReLU(torch.autogr...\n",
       "9659     [__getitem()__, /home/bohare/data/images, /hom...\n",
       "9660     [tensor([[[-0.0650, -0.0712, -0.1024, -0.0544,...\n",
       "9661     [tensor([[[-0.0650, -0.0712, -0.1024, -0.0544,...\n",
       "9663     [class CustomDataset(Dataset):\\r\\ndef __init__...\n",
       "9664     [complex_det, RuntimeError: isDifferentiableTy...\n",
       "9665     [shape = [784,64,64,64,10]\\r\\n, class Net(nn.M...\n",
       "9666     [1 from torch.distributions.multivariate_norma...\n",
       "9667     [T=32768;\\r\\nJ=8;\\r\\nQ=12;\\r\\nif use_cuda:\\r\\n...\n",
       "9668     [import warnings\\r\\nfrom torch.utils.data impo...\n",
       "9669     [3d_tensor + 1d_tensor, 1d_tensor[i], 3d_tenso...\n",
       "9670     [import torch\\r\\nfrom models.cnn import net\\r\\...\n",
       "9671     [import torch\\r\\n\\r\\nmodel = torch.load('./gru...\n",
       "9672     [self.env = self.ks_env.train([opponent, None]...\n",
       "9674     [def flatten_input64(Input): #convert (:,4,4,2...\n",
       "9675                                       [kl_divergence]\n",
       "9676     [ x_6 = torch.cat((x_1, x_2_1, x_3_1, x_5_1), ...\n",
       "9677     [# importing libraries\\r\\n\\r\\nimport tkinter a...\n",
       "9680     [import torch\\r\\nimport torch.nn.functional as...\n",
       "9681     [(3.6m, 30, 32), np.save(), np.save(), np.load...\n",
       "9682     [(3.6m, 30, 32), np.save(), np.save(), np.load...\n",
       "9683     [(3.6m, 30, 32), np.save(), np.save(), np.load...\n",
       "9685     [hstack, a = torch.tensor([1, 2, 3])\\r\\nb = to...\n",
       "9686     [def set_seed(seed, cuda=True):\\r\\n    np.rand...\n",
       "9688     [e.g.\\r\\ninputs = torch.rand(1,5)\\r\\nweights =...\n",
       "9689     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "9690     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "9691     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "9692     [import torch\\r\\nimport torch.nn.functional as...\n",
       "9693     [from torch_geometric.datasets import TUDatase...\n",
       "9694     [writer = SummaryWriter(log_dir='graphs')\\r\\n\\...\n",
       "9696     [model.state_dict(), model.parameters(), model...\n",
       "9698     [import torch.nn as nn\\r\\nfrom torch.nn.utils....\n",
       "9699     [from os.path import exists\\r\\ncuda_output = !...\n",
       "9700     [network = Network()\\r\\nnetwork.cuda()    \\r\\n...\n",
       "9701     [size = len(CIFAR10_training)\\r\\ndataset_indic...\n",
       "9702     [\\r\\nimport numpy as np\\r\\nimport torch\\r\\nimp...\n",
       "9703     [\\r\\nimport numpy as np\\r\\nimport torch\\r\\nimp...\n",
       "9704     [id, created_date, some_value_a, some_value_b,...\n",
       "9706                                     [[4,10], [4,5+5]]\n",
       "9707     [!pip install tensorboard\\r\\ntensorboard --log...\n",
       "9708     [transformers, 1 / 1\\r\\nCannot re-initialize C...\n",
       "9709     [valid_metrics, train_loop, def train_model(mo...\n",
       "9710     [# Example:\\r\\nx = torch.tensor([[1,2,3],\\r\\n ...\n",
       "9711     [# Example:\\r\\nx = torch.tensor([[1,2,3],\\r\\n ...\n",
       "9712     [output_dir = './ner_model/'\\r\\nmodel = BertFo...\n",
       "9713     [to_tensor = transforms.ToTensor()\\r\\n\\r\\nland...\n",
       "9714     [to_tensor = transforms.ToTensor()\\r\\nimg = to...\n",
       "9715     [to_tensor = transforms.ToTensor()\\r\\nimg = to...\n",
       "9716     [# Load pre-trained model (weights)\\r\\nmodel =...\n",
       "9717     [$ python\\r\\nPython 3.7.6 (default, Jan  8 202...\n",
       "9718     [mean = 0.0\\r\\nstd = 0.0\\r\\nnb_samples = 0.0\\r...\n",
       "9719     [ValueError: Expected input batch_size (64) to...\n",
       "9720     [class Classifier(nn.Module):\\r\\n    def __ini...\n",
       "9721     [# Device configuration\\r\\ndevice = torch.devi...\n",
       "9722     [num_classes = 4 * 2 #4 coordinates X and Y fl...\n",
       "9723     [def beam_search_decoder(data, k):\\r\\n    sequ...\n",
       "9724     [def beam_search_decoder(data, k):\\r\\n    sequ...\n",
       "9725     [!pip install git+https://github.com/philferri...\n",
       "9726     [&lt;pad&gt;, &lt;pad&gt;, mkdir data\\r\\nwget ...\n",
       "9727     [torch.Size([1, 16]), [1, 2, 3, 4, 5, 6, 7, 8,...\n",
       "9728     [loss.backward(), retain_graph=True, import to...\n",
       "9729     [torch.Size([1, 305760]), 305760, [1, 306000], 0]\n",
       "9731     [from .dataset import CloudDataset\\r\\nfrom .sp...\n",
       "9732     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9733     [CUDA out of memory, kill -9 PID, $ nvidi-smi,...\n",
       "9734     [transformed_dataset = MothLandmarksDataset(cs...\n",
       "9737     [git clone https://github.com/ElementAI/N-BEAT...\n",
       "9738     [# Improved version of: https://github.com/Pro...\n",
       "9739     [RuntimeError: Expected object of scalar type ...\n",
       "9740     [df.head(), df.object.value_counts(), human   ...\n",
       "9741     [import cv2\\r\\nfrom facial_emotion_recognition...\n",
       "9742     [import cv2\\r\\nfrom facial_emotion_recognition...\n",
       "9743     [conda create -n FairMOT\\r\\nconda activate Fai...\n",
       "9744     [import torch\\r\\ndef torch_conv_func(x, num_gr...\n",
       "9746     [a, [seq_len, 2], seq_len, a[:, 0], a[:, 1], a...\n",
       "9747     [a, [seq_len, 2], seq_len, a[:, 0], a[:, 1], a...\n",
       "9748     [  Largest program allocations in hbm:\\r\\n\\r\\n...\n",
       "9749     [mat=[[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,1...\n",
       "9750     [mat=[[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13,1...\n",
       "9751     [The size of tensor a (707) must match the siz...\n",
       "9752     [transforms = transforms.Compose([transforms.R...\n",
       "9753     [from __future__ import print_function\\r\\nimpo...\n",
       "9754     [class Model(nn.Module):\\r\\ndef __init__(self)...\n",
       "9755     [A.shape, B.shape, C[:, :, i, j] = torch.mean(...\n",
       "9756     [1&gt;[ RUN      ] EmbedderModelForwardFixture...\n",
       "9757     [import robust_loss_pytorch.general\\r\\n\\r\\nada...\n",
       "9758     [import torch\\r\\nimport numpy as np\\r\\n\\r\\nima...\n",
       "9759     [class BidirectionalGRU(nn.Module):\\r\\n    def...\n",
       "9761     [torch.nn.functional.interpolate, nearest, lin...\n",
       "9763     [batch_size = 2\\r\\ndata = torch.zeros((batch_s...\n",
       "9764     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9766     [pytorch, pytorch, import torch, top, ctrl-c, ...\n",
       "9767     [class BorderTransformer(torch.nn.Module):\\r\\n...\n",
       "9768     [RuntimeError: leaf variable has been moved in...\n",
       "9769     [ValueError                                Tra...\n",
       "9771     [class ResBlock(nn.Module, ABC):\\r\\n    def __...\n",
       "9772     [RuntimeError: expected scalar type Float but ...\n",
       "9773     [FROM python:latest\\r\\nADD requirements.txt .\\...\n",
       "9774     [class Neural_Net_Interface(ClassifierMixin, B...\n",
       "9775     [     output = net(input)\\r\\n\\r\\n     input = ...\n",
       "9776     [pytorch, dat.shape = torch.Size([128, 3, 64, ...\n",
       "9777     [pytorch, dat.shape = torch.Size([128, 3, 64, ...\n",
       "9778     [import torch\\r\\n\\r\\nx = torch.ones(3, require...\n",
       "9779     [from captum.attr import IntegratedGradients\\r...\n",
       "9781     [function_pytorch(prediction, Q_sample), funct...\n",
       "9782     [t, (6, 10), (3, 4, 10), t, t = torch.range(1,...\n",
       "9783     [    import os\\r\\n    import pandas as pd\\r\\n ...\n",
       "9784     [from keras.preprocessing.image import img_to_...\n",
       "9785     [a = torch.tensor([[4, 9, 7, 4, 0],\\r\\n       ...\n",
       "9786     [a = torch.tensor([[4, 9, 7, 4, 0],\\r\\n       ...\n",
       "9787     [a = torch.tensor([[4, 9, 7, 4, 0],\\r\\n       ...\n",
       "9788     [FROM pytorch/pytorch\\r\\nADD . / project/\\r\\nR...\n",
       "9789     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "9790     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "9792     [##torch.autograd.set_detect_anomaly(True)\\r\\n...\n",
       "9793                                        [[30522, 768]]\n",
       "9794                                        [[30522, 768]]\n",
       "9795     [import torch as torch\\r\\n\\r\\nn=10\\r\\nx = torc...\n",
       "9797     [nn.Identity(), W_s, \\r\\nclass ResidualBlock(n...\n",
       "9798     [torch.scatter_(), X = [batch, 100], label = [...\n",
       "9799     [def train_gray(epoch, data_loader, device, mo...\n",
       "9800     [class LinearRegression():\\r\\n    def __init__...\n",
       "9801     [:~$ gcloud compute tpus create train-bert-one...\n",
       "9803     [#Design the neural network\\r\\nmodel = Sequent...\n",
       "9804     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9805     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9806     [import matplotlib.pyplot as plt\\r\\n%matplotli...\n",
       "9808     [for epoch in range(num_epochs):\\r\\n        # ...\n",
       "9809     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9810     [archive/data.pkl, import torch\\r\\ncachefile =...\n",
       "9811     [archive/data.pkl, import torch\\r\\ncachefile =...\n",
       "9812     [archive/data.pkl, import torch\\r\\ncachefile =...\n",
       "9813     [layer {\\r\\n  name: \"conv3\"\\r\\n  type: \"Convol...\n",
       "9814     [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "9817     [   b_input_ids = batch[0].to(device)\\r\\n   b_...\n",
       "9819     [torchvision.transforms, torchvision.transform...\n",
       "9820     [torchvision.transforms, torchvision.transform...\n",
       "9821     [torchvision.transforms, torchvision.transform...\n",
       "9822     [train_data = np.array([np.sin(time), np.cos(t...\n",
       "9823     [conda env create -n torch -y python 3.7\\r\\nco...\n",
       "9824     [ a\\r\\ntensor([[1, 2, 0, 0],\\r\\n        [3, 4,...\n",
       "9825     [ a\\r\\ntensor([[1, 2, 0, 0],\\r\\n        [3, 4,...\n",
       "9826     [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "9828     [net = UNet(n_channels=3, n_classes=1, bilinea...\n",
       "9829     [  text = \"Some string about 5000 characters l...\n",
       "9830     [# pad the tensor\\r\\nzeros = torch.zeros(55).l...\n",
       "9832     [from torch.utils.data import TensorDataset, D...\n",
       "9835     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "9836     [conda install pytorch torchvision cudatoolkit...\n",
       "9837                     [padding='SAME', p = (n - 1) / 2]\n",
       "9839     [import torch\\r\\nn, d = 37700, 7842\\r\\nk = 4\\r...\n",
       "9840     [from sklearn.neural_network import MLPRegress...\n",
       "9841     [from sklearn.neural_network import MLPRegress...\n",
       "9842     [from sklearn.neural_network import MLPRegress...\n",
       "9843     [a, b, (m,n), m, d, m[i][j] = d(a[i], b[j]), c...\n",
       "9845     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "9846     [def split_equal_into_val_test(csv_file=None, ...\n",
       "9847     [class GraphSAGE(nn.Module):\\r\\n    def __init...\n",
       "9848     [RuntimeError: Boolean value of Tensor with mo...\n",
       "9849     [RuntimeError: /home/miranda9/data/f.pt is a z...\n",
       "9850     [RuntimeError: /home/miranda9/data/f.pt is a z...\n",
       "9851     [RuntimeError: /home/miranda9/data/f.pt is a z...\n",
       "9852     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "9853     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "9854     [def loss_fn(preds, targets):\\r\\n    return nn...\n",
       "9855     [class model(nn.Module):\\r\\ndef __init__(self)...\n",
       "9856     [class model(nn.Module):\\r\\ndef __init__(self)...\n",
       "9857     [pnt = [x y z]\\r\\n, def transform(pnt_cloud, T...\n",
       "9858     [Traceback (most recent call last):\\r\\n  File ...\n",
       "9859     [forward, class MyClass():\\r\\n    def __init__...\n",
       "9860     [forward, class MyClass():\\r\\n    def __init__...\n",
       "9861     [forward, class MyClass():\\r\\n    def __init__...\n",
       "9862     [forward, class MyClass():\\r\\n    def __init__...\n",
       "9863     [nn.DataParallel(model), .to(device), x, y, nn...\n",
       "9864     [optimizer = optim.LBFGS(model.parameters(), l...\n",
       "9865     [model = LongformerForMultiSequenceClassificat...\n",
       "9866     [from torch import nn\\r\\nfrom torch.autograd i...\n",
       "9867     [class LSTMClassifier(nn.Module):\\r\\n    def _...\n",
       "9868     [class LSTMClassifier(nn.Module):\\r\\n    def _...\n",
       "9871     [def grid_anchors(self, featmap_sizes, device=...\n",
       "9872     [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "9873     [nn.DataParallel, .to('cuda:0') and .to('cuda:...\n",
       "9874     [nn.DataParallel, .to('cuda:0') and .to('cuda:...\n",
       "9875     [WeightedRandomSampler, class GDataset(Dataset...\n",
       "9876     [def heatmap_to_pts(self, pts):  &lt;- pts [ba...\n",
       "9877     [boxes = torch.cat((boxes[classes==0], boxes[c...\n",
       "9878     [masks.shape:            torch.Size([10, 240, ...\n",
       "9879     [class LSTMModel(nn.Module):\\r\\n    def __init...\n",
       "9881     [class RecurrentNet(torch.nn.Module):\\r\\n    d...\n",
       "9882     [SEQ_LEN, (32, 32, 3, SEQ_LEN), SEQ_LEN = 10\\r...\n",
       "9883     [for iter in range(1, n_iters + 1):\\r\\n    cat...\n",
       "9884     [import onnx\\r\\nfrom onnx_tf.backend import pr...\n",
       "9885     [// Initialize 2-D array, each entry is some n...\n",
       "9886     [\\r\\nclass Model(nn.Module):\\r\\n   \\r\\n    def...\n",
       "9887     [def load_dataset():\\r\\n    train_loader = tor...\n",
       "9888     [def load_dataset():\\r\\n    train_loader = tor...\n",
       "9889     [W, b, W, b, # convert Numpy arrays to PyTorch...\n",
       "9890     [# torch = 1.5.0\\r\\n# transformers = 3.2.0\\r\\n...\n",
       "9891     [pytorch, nvidia-smi, 10.1, conda list, 10.2.8...\n",
       "9892     [Nvidie-430, 10.0.130, conda install -c pytorc...\n",
       "9893                              [numpy, pytorch, sin(x)]\n",
       "9894     [def forward(self, x):\\r\\n        with torch.s...\n",
       "9895     [model = my_model(input_size=1, hidden_layer_s...\n",
       "9896     [THCudaCheck FAIL file=/pytorch/aten/src/THC/T...\n",
       "9897     [state_dict(),         if('conv' in str(key)):...\n",
       "9898     [MNIST database of handwritten digits, t10k-im...\n",
       "9899     [MNIST database of handwritten digits, t10k-im...\n",
       "9900     [.pt, with open(a_sync_save, \"ab\") as f:\\r\\n  ...\n",
       "9902     [class DropoutLayer(nn.Module):\\r\\n    def __i...\n",
       "9904     [from multiprocessing import get_context\\r\\nim...\n",
       "9905     [pip3 install pytorch==1.0.1\\r\\nWARNING: pip i...\n",
       "9906     [pip3 install pytorch==1.0.1\\r\\nWARNING: pip i...\n",
       "9907     [torchaudio, ModuleNotFoundError: No module na...\n",
       "9909     [SharedMemory, c.to(device), import numpy as n...\n",
       "9910     [import torch.nn as nn\\r\\n\\r\\nclass mynet(nn.M...\n",
       "9911     [import torch.nn as nn\\r\\n\\r\\nclass mynet(nn.M...\n",
       "9912     [[I 16:02:20.653 NotebookApp] Kernel started: ...\n",
       "9913     [torch.nn.Conv1d(in_channels: int, out_channel...\n",
       "9914     [(base) mona@mona:~/research/3danimals/SMALVie...\n",
       "9915     [y_i = 3                             # Some in...\n",
       "9916     [class QuaternionLoss(torch.nn.Module):\\r\\n   ...\n",
       "9917     [def train(args, model, device, federated_trai...\n",
       "9918     [# I = [256, 256] image\\r\\nkernel_size = 16\\r\\...\n",
       "9919     [# I = [256, 256] image\\r\\nkernel_size = 16\\r\\...\n",
       "9920     [def get_weighted_imgs(points, centers, imgs):...\n",
       "9921     [tokenizer = BertTokenizerFast.from_pretrained...\n",
       "9923     [tokenizer = BertTokenizerFast.from_pretrained...\n",
       "9925     [$ python smal_viewer.py \\r\\nTraceback (most r...\n",
       "9926     [$ python smal_viewer.py \\r\\nTraceback (most r...\n",
       "9927     [from collections import OrderedDict\\r\\n\\r\\nim...\n",
       "9928     [from collections import OrderedDict\\r\\n\\r\\nim...\n",
       "9929     [1.3.1, 0.4.1, Installation\\r\\nWe recommend An...\n",
       "9930     [class DropoutLayer(nn.Module):\\r\\n    def __i...\n",
       "9931     [class DropoutLayer(nn.Module):\\r\\n    def __i...\n",
       "9932     [# fill the empty tensor iteratively\\r\\nbatch_...\n",
       "9933     [zarr, zarr, zarr, IterableDataset, class Data...\n",
       "9934     [\\theta, \\theta, class Net(Module):\\r\\n    def...\n",
       "9935     [src, (5, 3), adj, (5, 5), src = tensor([[ 0, ...\n",
       "9936     [src, (5, 3), adj, (5, 5), src = tensor([[ 0, ...\n",
       "9937     [BucketIterator, from allennlp.data.iterators ...\n",
       "9938     [ImportError                               Tra...\n",
       "9941     [def yinfer(X, beta):\\r\\n  return beta[0] + np...\n",
       "9942     [([[0.26, 0.09, 0.02],\\r\\n[0.27, 0.00, -0.05],...\n",
       "9943     [[(0,0),(1,0),(1,1)], [4,5,6], X[0,0] = 4, X[1...\n",
       "9944     [[(0,0),(1,0),(1,1)], [4,5,6], X[0,0] = 4, X[1...\n",
       "9945     [    Framecount  Expression                   ...\n",
       "9946     [result- tensor 1 X 251 X 20\\r\\nkernel - tenso...\n",
       "9947     [# Method 1\\r\\ndef __init__(self):\\r\\n    supe...\n",
       "9948     [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "9950     [librosa, python_speech_features, tensorflow.s...\n",
       "9951     [(base) C:\\Users\\My Pc&gt;pip install torch-po...\n",
       "9954     [import numpy as np\\r\\nimport torch\\r\\nx = np....\n",
       "9955     [register_hook, nn.Module, .grad, loss.backwar...\n",
       "9956     [lstm = nn.LSTM(input_size=26, hidden_size=128...\n",
       "9957     [for epoch in range(num_epochs):\\r\\n    epoch_...\n",
       "9958     [import torch\\r\\n\\r\\npositive_iter = torch.ten...\n",
       "9960     [class RNNModel(nn.Module):\\r\\ndef __init__(se...\n",
       "9961     [conda install pytorch torchvision cpuonly -c ...\n",
       "9962     [import torch\\r\\n\\r\\ntorch.cuda.is_available()...\n",
       "9963     [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "9964     [index_put, a = torch.zeros(2, 3)\\r\\na.index_p...\n",
       "9965     [train_dataset_full = torchvision.datasets.Fas...\n",
       "9966     [train_dataset_full = torchvision.datasets.Fas...\n",
       "9967     [train_dataset_full = torchvision.datasets.Fas...\n",
       "9968     [pipenv install [package], pipenv install torc...\n",
       "9969     [pipenv install [package], pipenv install torc...\n",
       "9970     [pipenv install [package], pipenv install torc...\n",
       "9971     [pipenv install [package], pipenv install torc...\n",
       "9972     [seed = 42\\r\\nos.environ['PYTHONHASHSEED'] = s...\n",
       "9973     [pip3 install torchvision, Requirement already...\n",
       "9974     [pip3 install torchvision, Requirement already...\n",
       "9975     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "9976     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "9977     [import torch\\r\\nimport torchvision\\r\\nmodel =...\n",
       "9978     [w = torch.randn(395,4, requires_grad=True)\\r\\...\n",
       "9980     [.numpy(), y_true = []\\r\\nfor X_batch, y_batch...\n",
       "9981     [.numpy(), y_true = []\\r\\nfor X_batch, y_batch...\n",
       "9982     [mnist-distributed.py, MASTER_ADDR, a.b.c.d, i...\n",
       "9984     [torch.cuda.is_available(), True, $ python\\r\\n...\n",
       "9985     [torch, arrays, import torch\\r\\nimport numpy a...\n",
       "9986     [a = np.arange(6).reshape((3, 2))\\r\\nf = np.re...\n",
       "9987     [a = np.arange(6).reshape((3, 2))\\r\\nf = np.re...\n",
       "9988     [((value0, row0, column0), (value1, row0, colu...\n",
       "9989     [    earlystop = EarlyStopping(monitor='val_ac...\n",
       "9990     [    earlystop = EarlyStopping(monitor='val_ac...\n",
       "9991     [pytorch, # optimizer = torch.optim.Adam(model...\n",
       "9992     [Cannot insert a Tensor that requires grad as ...\n",
       "9993     [Cannot insert a Tensor that requires grad as ...\n",
       "9994     [    L=[]\\r\\n    optimizer.zero_grad()\\r\\n    ...\n",
       "9995     [random.seed(args.seed)\\r\\nos.environ['PYTHONH...\n",
       "9996     [\\r\\ndef BERT_reasoning(tokens_tensor, segment...\n",
       "9997     [import numpy as np\\r\\nimport torch\\r\\nfrom sk...\n",
       "9998     [import torch\\r\\nfrom time import time\\r\\n\\r\\n...\n",
       "9999     [def train(epochs):\\r\\n    \"\"\"Main training lo...\n",
       "10000    [num_epochs = 10\\r\\nbatch_size = 64\\r\\nlearnin...\n",
       "10002         [for i, batch in enumerate(dataloader):\\r\\n]\n",
       "10003    [device = torch.device(\"cuda:0\")\\r\\n\\r\\nclass ...\n",
       "10004    [def process():\\r\\nfor img_file in os.listdir(...\n",
       "10005                                          [torch.det]\n",
       "10007    [a = tensor([[ 0.0113, -0.1666,  0.5960, -0.06...\n",
       "10008    [ID_REF  cg00001854  cg00270460  cg00293191  c...\n",
       "10009    [from pathlib import Path\\r\\nfrom absl import ...\n",
       "10010    [#transform for inceptionV3  \\r\\n\\r\\n\\r\\ntrain...\n",
       "10011    [device = torch.device(‘cuda’ if torch.cuda.is...\n",
       "10012    [input_data = Input(shape=(256, 64, 1), name=‘...\n",
       "10013                                            [PyTorch]\n",
       "10014    [img_test=Image.open(\"img.png\")\\r\\n\\r\\n#Perfor...\n",
       "10015    [bad_words_ids (List[int], optional) – List of...\n",
       "10016    [imdb, import transformers\\r\\nfrom sklearn imp...\n",
       "10017    [rho = base[0][:,1:,:]\\r\\nmu = base[1][:,1:,:]...\n",
       "10018    [import unittest\\r\\nimport torch\\r\\nfrom Seman...\n",
       "10019    [output, Dict[str, List[torch.Tensor]], c10::D...\n",
       "10022    [def to_var(x, volatile=True):\\r\\nif torch.cud...\n",
       "10023    [net = nn.Sequential(\\r\\n        nn.Conv2d(16,...\n",
       "10024    [batch_size * 1, indices, 0, 1, batch_size, in...\n",
       "10025    [ torch.sin(torch.ones(1)*2*np.pi)\\r\\ntensor([...\n",
       "10026    [(2, b, h), (b, 2*h), a = torch.tensor([[[1, 2...\n",
       "10027    [(2, b, h), (b, 2*h), a = torch.tensor([[[1, 2...\n",
       "10028    [import torch\\r\\nimport multiprocessing \\r\\n\\r...\n",
       "10029    [cmake_minimum_required(VERSION 3.0 FATAL_ERRO...\n",
       "10030    [class SiameseNetwork(nn.Module):\\r\\n    def _...\n",
       "10031    [model= models.segmentation.fcn_resnet101(pret...\n",
       "10032    [import pandas as pd\\r\\n\\r\\nimport sys\\r\\n\\r\\n...\n",
       "10033    [one_vec2 = torch.ones([batch_size, self.lbl_s...\n",
       "10034    [from transformers import AutoTokenizer, AutoM...\n",
       "10035    [from transformers import AutoTokenizer, AutoM...\n",
       "10036    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10037    [import torch\\r\\nmodel = torch.hub.load('pytor...\n",
       "10038    [    \\r\\ndef fl_train(args, model, device, fed...\n",
       "10039    [ARG BASE_IMAGE=pytorch/pytorch:1.5.1-cuda10.1...\n",
       "10042    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "10043    [Decoder(\\r\\n  (embedding): Embeddings(\\r\\n   ...\n",
       "10044    [import torch \\r\\nimport math \\r\\nimport numpy...\n",
       "10045    [trg_input = trg[:, :-1]\\r\\n, &lt;sos&gt; tok1...\n",
       "10046    [torch.Tensor, torch.Tensor, prob: torch.Tenso...\n",
       "10047                                     [autograd, 3, 3]\n",
       "10048    [class Autoencoder(nn.Module):\\r\\ndef __init__...\n",
       "10049    [prediction = myNetwork(img_batch)\\r\\nmax_act ...\n",
       "10050                   [grad_fn, grad_fn, next_functions]\n",
       "10051    [---------------------------------------------...\n",
       "10052    [import torch\\r\\nW_1 = = torch.reshape(W,(2,32...\n",
       "10053    [prng = RandomState(42)\\r\\nrandom_permute = pr...\n",
       "10054    [\\r\\nimport asyncio\\r\\nimport torch\\r\\nimport ...\n",
       "10055    [self.rnn = torch.nn.RNN(input_size=encoding_d...\n",
       "10057    [Collecting package metadata (current_repodata...\n",
       "10058    [Collecting package metadata (current_repodata...\n",
       "10059    [# pytorch client\\r\\nclient_output.backward(cl...\n",
       "10061    [SummaryWriter.add_hparams(params, values), 20...\n",
       "10062    [from sklearn.datasets import make_regression\\...\n",
       "10063    [device = torch.device('cuda:0' if torch.cuda....\n",
       "10065    [for ina,lab in train_loader:\\r\\n    print(typ...\n",
       "10066    [.eval(), (Pdb) p feature\\r\\ntensor([[[ -4.056...\n",
       "10067    [batch_first=False, import torch\\r\\nbatch_size...\n",
       "10069    [# tensorflow code\\r\\nwindow_size = 20\\r\\nbatc...\n",
       "10070    [2.00e-7, p = np.array([2.3078539778125768e-07...\n",
       "10071    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10072    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10073    [backward, y.backward(v), v, x = torch.randn(3...\n",
       "10074    [transform = transforms.Compose([transforms.Re...\n",
       "10075    [import torch.nn as nn\\r\\nclass DefaultModel(n...\n",
       "10077    [import torch\\r\\nfrom gan import Generator\\r\\n...\n",
       "10078    [data.shape [B,N,F], indices.shape [N,K], K, o...\n",
       "10079    [class RaccoonDataset(torch.utils.data.Dataset...\n",
       "10080    [[\\r\\n [tensor([-0.0705,  1.2019]), tensor([[0...\n",
       "10081    [[\\r\\n [tensor([-0.0705,  1.2019]), tensor([[0...\n",
       "10082    [L1Loss = nn.L1Loss(reduction='mean').to(devic...\n",
       "10083    [nvidia --version, nvidia-smi, pip3 install to...\n",
       "10084    [nvidia --version, nvidia-smi, pip3 install to...\n",
       "10085    [class Bottleneck(nn.Module):\\r\\n    def __ini...\n",
       "10086    [(x_train,y_train),(x_test,y_test)=cifar10.loa...\n",
       "10087    [def objective_function(self, x):\\r\\n    nvect...\n",
       "10088    [class MultiLayerPredictor(torch.nn.Module):\\r...\n",
       "10089    [class MultiLayerPredictor(torch.nn.Module):\\r...\n",
       "10090    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10091    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10092    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10093    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10094    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10095    [a, a[i][j], #include &lt;torch/extension.h&gt...\n",
       "10097    [data_ptr(), M, P, f: dtype(M)^2 -&gt; dtype(M...\n",
       "10098    [torch.no_grad(), forward(), torch.no_grad(), ...\n",
       "10099    [class DemoNN(nn.Module):\\r\\n    def __init__(...\n",
       "10100    [torch.einsum, einsum, a, b, (N,P), ni, (1,P),...\n",
       "10101    [torch.einsum, einsum, a, b, (N,P), ni, (1,P),...\n",
       "10102    [train_x_0.npy, train_x_1.npy, train_x_40.npy,...\n",
       "10103    [target = torch.tensor([1,2])\\r\\ninput = torch...\n",
       "10105    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10106    [UNet(\\r\\n  (conv_final): Conv2d(8, 1, kernel_...\n",
       "10107    [class MultiMLP(nn.Module):\\r\\n    \"\"\"\\r\\n    ...\n",
       "10109    [z, mat, z, z, def trans(z):\\r\\n    print(z)\\r...\n",
       "10110    [def mcdropout_test(batch_size,n_classes,model...\n",
       "10112    [    def batched_matrix_multiply(x, y, use_loo...\n",
       "10113    [+--------------------------------------------...\n",
       "10114    [+--------------------------------------------...\n",
       "10115    [C = nn.Conv1d(1, 1, kernel_size=1, stride=2)\\...\n",
       "10116    [embA0 embB0 1.0\\r\\nembA1 embB1 -1.0\\r\\nembA2 ...\n",
       "10117    [[16,3,256,256], [batch_size, in_channels, in_...\n",
       "10118    [[0, 255], [0,1], (data - mean) / std, 0.1307,...\n",
       "10119    [[0, 255], [0,1], (data - mean) / std, 0.1307,...\n",
       "10120    [[0, 255], [0,1], (data - mean) / std, 0.1307,...\n",
       "10121    [y_means = [1,2,3,4]\\r\\ny_variance = [0.01,0.0...\n",
       "10122    [BertTokenizer.save_pretrained(\"OUTPUT_DIR\")\\r\\n]\n",
       "10124        [loss = F.binary_cross_entropy(mask, gt)\\r\\n]\n",
       "10125        [loss = F.binary_cross_entropy(mask, gt)\\r\\n]\n",
       "10126    [for epoch in range((args.start_epoch+1), args...\n",
       "10127    [    for images,labels in testloader:\\r\\n     ...\n",
       "10129    [DataLoader, batch A (unaugmented images): 5, ...\n",
       "10131    [mat = torch.randn([20, 7]) * 100\\r\\nmat2 = to...\n",
       "10132    [mat = torch.randn([20, 7]) * 100\\r\\nmat2 = to...\n",
       "10133    [d:\\add_yolov3\\env\\lib\\site-packages\\PyInstall...\n",
       "10134    [class cost_function():\\r\\n    def __init__(se...\n",
       "10135    [class GraphAttentionLayer(nn.Module):\\r\\n    ...\n",
       "10136    [func, func, patient_name, device = torch.devi...\n",
       "10137    [import cv2\\r\\nimport numpy as np\\r\\nfrom tqdm...\n",
       "10138    [import cv2\\r\\nimport numpy as np\\r\\nfrom tqdm...\n",
       "10140    [torch.Size([8, 23])\\r\\n\\r\\n// where,\\r\\n// 8 ...\n",
       "10141    [import torch\\r\\nclass MyIterableDataset(torch...\n",
       "10142    [def mytest(model, data_loader):\\r\\n    with t...\n",
       "10143    [Input Tensor:  torch.Size([6, 1])\\r\\nTarget T...\n",
       "10144    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10145    [x = torch.arange(16, dtype=torch.float).resha...\n",
       "10146    [torch.manual_seed(1)\\r\\n\\r\\nclass build_EHRNN...\n",
       "10148    [Linear -&gt; ReLU -&gt; BatchNorm -&gt; Dropo...\n",
       "10149    [No checkpoint was found.\\r\\n\\r\\nProbable caus...\n",
       "10150    [py -m pip install torch==1.6.0+cpu torchvisio...\n",
       "10151    [import sys\\r\\n\\r\\nimport numpy as np\\r\\n\\r\\ni...\n",
       "10152    [import sys\\r\\n\\r\\nimport numpy as np\\r\\n\\r\\ni...\n",
       "10153    [['bert/embeddings/layer_normalization/beta', ...\n",
       "10154    [x = torch.tensor([ \\r\\n    [ True, True, Fals...\n",
       "10155    [def load_checkpoint(filepath, model):\\r\\n   c...\n",
       "10156    [classifier = cnn.CNN(in_shape=(1,28,28), n_cl...\n",
       "10159                                            [is_leaf]\n",
       "10160    [model = DistillBERTClass(), model.to(device),...\n",
       "10161    [from google.colab import drive\\r\\ndrive.mount...\n",
       "10162    [encoder = Encoder_CNN(latent_dim, n_c)\\r\\nenc...\n",
       "10163    [ File \"/home/ubuntu/anaconda3/lib/python3.7/s...\n",
       "10164    [torch.normal, RuntimeError: Expected all tens...\n",
       "10165    [pytorch, torch-vision, python -c \"import torc...\n",
       "10166    [class DiceLoss(nn.Module):\\r\\n    def __init_...\n",
       "10167    [sample_real_video_batch, 142, def sample_real...\n",
       "10168    [import data_load_test\\r\\nfrom tqdm import tqd...\n",
       "10169    [\\r\\n                # BUILD THE NETWORK\\r\\nim...\n",
       "10170    [import torch\\r\\nd = 2\\r\\nn = 50\\r\\nX = torch....\n",
       "10171    [import argparse\\r\\nimport pandas as pd\\r\\nimp...\n",
       "10172    [import argparse\\r\\nimport pandas as pd\\r\\nimp...\n",
       "10173    [def evaluate(model, dataloader, calc_loss=Fal...\n",
       "10174    [import torch\\r\\nfrom model import End_to_end\\...\n",
       "10175    [    seq = dataset['features'][...]\\r\\n    pri...\n",
       "10176    [(batch_size, max_len, num_classes), (batch_si...\n",
       "10177    [def convert_tf_checkpoint_to_pytorch(*, tf_ch...\n",
       "10178    [# Training the model again from the last CNN ...\n",
       "10179    [class custom_small_CNN(nn.Module):\\r\\n\\r\\n   ...\n",
       "10180    [import torch\\r\\nx = torch.ones(2, 2, requires...\n",
       "10181    [import torch\\r\\na = torch.randn(2, 2)\\r\\na = ...\n",
       "10182    [import torch\\r\\na = torch.randn(2, 2)\\r\\na = ...\n",
       "10183    [[2020-08-29 09:03:04,015: ERROR/ForkPoolWorke...\n",
       "10184    [[2020-08-29 09:03:04,015: ERROR/ForkPoolWorke...\n",
       "10185    [[2020-08-29 09:03:04,015: ERROR/ForkPoolWorke...\n",
       "10186    [PyTorch, w, x, sum(w * x) / sum(w), y, pytorc...\n",
       "10187    [for epoch in range((args.start_epoch+1), args...\n",
       "10188    [ValueError: Expected input batch_size (1) to ...\n",
       "10189    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "10190    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "10191    [MODULE_PATH = \"/home/abc/anaconda3/envs/env/l...\n",
       "10192    [class myNetwork(nn.Module):\\r\\n    def __init...\n",
       "10193    [class myNetwork(nn.Module):\\r\\n    def __init...\n",
       "10194    [class myNetwork(nn.Module):\\r\\n    def __init...\n",
       "10195    [(M, N), impor torch\\r\\nimport pyro\\r\\nwith py...\n",
       "10197    [review_text = \"I love completing my todos! Be...\n",
       "10198    [import os\\r\\nimport torch\\r\\nimport torchvisi...\n",
       "10199    [In [1]: torch.Tensor([[[] for _ in range(3)] ...\n",
       "10200    [In [1]: torch.Tensor([[[] for _ in range(3)] ...\n",
       "10202    [X, n x m, Y, n x m, X, X, Y, X[Y].mean(dim=1)...\n",
       "10203    [X, n x m, Y, n x m, X, X, Y, X[Y].mean(dim=1)...\n",
       "10204    [X, n x m, Y, n x m, X, X, Y, X[Y].mean(dim=1)...\n",
       "10205    [import torch\\r\\n# check if pytorch is using c...\n",
       "10206    [inputs, &lt;class 'torch.Tensor'&gt;, &lt;cla...\n",
       "10207    [f = tensor[1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1...\n",
       "10209    [m = nn.Linear(20, 30)\\r\\ninput = torch.randn(...\n",
       "10212    [#instantiation of lstm unit\\r\\nnet1=LSTM_net(...\n",
       "10213    [class Net(torch.nn.Module):\\r\\ndef __init__(s...\n",
       "10214    [import torchvision as tv\\r\\nfrom PIL import I...\n",
       "10215    [class TCNModel(nn.Module):\\r\\n    def __init_...\n",
       "10216    [import torch\\r\\nfrom torch.nn import function...\n",
       "10217    [def build_valid_loader(cfg):\\r\\n    _cfg = cf...\n",
       "10218    [run_language_model.py, model = XLNetLMHeadMod...\n",
       "10220    [class ResNet50(torch.nn.Module):\\r\\n    def _...\n",
       "10221    [pose.frames.ind\\r\\n, from mat4py import loadm...\n",
       "10222    [&gt;&gt; predictions\\r\\nOut[34]: \\r\\ntensor([...\n",
       "10223    [RuntimeError: CUDA out of memory.,  - python ...\n",
       "10224    [[{'text': ['The', 'Fulton', 'County', 'Grand'...\n",
       "10225    [import pickle\\r\\nimport matplotlib.pyplot as ...\n",
       "10226    [\\r\\nto_tensor = transforms.ToTensor()\\r\\nnew_...\n",
       "10227    [datagen =  ImageDataGenerator(\\r\\n  shear_ran...\n",
       "10228    [import os.path as osp\\r\\nimport torch\\r\\nimpo...\n",
       "10229    [import os.path as osp\\r\\nimport torch\\r\\nimpo...\n",
       "10230    [my_tensor.detach().numpy(), torch, import tor...\n",
       "10232    [my_tensor.detach().numpy(), torch, import tor...\n",
       "10233    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "10234    [for seq, y_train in train_data:\\r\\n    optimi...\n",
       "10235    [!pip install cloud-tpu-client==0.10 https://s...\n",
       "10236    [class Net(nn.Module):\\r\\n\\r\\ndef __init__(sel...\n",
       "10237    [ValueError: All bounding boxes should have po...\n",
       "10238    [ First tensor has rank\\r\\n torch.Size([1000, ...\n",
       "10239    [RuntimeError: Legacy autograd function with n...\n",
       "10240    [from pathlib import Path\\r\\nimport requests\\r...\n",
       "10241    [import torch\\r\\n\\r\\nn = 10\\r\\n\\r\\ntensor_list...\n",
       "10242    [class VideoRNN(nn.Module):\\r\\n  def __init__(...\n",
       "10243    [energy.masked_fill(mask == 0, float(\"-1e20\"))...\n",
       "10244    [.clone(), inplace operation, class Model(torc...\n",
       "10245    [register_hook, retain_grad(), register_hook, ...\n",
       "10248    [import numpy as np\\r\\nimport torch \\r\\n\\r\\nde...\n",
       "10249    [J, f, x1, x2, J(x1)*J(x2).transpose(), J, jvp...\n",
       "10250    [conda install pytorch torchvision cudatoolkit...\n",
       "10251    [def Arrow_Hurwicz_algorithm(dim,NMC,S12,iterm...\n",
       "10254    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10255    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10256    [$ seq 1 4 | taskset -c 0-3 parallel -j4 -u &l...\n",
       "10257    [$ seq 1 4 | taskset -c 0-3 parallel -j4 -u &l...\n",
       "10258    [snlp = stanza.Pipeline(lang=\"en\", use_gpu=Tru...\n",
       "10259    [torch.cuda.empty_cache(), multiprocessing.Bou...\n",
       "10261    [20x, num_epochs = 500\\r\\n\\r\\ncriterion = torc...\n",
       "10262    [import torch \\r\\nimport torch.nn as nn\\r\\n \\r...\n",
       "10264    [KeyError                                  Tra...\n",
       "10265    [lstsq, import numpy as np\\r\\nimport torch \\r\\...\n",
       "10266    [inf_data = InfDataloader(img_folder=args.imgs...\n",
       "10268    [torch.__version__, import torch\\r\\nprint(torc...\n",
       "10270    [img.shape=[H,W,F], indices.shape=[N,2], indic...\n",
       "10271    [layers = [\\r\\n        nn.Conv2d(in_channels, ...\n",
       "10272    [# Model definition\\r\\n\\r\\nclass EncoderLSTM(n...\n",
       "10273    [inf_data = InfDataloader(img_folder=args.imgs...\n",
       "10274    [class Model(nn.Module):\\r\\ndef __init__(self,...\n",
       "10278    [num_workers=32, DataLoader, htop, VIRT, RES, ...\n",
       "10279    [def ext():\\r\\n    imgPathList = glob.glob(\"im...\n",
       "10280    [def ext():\\r\\n    imgPathList = glob.glob(\"im...\n",
       "10281    [abinali/pytorch, File \"test.py\", line 1, in &...\n",
       "10282    [abinali/pytorch, File \"test.py\", line 1, in &...\n",
       "10283    [class HDF5Dataset(torch.utils.data.Dataset):\\...\n",
       "10284    [#Defining the directories to the file\\r\\ntrai...\n",
       "10285    [(112x112), (1x512), cv2.resize(), Transform.r...\n",
       "10286    [feedforward(), def forward(self, e1, rel, bat...\n",
       "10287    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "10289    [class ResNet(nn.Module):\\r\\n    def __init__(...\n",
       "10290    [from torch import nn\\r\\nimport torch.nn.funct...\n",
       "10291    [class MonitorCallback(CallbackAny2Vec):\\r\\n  ...\n",
       "10292    [output_padding = SOME NUMBER\\r\\npadding = SOM...\n",
       "10293    [batch, torch.Size([n, 8]), valid_indices, val...\n",
       "10294    [l1 = f(x.detach(), y)\\r\\nl1.backward(retain_g...\n",
       "10295    [    def __init__(...):\\r\\n       ...\\r\\n     ...\n",
       "10296    [# each row is a record of data\\r\\nlogits = np...\n",
       "10297    [WEB_CONCURRENCY, api.sh, export WEB_CONCURREN...\n",
       "10298    [import cv2\\r\\nimport numpy as np \\r\\nimport t...\n",
       "10299    [class LogisticRegression(nn.Module):\\r\\n  def...\n",
       "10300    [randperm, CPUFloatType{10}, int N_SAMPLES = 1...\n",
       "10301    [1d, cos(x), 0.856cos(x) - 1.3cos(0.1x), [0, 1...\n",
       "10302    [#clasify\\r\\nimport torchvision.transforms as ...\n",
       "10303    [if sample_rate != sr:\\r\\n        waveform = t...\n",
       "10305    [# Set upper and lower data values\\r\\nbounds =...\n",
       "10306    [# Constructor\\r\\ndef __init__(self, base, bat...\n",
       "10307    [[0, N], Sampler, [0, N_0], [N_0, N_1], ..., [...\n",
       "10308    [def get_preprocess_transform():    \\r\\ntransf...\n",
       "10309    [def get_preprocess_transform():    \\r\\ntransf...\n",
       "10310    [Params in epoch 2\\r\\n, Epoch 2 params distrib...\n",
       "10311    [torch::Tensor::is_same, is_same, torch::Tenso...\n",
       "10313    [PS C:\\Users\\kelekelekle&gt; python\\r\\nPython ...\n",
       "10314    [    conda --version\\r\\n    conda 4.8.4\\r\\n, p...\n",
       "10315    [def train(net, opt, criterion,ucf_train, batc...\n",
       "10316    [for inputs, labels in dataloaders[phase]:\\r\\n...\n",
       "10317    [import argparse\\r\\nimport datetime\\r\\nimport ...\n",
       "10318    [def find_top(self, x, y, n_neighbors, unit_ve...\n",
       "10319    [num_workers = 0, num_workers, from torch.util...\n",
       "10320    [data = data.cuda(non_blocking=True), train_lo...\n",
       "10322    [from efficientnet_pytorch import EfficientNet...\n",
       "10324    [groups=1, [48, 3, 3, 3], [5, 128, 129, 4],   ...\n",
       "10325    [trainloader = torch.utils.data.DataLoader(lis...\n",
       "10326    [for l in range(L):\\r\\n    mask = torch.zeros(...\n",
       "10330    [class LSTM_net(nn.Module):\\r\\ndef __init__(se...\n",
       "10331    [class LSTM_net(nn.Module):\\r\\ndef __init__(se...\n",
       "10332    [class MnistModel(nn.Module):\\r\\ndef __init__(...\n",
       "10333    [train_load_1 = DataLoader(dataset=train_datas...\n",
       "10334    [train_load_1 = DataLoader(dataset=train_datas...\n",
       "10335    [batch.to(device), train_dataloader = DataLoad...\n",
       "10336    [import torch\\r\\nfrom torch import nn\\r\\nconv ...\n",
       "10337    [import torch\\r\\nfrom torch import nn\\r\\nconv ...\n",
       "10338    [# SageMaker PyTorch image\\r\\nFROM 76310435188...\n",
       "10340    [theta = torch.tensor(np.random.uniform(low=-n...\n",
       "10341    [class TransformerModel(nn.Module):, def make_...\n",
       "10342    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10343    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10344    [torchvision.datasets, DataLoader, import torc...\n",
       "10345    [Resnet18, ResNet(\\r\\n  (conv1): Conv2d(3, 64,...\n",
       "10346    [In [42]: x = torch.tensor([1,2,3])\\r\\n\\r\\n\\r\\...\n",
       "10347    [k = torch.rand(2, 3, 4, 4)\\r\\nprint(k):\\r\\n\\r...\n",
       "10348    [k = torch.rand(2, 3, 4, 4)\\r\\nprint(k):\\r\\n\\r...\n",
       "10349    [        mean_test_error = mean_test_error.det...\n",
       "10351    [RuntimeError: Input and hidden tensors are no...\n",
       "10352    [x_convs = self.convs(Variable(torch.from_nump...\n",
       "10353    [x_convs = self.convs(Variable(torch.from_nump...\n",
       "10354    [srun -n24 --mem = 12g python web.py\\r\\n, clas...\n",
       "10355    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10356    [# main training loop\\r\\nglobal_step = 0\\r\\nbe...\n",
       "10357    [    grid = np.arange(grid_size)\\r\\n    a,b = ...\n",
       "10358    [(size, 1), (size, lookback, 1), size = 7\\r\\nl...\n",
       "10360    [TxK, K &lt;&lt; T, TxT, i, i, inputs: T= 5, a...\n",
       "10361    [TxK, K &lt;&lt; T, TxT, i, i, inputs: T= 5, a...\n",
       "10363    [torch.load, torch.load('./latest_net_G.pth', ...\n",
       "10364    [(n,2), t, S, d, (m,2), S, t, S = [0,1,2,3,7]\\...\n",
       "10365    [class Net():\\r\\n    def __init__(self,pretrai...\n",
       "10366    [    global_step = 0\\r\\nbest_test_error = 1000...\n",
       "10367    [import torch\\r\\n    \\r\\n@torch.jit.script\\r\\n...\n",
       "10370    [# Model\\r\\nclass Net(nn.Module):\\r\\n    def _...\n",
       "10372    [def classes_freq():\\r\\n    for images, labels...\n",
       "10373    [model.eval()\\r\\nfor images, paths in tqdm(loa...\n",
       "10374    [import torch\\r\\nimport torch.nn as nn    #neu...\n",
       "10375    [from detectron2.engine import DefaultTrainer\\...\n",
       "10376    [model_final.pth, cfg.MODEL.WEIGHTS, cfg.MODEL...\n",
       "10378    [# Dataloader\\r\\nfrom torch.utils.data import ...\n",
       "10379    [# Dataloader\\r\\nfrom torch.utils.data import ...\n",
       "10380    [# Dataloader\\r\\nfrom torch.utils.data import ...\n",
       "10381    [labels = torch.tensor([0, 1, 0])\\r\\nx = torch...\n",
       "10382    [labels = torch.tensor([0, 1, 0])\\r\\nx = torch...\n",
       "10383    [cosine, B, K, B, K, B = 5, K = 8, 2pi / 8, 40...\n",
       "10384    [X=xarray.open_dataset(\"Test_file.nc\"), X, X=X...\n",
       "10385    [red : 0, blue: 1, green: 2, for epoch in rang...\n",
       "10386    [red : 0, blue: 1, green: 2, for epoch in rang...\n",
       "10387    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "10388    [B = [\\r\\n    [[[0.5000, 0.5625],\\r\\n      [0....\n",
       "10389    [import os\\r\\nimport numpy as np\\r\\nimport req...\n",
       "10391    [import torch\\r\\nimport torch.nn as nn    #neu...\n",
       "10392    [N = 4 M = 3\\r\\n[[[1,1,1,1],[1,1,1,1],[1,1,1,1...\n",
       "10393    [N = 4 M = 3\\r\\n[[[1,1,1,1],[1,1,1,1],[1,1,1,1...\n",
       "10394    [import torch\\r\\nfrom torch import matmul, mm,...\n",
       "10395    [batchSize = 64\\r\\nimageSize = 64\\r\\n\\r\\ntrans...\n",
       "10396    [#tensor shape:\\r\\n data.shape\\r\\n (4,1500)\\r\\...\n",
       "10397    [import torch\\r\\nfrom allennlp.modules import ...\n",
       "10398    [TensorBoard logging requires TensorBoard vers...\n",
       "10399    [TensorBoard logging requires TensorBoard vers...\n",
       "10400    [TensorBoard logging requires TensorBoard vers...\n",
       "10401    [TensorBoard logging requires TensorBoard vers...\n",
       "10402    [TensorBoard logging requires TensorBoard vers...\n",
       "10403    [conda env update --file main.yml , conda env ...\n",
       "10404    [torch::Tensor r_data1 = torch::from_blob(raw_...\n",
       "10405    [for iters in range(args.iterations):\\r\\n\\r\\nw...\n",
       "10406    [for iters in range(args.iterations):\\r\\n\\r\\nw...\n",
       "10407    [def forward(self):\\r\\n    ...\\r\\n    for b in...\n",
       "10408    [plt.imshow(torchvision.utils.make_grid(images...\n",
       "10409    [k_next_words, (batch_size, d1, d2) = (4,5,6),...\n",
       "10410    [1x1024, 32x32, x.reshape(-1,32), In [2]: a = ...\n",
       "10411    [target_transform, train_dataset = torchvision...\n",
       "10413    [torch.utils.mobile_optimizer.optimize_for_mob...\n",
       "10414    [num_workers=0, pin_memory=True, model = CNN()...\n",
       "10415    [  File \"&lt;ipython-input-11-89006c750b74&gt;...\n",
       "10416    [t = torch.tensor([[[0, 0, 1],\\r\\n            ...\n",
       "10417    [t = torch.tensor([[[0, 0, 1],\\r\\n            ...\n",
       "10418    [loss = loss_func(prediction, outputs)\\r\\n, im...\n",
       "10419    [torch.utils.bottleneck, Traceback (most recen...\n",
       "10420    [TypeError: Caught TypeError in DataLoader wor...\n",
       "10421    [TypeError: Caught TypeError in DataLoader wor...\n",
       "10422    [data_dir=\"D:\\ML-ComputerVision\\Datasets\"\\r\\nt...\n",
       "10423    [data_dir=\"D:\\ML-ComputerVision\\Datasets\"\\r\\nt...\n",
       "10424    [PyTorch, a, import torch\\r\\na = torch.tensor(...\n",
       "10425    [class MSE_Mask_Loss(_Loss):\\r\\n\\r\\n   def __i...\n",
       "10427    [at::Tensor,     at::Tensor gpu = at::randn({1...\n",
       "10428    [#Object Detection\\r\\n\\r\\n#Importing Libraries...\n",
       "10430    [def cutting_model(model):\\r\\n    head = nn.Se...\n",
       "10432    [Inverse_Norm = transforms.Normalize(\\r\\n   me...\n",
       "10433    [dim, m, [m ** dim, dim], [[1,...,1,1],\\r\\n [1...\n",
       "10434    [dim, m, [m ** dim, dim], [[1,...,1,1],\\r\\n [1...\n",
       "10435    [shape = [batch_size, d_0, d_1, ..., d_k]\\r\\ni...\n",
       "10436    [    sample[:, :, 0] = 0\\r\\nTypeError: 'Image'...\n",
       "10437    [(0, 1), UpDownUpUp            \\r\\n(2, 3), UpU...\n",
       "10438    [self.theta, self.beta, eta, self.theta[0]=sel...\n",
       "10439    [train_transform = transforms.Compose([\\r\\n#tr...\n",
       "10440    [torch.device('cuda' if torch.cuda.is_availabl...\n",
       "10441    [TypeError: iter() returned non-iterator of ty...\n",
       "10442    [arr1 = np.array([[1.,2,3], [4,5,6], [7,8,9]])...\n",
       "10443    [/xxx/lib/python3.6/site-packages/PIL/TiffImag...\n",
       "10446    [torch.onnx.export, training, train, import to...\n",
       "10447    [def gaussian_blur(img):\\r\\n    image = np.arr...\n",
       "10448    [def gaussian_blur(img):\\r\\n    image = np.arr...\n",
       "10449    [reconstructed_prob = np.zeros((len(dataset),)...\n",
       "10450    [\\r\\n def mcdropout_test(model):\\r\\n    model....\n",
       "10451    [def identity_block(input_tensor, units):\\r\\n ...\n",
       "10452    [encode_plus, truncation, max_length, encode_p...\n",
       "10453    [File \"D:\\anaconda\\lib\\site-packages\\tensorboa...\n",
       "10454    [self.gru = nn.GRU(\\r\\n            700,\\r\\n   ...\n",
       "10455    [__init__, __len__, __len__, from torch.utils....\n",
       "10456    [__init__, __len__, __len__, from torch.utils....\n",
       "10457    [...\\r\\nfor epoch_idx range(max_epoch):\\r\\n   ...\n",
       "10458    [for batch_idx, (image, label) in enumerate(da...\n",
       "10459    [args = parse_args()\\r\\n\\r\\ntorch_model = Ugat...\n",
       "10462    [import pandas as pd\\r\\nimport torch\\r\\nimport...\n",
       "10463    [data\\r\\n  |_ classe1\\r\\n        |_ image1\\r\\n...\n",
       "10464    [from torch.utils.data import DataLoader\\r\\n\\r...\n",
       "10465    [from torch.utils.data import DataLoader\\r\\n\\r...\n",
       "10466    [def train(model, device, train_loader, criter...\n",
       "10468    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nnp_...\n",
       "10469    [pytorch_total_params = sum(p.numel() for p in...\n",
       "10470    [torchtext, tokenizer = XLNetTokenizer.from_pr...\n",
       "10471    [C:\\Python36\\lib\\site-packages\\onnx_tf\\common\\...\n",
       "10472    [import chess\\r\\nimport chess.pgn\\r\\nimport ch...\n",
       "10474    [        context = torch.tensor(context, dtype...\n",
       "10475    [        context = torch.tensor(context, dtype...\n",
       "10476    [Error(s) in loading state_dict for CamembertF...\n",
       "10477    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10478    [onn_network = ONN(features_size=10, max_num_h...\n",
       "10479    [# net is my trained NSGA-Net PyTorch model\\r\\...\n",
       "10480    [ import torch\\r\\n thing = [[1, 2, 3, 4, 5], [...\n",
       "10481    [ import torch\\r\\n thing = [[1, 2, 3, 4, 5], [...\n",
       "10482    [def get_input_layer(word_idx) :\\r\\nx = torch....\n",
       "10483    [#self.getFeatures() returns a dictionary, so ...\n",
       "10484    [Dropout(),\\r\\nLinear(in_features=9216, out_fe...\n",
       "10486    [import os\\r\\n\\r\\nimport numpy as np\\r\\nimport...\n",
       "10487    [import os\\r\\n\\r\\nimport numpy as np\\r\\nimport...\n",
       "10488    [A = N x M, B = N x P x M, 9, 15, a, A, pi, B,...\n",
       "10489    [A = N x M, B = N x P x M, 9, 15, a, A, pi, B,...\n",
       "10490    [from transformers import DistilBertForSequenc...\n",
       "10491    [from transformers import DistilBertForSequenc...\n",
       "10492    [from transformers import DistilBertForSequenc...\n",
       "10493    [RuntimeError(\"grad can be implicitly created ...\n",
       "10494    [import os\\r\\n\\r\\nsave_path = 'drive/My Drive/...\n",
       "10495    [HxW, F, HxWx1, N, x, y, val, val, n, N, val, ...\n",
       "10496    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "10497    [# Loading the MNISR data reduced to  the 0/1 ...\n",
       "10498    [numpy, torch, def gradient(x,y, y_predicted):...\n",
       "10499    [import torch.nn as nn\\r\\nX = np.array([[1, 3,...\n",
       "10500    [import pandas as pd\\r\\nimport torch\\r\\nimport...\n",
       "10501    [# load an instance segmentation model pre-tra...\n",
       "10502    [# load an instance segmentation model pre-tra...\n",
       "10503    [a=torch.tensor([1,2,3], dtype=torch.float32, ...\n",
       "10504    [TypeError: 'Tensor' object is not callable, T...\n",
       "10505    [import os\\r\\nos.environ[\"CUDA_VISIBLE_DEVICES...\n",
       "10506    [class LanguageModel(nn.Module):\\r\\n  \"\"\"\\r\\n ...\n",
       "10507                         [[N, 2, H, W], [N, 3, H, W]]\n",
       "10508    [out[i][j][k] = input[index[i][j][k]][j][k]  #...\n",
       "10509    [for i in range(len(model_list)):\\r\\n\\r\\n    o...\n",
       "10510    [my_transforms = transforms.Compose([\\r\\n    t...\n",
       "10512    [pytorch, IterableDataset, zarr, class Data(It...\n",
       "10515    [{'class': 'bird', 'confidence':'0.8932'}\\r\\n,...\n",
       "10516    [def adaptive_instance_normalization(content_f...\n",
       "10518                   [train(), eval(), train(), eval()]\n",
       "10519    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10520    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10522    [input = np.array([\\r\\n                  [[313...\n",
       "10523    [max_node, counter = 0, 0\\r\\nbatch_size, n_day...\n",
       "10525    [py3.7_cuda102_cudnn7_0, pip, conda, conda ins...\n",
       "10526    [\\r\\n    def split_heads(self, x, batch_size):...\n",
       "10527    [import nltk \\r\\n#nltk.download('punkt')\\r\\nfr...\n",
       "10528    [base = torch.ones((2, 3, 5, 5))\\r\\nto_multipl...\n",
       "10529    [joblib.dump, pickle.dump(study, open('name.pk...\n",
       "10530    [ torch.tensor(nn.softmax(x)), RuntimeError: C...\n",
       "10531    [RuntimeError: shape '[-1, 14]' is invalid for...\n",
       "10532    [import torch\\r\\nimport numba\\r\\n\\r\\n@numba.nj...\n",
       "10533    [import torch\\r\\nimport numba\\r\\n\\r\\n@numba.nj...\n",
       "10534    [import torch\\r\\nimport numba\\r\\n\\r\\n@numba.nj...\n",
       "10535    [if os.path.isfile(PATH):\\r\\n      print(\"chec...\n",
       "10536    [for epoch in range(epochs):\\r\\n    loss = n_c...\n",
       "10537    [        def __init__(self):\\r\\n        super(...\n",
       "10538    [classifier_weights, classifier_weights = {}\\r...\n",
       "10539    [model.eval(), for t in range(num_epochs):\\r\\n...\n",
       "10540    [from detectron2.modeling import build_model\\r...\n",
       "10541    [import torch\\r\\nfrom scipy.optimize import mi...\n",
       "10542    [w -= lr * w.grad\\r\\n, w = w - lr * w.grad\\r\\n...\n",
       "10546    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nx =...\n",
       "10547    [folder 1\\r\\n  part0001.csv\\r\\n  part0002.csv\\...\n",
       "10548    [        # SE layers\\r\\n        self.fc1 = nn....\n",
       "10549    [$ pip install torch==1.5.0 torchvision==0.6.0...\n",
       "10550    [a = np.array([1,2,3])\\r\\nb = np.array([[[1,2]...\n",
       "10551    [a = np.array([1,2,3])\\r\\nb = np.array([[[1,2]...\n",
       "10552    [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nf...\n",
       "10553    [        def trn_l(totall_lc, totall_lw, total...\n",
       "10554    [        def trn_l(totall_lc, totall_lw, total...\n",
       "10555    [data.shape, #%%\\r\\nfrom sklearn.feature_selec...\n",
       "10556    [FROM ubuntu:18.04\\r\\n\\r\\nMAINTAINER Amazon AI...\n",
       "10557    [FROM ubuntu:18.04\\r\\n\\r\\nMAINTAINER Amazon AI...\n",
       "10558    [import torch.nn as nn\\r\\nimport numpy as np\\r...\n",
       "10559    [from transformers import AutoModelWithLMHead,...\n",
       "10560    [this_file = os.path.dirname(os.path.realpath(...\n",
       "10561    [\\r\\nimport os\\r\\nimport torch\\r\\nfrom transfo...\n",
       "10563    [import torch\\r\\n\\r\\ndef convert_pytorch2onnx(...\n",
       "10564    [a = np.random.randint(0,5,20)\\r\\na\\r\\nOut[23]...\n",
       "10565    [a = np.random.randint(0,5,20)\\r\\na\\r\\nOut[23]...\n",
       "10566    [conda install pytorch torchvision cudatoolkit...\n",
       "10567    [conda install pytorch torchvision cudatoolkit...\n",
       "10568    [model_mlp=Sequential()\\r\\nmodel_mlp.add(Dense...\n",
       "10569    [import torch as t\\r\\nimport torch.nn as tn\\r\\...\n",
       "10570    [import torch as t\\r\\nimport torch.nn as tn\\r\\...\n",
       "10571    [train_dataset = TensorDataset(features,target...\n",
       "10572    [&gt; class RNN(nn.Module):\\r\\n&gt; \\r\\n\\r\\n&g...\n",
       "10573    [&gt; class RNN(nn.Module):\\r\\n&gt; \\r\\n\\r\\n&g...\n",
       "10574    [[test_dataloader.dataset[i][0] for i in [0,1,...\n",
       "10575    [def train_model(model, criterion, optimizer, ...\n",
       "10576    [import os\\r\\nfrom process_file import process...\n",
       "10577    [OSError                                   Tra...\n",
       "10578    [def run():\\r\\n    torch.multiprocessing.freez...\n",
       "10581    [multiprocessing, torch.multiprocessing, Jobli...\n",
       "10582       [torch.optim.lr_scheduler.ReduceLROnPlateau()]\n",
       "10583       [torch.optim.lr_scheduler.ReduceLROnPlateau()]\n",
       "10584    [    def train(num_epochs,optimizer,criterion,...\n",
       "10585    [Collecting torch==1.5.1\\r\\n  Downloading torc...\n",
       "10586    [scores = [s[tuple(k.t())] for s, k in zip(sco...\n",
       "10587    [scores = [s[tuple(k.t())] for s, k in zip(sco...\n",
       "10588    [def custom_dec(self, module):\\r\\n        def ...\n",
       "10589    [scaler = torch.cuda.amp.GradScaler(init_scale...\n",
       "10590    [normalize = transforms.Normalize(\\r\\nmean=[0....\n",
       "10591    [torch.optim.lr_scheduler, param_list = []\\r\\n...\n",
       "10592    [a = torch.tensor([1., 2, 3], requires_grad=Tr...\n",
       "10593    [targets = torch.tensor([metadata['count'][os....\n",
       "10594    [class TD3(object):\\r\\n\\r\\ndef __init__(\\r\\n  ...\n",
       "10595    [Xv.requires_grad_()\\r\\nXT.requires_grad_()\\r\\...\n",
       "10596    [tensor.stride(), In [15]: x = torch.arange(1,...\n",
       "10597    [import torch\\r\\n\\r\\npred = torch.tensor([1,2,...\n",
       "10598    [def get_train_valid_splits(data_dir,\\r\\n     ...\n",
       "10599    [def get_train_valid_splits(data_dir,\\r\\n     ...\n",
       "10600    [pytorch, torch.triu(), import torch\\r\\na=torc...\n",
       "10601    [{'1185869': [tensor(indices=tensor([[   31,  ...\n",
       "10602                                         [torch.save]\n",
       "10604    [Imagelist.from_folder(), Imagelist.from_folde...\n",
       "10605    [Target: tensor([ 1, 6, 5, 8, 10, 5, 4, 5, 10,...\n",
       "10606    [result[i][j][:] = source[idx[i][j][0]] [idx[i...\n",
       "10608    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "10609    [import os\\r\\nimport time\\r\\nimport random\\r\\n...\n",
       "10610    [RuntimeError: Detected that PyTorch and torch...\n",
       "10612    [\\r\\ndef f(x):\\r\\n    return x * np.sin(x) # f...\n",
       "10614    [super(LR, self).__init__(), self.linear = nn....\n",
       "10615    [super(LR, self).__init__(), self.linear = nn....\n",
       "10616    [torch::Embedding, Expected object of device t...\n",
       "10617    [index = [[2,0,1], [2,2,0]]\\r\\nvalue = [[0.1, ...\n",
       "10618    [index = [[2,0,1], [2,2,0]]\\r\\nvalue = [[0.1, ...\n",
       "10619    [index = [[2,0,1], [2,2,0]]\\r\\nvalue = [[0.1, ...\n",
       "10620    [pytorch, torch.set_num_interop_threads(1), to...\n",
       "10621    [#Split data into training and validation 70 /...\n",
       "10622    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "10624    [x_values = sklearn.preprocessing.normalize(x_...\n",
       "10625    [torch.cat, torch.stack, x = torch.tensor([])....\n",
       "10626    [BERT, cosine_similarity, hello world, hello h...\n",
       "10627                   [d2l, conda, conda, pip, d2l, pip]\n",
       "10628    [def load(inp):\\r\\n    \\r\\n    global words,la...\n",
       "10629    [TensorDataset, torch.sparse.FloatTensor, Data...\n",
       "10630    [int main(int argc, char** argv)\\r\\n{\\r\\n    /...\n",
       "10631    [for i in range(1000):\\r\\n   image = [0] * (IM...\n",
       "10632    [for i in range(1000):\\r\\n   image = [0] * (IM...\n",
       "10633    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "10634    [tf.gradient, dfdx,dfdy,dfdz = tf.gradients(pr...\n",
       "10635    [torch.save(model.state_dict(), PATH)\\r\\n, dev...\n",
       "10636    [def assign_gpu(token):\\r\\n    token_tensor = ...\n",
       "10637    [my_root = '/mini_imagenet_full_size/train/'\\r...\n",
       "10638    [x, y, x, import torch\\r\\ndef minus_min(raw):\\...\n",
       "10639    [for epoch in range(nepoch):\\r\\n    model.trai...\n",
       "10640    [tensorA, 10x4x9x2, tensorB, 10x5x2, tensorA, ...\n",
       "10641    [RandomHorizontalFlip, RandomRotation, [0.1, 0...\n",
       "10642    [RandomHorizontalFlip, RandomRotation, [0.1, 0...\n",
       "10643    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nimp...\n",
       "10645    [# output is the last hidden layer of bert, tr...\n",
       "10646    [import torch\\r\\ndef activation(x):\\r\\n    ret...\n",
       "10647    [import torch\\r\\ndef activation(x):\\r\\n    ret...\n",
       "10649    [if torch.cuda.is_available():\\r\\n    device =...\n",
       "10650    [if torch.cuda.is_available():\\r\\n    device =...\n",
       "10651    [(batch_size, seq_len, one_hot_features), one_...\n",
       "10652    [self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 ...\n",
       "10653    [transform = transforms.Compose([transforms.To...\n",
       "10654    [model.cov2, AttributeError: 'CNN' object has ...\n",
       "10655    [model.cov2, AttributeError: 'CNN' object has ...\n",
       "10656    [RuntimeError: Error(s) in loading state_dict ...\n",
       "10657    [numpy.linalg.eigh(), torch.symeig(), import n...\n",
       "10658    [A, torch.Size([32, 32, 3, 3]), B, torch.Size(...\n",
       "10659    [def lbp(x):\\r\\n\\r\\nimgUMat = np.float32(x)\\r\\...\n",
       "10661    [img = Image.open(img_path) # Load the image\\r...\n",
       "10662    [chips = F.unfold(img_t.data, kernel_size=300)...\n",
       "10663    [class Generator(nn.Module):\\r\\n    def __init...\n",
       "10664    [model = MyModel()\\r\\nmodel.load_state_dict(ch...\n",
       "10665    [n_embedded = 400\\r\\nclass AE400_10(nn.Module)...\n",
       "10666    [n_embedded = 400\\r\\nclass AE400_10(nn.Module)...\n",
       "10667    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "10668    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "10669    [class Net(nn.module):\\r\\n   def __init__():\\r...\n",
       "10670    [class Net(nn.module):\\r\\n   def __init__():\\r...\n",
       "10671    [File \"main.py\", line 95, in train loss.backwa...\n",
       "10672    [data_transforms = {\\r\\n    'train': transform...\n",
       "10673    [def getLinearImage():\\r\\n  with torch.no_grad...\n",
       "10674    [lr, softmax, torch.sigmoid, torch.data.DataLo...\n",
       "10675    [model = nn.DataParallel(model, device_ids = [...\n",
       "10676    [with torch.cuda.device(2):\\r\\n    train_load,...\n",
       "10677    [FROM python:3.7\\r\\n\\r\\nWORKDIR /app\\r\\n\\r\\nCO...\n",
       "10679    [import shutil\\r\\nimport os\\r\\nimport time\\r\\n...\n",
       "10681    [import torch\\r\\nx = torch.zeros(1,8,4,576) # ...\n",
       "10682    [def create_links():\\r\\n    data_dir = \"/myfol...\n",
       "10683    [class PolicyNetwork(nn.Module):\\r\\n    ''' Ne...\n",
       "10684    [for batch_index, batch_samples in enumerate(t...\n",
       "10685    [torch.split, ls \\r\\n[tensor([[0.8469, 0.3712,...\n",
       "10686    [torch.split, ls \\r\\n[tensor([[0.8469, 0.3712,...\n",
       "10687    [for e in range(self.epochs):\\r\\n  self.model....\n",
       "10688    [inp = torch.tensor([[ 1,  2],\\r\\n [ 3,  4],\\r...\n",
       "10691    [tensor([[0.8831, 0.5263],\\r\\n        [0.5528,...\n",
       "10692    [  def train_model(model, criterion, optimizer...\n",
       "10693    [  def train_model(model, criterion, optimizer...\n",
       "10694    [  def train_model(model, criterion, optimizer...\n",
       "10695    [  def train_model(model, criterion, optimizer...\n",
       "10696    [nvidia-smi, import tensorflow as tf\\r\\nimport...\n",
       "10698    [_fc, swish, (_bn1): BatchNorm2d(1280, eps=0.0...\n",
       "10699    [import uvicorn\\r\\nimport json\\r\\nfrom typing ...\n",
       "10700    [   _transforms = transforms.Compose([\\r\\n    ...\n",
       "10701    [from nltk_utils import tokenize, stem, bag_of...\n",
       "10702    [pandas DataFrame, torch.tensor, # output firs...\n",
       "10703    [X_train = torch.tensor(train_set_x, dtype=dty...\n",
       "10704    [---------------------------------------------...\n",
       "10705    [!git clone https://github.com/SeanNaren/warp-...\n",
       "10706    [criterion = nn.CrossEntropyLoss(), import tor...\n",
       "10708    [databunch_lm = BertLMDataBunch.from_raw_corpu...\n",
       "10709    [torch.save(model.state_dict(), f'BERT_ft_epoc...\n",
       "10710    [torch.save(model.state_dict(), f'BERT_ft_epoc...\n",
       "10711    [class PredictFromEmbeddParaSmall(LightningMod...\n",
       "10712    [class PredictFromEmbeddParaSmall(LightningMod...\n",
       "10713    [python main.py, DeepLearningProject/\\r\\n├── D...\n",
       "10714    [train_data = torchvision.datasets.CIFAR10(roo...\n",
       "10715    [sentence_transformers, sentence_transformers ...\n",
       "10716    [def create_dataset(tok_docs, vocab, n):\\r\\n  ...\n",
       "10717    [self.conv = nn.Conv2d(3, 64, kernel_size=3, s...\n",
       "10718    [y = 2x, __len__, import numpy as np\\r\\nfrom t...\n",
       "10719    [import os\\r\\n\\r\\nimport numpy as np\\r\\nimport...\n",
       "10720    [torch.nn.Sequential, torch.save, torch.save, ...\n",
       "10721    [(3,1), b[1:, 1:], (3,3), (3,1), (2,1), import...\n",
       "10722    [#import necessary libraries\\r\\nfrom torch imp...\n",
       "10723                [(2000,10000), (2000,1), (2000,9999)]\n",
       "10724    [import tensorflow\\r\\nfrom tensorflow.keras im...\n",
       "10725    [Runtime ERROR: One of the differentiated Tens...\n",
       "10726    [class classifier(nn.Module):\\r\\n  def __init_...\n",
       "10727    [import torchvision.transforms.functional as F...\n",
       "10728    [import torch\\r\\nfrom midas import midas_net\\r...\n",
       "10729    [PyTorchModel(model_data=model_artifact,\\r\\n  ...\n",
       "10730    [PyTorchModel(model_data=model_artifact,\\r\\n  ...\n",
       "10731    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "10732    [[nXn], inp=[ [i_11, i_12, i_13, ..., i_1n],[i...\n",
       "10733    [    final_dists=torch.zeros((batch_size,dec_m...\n",
       "10734    [X = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1,...\n",
       "10735    [X = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1,...\n",
       "10736    [sign_x = torch.sign(x)\\r\\nsign_y = torch.sign...\n",
       "10738    [import shutil\\r\\nimport os\\r\\nimport time\\r\\n...\n",
       "10739    [K1=K2, H, model(weights, H, x), while i &lt; ...\n",
       "10740    [pkl_load = torch.load(trained_model_dir)\\r\\np...\n",
       "10741    [torch.nn.Conv2d(7, 64, kernel_size=(7, 7), st...\n",
       "10742    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nmat...\n",
       "10743    [ Train: {'0': 126315, '1': 2915}\\r\\n    Val  ...\n",
       "10744    [Conv1d, x, y, # size = [4, 3]\\r\\nx = torch.te...\n",
       "10745    [Conv1d, x, y, # size = [4, 3]\\r\\nx = torch.te...\n",
       "10746    [PReLU, PReLU, ReLU, PReLU, torch.FloatFunctio...\n",
       "10750    [import numpy as np\\r\\nimport torch\\r\\nfrom jo...\n",
       "10751    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nX =...\n",
       "10752    [def train(net, x_train, x_opt, BATCH_SIZE, EP...\n",
       "10753    [ import torch\\r\\n torch.random()\\r\\nTraceback...\n",
       "10754    [(30, 24, 512), 30, A, B, A, A, B, A, B, (1 * ...\n",
       "10756    [class CyclicIterator:\\r\\n    def __init__(sel...\n",
       "10757    [X = np.array([[1, 3, 2, 3], [2, 3, 5, 6]])\\r\\...\n",
       "10758    [emb = nn.Embedding(6, 3)\\r\\n\\r\\ninput = torch...\n",
       "10759    [AttributeError: 'int' object has no attribute...\n",
       "10760    [def train(self, training_reviews, training_la...\n",
       "10764    [imageFolder, train_test_split, ds = ImageFold...\n",
       "10765    [imageFolder, train_test_split, ds = ImageFold...\n",
       "10766    [import cv2\\r\\ndevice = \"cpu\"\\r\\nimport torch....\n",
       "10767    [array([[array([[ 89, 117,  59, ...,  39,  48,...\n",
       "10768    [role = sagemaker.get_execution_role()\\r\\n\\r\\n...\n",
       "10769    [Epoch [10/100], Loss: 222273830912.0000\\r\\nEp...\n",
       "10770    [def unsorted_segment_sum(data, segment_ids, n...\n",
       "10771    [for (waveform, _, utterance, _, _, _) in data...\n",
       "10772    [norm = torch.distributions.multivariate_norma...\n",
       "10773    [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "10774    [def forward(self, inputs):\\r\\n    word_embedd...\n",
       "10775    [def __getitem__(self,idx):\\r\\n        img_pat...\n",
       "10777    [torch.Size([12, 64, 8, 8, 3]) , torch.Size([1...\n",
       "10778    [TypeError                                 Tra...\n",
       "10779    [TypeError                                 Tra...\n",
       "10780    [import  tensorflow as tf\\r\\n\\r\\nfrom    tenso...\n",
       "10781    [def forward(self, input_index_batch, output_i...\n",
       "10782    [img = np.fromfile(dir_train + image_name)\\r\\n...\n",
       "10783    [import torch\\r\\nimport torch.nn.functional as...\n",
       "10784                              [x, x.item(), float(x)]\n",
       "10786    [ **# Train the model\\r\\n  total_step = len(tr...\n",
       "10787    [mae = 0\\r\\nfor i in range(len(img_paths)):\\r\\...\n",
       "10789    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "10790    [adv_loss = torch.nn.BCELoss(), 'Tensor' objec...\n",
       "10791    [(feature_vis.py:27730): Gdk-WARNING **: 03:23...\n",
       "10792    [tensor([[[-3, -6, -1],\\r\\n         [-6, -10, ...\n",
       "10793    [tensor([[[-3, -6, -1],\\r\\n         [-6, -10, ...\n",
       "10794    [ transform = Compose([\\r\\n    FiveCrop(size),...\n",
       "10796    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10797    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10798    [    print(\"Calculating threshold\")\\r\\n    x_o...\n",
       "10799    [    from torchvision import datasets, transfo...\n",
       "10801    [tensor.max(), A = np.random.randint( 0, 29, (...\n",
       "10802    [ImportError: /usr/local/lib/python3.6/dist-pa...\n",
       "10803    [tensor([-1.6975e+00,  1.7556e-02, -2.4441e+00...\n",
       "10804    [torch, pip, pip install torch===1.5.1 torchvi...\n",
       "10805    [for (data, labels) in loader:\\r\\n    data, la...\n",
       "10806    [    for epoch in range(training_configuration...\n",
       "10807    [(batch_size is 2)\\r\\nstart_pos_labels.sum(dim...\n",
       "10808    [$ cd install/path\\r\\n$ git clone https://gith...\n",
       "10809    [  File \"train_filename.py\", line 140, in &lt;...\n",
       "10810    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10812    [---------------------------------------------...\n",
       "10813    [validation_epoch_end, LightningModule, .cuda(...\n",
       "10814    [main\\r\\n  - annotations:\\r\\n    - instances_t...\n",
       "10815    [torch.nn.Module, def validate(logger, config,...\n",
       "10816    [mmconvert -sf mxnet -in model-symbol.json -iw...\n",
       "10817    [X = np.array([\\r\\n    [-2,4,-1],\\r\\n    [4,1,...\n",
       "10818    [X = np.array([\\r\\n    [-2,4,-1],\\r\\n    [4,1,...\n",
       "10819    [X = np.array([\\r\\n    [-2,4,-1],\\r\\n    [4,1,...\n",
       "10820    [torch.nonintersection, a = torch.tensor([[ 0....\n",
       "10821    [import torch\\r\\n\\r\\nclass SelfAttention():\\r\\...\n",
       "10822    [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "10823    [RuntimeError                              Tra...\n",
       "10824    [...\\r\\ntorch.nn.functional.nll_loss(output, t...\n",
       "10827    [x=torch.Tensor([[10,20,30],\\r\\n              ...\n",
       "10828    [torch.utils.data.DataLoader, trainloader = to...\n",
       "10829    [torch.utils.data.DataLoader, trainloader = to...\n",
       "10830    [from transformers import BertTokenizer\\r\\ncla...\n",
       "10832    [RuntimeError: CuDNN error: CUDNN_STATUS_SUCCE...\n",
       "10833    [RuntimeError: CuDNN error: CUDNN_STATUS_SUCCE...\n",
       "10835    [!pip install transformers \\r\\n, !python /usr/...\n",
       "10836                         [torchtext, dump, torchtext]\n",
       "10837    [class ConvNet(nn.Module):\\r\\ndef __init__(sel...\n",
       "10838    [conda install pytorch torchvision cudatoolkit...\n",
       "10839    [torch.nn.utils.rnn.pack_padded_sequence, torc...\n",
       "10840    [FULL Dataset: (1220, 2)\\r\\nTRAIN Dataset: (85...\n",
       "10841    [.wav, (593, 3, 227, 227), Traceback (most rec...\n",
       "10842    [ValueError                                Tra...\n",
       "10845    [import torchvision.transforms.functional as F...\n",
       "10846    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10847    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10848                   [last_epoch, last_epoch (int), -1]\n",
       "10849    [conda search pytorch, conda list, pytorch    ...\n",
       "10850    [class GetMetaBatch_NK_WayClassTask:\\r\\n\\r\\n  ...\n",
       "10852    [for k, image_path in enumerate(image_list):\\r...\n",
       "10853    [for k, image_path in enumerate(image_list):\\r...\n",
       "10854    [tf.math.reduce_max, tf.math.reduce_max, torch...\n",
       "10855    [!pip install efficientnet_pytorch -q\\r\\n\\r\\n\\...\n",
       "10856    [    class Avg_Combine(nn.Module):\\r\\n        ...\n",
       "10857    [Traceback (most recent call last):\\r\\n  File ...\n",
       "10858    [from numpy import asarray\\r\\nfrom PIL import ...\n",
       "10859    [from numpy import asarray\\r\\nfrom PIL import ...\n",
       "10860    [from PIL import Image\\r\\n\\r\\n# load one batch...\n",
       "10861    [torch tensors, list_tensor = [tensor([[1, 2, ...\n",
       "10862    [torch tensors, list_tensor = [tensor([[1, 2, ...\n",
       "10863    [model.pkl  README.md          images/        ...\n",
       "10864    [model.pkl  README.md          images/        ...\n",
       "10865    [DEBUG=True\\r\\nVERSION = 1\\r\\nMAX_LEN = 200 #S...\n",
       "10866    [model.eval()\\r\\nwith torch.no_grad():\\r\\n    ...\n",
       "10867    [model.eval()\\r\\nwith torch.no_grad():\\r\\n    ...\n",
       "10868    [model.eval()\\r\\nwith torch.no_grad():\\r\\n    ...\n",
       "10869    [The current process just got forked. Disablin...\n",
       "10870    [The current process just got forked. Disablin...\n",
       "10872    [def predict(image, model, topk=5):\\r\\n''' Pre...\n",
       "10873    [def forward(self, x):\\r\\n        mem_outpus =...\n",
       "10874    [nn.Conv2d(128,128,1)\\r\\n, RuntimeError: Given...\n",
       "10875    [import scipy .io\\r\\nemnist = scipy.io.loadmat...\n",
       "10876    [criterion = nn.CrossEntropyLoss()\\r\\n, iter =...\n",
       "10877    [criterion = nn.CrossEntropyLoss()\\r\\n, iter =...\n",
       "10878    [[\\r\\n  [1, 1, 1, 1],\\r\\n  [1, 1, 1, 1],\\r\\n  ...\n",
       "10879    [y_train, import scipy .io\\r\\nemnist = scipy.i...\n",
       "10880    [from torch.utils.data import Subset\\r\\na = ds...\n",
       "10881    [import torch\\r\\nimport numpy as np\\r\\nx = tor...\n",
       "10882    [targets-&gt; [{'boxes': tensor([[ 23.7296,  2...\n",
       "10883    [docker build -t gcr.io/${PROJECT_ID}/insuranc...\n",
       "10884    [annotations-&gt; [{'boxes': tensor([[131.5124...\n",
       "10885    [coords = torch.Tensor([[0, 0, 1, 2],\\r\\n     ...\n",
       "10886    [coords = torch.Tensor([[0, 0, 1, 2],\\r\\n     ...\n",
       "10888    [class My_H5Dataset(torch.utils.data.Dataset):...\n",
       "10890    [output = net(input)\\r\\nloss = g(output)\\r\\nlo...\n",
       "10891    [class gating_net(nn.Module):\\r\\n    def __ini...\n",
       "10892    [class BertForBinaryDocumentClassification(Ber...\n",
       "10893    [class Dataset(torch.utils.data.Dataset):\\r\\n\\...\n",
       "10894    [target=0, target=1, target=0.5, class myLoss(...\n",
       "10895    [nn.Module, class New_net(nn.Module):\\r\\n    d...\n",
       "10896    [            traced_script_module = torch.jit....\n",
       "10897    [#============================================...\n",
       "10898          [kernel = kernel.repeat((B, 64, 1, 1))\\r\\n]\n",
       "10899    [train_data_len = len(train_loader.dataset)\\r\\...\n",
       "10900    [torchvision.transforms.RandomRotation, torchv...\n",
       "10901    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "10903    [y, [3,4], x, [3,4], import torch as T\\r\\n# Te...\n",
       "10904    [y, [3,4], x, [3,4], import torch as T\\r\\n# Te...\n",
       "10905    [48 34 21 18 16 21 26 36 40...44 53 57 64 82 9...\n",
       "10906    [48 34 21 18 16 21 26 36 40...44 53 57 64 82 9...\n",
       "10907    [import torchvision.transforms.functional as t...\n",
       "10908    [import torchvision.transforms.functional as t...\n",
       "10909    [model = nn.Sequential(nn.Linear(4999, 1000),\\...\n",
       "10910    [a = tensor([[ 1,  2,  3,  4,  5],\\r\\n        ...\n",
       "10911    [{\\r\\n  \"architectures\": [\\r\\n    \"ReformerFor...\n",
       "10912    [(17): InvertedResidual(\\r\\n      (conv): Sequ...\n",
       "10913    [    train_transform = transforms.Compose([\\r\\...\n",
       "10914    [&lt;tb&gt;, sentences = [\"This is the first s...\n",
       "10915    [AssertionError: \\r\\nFound no NVIDIA driver on...\n",
       "10916    [AssertionError                            Tra...\n",
       "10917    [on client node:\\r\\n\\r\\n    grads = []\\r\\n    ...\n",
       "10918    [type(),      class Foo(object):\\r\\n    ...   ...\n",
       "10919    [type(),      class Foo(object):\\r\\n    ...   ...\n",
       "10920    [type(),      class Foo(object):\\r\\n    ...   ...\n",
       "10921    [1.6.0, RuntimeError: version_ &lt;= kMaxSuppo...\n",
       "10922    [flair, pytorch, pipenv, Pipfile + Pipfile.loc...\n",
       "10923    [1st tensor\\r\\n[[0,0],[0,1],[0,2],[1,3],[1,4],...\n",
       "10924    [1st tensor\\r\\n[[0,0],[0,1],[0,2],[1,3],[1,4],...\n",
       "10925    [torch.load, Traceback (most recent call last)...\n",
       "10926    [import random\\r\\nimport torch\\r\\nfrom torchvi...\n",
       "10927    [import torch.nn as nn \\r\\n\\r\\nclass model(nn....\n",
       "10928    [nan, class NEG_loss(nn.Module):\\r\\n    def __...\n",
       "10930    [\\r\\nx=np.linspace(0,20,100)\\r\\n\\r\\n\\r\\ng=1+0....\n",
       "10931    [image[...,list()], self.probability = 0.5\\r\\n...\n",
       "10932    [image[...,list()], self.probability = 0.5\\r\\n...\n",
       "10933    [g++ rnxt.cpp -o rnxt, #include &lt;cuda_runti...\n",
       "10934    [A, B, A.shape, [batch_size, m, n], B.shape, [...\n",
       "10935    [[0, 1, 1, 1, 1]\\r\\n[0, 0, 1, 1, 1]\\r\\n[0, 0, ...\n",
       "10936    [import torchvision\\r\\nfrom torchvision import...\n",
       "10938    [cv2.rectangle(img=sample,\\r\\n                ...\n",
       "10939    [def __init__(self):\\r\\n        super(Net, sel...\n",
       "10941    [Dataset, class KaggleMNIST(Dataset):\\r\\n\\r\\n ...\n",
       "10943    [torch.jit.save,   net = torch.jit.load(r\"scri...\n",
       "10944    [Traceback (most recent call last):\\r\\n\\r\\n  F...\n",
       "10945    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "10946    [nvidia-smi, a = torch.rand(100000)\\r\\n, devic...\n",
       "10947    [class RL_Agents:\\r\\n    def __init__(self, bu...\n",
       "10948    [  x_train_folds = torch.chunk(x_train, num_fo...\n",
       "10951    [dataset.py, SpaceNetDataset, import os\\r\\n# I...\n",
       "10952    [trainset = datasets.ImageFolder('data/Cat_Dog...\n",
       "10953    [model.load_state_dict(torch.load(Mymodel.pt)\\...\n",
       "10954    [from transformers import BertTokenizer\\r\\nber...\n",
       "10955    [from transformers import BertTokenizer\\r\\nber...\n",
       "10956    [from transformers import BertTokenizer\\r\\nber...\n",
       "10958    [valid_and_test_set = torchvision.datasets.MNI...\n",
       "10959    [valid_and_test_set = torchvision.datasets.MNI...\n",
       "10960    [#!/bin/bash\\r\\nsudo -u ec2-user -i &lt;&lt;'E...\n",
       "10961    [lr=0.001\\r\\n\\r\\nx=np.linspace(-6,6,120)\\r\\ny=...\n",
       "10962    [x = torch.ones(1, requires_grad=True)\\r\\nprin...\n",
       "10963    [x = torch.ones(1, requires_grad=True)\\r\\nprin...\n",
       "10964    [modelmix.stem[0].weight = modelSep.stem[0].we...\n",
       "10965    [def __init__(self, in_dim, h_dim, out_dim, n_...\n",
       "10966    [import torch \\r\\n\\r\\ndef g(x):\\r\\n    return ...\n",
       "10967                               [run_glue.py, train()]\n",
       "10968                               [run_glue.py, train()]\n",
       "10969                               [run_glue.py, train()]\n",
       "10970    [MobileNet = models.mobilenet_v2(pretrained = ...\n",
       "10971    [MobileNet = models.mobilenet_v2(pretrained = ...\n",
       "10972    [b=8\\r\\na-&gt;b\\r\\nprint(a) --&gt; 8\\r\\nb=10\\r...\n",
       "10973    [b=8\\r\\na-&gt;b\\r\\nprint(a) --&gt; 8\\r\\nb=10\\r...\n",
       "10974    [device = \"cuda\"\\r\\n\\r\\n\\r\\nepochs=4\\r\\nprint(...\n",
       "10975    [import matplotlib.pyplot as plt\\r\\n\\r\\n# use ...\n",
       "10976    [(base) corey@corona:~/Desktop/pycity/GALD-Net...\n",
       "10977    [(base) corey@corona:~/Desktop/pycity/GALD-Net...\n",
       "10978    [class Residual(nn.Module):\\r\\n    def __init_...\n",
       "10980    [A*A*X*W0*W1 w.r.t A, def torch_grad(A, W0, W1...\n",
       "10981    [\\r\\ndef k_means_torch(dictionary, model):\\r\\n...\n",
       "10983    [import argparse\\r\\nimport os\\r\\n\\r\\nimport to...\n",
       "10984    [import argparse\\r\\nimport os\\r\\n\\r\\nimport to...\n",
       "10985    [nn.GRU, for i in range(self.n_layers):\\r\\n   ...\n",
       "10986    [output = model(images)\\r\\npreds = output.sum(...\n",
       "10987    [        self.conv1 = Conv2d(self.channels, 32...\n",
       "10990    [class Net(nn.Module):\\r\\n   def __init__(self...\n",
       "10991    [class pu_fc(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "10993    [from torch.utils.data import TensorDataset , ...\n",
       "10994    [print(train_x.shape, len(train_y))\\r\\ntorch.S...\n",
       "10995    [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "10996    [def grad(A, W0, W1, X):\\r\\n    dim = A.shape\\...\n",
       "10997    [for i, data in enumerate(dataloader, 0):\\r\\n ...\n",
       "10998    [for i, data in enumerate(dataloader, 0):\\r\\n ...\n",
       "10999    [train_transform = Compose([\\r\\n    transforms...\n",
       "11000    [MobileNet = models.mobilenet_v2(pretrained = ...\n",
       "11001    [test_loss_history = [] train_loss_history = [...\n",
       "11002    [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "11003    [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "11004                      [transforms.Compose(), hflip()]\n",
       "11005    [import torchvision.datasets as dset\\r\\nimport...\n",
       "11006    [num_samples=5,     generated = torch.cat((gen...\n",
       "11007    [AutoTokenizer.from_pretrained, [1]:    tokeni...\n",
       "11008    [AutoTokenizer.from_pretrained, [1]:    tokeni...\n",
       "11009    [AttributeError: module 'torch.optim' has no a...\n",
       "11011    [(N, I), N, I, 0, Z, N=5, I=3, Z=100, foo = te...\n",
       "11012    [self.layer1 = nn.Sequential(nn.Conv1d(input_d...\n",
       "11013    [transformers, PyTorch, # train the model\\r\\n%...\n",
       "11014    [from torchtext import datasets\\r\\nimport rand...\n",
       "11015    [for epoch in progress_bar(range(num_epochs)):...\n",
       "11016    [# x is input and y_yellow, y_purple are label...\n",
       "11018    [class myNetwork(nn.Module):\\r\\n   def __init_...\n",
       "11019    [DataLoader, dataset = HD5Dataset(args.dataset...\n",
       "11020    [DataLoader, dataset = HD5Dataset(args.dataset...\n",
       "11021    [#self.param_groups = _copy.deepcopy(other.par...\n",
       "11024                          [torch.nn.CrossEntropyLoss]\n",
       "11026    [RuntimeError \\r\\nTraceback (most recent call ...\n",
       "11027    [tensorboard, model = SimpleLSTM(4, HIDDEN_DIM...\n",
       "11028    [print(label.shape)\\r\\n, plt.imshow(fake_seg_t...\n",
       "11029    [b = 128\\r\\n\\r\\nembedding_matrix = [[20000,300...\n",
       "11030    [libc++abi.dylib: terminating with uncaught ex...\n",
       "11031    [..., ...,         prediction = (\\r\\n         ...\n",
       "11032    [images = ImageList.from_tensors(lst[:1], size...\n",
       "11033    [class Model:\\r\\n   def __init__(self, nets):\\...\n",
       "11034    [model = nn.Sequential, out = model(X)\\r\\n# OR...\n",
       "11035    [model = nn.Sequential, out = model(X)\\r\\n# OR...\n",
       "11036    [OrderedDict, layers = (784, 392, 196, 98, 10)...\n",
       "11038    [Found GPU0 GeForce GTX 770 which is of cuda c...\n",
       "11039    [.clone(), .detach(), copy.deepcopy, require_g...\n",
       "11041    [InputFeatures, class InputFeatures:\\r\\n    .....\n",
       "11042    [class MyDataset(Dataset):\\r\\n\\r\\n    def __in...\n",
       "11043    [emnist = scipy.io.loadmat(DATA_DIR + '/emnist...\n",
       "11045          [PyTorch's, CosineAnnealingWarmRestarts().]\n",
       "11046          [PyTorch's, CosineAnnealingWarmRestarts().]\n",
       "11047    [import scipy .io\\r\\nemnist = scipy.io.loadmat...\n",
       "11048    [- Layer Normalization \\r\\n- Bi-directional GR...\n",
       "11050    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "11051    [tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],  # cl...\n",
       "11052    [train.head()\\r\\n\\r\\nimage_names emergency_or_...\n",
       "11053    [&gt;&gt; import torch\\r\\n\\r\\n&gt;&gt; torch.c...\n",
       "11054    [    x = # [batchsize , length , 1024]\\r\\n    ...\n",
       "11055    [# The code above is miscellaneous training da...\n",
       "11056    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "11057    [print(dataset_train[0][0].shape), torch.Size(...\n",
       "11058    [print(dataset_train[0][0].shape), torch.Size(...\n",
       "11059    [resnet50_model = torchvision.models.resnet50(...\n",
       "11060    [#custom data loader\\r\\nclass set(Dataset):\\r\\...\n",
       "11061    [def __init__(self):\\r\\n        super(Lightnin...\n",
       "11062    [optimizer.options.learning_rate();\\r\\n, learn...\n",
       "11063    [def error_unexpected_way_to_by_pass_safety():...\n",
       "11064    [def error_unexpected_way_to_by_pass_safety():...\n",
       "11065    [torch.clamp, import torch\\r\\nt = torch.tensor...\n",
       "11066    [torch.clamp, import torch\\r\\nt = torch.tensor...\n",
       "11067    [transforms.Compose(), (num_samples, width, he...\n",
       "11068    [class KeplerDataset(Dataset):\\r\\n    def __in...\n",
       "11069    [x, y = np.meshgrid(np.random.randn(100) , np....\n",
       "11070    [int main(int argc, const char* argv[]) {\\r\\n\\...\n",
       "11071    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11072    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11073    [torch.cuda.is_available()\\r\\n, False, torch._...\n",
       "11074    [if __name__ == \"__main__\":\\r\\n\\r\\nmyNet      ...\n",
       "11075    [multiprocessing.Process, tensorflow-gpu==1.14...\n",
       "11076    [src = [20, 95], src_mask = [20, 95], layer=to...\n",
       "11077    [class CartPoleEnvManager(): #manage cartpole ...\n",
       "11078    [#getting weights and biases from tensorflow m...\n",
       "11081    [\\r\\ndef inner_loop1():\\r\\n    n_inner_iter = ...\n",
       "11082    [\\r\\ndef inner_loop1():\\r\\n    n_inner_iter = ...\n",
       "11086    [MSELoss, import numpy as np\\r\\nimport torch\\r...\n",
       "11087    [MSELoss, import numpy as np\\r\\nimport torch\\r...\n",
       "11088    [for epoch in range(EPOCHS):\\r\\n\\r\\n    for id...\n",
       "11089    [.named_children, .named_modules, In [19]: imp...\n",
       "11090    [  File \"/home/jq/PycharmProjects/Unet/Code/Li...\n",
       "11091    [Input = torch.tensor([1,2,3,4,5,6,7,8,9,0,1,2...\n",
       "11092    [input = torch.randn(6, 512, 768) \\r\\n, in_cha...\n",
       "11093    [input = torch.randn(6, 512, 768) \\r\\n, in_cha...\n",
       "11094    [input = torch.randn(6, 512, 768) \\r\\n, in_cha...\n",
       "11095    [tensor([[-5.1949, -6.2621, -6.2051, -5.8983, ...\n",
       "11096    [tensor([[-5.1949, -6.2621, -6.2051, -5.8983, ...\n",
       "11097    [tensor([[-5.1949, -6.2621, -6.2051, -5.8983, ...\n",
       "11099    [      column_1  column_2  or  and  xor\\r\\n0  ...\n",
       "11100    [tune, import torch.optim as optim\\r\\nfrom ray...\n",
       "11101    [dataset = datasets.MNIST(root=root, train=ist...\n",
       "11103    [class ActionNet(Module):\\r\\n\\r\\n    def __ini...\n",
       "11105    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "11106    [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "11107    [from torch.utils.data import DataLoader, Data...\n",
       "11108    [from torch.utils.data import DataLoader, Data...\n",
       "11109    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11110    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11111    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11112    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11113    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11114    [lspci | grep nvidia, 01:00.0 3D controller: N...\n",
       "11116    [torchvision.models.resnet18(), net = torchvis...\n",
       "11117    [class DPWHDataset(Dataset):\\r\\n  def __init__...\n",
       "11118    [K = torch.random.randn(20, 2000, 2000)\\r\\nK_s...\n",
       "11119    [torch.nn.Parameters, to_sparse, Parameters, T...\n",
       "11120    [import torch\\r\\nimport torch.multiprocessing ...\n",
       "11122    [    X_train = df.drop('class', axis=1).to_num...\n",
       "11123    [Input = torch.tensor([[2, 3], [3, 4], [4, 5]]...\n",
       "11124    [Input = torch.tensor([[2, 3], [3, 4], [4, 5]]...\n",
       "11126    [Target size (torch.Size([4, 1, 320, 480, 6]))...\n",
       "11127    [from torch.distributions.multivariate_normal ...\n",
       "11128    [df_for_torch = pd.DataFrame(columns=['inputs'...\n",
       "11129    [Tree enc done\\r\\nBegin tree prediction&lt;---...\n",
       "11132    [import torch.nn as nn\\r\\nfrom skorch import N...\n",
       "11133    [Missing key(s) in state_dict: \"layer2.0.layer...\n",
       "11134    [tensorboard --logdir=runs, tensorboard --logd...\n",
       "11135    [tensorboard --logdir=runs, tensorboard --logd...\n",
       "11136    [!nvidia-smi, +-------------------------------...\n",
       "11137    [ from torchvision.models.detection.faster_rcn...\n",
       "11138    [ from torchvision.models.detection.faster_rcn...\n",
       "11139    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "11140    [prediction = np.argmax(y_hat.detach().numpy, ...\n",
       "11141    [def get_sharpness(data_loader, model, criteri...\n",
       "11142    [SAGEConv, SAGEConv, NNConv, NNConv, edge_func...\n",
       "11143    [ x = torch.arange(1., 8)\\r\\n x\\r\\ntensor([ 1....\n",
       "11144    [EfficientDet(\\r\\n  (backbone): EfficientNetFe...\n",
       "11145    [tf.norm(my_tensor, ord=2, axis=1), torch.norm...\n",
       "11146    [root\\r\\n|- Application 1\\r\\n|   |- image 1\\r\\...\n",
       "11147    [root\\r\\n|- Application 1\\r\\n|   |- image 1\\r\\...\n",
       "11148    [def Read_LMDB(root, classes):\\r\\n    d1 = tor...\n",
       "11149    [torch.nn.utils.prune, def prune_net(net):\\r\\n...\n",
       "11151    [UserWarning: Using a target size (torch.Size(...\n",
       "11152    [class LoadDataset(Dataset):\\r\\n    def __init...\n",
       "11153    [batch_size = 64\\r\\nvalidation_split = 0.2\\r\\n...\n",
       "11154    [batch_size = 64\\r\\nvalidation_split = 0.2\\r\\n...\n",
       "11155    [transform = T.Compose([\\r\\n    T.Resize(224),...\n",
       "11156    [torch.zeros()\\r\\n, [layer_dim, batch, hidden_...\n",
       "11157    [torch.zeros()\\r\\n, [layer_dim, batch, hidden_...\n",
       "11158    [x, [num_elem, 128], batch, [num_elem, 1], bat...\n",
       "11159    [tokenizer.decode(), from transformers.tokeniz...\n",
       "11160    [tokenizer.decode(), from transformers.tokeniz...\n",
       "11161    [if (OLD_ITERATIONS + i)%10 is 0 and i is not ...\n",
       "11162    [(env_peem) PS E:\\Users\\Maggie\\TS_MatSeg_Share...\n",
       "11163    [(env_peem) PS E:\\Users\\Maggie\\TS_MatSeg_Share...\n",
       "11165    [bert, import torch\\r\\nfrom torch import nn\\r\\...\n",
       "11166                                    [E * A.mm(B)\\r\\n]\n",
       "11167    [class Network(torch.nn.Module):\\r\\n    def __...\n",
       "11168    [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "11169    [class Model(nn.Module):\\r\\ndef __init__(self,...\n",
       "11170    [Collecting package metadata (current_repodata...\n",
       "11171    [total_epoch = 1   \\r\\nbest_epoch = 0\\r\\ntrain...\n",
       "11172    [\\r\\nlabels = {'id1':0,'id2':2,'id3':1,'id4':3...\n",
       "11174    [class Flatten(Module):\\r\\n\\r\\n    def forward...\n",
       "11175    [torch.Tensor(([1, 2, 3, 4, 3, 3, 4],\\r\\n     ...\n",
       "11176    [//imports including import deepnet.py\\r\\ncudn...\n",
       "11177    [  File \"run_ner.py\", line 594, in &lt;module&...\n",
       "11180    [V x D, V, D, weights, # Keras code.\\r\\nembedd...\n",
       "11181    [l = []\\r\\nl.append(datasets.ImageFolder(file_...\n",
       "11183    [N = 5000\\r\\nx = np.linspace(-np.pi, np.pi, N)...\n",
       "11184    [from torch.nn import TransformerEncoder, Tran...\n",
       "11185    [model = nn.Sequential(\\r\\n    nn.BatchNorm2d(...\n",
       "11186    [RuntimeError: running_mean should contain 64 ...\n",
       "11188    [This attribute exists on the Python module, b...\n",
       "11189    [def forward(self, input):\\r\\n    x1, x2 = inp...\n",
       "11190    [{\"train\": [{\"input\": [[3, 1, 2], [3, 1, 2], [...\n",
       "11191    [Merkel bemoans lack of rain as Germany fears ...\n",
       "11192    [arr = [1,2,3,4,5,6,7,8,9,10].\\r\\n, [1,2,5,6,9...\n",
       "11194    [def cxcy_to_xy(cxcy):\\r\\n    \"\"\"\\r\\n    Conve...\n",
       "11195    [LSTM(512,\\r\\n     stateful = False,\\r\\n     r...\n",
       "11196    [#tensorflow auto-broadcasts singleton dimensi...\n",
       "11197    [#tensorflow auto-broadcasts singleton dimensi...\n",
       "11198    [    import torch\\r\\n    dtype = torch.float\\r...\n",
       "11199    [def _make_batches(self, lines):\\r\\n        to...\n",
       "11200    [df.head()\\r\\nOut[46]: \\r\\n             file_p...\n",
       "11201    [data.shape = [batch_size, sequence_length, vo...\n",
       "11202    [def nesterov_update(w, dw, v, lr, weight_deca...\n",
       "11203    [ CUDA error: CUBLAS_STATUS_ALLOC_FAILED when ...\n",
       "11204    [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "11205    [def confusion_matrix(y_pred: torch.Tensor, y_...\n",
       "11206    [self.up = nn.Upsample(scale_factor=2, mode='b...\n",
       "11208    [generation model p(x_{1:T} | z_{1:T}) p(z_{1:...\n",
       "11209    [ b['optimizer_state_dict']['state'].keys()\\r\\...\n",
       "11210    [torch.utils.data.DataLoader, torchvision.data...\n",
       "11211    [nn.CrossEntropyLoss, predictions = torch.rand...\n",
       "11212    [[torch.cuda.FloatTensor [256, 1, 4, 4]] is at...\n",
       "11213    [net=Net10(5,2,4,3,1,1), kernel_size, self.Con...\n",
       "11214    [model.cuda()\\r\\nfor epoch in range(10):\\r\\n  ...\n",
       "11215    [w2, h_relu, w1, w2, w2, y_pred, grad_w2 = h_r...\n",
       "11216    [Called with args:\\r\\nNamespace(batch_size=1, ...\n",
       "11217    [nn.Upsample, upConv, summary(UNetPP, (3, 128,...\n",
       "11218    [from PIL import Image, ImageOps\\r\\nimport tor...\n",
       "11219    [n, \\r\\ndef batch_tensor_to_onehot(tnsr, class...\n",
       "11220    [n, \\r\\ndef batch_tensor_to_onehot(tnsr, class...\n",
       "11221    [N = 2\\r\\nk = 3\\r\\nd = 2\\r\\n\\r\\nL = torch.aran...\n",
       "11222    [model = torchvision.models.detection.maskrcnn...\n",
       "11223    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11224    [bert, huggingface transformers bert, num_labe...\n",
       "11225    [def one_epoch(net, loss, dl, opt=None, metric...\n",
       "11226    [ t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, ...\n",
       "11227    [ t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, ...\n",
       "11228    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11229    [torch.save(net, 'lenet5_mnist_model')\\r\\n, pr...\n",
       "11230    [class convnet(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "11231    [class Netz(nn.Module):\\r\\ndef __init__(self):...\n",
       "11232    [version: 1\\r\\n\\r\\nkind: experiment\\r\\n\\r\\nenv...\n",
       "11234    [@staticmethod\\r\\ndef rescale_bounding_box(det...\n",
       "11235    [import numpy as np\\r\\nimport torch as t\\r\\nim...\n",
       "11237    [import torch\\r\\n\\r\\nclass Custom_Dataset(torc...\n",
       "11238    [(encoder): AlbertTransformer(\\r\\n      (embed...\n",
       "11239    [import numpy as np\\r\\n#set up the array conta...\n",
       "11240    [return_sequences = False, import torch\\r\\nfro...\n",
       "11241    [   POSITION\\r\\nx     y     z     (feature 1 x...\n",
       "11242    [ text.TransformerSummarizer()\\r\\n,  Transform...\n",
       "11243    [S, T, (s1,...,sm), (t1,...,tn), si &lt; ti, T...\n",
       "11244    [x = torch.ones(2,2, requires_grad=True)\\r\\nx....\n",
       "11246    [Waiting for stack website-aws-api-dev to upda...\n",
       "11247    [.to(device), t.Tensor(w_txt[0]).to(device)), ...\n",
       "11248    [def collate(samples) :\\r\\n  graphs,labels = m...\n",
       "11249    [Expected object of scalar type Float but got ...\n",
       "11250    [    from torch.nn.utils import weight_norm\\r\\...\n",
       "11252    [    w, h = hr_image.shape\\r\\n    ret = np.emp...\n",
       "11253    [l_conv7 = self.loc_conv7(conv7_feats)  # (N, ...\n",
       "11254    [old_values = torch.Tensor([1, 2, 3, 4, 5, 5, ...\n",
       "11255    [old_values = torch.Tensor([1, 2, 3, 4, 5, 5, ...\n",
       "11257    [numpy, torch, tensorflow, numpy, def unpack_n...\n",
       "11258    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "11259    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "11260    [forward, nn.CrossEntropyLoss(), NaN,     src_...\n",
       "11261    [torch.nn.functional.affine_grid, (N x 3 x 4),...\n",
       "11262    [    model = Sequential()\\r\\n    model.add(Con...\n",
       "11263    [    model = Sequential()\\r\\n    model.add(Con...\n",
       "11264    [    model = Sequential()\\r\\n    model.add(Con...\n",
       "11265    [    model = Sequential()\\r\\n    model.add(Con...\n",
       "11267    [Q = Q_Network(input_size, hidden_size, output...\n",
       "11268    [# Localization prediction convolutions (predi...\n",
       "11269    [            nn.Conv1d(depth_1, depth_2, kerne...\n",
       "11270    [import torch\\r\\nimport torch.nn.functional as...\n",
       "11271    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "11272    [features = df.drop(['quality'], axis = 1)\\r\\n...\n",
       "11273    [#include &lt;iostream&gt;\\r\\n\\r\\n#include &lt...\n",
       "11274    [batch_size = 100\\r\\nlearning_rate = 0.001\\r\\n...\n",
       "11275    [batch_size = 100\\r\\nlearning_rate = 0.001\\r\\n...\n",
       "11276    [X = [\\r\\n[0., 1.5, 4.7],\\r\\n[4., 0., 0.],\\r\\n...\n",
       "11277    [X = [\\r\\n[0., 1.5, 4.7],\\r\\n[4., 0., 0.],\\r\\n...\n",
       "11278    [pytorch, import sys \\r\\nimport random \\r\\nimp...\n",
       "11279    [Failed to export an ONNX attribute 'onnx::Gat...\n",
       "11281    [model_ft, hist = train_model(model_ft, datalo...\n",
       "11282    [*Traceback (most recent call last):\\r\\n  File...\n",
       "11283    [&lt;ipython-input-16-e211160f5ce8&gt; in &lt;...\n",
       "11284    [torch.save(), # default_lr = 5\\r\\n# default_w...\n",
       "11285    [def gen_initialization(m):\\r\\n    if type(m) ...\n",
       "11286    [prior_boxes = torch.FloatTensor(prior_boxes)....\n",
       "11288    [nn.Conv2d(16, 16, 3, padding = 1), self.conv1...\n",
       "11289    [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "11290    [state = torch.load('drive/My Drive/MODEL/4 CB...\n",
       "11291    [    mkdir python\\r\\n    docker run \\\\r\\n     ...\n",
       "11292    [    self.quantizer = q = nn.Conv1d(1, 2*nq, k...\n",
       "11293    [# computing loss_g and loss_d...\\r\\noptim_g.z...\n",
       "11294    ['''\\r\\n\\r\\ndef evaluate(dataloader_val):\\r\\n\\...\n",
       "11295    [encoder, decoder, features = encoder(input)\\r...\n",
       "11296    [log_preds,y = learn.TTA(scale=1.1, ds_type=Da...\n",
       "11297    [def fit(epochs, lr, model, train_loader, val_...\n",
       "11298    [def windowz(data, size):\\r\\n   start = 0\\r\\n ...\n",
       "11299    [RuntimeError: size mismatch, m1: [4 x 1024], ...\n",
       "11300    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11301    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11302    [    Traceback (most recent call last):\\r\\n  F...\n",
       "11303    [    Traceback (most recent call last):\\r\\n  F...\n",
       "11304    [import math\\r\\nimport torch as th\\r\\nimport t...\n",
       "11305    [def get_vector(image):\\r\\n\\r\\n#layer = model....\n",
       "11307    [grad_loss.backward(),     for (images, one_ho...\n",
       "11308    [grad_loss.backward(),     for (images, one_ho...\n",
       "11309    [import torch\\r\\nx = torch.randn(3,requires_gr...\n",
       "11310    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "11311    [pretrained pytorch, fp16, fp32, gpu, cpu, \"su...\n",
       "11312    [C: lUsers / ruiha Desktopl flappy_DQL&gt;pyth...\n",
       "11313    [C: lUsers / ruiha Desktopl flappy_DQL&gt;pyth...\n",
       "11315    [import torch.utils as utils\\r\\n\\r\\ntrain_load...\n",
       "11317    [class BertOnlyNSPHead(nn.Module):\\r\\n    def ...\n",
       "11318    [def shallownet(nb_classes):\\r\\n    global img...\n",
       "11319    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11320    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "11321    [output, values, k, import torch\\r\\n\\r\\nn = 4\\...\n",
       "11322    [import math\\r\\nimport torch as th\\r\\nimport t...\n",
       "11323    [!onmt_preprocess  \\\\\\r\\n-train_src //content/...\n",
       "11324    [tf.get_variable(\"char_embeddings\", [len(data....\n",
       "11325    [import timeit\\r\\n\\r\\nimport torch\\r\\nimport n...\n",
       "11326    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "11327    [np.random.seed(42)\\r\\n\\r\\npath = '/content/fo...\n",
       "11328    [\\r\\nw = np.array([[2., 2.],[2., 2.]])\\r\\nx = ...\n",
       "11330    [torch.distributed, def main():\\r\\n    np.rand...\n",
       "11331    [y = Y(x;theta), theta = M(t;omega), x, t, the...\n",
       "11332    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11334    [checkpoint = {'model': Net(), 'state_dict': m...\n",
       "11335    [checkpoint = {'model': Net(), 'state_dict': m...\n",
       "11336    [python 3.6\\r\\npytorch 1.0.1.post2\\r\\nnumpy, o...\n",
       "11337    [python 3.6\\r\\npytorch 1.0.1.post2\\r\\nnumpy, o...\n",
       "11338    [python 3.6\\r\\npytorch 1.0.1.post2\\r\\nnumpy, o...\n",
       "11339    [python 3.6\\r\\npytorch 1.0.1.post2\\r\\nnumpy, o...\n",
       "11340    [    def get_model(path, device):\\r\\n        m...\n",
       "11341    [\\r\\n    optimizer = torch.optim.Adam(net.para...\n",
       "11342    [TypeError                                 Tra...\n",
       "11343    [model = models.squeezenet1_1(pretrained=True)...\n",
       "11345    [bs = 64\\r\\ndata_lm = (TextList.from_df(df, pa...\n",
       "11346    [run_glue.py, # Set the seed value all over th...\n",
       "11347    [run_glue.py, # Set the seed value all over th...\n",
       "11348    [    C:\\Users\\aishv\\output&gt;qa.exe\\r\\nTo use...\n",
       "11349    [x, (n_samples, time_steps, n_features), (n_sa...\n",
       "11350    [numpy, import numpy as np\\r\\n\\r\\ndef mean_euc...\n",
       "11351    [n_id = np.random.choice(np.arange(2708), size...\n",
       "11352    [Residual Channel Attention Block(RCAB){\\r\\n\\r...\n",
       "11353    [class MMDataset(torch.utils.data.Dataset):\\r\\...\n",
       "11354    [gcloud, {\\r\\n  \"error\": \"Prediction failed: u...\n",
       "11355    [class TfidfEmbeds(BaseEmbeds):\\r\\n    # Input...\n",
       "11356    [\\r\\nimport numpy as np\\r\\nimport pandas as pd...\n",
       "11357    [conda install pytorch torchvision cudatoolkit...\n",
       "11358    [nn.LSTM, nn.Linear, state, forward(), (32, 20...\n",
       "11359    [nn.LSTM, nn.Linear, state, forward(), (32, 20...\n",
       "11360    [PyTorch, import numpy as np\\r\\nimport torch\\r...\n",
       "11361    [PyTorch, import numpy as np\\r\\nimport torch\\r...\n",
       "11362    [# creat a dummy deep net\\r\\nclass Net(nn.Modu...\n",
       "11363    [tensor(indices=tensor([[     0,      0,      ...\n",
       "11364    [import keras.backend as K\\r\\n\\r\\ndef guassian...\n",
       "11365    [class DeConv2d(nn.Module):\\r\\n    def __init_...\n",
       "11366    [class DeConv2d(nn.Module):\\r\\n    def __init_...\n",
       "11367    [%reset -f\\r\\n\\r\\nimport torch\\r\\nfrom torch.a...\n",
       "11368    [pytorch-1.5, gan, import torch\\r\\nimport torc...\n",
       "11369    [tensor results1=(\\r\\n[102(another id), 12(ran...\n",
       "11371    [python setup.py install, Processing dependenc...\n",
       "11372    [conv1d, in_channels, out_channels, (conv): Co...\n",
       "11374    [stack, cat, import torch as tc\\r\\nimport torc...\n",
       "11375    [[[1,2]\\r\\n[2,3]\\r\\n[4,6]\\r\\n...]\\r\\n, [[1,2]\\...\n",
       "11376    [[[1,2]\\r\\n[2,3]\\r\\n[4,6]\\r\\n...]\\r\\n, [[1,2]\\...\n",
       "11379    [import torch \\r\\ntorch.set_printoptions(preci...\n",
       "11380    [conda install pytorch torchvision cudatoolkit...\n",
       "11381    [staticmethod, net, path, net, @staticmethod\\r...\n",
       "11382    [def shallownet(nb_classes):\\r\\n    global img...\n",
       "11383                                        [torch.bmm()]\n",
       "11384    [with torch.no_grad():\\r\\n\\r\\n    for _ in ran...\n",
       "11386    [import sys\\r\\nimport os.path\\r\\nimport glob\\r...\n",
       "11387    [def train_dataloader(self):\\r\\n    train_set ...\n",
       "11388    [%timeit, UnboundLocalError: local variable 'a...\n",
       "11389    [BERT, softmax, answer_start_index, answer_end...\n",
       "11390    [import torch\\r\\na = torch.rand(10).cuda()\\r\\n...\n",
       "11391    [import torch\\r\\na = torch.rand(10).cuda()\\r\\n...\n",
       "11396    [nn.ReflectionPad2d(1)\\r\\n, tf.pad(t, tf.const...\n",
       "11397    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "11398    [nn.MSELoss(), torch.sqrt(), bs, [bs , 20],   ...\n",
       "11399    [nn.MSELoss(), torch.sqrt(), bs, [bs , 20],   ...\n",
       "11400    [def preprocess_image(pil_im, resize_im=True):...\n",
       "11401    [def preprocess_image(pil_im, resize_im=True):...\n",
       "11402    [h() missing 1 required positional argument: '...\n",
       "11403    [outputs = model(article_tens, labels=article_...\n",
       "11404                   [std::vector&lt;torch::Tensor&gt;]\n",
       "11407    [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "11408    [        losso = 0\\r\\n        for g, logprob i...\n",
       "11409    [from torch import nn\\r\\n\\r\\nclass FixedModule...\n",
       "11410    [from torch import nn\\r\\n\\r\\nclass FixedModule...\n",
       "11411    [/opt/conda/conda-bld/pytorch_1565272269120/wo...\n",
       "11412    [RuntimeError                              Tra...\n",
       "11413    [gpu_options = tf.GPUOptions(per_process_gpu_m...\n",
       "11414    [from torchvision import models\\r\\nfrom PIL im...\n",
       "11415    [array.shape\\r\\n, torch.from_numpy, torch.tens...\n",
       "11416    [BertForSequenceClassification, k, import torc...\n",
       "11417    [Optimizing the network with batch size 25\\r\\n...\n",
       "11418    [Scaling = \\r\\n[[0.75, 0, 0, 0],\\r\\n[[0, 0.75,...\n",
       "11419    [def generate(rnn, prime_id, int_to_vocab, tok...\n",
       "11420    [hidden_size=10\\r\\nembedding = nn.Embedding(VO...\n",
       "11421    [import torch\\r\\nT = torch.FloatTensor(range(0...\n",
       "11422    [class Autoencoder(nn.Module):\\r\\n    def __in...\n",
       "11423    [# Using loss weights, the inverse of class fr...\n",
       "11424    [torch.Size([8, 768]), embeddings,  tensor([[-...\n",
       "11425    [A = torch.arange(24).view(4, 3, 2)\\r\\nprint(A...\n",
       "11426    [A = torch.arange(24).view(4, 3, 2)\\r\\nprint(A...\n",
       "11427    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11428    [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "11429    [THCudaCheck FAIL file=/pytorch/aten/src/THC/T...\n",
       "11430    [Embedding_Model(nn.Module):\\r\\n    def __init...\n",
       "11431    [class Net(nn.Module):\\r\\n    ...\\r\\n    def f...\n",
       "11432    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11433    [pip list,  import torch\\r\\nTraceback (most re...\n",
       "11434    [class LSTM_NN(nn.Module):\\r\\n\"\"\"\\r\\nStores th...\n",
       "11435    [class CNet(nn.Module):\\r\\n    def __init__(se...\n",
       "11436    [def collate_fn_padd(batch):\\r\\n    '''\\r\\n   ...\n",
       "11437    [def collate_fn_padd(batch):\\r\\n    '''\\r\\n   ...\n",
       "11438    ['Medium size class', 'mdmsc', class Autoencod...\n",
       "11439    [training_batch = torch.cat ([real_batch, fake...\n",
       "11440    [training_batch = torch.cat ([real_batch, fake...\n",
       "11441    [torch, torchvision, torchvision, torchvision,...\n",
       "11442    [import torch\\r\\n, raceback (most recent call ...\n",
       "11443    [for epoch in range(start_epoch, epochs):\\r\\n ...\n",
       "11444    [/home/user/.local/lib/python3.6/site-packages...\n",
       "11445    [3,256,256, img = Image.fromarray((255*imgs[i]...\n",
       "11447    [checkpoint  = torch.load('model.pth', map_loc...\n",
       "11448    [scipy.odeint, import torch\\r\\nimport numpy as...\n",
       "11449    [class MyModule(torch.nn.Module):\\r\\n    def _...\n",
       "11450    [class kfkdataset(Dataset):\\r\\ndef __init__(se...\n",
       "11451    [class environment_step:\\r\\n    def __init__(s...\n",
       "11452    [Band5','Band6', 'Band7', [batch, w, h], x = c...\n",
       "11453    [import torchvision\\r\\nimport torch\\r\\nimport ...\n",
       "11455    [conda create -n pytorch_p37 python=3.7\\r\\ncon...\n",
       "11456    [conda create -n pytorch_p37 python=3.7\\r\\ncon...\n",
       "11457    [i=20\\r\\nj=30\\r\\nz = np.zeros((50,50))\\r\\nwhil...\n",
       "11458    [a = torch.randn(10, 1000, 1, 4)\\r\\nb = torch....\n",
       "11459    [def __len__(self):\\r\\n        return len(self...\n",
       "11460    [def _mp_fn(index, batch_size, model, typee, d...\n",
       "11461    [# -*- coding: utf-8 -*-\\r\\n\\r\\n\\r\\n\\r\\n#Libra...\n",
       "11462    [class WeightedLabels(ItemBase):\\r\\n\"\"\"\\r\\nCus...\n",
       "11463    [train_data = CUB200.CUB200(transform=transfor...\n",
       "11464    [import numpy as np\\r\\nfrom time import time\\r...\n",
       "11465    [---------------------------------------------...\n",
       "11466    [Downloading https://www.cs.toronto.edu/~kriz/...\n",
       "11467    [max_score_broadcast = max_score.view(1, -1).e...\n",
       "11468    [my_model = nn.Sequential(\\r\\n            nn.L...\n",
       "11469    [class RNNModule(nn.Module):\\r\\n    def __init...\n",
       "11470    [self.W_x = nn.Linear(self.input_dim, self.hid...\n",
       "11471    [images = img_tensor.cpu().detach().permute(0,...\n",
       "11472    [images = img_tensor.cpu().detach().permute(0,...\n",
       "11473    [train = datasets.MNIST(\"\", train=True, downlo...\n",
       "11475    [class BERTBaseUncased(nn.Module):\\r\\n    def ...\n",
       "11476    [class BERTBaseUncased(nn.Module):\\r\\n    def ...\n",
       "11477    [optimizer = optim.SGD(net.parameters(), lr=0....\n",
       "11478    [class FNet(nn.Module):\\r\\n    def __init__(se...\n",
       "11479    [class FNet(nn.Module):\\r\\n    def __init__(se...\n",
       "11481    [device_ids = list(range(num_gpus))\\r\\nmodel =...\n",
       "11482    [device_ids = list(range(num_gpus))\\r\\nmodel =...\n",
       "11483    [torch.optim.adam, translation, vertices = []\\...\n",
       "11484    [torch.optim.adam, translation, vertices = []\\...\n",
       "11485    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11488    [import torch\\r\\nfrom onnx_coreml import conve...\n",
       "11490    [!curl https://raw.githubusercontent.com/pytor...\n",
       "11491    [!curl https://raw.githubusercontent.com/pytor...\n",
       "11492    [all_params = chain(module_a.parameters(), mod...\n",
       "11494    [class myNet(nn.Module):\\r\\n    def __init__(s...\n",
       "11495    [(-1,128,6), serverModel = Sequential()\\r\\nser...\n",
       "11496    [batch_boyut = 2\\r\\n\\r\\ntrain_loader = torch.u...\n",
       "11497    [class Block_of_net(nn.Module):\\r\\n  def __ini...\n",
       "11498    [ERROR: Could not find a version that satisfie...\n",
       "11499    [ERROR: Could not find a version that satisfie...\n",
       "11500    [ERROR: Could not find a version that satisfie...\n",
       "11501    [ERROR: Could not find a version that satisfie...\n",
       "11502    [class autoencoder(nn.Module):\\r\\n    def __in...\n",
       "11503    [def __init__(self,input_size,hidden_size,outp...\n",
       "11504    [[0,1,0,1,0,1,0,1,0],[0,1,1,0,0,1,0,1,0],[0,1,...\n",
       "11505    [[0,1,0,1,0,1,0,1,0],[0,1,1,0,0,1,0,1,0],[0,1,...\n",
       "11506    [for i in range(int(image_size/2-5),int(image_...\n",
       "11508    [eval(), def eval(file):\\r\\n    image = io.imr...\n",
       "11509    [import torch\\r\\ntacotron2 = torch.hub.load('n...\n",
       "11513    [np.savez(outpath + \"/data.npz\", **keywords), ...\n",
       "11514    [.to(), # let us run this cell only if CUDA is...\n",
       "11515    [class BDRWDataset(Dataset):\\r\\n\"\"\"BDRW datase...\n",
       "11516    [from torch.utils.data import Dataset, DataLoa...\n",
       "11517    [Shape of tensor_1 : (1, 3, 10, 10, 1)\\r\\nShap...\n",
       "11518    [Shape of tensor_1 : (1, 3, 10, 10, 1)\\r\\nShap...\n",
       "11519    [#define policy model (model to learn a policy...\n",
       "11520    [#define policy model (model to learn a policy...\n",
       "11521    [#define policy model (model to learn a policy...\n",
       "11522    [RuntimeError: Expected hidden[0] size (4, 600...\n",
       "11523    [&gt; len(x)\\r\\n,  (x=array([[[[ 0.07499999,  ...\n",
       "11524    [&gt; len(x)\\r\\n,  (x=array([[[[ 0.07499999,  ...\n",
       "11526    [a * x + b = x, a, b, x, import torch\\r\\nX = t...\n",
       "11527    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "11528    [class SiameseCNN(nn.Module):\\r\\n    def __ini...\n",
       "11529    [class SiameseCNN(nn.Module):\\r\\n    def __ini...\n",
       "11531    [[100K, 300], [300, 1], [100K, 300]*[300, 1] =...\n",
       "11532    [x.shape = (243, 108)\\r\\ny.shape = (243,)\\r\\n,...\n",
       "11533    [class Cudnn_RNN:\\r\\n\\r\\n    def __init__(self...\n",
       "11534    [net = &lt;my defined model, from another func...\n",
       "11535    [FROM python:3.6-stretch\\r\\n\\r\\n\\r\\n# install ...\n",
       "11536    [M, (n,m), M[i][j], (p, q, r, ...), M, (n,m,p,...\n",
       "11537    [M, (n,m), M[i][j], (p, q, r, ...), M, (n,m,p,...\n",
       "11538    [pos = tf.ones((12, 2)) ## stands for a set of...\n",
       "11539    [pos = tf.ones((12, 2)) ## stands for a set of...\n",
       "11540    [pos = tf.ones((12, 2)) ## stands for a set of...\n",
       "11541    [x.shape = (244, 108)\\r\\nx = np.expand_dims(x,...\n",
       "11542    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "11543    [https://github.com/shishishu/pytorch-captcha-...\n",
       "11544    [def train(train_img_path, train_label_path, p...\n",
       "11545    [with np.load('prediction-challenge-01-data.np...\n",
       "11546    [def multi_acc(pred, label):\\r\\n    probs = to...\n",
       "11547    [def multi_acc(pred, label):\\r\\n    probs = to...\n",
       "11549                             [x, y, x = x.add(y)\\r\\n]\n",
       "11550                             [x, y, x = x.add(y)\\r\\n]\n",
       "11551                             [x, y, x = x.add(y)\\r\\n]\n",
       "11552                                      [[\"acc_delta\"]]\n",
       "11553                                      [[\"acc_delta\"]]\n",
       "11554    [Traceback (most recent call last):\\r\\n    Fil...\n",
       "11555    [0.8, 0.1, 0.9, 0.2\\r\\n0.7, 0.1, 0.4, 0.6\\r\\n,...\n",
       "11556    [0.8, 0.1, 0.9, 0.2\\r\\n0.7, 0.1, 0.4, 0.6\\r\\n,...\n",
       "11557    [0.8, 0.1, 0.9, 0.2\\r\\n0.7, 0.1, 0.4, 0.6\\r\\n,...\n",
       "11559    [a, b, loss1, loss2 = f(a,b), g(a,b), f, g, fg...\n",
       "11560    [Query (Q), Key (K), Q = batch_size x seq_leng...\n",
       "11561    [Query (Q), Key (K), Q = batch_size x seq_leng...\n",
       "11562    [\"*variable_name\", print(\"top_class.shape {}\"....\n",
       "11563    [import numpy as np\\r\\nimport torch\\r\\n\\r\\ntor...\n",
       "11564    [which nvcc, nvidia-smi, $ which nvcc\\r\\n/usr/...\n",
       "11565    [which nvcc, nvidia-smi, $ which nvcc\\r\\n/usr/...\n",
       "11566    [which nvcc, nvidia-smi, $ which nvcc\\r\\n/usr/...\n",
       "11567    [gcloud app browse, app.yaml, gunivorn, -w 24 ...\n",
       "11570    [import numpy.core.multiarray  # which is a wo...\n",
       "11571    [path, iloc,  img_path = os.path.join(self.roo...\n",
       "11572    [VG1 = vgg.VGG16(\"/kaggle/working/transformer_...\n",
       "11573    [batch_size=10\\r\\nchannels = 2\\r\\nn_coords = 1...\n",
       "11574    [class Encoder(nn.Module):\\r\\n    r\"\"\"Applies ...\n",
       "11575    [def train_models(inputs, targets):\\r\\n    net...\n",
       "11576    [# n, k           10000000         ( 1E7 )\\r\\n...\n",
       "11577    [\\r\\ndef pad_sents(sents, pad_token):  #Pad li...\n",
       "11578    [file_parse = r'/([^/]+)_\\d+\\.(png|jpg|jpeg)$'...\n",
       "11579    [class CNN_simple(nn.Module):\\r\\n    def __ini...\n",
       "11580    [import argparse\\r\\nimport torch\\r\\nimport tor...\n",
       "11581    [import numpy as np\\r\\nfrom transformers impor...\n",
       "11582                             [scp, ssh, state_dict()]\n",
       "11583    [model, model2, self.ddqn = False,     def rep...\n",
       "11584    [[64, 4, 300], [64, 300], [64, 5, 300], tensor...\n",
       "11585    [&lt;ipython-input-28-508d35ac5f5f&gt; in flat...\n",
       "11587    [torch, ImportError:numpy.core.multiarray fail...\n",
       "11588    [model = torchvision.models.resnet18()\\r\\nop =...\n",
       "11589    [ class WeightDropout(Module):\\r\\n        \"A m...\n",
       "11590    [010, 10, int, tensor,   y_label = torch.tenso...\n",
       "11591    [def mixup_data(x, y, alpha=1.0):\\r\\n    lam =...\n",
       "11592    [def mixup_data(x, y, alpha=1.0):\\r\\n    lam =...\n",
       "11593    [Step #1 - \"builder\": OSError: [Errno 12] Cann...\n",
       "11594    [Epoch: [6]  [  0/119]  eta: 0:01:16  lr: 0.00...\n",
       "11595    [line = \"1 5 3 7 4\"\\r\\nnp_array = np.fromstrin...\n",
       "11596    [line = \"1 5 3 7 4\"\\r\\nnp_array = np.fromstrin...\n",
       "11597    [RuntimeError: one of the variables needed for...\n",
       "11598    [feature_extractor.py, import torch\\r\\nimport ...\n",
       "11599    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "11600    [(8, 5, 300), T = T.reshape(5, 300, 8)\\r\\nT.sh...\n",
       "11601    [class RotNet1(nn.Module):\\r\\n    def __init__...\n",
       "11602    [from transformers import DistilBertTokenizerF...\n",
       "11603    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11604    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11605    [class SnakeAI(nn.Module):\\r\\n    def __init__...\n",
       "11606    [class SnakeAI(nn.Module):\\r\\n    def __init__...\n",
       "11607    [ import torch\\r\\n    Traceback (most recent c...\n",
       "11608    [def forward(self, sequence):\\r\\n        print...\n",
       "11609    [def get_accuracy(pred, actual):\\r\\n  assert l...\n",
       "11611    [BertForSequenceClassification, nn.Module, fro...\n",
       "11612    [Fint_MAT        = torch.zeros((tne,N))\\r\\nFin...\n",
       "11613    [Dataset, Dataloader, array, torch.Size([1, 56...\n",
       "11614    [Dataset, Dataloader, array, torch.Size([1, 56...\n",
       "11615    [batch = torch.tensor([\\r\\n                   ...\n",
       "11616    [batch = torch.tensor([\\r\\n                   ...\n",
       "11617    [import numpy as np\\r\\nn= 3\\r\\nm = 2\\r\\nx = np...\n",
       "11618    [xy, x_data, y_data, torch.autograd.Variable, ...\n",
       "11619    [ from __future__ import division\\r\\n\\r\\nfrom ...\n",
       "11620    [import torch\\r\\nimport torch.onnx\\r\\nimport o...\n",
       "11621    [q_s.shape\\r\\nOut[161]: torch.Size([8, 1, 128]...\n",
       "11622    [output = tensor([[[ 0.0868, -0.2623],\\r\\n    ...\n",
       "11623    [output = tensor([[[ 0.0868, -0.2623],\\r\\n    ...\n",
       "11626    [out = Dense(10,activation='softmax')(previous...\n",
       "11627    [import torch\\r\\nfrom torchvision import model...\n",
       "11631    [ImportError: cannot import name 'mobilenet_v2...\n",
       "11632    [class Network(nn.Module):\\r\\n  def __init__(s...\n",
       "11633    [a = torch.FloatTensor(\\r\\n   [[5, 5],\\r\\n    ...\n",
       "11634    [a = torch.FloatTensor(\\r\\n   [[5, 5],\\r\\n    ...\n",
       "11635    [ # To get the images and labels from file\\r\\n...\n",
       "11636    [data_idx, data_idx = [2, 5, 5, 0, 4, 1, 4, 5,...\n",
       "11637    [import torch.multiprocessiA3Cng as mp\\r\\nimpo...\n",
       "11638    [class MorphNetwork(nn.Module):\\r\\n    def __i...\n",
       "11639    [from detectron2.utils.visualizer import Color...\n",
       "11640    [    print(self.global_model.state_dict())\\r\\n...\n",
       "11641    [from PIL import Image \\r\\nimg = Image.open(\"c...\n",
       "11642    [forward,     def forward(self, x):\\r\\n       ...\n",
       "11643    [COMET INFO:     sys.cpu.percent.43       : (0...\n",
       "11644    [import torch\\r\\n\\r\\nfrom torch.autograd impor...\n",
       "11645    [message Tensor {\\r\\n    google.protobuf.Any o...\n",
       "11646    [AttributeError                            Tra...\n",
       "11647    [AttributeError                            Tra...\n",
       "11648    [# CNN Model - LeNet    \\r\\nclass LeNet_ReLU(n...\n",
       "11649    [pad_packed_sequence, MAX_LEN, [12, 384, 768],...\n",
       "11650    [class DenseSynthesizer(nn.Module):\\r\\n    def...\n",
       "11652    [transformations = transforms.Compose([\\r\\n   ...\n",
       "11654    [import math\\r\\nclass PositionalEncoding(nn.Mo...\n",
       "11655                         [x, y, xs, ys, Ys, x[0], xs]\n",
       "11656                         [x, y, xs, ys, Ys, x[0], xs]\n",
       "11657    [# Since we just updated D, perform another fo...\n",
       "11658    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "11659    [IoU metric: bbox\\r\\n Average Precision  (AP) ...\n",
       "11660    [import torch\\r\\nparams = [torch.nn.Parameter(...\n",
       "11661    [import torch\\r\\nparams = [torch.nn.Parameter(...\n",
       "11662    [import torch\\r\\nparams = [torch.nn.Parameter(...\n",
       "11663    [from tokenizers import ByteLevelBPETokenizer\\...\n",
       "11664    [squeeze, unsqueeze, x = torch.rand(3,2,dtype=...\n",
       "11665    [squeeze, unsqueeze, x = torch.rand(3,2,dtype=...\n",
       "11666    [squeeze, unsqueeze, x = torch.rand(3,2,dtype=...\n",
       "11668    [class LogisticRegressionModel(nn.Module):\\r\\n...\n",
       "11669    [RuntimeError: size mismatch, m1: [5 x 10], m2...\n",
       "11670    [def train_and_evaluate(net, optimizer, criter...\n",
       "11671    [#!/usr/bin/env python3\\r\\n#encoding:utf-8\\r\\n...\n",
       "11672    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "11673    [loss.backward(retain_graph=True, create_graph...\n",
       "11678    [class Softmax(nn.Module):\\r\\n    def __init__...\n",
       "11679    [class ConvolutionalNetwork(nn.Module):  \\r\\n\\...\n",
       "11680    [torch.nn.functional, import torch\\r\\nimport t...\n",
       "11681    [conda install -c pytorch -c fastai fastai, in...\n",
       "11682    [Food-101\\r\\n      images\\r\\n            train...\n",
       "11683    [__init__, self._load_config_file(cfg_file)\\r\\...\n",
       "11684    [__init__, self._load_config_file(cfg_file)\\r\\...\n",
       "11685    [X_train, X_test, y_train, y_test = train_test...\n",
       "11686    [torch.data.dataset, Traceback (most recent ca...\n",
       "11687                                  [(16384,3,224,224)]\n",
       "11688    [learn = cnn_learner(data, models.resnet50, me...\n",
       "11689    [learn = cnn_learner(data, models.resnet50, me...\n",
       "11690    [  Ġlives   \\r\\n  Ġo\\r\\n  Ġn\\r\\n  ĠCali\\r\\n, d...\n",
       "11691    [(512,3,224,224), 2, scores, label = torch.one...\n",
       "11692    [nn.Linear(vocab_size, num_labels), num_labels...\n",
       "11693    [from __future__ import print_function, divisi...\n",
       "11694    [test = torch.zeros(10000)\\r\\ndiv = torch.div(...\n",
       "11695    [a = torch.rand(1,5,2,2)\\r\\nprint(a.shape)\\r\\n...\n",
       "11696    [for each image in poorQualityImages:\\r\\n    s...\n",
       "11698                                [ps -a | grep python]\n",
       "11699    [from torch.utils.data.dataset import Dataset\\...\n",
       "11700    [python run_glue.py --model_name_or_path bert-...\n",
       "11701    [model.cuda()\\r\\n, AssertionError: \\r\\nFound n...\n",
       "11702    [import torchtext.vocab as vocab\\r\\n\\r\\ncustom...\n",
       "11703    [loss, tensor([0.0430, 0.0443, 0.0430, 0.0430,...\n",
       "11704    [nn.Sequential(), import torch\\r\\n\\r\\n\\r\\nclas...\n",
       "11705    [nn.Sequential(), import torch\\r\\n\\r\\n\\r\\nclas...\n",
       "11706    [# Training Loop\\r\\n# Lists to keep track of p...\n",
       "11708    [def _initialize_weights(self):\\r\\n    for m i...\n",
       "11709    [(1,784), (1,256), nn.Linear(in_features=784, ...\n",
       "11710    [state_dict = state_dict.copy(), state_dict, #...\n",
       "11712    [{'word1': array([ 4.530e-02, -1.170e-02, -1.2...\n",
       "11713    [for t,(input, image_id) in enumerate(loader):...\n",
       "11714    [class decode_images(Dataset):\\r\\n\\r\\n    def ...\n",
       "11715    [torch.from_numpy(), import numpy as np\\r\\nimp...\n",
       "11716    [import numpy as np\\r\\nimport random\\r\\nimport...\n",
       "11717    [torch, Image not Found, import torch, -------...\n",
       "11718    [torch, Image not Found, import torch, -------...\n",
       "11719    [vgg16 = models.vgg16(pretrained=True)\\r\\nvgg1...\n",
       "11720    [vgg16 = models.vgg16(pretrained=True)\\r\\nvgg1...\n",
       "11721    [torch, (100, 4), (100), data_tr, targets_tr, ...\n",
       "11722    [python -m tf_encrypted.player --config /tmp/t...\n",
       "11723    [estimator = PyTorch(entry_point='train_script...\n",
       "11724    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "11725    [models.vgg16(pretrained=True), trainloader = ...\n",
       "11726    [models.vgg16(pretrained=True), trainloader = ...\n",
       "11727    [no instance of overloaded function \"MyModel::...\n",
       "11728    [nn.Conv2d([batch_size, channels, height, widt...\n",
       "11729    [def forward(self, x):\\r\\n  c = torch.nn.funct...\n",
       "11730    [(2,2,2,2), tensor([[[[   5.,    5.],\\r\\n     ...\n",
       "11731    [(2,2,2,2), tensor([[[[   5.,    5.],\\r\\n     ...\n",
       "11732    [class SiameseNetwork(nn.Module):\\r\\ndef __ini...\n",
       "11733    [import torch.nn as nn\\r\\n\\r\\nclass NN(nn.Modu...\n",
       "11734    [import torch.nn as nn\\r\\n\\r\\nclass NN(nn.Modu...\n",
       "11735    [import torch\\r\\n\\r\\ntorch.cuda.is_available()...\n",
       "11736    [torch.cuda.empty_cache(), import, with torch....\n",
       "11738    [train.py, model.py, epoch for loop, train.py,...\n",
       "11739    [tfms = get_transforms(do_flip=True,flip_vert=...\n",
       "11742    [batch_size = 1, logit: tensor([0.1198, 0.1911...\n",
       "11743    [    train_inputs, validation_inputs, train_la...\n",
       "11745    [t = torch.tensor([0,2])\\r\\ndim2_size = 3\\r\\ni...\n",
       "11746    [t = torch.tensor([0,2])\\r\\ndim2_size = 3\\r\\ni...\n",
       "11747    [t = torch.tensor([0,2])\\r\\ndim2_size = 3\\r\\ni...\n",
       "11749    [import numpy \\r\\n\\r\\n\\r\\n\\r\\ndef dice_coeff(i...\n",
       "11750    [ Traceback (most recent call last):\\r\\n  File...\n",
       "11751    [param.requires_grad = False, import torch\\r\\n...\n",
       "11752    [imshow(image1, title='1')\\r\\nimshow(image2, t...\n",
       "11753    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11754    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11755    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11756    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11757    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11758    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11759    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "11760    [AttributeError: 'Tensor' object has no attrib...\n",
       "11761    [---------------------------------------------...\n",
       "11762    [---------------------------------------------...\n",
       "11763    [sys.getsizeof(train_set.sample_list[0][0].sto...\n",
       "11764    [import torch\\r\\n\\r\\nclass LSTMForecast(torch....\n",
       "11765    [import torch as T\\r\\nx = T.randn(3, requires_...\n",
       "11766    [ RuntimeError: CUDA out of memory. Tried to a...\n",
       "11767    [out, torch.Size([4, 644, 25])\\r\\n, x, torch.S...\n",
       "11770    [loss_function = nn.CrossEntropyLoss()\\r\\nopti...\n",
       "11771    [SSD300(\\r\\n  (feature_layers): ModuleDict(\\r\\...\n",
       "11772    [from torch.utils.data import Dataset, TensorD...\n",
       "11773    [Traceback (most recent call last):\\r\\n  File ...\n",
       "11774    [model = XLNetForSequenceClassification.from_p...\n",
       "11775    [class Linear():\\r\\n    def __init__(self, w, ...\n",
       "11777    [transform = transforms.Compose([\\r\\n\\r\\n     ...\n",
       "11778    [self.modules = torch.nn.ModuleList([])\\r\\npri...\n",
       "11779    [import torch as tr\\r\\nimport time\\r\\nfrom num...\n",
       "11780    [class BasicBlock(nn.Module):\\r\\n    def __ini...\n",
       "11781    [Standard out, metrics.json, coco_instances_re...\n",
       "11782    [a = torch.tensor(1., requires_grad=True)\\r\\nb...\n",
       "11783    [INFO:pytorch_transformers.tokenization_utils:...\n",
       "11784    [estimator = PyTorch(entry_point='model.py',\\r...\n",
       "11785    [from torch import nn\\r\\nimport torch\\r\\nsoftm...\n",
       "11786    [from torch import nn\\r\\nimport torch\\r\\nsoftm...\n",
       "11787    [$ conda install -c pytorch pytorch torchvisio...\n",
       "11788    [class PACT(nn.Module):\\r\\n  def __init__(self...\n",
       "11789    [from transformers import pipeline\\r\\nnlp_fill...\n",
       "11790    [        dataQueue = queue.Queue()\\r\\n\\r\\n    ...\n",
       "11791    [           with torch.no_grad():\\r\\n         ...\n",
       "11792    [// tensorRT code to get half type outpus\\r\\nh...\n",
       "11793    [predictions = torch.tensor([[ True, False, Fa...\n",
       "11794    [class Rescale(object):\\r\\n    def __init__(se...\n",
       "11796    [import matplotlib.pyplot as plt\\r\\n\\r\\nimport...\n",
       "11797    [ID   Path   Score\\r\\nfig1  /folder/fig1.jpg  ...\n",
       "11798    [        b_output = []\\r\\n\\r\\n        for each...\n",
       "11799    [############################\\r\\n  # (1) Updat...\n",
       "11800    [def __init__(self, model, n_class, dropout_ra...\n",
       "11801    [def __init__(self, model, n_class, dropout_ra...\n",
       "11804    [conv module,         return torch.nn.Sequenti...\n",
       "11805    [from transformers import BertTokenizer, BertF...\n",
       "11806    [from transformers import BertTokenizer, BertF...\n",
       "11807    [__init__, \\r\\n        self.downscale_time_con...\n",
       "11808    [torch.Size([1, 3, 224, 224]), transforms.ToPI...\n",
       "11809    [    from sklearn.pipeline import Pipeline\\r\\n...\n",
       "11810    [module.forward, @WorkerThread\\r\\n@Nullable\\r\\...\n",
       "11811    [import torch.nn as nn\\r\\n\\r\\nclass PGN(nn.Mod...\n",
       "11812    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "11813    [class ImgAugTransform:\\r\\n    def __init__(se...\n",
       "11814    [class ImgAugTransform:\\r\\n    def __init__(se...\n",
       "11817    [out = out[lengths - 1, range(len(lengths))]\\r\\n]\n",
       "11818    [\\r\\nclass ClassifierModule(nn.Module):\\r\\n   ...\n",
       "11819    [class CustomConvNet(nn.Module):\\r\\n    def __...\n",
       "11820    [&lt;function resnext101_32x8d at 0x00000178CC...\n",
       "11823    [model = MyNetwork()\\r\\nimages, labels  = iter...\n",
       "11824              [Softmax(xi​)=exp(xi)/∑j​exp(xj​)​\\r\\n]\n",
       "11825    [with torch.no_grad():\\r\\n    #Mean calculatio...\n",
       "11826    [   d = numpy.zeros((10000 , 10000))\\r\\n   for...\n",
       "11827    [IndexError                                Tra...\n",
       "11828    [# Hyper Parameters\\r\\ninput_size = 14\\r\\nhidd...\n",
       "11830    [RuntimeError: Given groups=1, weight of size ...\n",
       "11831    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "11832    [tensor, FloatTensor, IntTensor, tensor, Float...\n",
       "11833    [tensor, FloatTensor, IntTensor, tensor, Float...\n",
       "11834    [import torch.nn.functional as F\\r\\n\\r\\ndef se...\n",
       "11835    [import torch.nn.functional as F\\r\\n\\r\\ndef se...\n",
       "11836    [data_transforms = {\\r\\n'train': transforms.Co...\n",
       "11837    [requires_grad=True, loss.backward()\\r\\nfor na...\n",
       "11838    [def pull_item(self, index):\\r\\n\\r\\n        I ...\n",
       "11839    [class CustomDataset : public torch::data::dat...\n",
       "11840    [tensor([[-0.2,  0.3],\\r\\n    [-0.5,  0.1],\\r\\...\n",
       "11842    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11844    [# Train the model\\r\\ntotal_step = len(train_l...\n",
       "11845    [import torch\\r\\nimport torch.autograd as auto...\n",
       "11846    [import torch\\r\\nimport torch.autograd as auto...\n",
       "11847    [\"\"\"run.py:\"\"\"\\r\\n#!/usr/bin/env python\\r\\nimp...\n",
       "11848    [!pip install --upgrade torch-scatter\\r\\n\\r\\n!...\n",
       "11849    [!pip install --upgrade torch-scatter\\r\\n\\r\\n!...\n",
       "11851    [x, x_sep, x, import torch\\r\\nimport torch.nn ...\n",
       "11852    [e = dir(nn.Module())\\r\\nf = dir(nn.Module)\\r\\...\n",
       "11853    [inp =  torch.randn(4, 1040, 161)\\r\\n, indices...\n",
       "11854    [inp =  torch.randn(4, 1040, 161)\\r\\n, indices...\n",
       "11855    [class VGG19(nn.Module):\\r\\n\\r\\n\\r\\n  def __in...\n",
       "11856    [mprof run --include-children python my_sctipt...\n",
       "11857    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "11858    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "11859    [BERT, 2.8.0, huggingface transformers 2.8.0 B...\n",
       "11860    [def bi_linear_attn(self, Q, K):\\r\\n    \"\"\"\\r\\...\n",
       "11861    [network = Network()\\r\\noptimizer = optim.Adam...\n",
       "11862    [actor = Net1()\\r\\ncritic = Net2()\\r\\n, optim_...\n",
       "11863    [# initialize and load the model\\r\\npathModel ...\n",
       "11864    [a = torch.ones(10)\\r\\nb = torch.nn.Parameter(...\n",
       "11865    [x = tf.keras.layers.Dropout(0.2)(input) \\r\\nx...\n",
       "11866    [torch.histc,  tt2 = torch.from_numpy(np.array...\n",
       "11867    [torch.histc,  tt2 = torch.from_numpy(np.array...\n",
       "11868    [embedding_dim = 64\\r\\n\\r\\nn_layers = 1\\r\\n\\r\\...\n",
       "11869    [&gt; edge_index.numpy() = array([[    0,     ...\n",
       "11870    [import torch\\r\\nimport torch.nn.functional as...\n",
       "11871    ['correct+=(yhat==y_test).sum().int()'\\r\\n, fo...\n",
       "11872    ['correct+=(yhat==y_test).sum().int()'\\r\\n, fo...\n",
       "11873    [AttributeError                            Tra...\n",
       "11874    [loss.backward(), class RNN2(nn.Module):\\r\\n  ...\n",
       "11875    [[1,2,3],[1,2,3],[100,200,500], epochs = 1000\\...\n",
       "11876    [[1,2,3],[1,2,3],[100,200,500], epochs = 1000\\...\n",
       "11877    [a, [tensor([0.0014, 0.0021, 0.0015, 0.0007, 0...\n",
       "11878    [a, [tensor([0.0014, 0.0021, 0.0015, 0.0007, 0...\n",
       "11880    [| experiments/\\r\\n|--| experiment_runner.py\\r...\n",
       "11881    [for epoch in range(num_epochs):\\r\\n        fo...\n",
       "11882    [def create_tabularDataset_object(self,csv_pat...\n",
       "11883    [def create_tabularDataset_object(self,csv_pat...\n",
       "11884    [9.06 GiB reserved in total by PyTorch, 7.80 G...\n",
       "11885    [state_dict, device = torch.device(\"cuda:0\" if...\n",
       "11886    [state_dict, device = torch.device(\"cuda:0\" if...\n",
       "11887    [torch.cdist(), def new_cdist(p, eta):\\r\\n    ...\n",
       "11888    [(predictions[0, -1, :]), [0], predictions = o...\n",
       "11889    [class MetaBackProp(torch.optim.Optimizer):\\r\\...\n",
       "11890    [File \"main.py\", line 50, in &lt;module&gt;\\r\\...\n",
       "11891    [from torchtext.vocab import GloVe\\r\\nfrom tor...\n",
       "11892    [import torch\\r\\nfrom onnx_coreml import conve...\n",
       "11893    [import os\\r\\nimport numpy as np\\r\\nimport cv2...\n",
       "11894    [dynamic_axes, create_onnx, Description of ima...\n",
       "11895    [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "11896    [import scipy.signal\\r\\nimport torch\\r\\n\\r\\nra...\n",
       "11897    [rand_gen = np.random.RandomState(seed)\\r\\nran...\n",
       "11898    [from __future__ import print_function\\r\\nimpo...\n",
       "11899    [torch.save(), torch.load_state_dict(), torch....\n",
       "11900     [.detach().numpy(), b'0.06722715', byte, type()]\n",
       "11901    [&lt;s&gt; A &lt;/s&gt;&lt;/s&gt; B &lt;/s&gt;...\n",
       "11902    [import imageio\\r\\nimport cv2 as cv\\r\\nimport ...\n",
       "11903    [self.conv_seqn = nn.Sequential(\\r\\nnn.Conv2d(...\n",
       "11904    [import torch\\r\\nx = torch.tensor([1., 2., ], ...\n",
       "11905    [databunch = BertDataBunch(args['data_dir'], L...\n",
       "11906    [for name, param in model.state_dict():\\r\\n   ...\n",
       "11907    [ValueError                                Tra...\n",
       "11908    [from pandas.api.types import CategoricalDtype...\n",
       "11909    [import spacy\\r\\nimport torchtext\\r\\nfrom torc...\n",
       "11910    [size mismatch for classifier.weight: copying ...\n",
       "11911    [class DogCatClassifier(nn.Module):\\r\\n    def...\n",
       "11912    [    input_ids = tokenizer.encode(question, te...\n",
       "11913    [def load_checkpoint(chkptJP):\\r\\ncheckpoint =...\n",
       "11914    [import torch\\r\\n\\r\\nimport torch.nn as nn\\r\\n...\n",
       "11915    [Deep Learning AMI (Ubuntu 18.04) Version 27.0...\n",
       "11916    [d, def train_and_eval(self):\\r\\n        self....\n",
       "11917    [x = x.reshape(N*D, C, H, W), x = x.squeeze(0)...\n",
       "11918    [import torch as pt\\r\\n# Objective function\\r\\...\n",
       "11919    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11920    [class MyConvBlockFunction(Function):\\r\\n\\r\\n ...\n",
       "11924    [        self.conv1 = nn.Conv2d(in_channels = ...\n",
       "11925    [class Net(torch.nn.Module):\\r\\n    def __init...\n",
       "11926                       [torch.nn.BatchNorm1d(d1), d1]\n",
       "11928    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11930    [class CamemBERTQA(nn.Module):\\r\\n\\r\\n# the in...\n",
       "11931    [import torch\\r\\nx = torch.tensor([-1.], requi...\n",
       "11933    [torch.tensor, torch_tensor = torch.tensor(fin...\n",
       "11936    [padding_idx, torch.nn.Embedding(n1, d1, paddi...\n",
       "11937    [padding_idx, torch.nn.Embedding(n1, d1, paddi...\n",
       "11938    [Specs:\\r\\nPython=3.7\\r\\nPip=18.1\\r\\nCuda=10.0...\n",
       "11939    [x=np.random.rand(3,2,2,2)\\r\\nxTorch=torch.Flo...\n",
       "11940    [import os\\r\\nimport torch\\r\\nimport torch_xla...\n",
       "11941    [x.shape = [3, 2, 2], import torch\\r\\n\\r\\nx = ...\n",
       "11942    [x.shape = [3, 2, 2], import torch\\r\\n\\r\\nx = ...\n",
       "11943    [x.shape = [3, 2, 2], import torch\\r\\n\\r\\nx = ...\n",
       "11944    [x.shape = [3, 2, 2], import torch\\r\\n\\r\\nx = ...\n",
       "11945    [sqrt(), needs_input_grad[], def new_cdist(p, ...\n",
       "11946    [side_inputs, .shape, [48, 161], n, side_input...\n",
       "11947    [model = nn.Sequential(\\r\\n    nn.Conv2d(1, 16...\n",
       "11948    [RuntimeError: Input type (torch.FloatTensor) ...\n",
       "11949                 [x = model_vgg.features(inputs)\\r\\n]\n",
       "11950    [class AffineTrans(object):\\r\\ndef __init__(se...\n",
       "11952    [from transformers import AutoModel, AutoToken...\n",
       "11953    [my_dataset = data.TensorDataset(train_x,train...\n",
       "11954    [  File \".conda/envs/py37/lib/python3.7/site-p...\n",
       "11955    [  File \".conda/envs/py37/lib/python3.7/site-p...\n",
       "11956    [def zero_padding(img, size0, pad1, pad2):\\r\\n...\n",
       "11957    [png, ITK, Tensor, PNG -&gt; RGBPixel[] -&gt; ...\n",
       "11958    [# basic LeNet5 network\\r\\nclass LeNet5_mode0 ...\n",
       "11960    [outputs: torch.Size([4, 27, 161])       pred:...\n",
       "11961    [for batch_idx, (inputs, targets) in enumerate...\n",
       "11962    [input_sequence_length, 10, 15, 20,     if bat...\n",
       "11963    [run_generation.py, $ python transformers/exam...\n",
       "11964    [run_generation.py, $ python transformers/exam...\n",
       "11965    [class Faster_RCNN(nn.Module):\\r\\n    def __in...\n",
       "11966    [mask = torch.zeros(5,3, dtype=torch.bool)\\r\\n...\n",
       "11967    [torch.autograd.Function, nn.Sequential, nn.Mo...\n",
       "11968    [torch.autograd.Function, nn.Sequential, nn.Mo...\n",
       "11969    [import torch.nn as nn\\r\\n\\r\\nclass A(nn.Modul...\n",
       "11970    [inp_conv = Conv2D(in_channels=1,out_channels=...\n",
       "11971    [import torch.nn as nn\\r\\nfrom torchsummary im...\n",
       "11973    [model = []\\r\\nmodel += [Conv2dBlock(2048, 256...\n",
       "11974    [trainloader = torch.utils.data.DataLoader(tra...\n",
       "11975    [trainloader = torch.utils.data.DataLoader(tra...\n",
       "11976    [x: torch.Size([10, 120, 180, 30]) # (N, H, W,...\n",
       "11977    [def train_net(epochs,batch_size,train_x,train...\n",
       "11978    [tensor([[14, 13,  8, 11, 18, 12,  5,  1,  0, ...\n",
       "11979    [from transformers import pipeline\\r\\n\\r\\nnlp ...\n",
       "11981    [torch.Size([4, 161, 325]), torch.Size([4, 161...\n",
       "11982    [a= torch.randn(28, 28, 8), b = a.transpose(2,...\n",
       "11983    [a= torch.randn(28, 28, 8), b = a.transpose(2,...\n",
       "11984    [import numpy as np\\r\\nimport time\\r\\nfeatures...\n",
       "11985    [inps, [64, 161, 1], d, [64, 161], d, inps, [6...\n",
       "11988    [dataiter = iter(test_loader)\\r\\nimages, label...\n",
       "11989    [x = torch.tensor([[1, 2, 3],\\r\\n             ...\n",
       "11990    [x = torch.tensor([[1, 2, 3],\\r\\n             ...\n",
       "11991    [import torch\\r\\nfrom torch import distributed...\n",
       "11992    [import torch\\r\\nfrom torch import distributed...\n",
       "11995    [for, Python, \\r\\n            for batch_index,...\n",
       "11997    [train_loader, test_loader = get_train_test_lo...\n",
       "11998    [import os\\r\\nimport torch\\r\\nfrom torchtext i...\n",
       "11999    [import os\\r\\nimport torch\\r\\nfrom torchtext i...\n",
       "12000    [# the code calculates T x W + B ---&gt; K1\\r\\...\n",
       "12001    [zero_grad(), zero_grad(), zero_grad(), X, y =...\n",
       "12002    [import torch \\r\\nfrom kornia.geometry.transfo...\n",
       "12003    [python train_net.py  --config-file configs/In...\n",
       "12004    [Command-prompt, *(DL) C:\\Users\\User&gt;nvcc -...\n",
       "12005    [Command-prompt, *(DL) C:\\Users\\User&gt;nvcc -...\n",
       "12006    [conda update --all, conda install -c pytorch ...\n",
       "12007    [enter code class Network(nn.Module):\\r\\ndef _...\n",
       "12008    [import torch\\r\\nfrom torchtext import data, d...\n",
       "12010    [class semi_C3D(nn.Module):\\r\\n\\r\\n\\r\\n    def...\n",
       "12011    [from MyDetector import Helmet_Detector\\r\\nfro...\n",
       "12012    [import os\\r\\nimport glob\\r\\nimport numpy as n...\n",
       "12013    [transforms.Compose([\\r\\n                  tra...\n",
       "12014    [name = 'astronaut'\\r\\nimshow(images[name], na...\n",
       "12015    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12016    [*** RuntimeError: size mismatch, m1: [288 x 9...\n",
       "12017    [2 * config.hidden_dim, class Encoder(nn.Modul...\n",
       "12018    [mask, torch.Size([20, 1, 199]), reconstruct_o...\n",
       "12019    [inputs, size, torch.Size([20, 1, 161, 199]), ...\n",
       "12020    [list_of_tensors = [tensor1, tensor2, tensor3,...\n",
       "12021    [lr_find_epochs = 2\\r\\nstart_lr = 1e-7\\r\\nend_...\n",
       "12022    [class SobelFilter(nn.Module):\\r\\n    def __in...\n",
       "12023    [(tensor1, tensor2, tensor3, tensor4), (1, 1, ...\n",
       "12024    [w, rnn, import numpy as np\\r\\nimport torch as...\n",
       "12025    [w, rnn, import numpy as np\\r\\nimport torch as...\n",
       "12026    [from torch.distributions import Normal\\r\\nnoi...\n",
       "12027    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12028    [if not args.multiprocessing_distributed or (a...\n",
       "12029    [self.list_of_blocks = [EncoderBlock(n_feature...\n",
       "12030    [start_indices, end_indices, tensor[start_indi...\n",
       "12031    [start_indices, end_indices, tensor[start_indi...\n",
       "12032    [optimizer = optim.Adam(resnet.parameters(), l...\n",
       "12033    [optimizer = optim.Adam(resnet.parameters(), l...\n",
       "12034    [torch.arange(10), tensor([1,5,7,9,2]), tensor...\n",
       "12035    [import torch\\r\\na = torch.rand(5,256,120)\\r\\n...\n",
       "12037    [a = torch.arange(20).reshape(4,5) \\r\\nb = a *...\n",
       "12038    [a = torch.arange(20).reshape(4,5) \\r\\nb = a *...\n",
       "12039    [Dataloader, (shuffle = True), Dataloader, Dat...\n",
       "12040    [X_train= torch.tensor(X_train, dtype= torch.f...\n",
       "12041    [Building Wave-RNN\\r\\nTrainable Parameters: 4....\n",
       "12042    [class classifier(nn.Module):\\r\\n\\r\\n#define a...\n",
       "12043    [(2, 2, 3), a= tensor ([[[2, 0, 2],[1, 0, 0]],...\n",
       "12045    [torch.stack, --------------------------------...\n",
       "12046    [torch.stack, --------------------------------...\n",
       "12047    [torch.stack, --------------------------------...\n",
       "12048    [self.data_loader = torch.utils.data.DataLoade...\n",
       "12049    [self.data_loader = torch.utils.data.DataLoade...\n",
       "12050    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12051    [torch.nn.Module, Net_par, state_dict, state_d...\n",
       "12052    [bert = transformers.BertForMaskedLM.from_pret...\n",
       "12053    [Dockerfile, requirements.txt, Cython\\r\\npytho...\n",
       "12054    [tempScale = torch.zeros((total, len(scale)))....\n",
       "12055    [class AutoEncoder(nn.Module):\\r\\n\\r\\n    def ...\n",
       "12056    [def load_data(train_file, test_file):\\r\\n# Lo...\n",
       "12057             [torch.utils.data.dataloader.DataLoader]\n",
       "12058             [torch.utils.data.dataloader.DataLoader]\n",
       "12059    [def forward(self, x):\\r\\n    x1 = self.in_con...\n",
       "12060    [def forward(self, x):\\r\\n    x1 = self.in_con...\n",
       "12062    [torch.autograd.no_grad, import torch\\r\\nimpor...\n",
       "12064    [torch.jit.optimized_execution(True, {'target_...\n",
       "12065    [from sklearn.datasets import make_blobs\\r\\nde...\n",
       "12068    [mask, [64, 2895], pred, [64, 2895, 161], mask...\n",
       "12069    [PublicTest, transform test,     transform_tes...\n",
       "12072    [q, p, data_k_vec = data.repeat_interleave(K,0...\n",
       "12073    [class DatasetLoader(Dataset):\\r\\n\\r\\n  def __...\n",
       "12074    [int shape[] = {1,1,100,100};\\r\\ntorch::Tensor...\n",
       "12075    [import torch    \\r\\nA = torch.rand(9).view((3...\n",
       "12076    [import psutil\\r\\nimport torch\\r\\n\\r\\n\\r\\ndef ...\n",
       "12077    [writer1 = SummaryWriter('runs/1')\\r\\nwriter2 ...\n",
       "12078    [EPOCHS        = 5\\r\\nLEARNING_RATE = 0.0001\\r...\n",
       "12079    [EPOCHS        = 5\\r\\nLEARNING_RATE = 0.0001\\r...\n",
       "12080    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12081    [predictions.append(logits.argmax(1))\\r\\n, [ar...\n",
       "12082    [predictions.append(logits.argmax(1))\\r\\n, [ar...\n",
       "12083    [KLDivLoss, # last hidden state of the encoder...\n",
       "12084    [import tensorflow as tf\\r\\n\\r\\nc = tf.constan...\n",
       "12085    [defaultdicts, import torch\\r\\nfrom collection...\n",
       "12086    [+=, x = torch.arange(5, dtype=torch.float, re...\n",
       "12088    [C:\\Users\\...\\pytorch-0.4.1\\build&gt;msbuild I...\n",
       "12089    [C:\\Users\\...\\pytorch-0.4.1\\build&gt;msbuild I...\n",
       "12090    [    Traceback (most recent call last):\\r\\n  F...\n",
       "12091    [   import matplotlib.pyplot as plt\\r\\n   impo...\n",
       "12093    [  batchSize = 50\\r\\n\\r\\ntrainingLoad = DataLo...\n",
       "12096    [self.X[:, nc:] = D\\r\\n, self.X[:, nc:], slice...\n",
       "12097    [self.X[:, nc:] = D\\r\\n, self.X[:, nc:], slice...\n",
       "12098    [enter code here\\r\\nepochs = 10\\r\\nmax_grad_no...\n",
       "12099    [+---+---+---+---+\\r\\n| 5 | 5 | 5 | 5 |\\r\\n+--...\n",
       "12100    [+---+---+---+---+\\r\\n| 5 | 5 | 5 | 5 |\\r\\n+--...\n",
       "12101    [rnn(input, hidden, output)\\r\\nfor i in range(...\n",
       "12102    [def _decompose(self, value, exp_bias=None):\\r...\n",
       "12103    [Training Loss   Valid. Loss Valid. Accur.   T...\n",
       "12104         [torch.Size([64, 2941]), torch.Size([2941])]\n",
       "12105    [/pytorch/aten/src/ATen/native/cuda/IndexKerne...\n",
       "12106    [a, b, import torch\\r\\na = torch.tensor([0, 1,...\n",
       "12108    [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "12109    [pip install torch==1.4.0+cpu torchvision==0.5...\n",
       "12110    [pip install torch==1.4.0+cpu torchvision==0.5...\n",
       "12111    [pip install torch==1.4.0+cpu torchvision==0.5...\n",
       "12112    [pip install torch==1.4.0+cpu torchvision==0.5...\n",
       "12113    [learn = language_model_learner(data_lm, Trans...\n",
       "12114    [grad_output, grad_input, grad_input[input &lt...\n",
       "12116    [nn.Module.cuda(), class ToyModule(torch.nn.Mo...\n",
       "12118    [q_pred = self.Q.forward(states), tensor([[-4....\n",
       "12119    [comment, pretrain_train_writer = SummaryWrite...\n",
       "12120    [#model_1 needs to be trained\\r\\noutputs = mod...\n",
       "12121    [mask.size() == torch.Size([1, 400])\\r\\nclean_...\n",
       "12122    [mask.size() == torch.Size([1, 400])\\r\\nclean_...\n",
       "12124    [@app.route('/predict', methods=['POST'])\\r\\nd...\n",
       "12125    [step1 = Pss-(k*Pvv)\\r\\nstep2 = step1*s\\r\\nste...\n",
       "12127    [mask = mask_model(input_spectrogram)\\r\\nmask ...\n",
       "12128    [train_dataset = torchvision.datasets.ImageFol...\n",
       "12129    [train_dataset = torchvision.datasets.ImageFol...\n",
       "12130    [(#characters of name, #target classes), (1,#t...\n",
       "12131    [(#characters of name, #target classes), (1,#t...\n",
       "12132    [torch.Size([7, 20, 180]), dim=1, torch.Size([...\n",
       "12133    [train_size = int(0.8 * len(full_dataset))\\r\\n...\n",
       "12134    [train_size = int(0.8 * len(full_dataset))\\r\\n...\n",
       "12135    [RuntimeError: CUDA error: device-side assert ...\n",
       "12136    [     22         print(z1.size())\\r\\n---&gt; 2...\n",
       "12137    [from torch.optim import lr_scheduler\\r\\nN_EPO...\n",
       "12138    [class MyDataset(Dataset):\\r\\n\\r\\n  def __init...\n",
       "12139    [CLS, BertForSequenceClassification, print(mod...\n",
       "12140    [IndexError: tensors used as indices must be l...\n",
       "12141    [# Assuming all images are the same size, get ...\n",
       "12142    [class Pytorch_LSTM(nn.Module):\\r\\n    def __i...\n",
       "12143    [a, b, import torch\\r\\na = torch.tensor([[[ 0....\n",
       "12144    [from torch import tensor\\r\\nx = {tensor(0): [...\n",
       "12145    [from torch import tensor\\r\\nx = {tensor(0): [...\n",
       "12148    [pip install torch torchvision, cd scripts/gen...\n",
       "12150    [im=th.arange(4*5*6,dtype=th.float32).view(4,5...\n",
       "12151    [pytorch, (50, 100, 1), (50, 100, 3), matplotl...\n",
       "12152    [T, retain_grad(),         hidden_copy = hidde...\n",
       "12153    [torch::data::make_data_loader, torch::data::d...\n",
       "12155    [from transformers import BertTokenizer, BertF...\n",
       "12158    [for epoch in:\\r\\n        alst = []\\r\\n       ...\n",
       "12159    [.pth, .onnx, from torch.autograd import Varia...\n",
       "12160    [from transformers import pipeline\\r\\nsummariz...\n",
       "12161    [model = models.densenet121(pretrained=True)\\r...\n",
       "12162    [model = models.densenet121(pretrained=True)\\r...\n",
       "12164    [import torch\\r\\n\\r\\ninput_sliced = torch.rand...\n",
       "12165    [from torch.utils.data import DataLoader, Conc...\n",
       "12166    [from torch.utils.data import DataLoader, Conc...\n",
       "12167    [from torch.utils.data import DataLoader, Conc...\n",
       "12168    [#include &lt;torch/torch.h&gt;\\r\\n\\r\\n#includ...\n",
       "12169    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12170    [int main()\\r\\n{\\r\\n    ...\\r\\n    std::string...\n",
       "12171    [CUDA kernel failed : no kernel image is avail...\n",
       "12172    [   #include &lt;torch/torch.h&gt;\\r\\n   #incl...\n",
       "12173    [full_dataset = ImageFolder(root = os.path.joi...\n",
       "12175    [with h5py.File(fileName, 'w') as f:\\r\\n      ...\n",
       "12176    [class Block(nn.Module):\\r\\n    def __init__(s...\n",
       "12177    [is_zero(),  arr.nonzero()\\r\\ntensor([[0, 1],\\...\n",
       "12178    [# Clear the previous gradients\\r\\ndiscriminat...\n",
       "12179    [    Found GPU0 GeForce GTX 670 which is of cu...\n",
       "12180    [with torch.no_grad():\\r\\n    input = Variable...\n",
       "12181    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12182    [label = 3\\r\\nNumClass = 10\\r\\nNumRows  = 100\\...\n",
       "12183    [\\r\\nLoading model\\r\\nTraceback (most recent c...\n",
       "12184    [# Loop over epochs\\r\\nfor epoch in range(max_...\n",
       "12185    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "12186    [PyTorch, Data input configuration, Data Input...\n",
       "12187    [        print('\\ninp', inp.min(), inp.mean(),...\n",
       "12188    [        print('\\ninp', inp.min(), inp.mean(),...\n",
       "12189    [d_optim.zero_grad()\\r\\n\\r\\nreal_pred = d(real...\n",
       "12190    [320 -&gt; 160 -&gt; 80 -&gt; 40 -&gt; 80 -&gt...\n",
       "12193    [pandas, torch, numpy, pandas, numpy, torch, p...\n",
       "12194    [pandas, torch, numpy, pandas, numpy, torch, p...\n",
       "12196    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "12197    [train.py, output_c1[output_c1 &gt; 0.5] = 1.\\...\n",
       "12198    [__init__(), def __init__(self, d_model, dropo...\n",
       "12199    [__init__(), def __init__(self, d_model, dropo...\n",
       "12200    [__init__(), def __init__(self, d_model, dropo...\n",
       "12201    [    Fri Mar 20 04:29:49 2020       \\r\\n+-----...\n",
       "12202    [    Fri Mar 20 04:29:49 2020       \\r\\n+-----...\n",
       "12203    [no_grad, set_grad_enabled,     def __init__()...\n",
       "12204    [Why is it rare to discover new marine mammal ...\n",
       "12205    [\\r\\nclass Dataset(data.Dataset):\\r\\n    def _...\n",
       "12206    [import torch\\r\\nfrom torch.distributions impo...\n",
       "12207    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "12208    [\\r\\n# import the usual resources\\r\\nimport ma...\n",
       "12209    [    import spacy\\r\\n    from spacy.util impor...\n",
       "12210    [import torch\\r\\nfrom torchvision.models impor...\n",
       "12211    [dataparallel, device = torch.device(\"cuda\" if...\n",
       "12212    [import numpy as np \\r\\nimport gym\\r\\nimport r...\n",
       "12216     [conda install -c peterjc123 pytorch=0.1.12\\r\\n]\n",
       "12217     [conda install -c peterjc123 pytorch=0.1.12\\r\\n]\n",
       "12219     [conda install -c peterjc123 pytorch=0.1.12\\r\\n]\n",
       "12224    [caffe2_model = Caffe2Model.load_protobuf(inpu...\n",
       "12225    [AttributeError: module 'tensorflow._api.v1.io...\n",
       "12226    [AttributeError: module 'tensorflow._api.v1.io...\n",
       "12227    [gres/gpu: count changed for node node002 from...\n",
       "12228    [onnx-coreml,     YOLOv3-CoreML[13481:1004975]...\n",
       "12229    [models.py, -FV_dir\\r\\n ---__init__.py\\r\\n ---...\n",
       "12230    [batch_1 = {0,0,0,0,0,0,0,0}\\r\\n\\r\\nbatch_2 = ...\n",
       "12231    [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "12232    [var onnxPipeline = mLContext.Transforms.Resiz...\n",
       "12233    [def multi_dimensional_attention(rep_tensor, r...\n",
       "12234    [!pip install torchaudio\\r\\nimport os\\r\\nasser...\n",
       "12235    [!pip install torchaudio\\r\\nimport os\\r\\nasser...\n",
       "12236    [def forward(self, inputs, hidden):\\r\\n    if ...\n",
       "12237    [def distance(p1, p2,labels):\\r\\n        \"\"\"\\r...\n",
       "12239    [class doubleNetwork(nn.Module):\\r\\n\\r\\ndef __...\n",
       "12240    [torchvision datasets.ImageFolder, torchvision...\n",
       "12241    [class AutoEncoder(nn.Module):\\r\\n    def __in...\n",
       "12242    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "12243    [tensor(img.rotate(rotation)).view(784), d, .p...\n",
       "12244    [import torch\\r\\nimport numpy\\r\\nx = torch.ten...\n",
       "12245    [/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1...\n",
       "12246    [for name, _ in model.named_modules():\\r\\n    ...\n",
       "12247    [Too many connections! The tunnel session '1Z8...\n",
       "12248    [im = cv2.imread(image_path)\\r\\nim_nonoise = c...\n",
       "12249    [import pyarrow.parquet as pq\\r\\ndataset = pq....\n",
       "12250    [import pyarrow.parquet as pq\\r\\ndataset = pq....\n",
       "12251    [x = torch.randn(5, 5)\\r\\n, tensor([[ 0.5756, ...\n",
       "12253    [File \"/usr/local/lib/python3.6/dist-packages/...\n",
       "12254    [File \"/usr/local/lib/python3.6/dist-packages/...\n",
       "12255    [File \"/usr/local/lib/python3.6/dist-packages/...\n",
       "12256    [File \"/usr/local/lib/python3.6/dist-packages/...\n",
       "12257    [preds_str, gpu_id=0, def recognize(imgs, mode...\n",
       "12258    [import numpy as np\\r\\nimport os, sys\\r\\nfrom ...\n",
       "12259    [model = Siamese()\\r\\n\\r\\n# Load state_dict\\r\\...\n",
       "12261    [Conv1d, [64, 20, 161], Conv1d, self.conv1 = t...\n",
       "12262    [np.random.seed(1)\\r\\n\\r\\nraw_data = pd.DataFr...\n",
       "12264    [A = \\r\\n[[0.9133, 0.5071, 0.6222, 3.],\\r\\n [0...\n",
       "12265    [A = \\r\\n[[0.9133, 0.5071, 0.6222, 3.],\\r\\n [0...\n",
       "12266    [(3,3), (1, 1), import torch\\r\\n\\r\\na = torch....\n",
       "12267    [(3,3), (1, 1), import torch\\r\\n\\r\\na = torch....\n",
       "12269    [test=[]\\r\\ndata=np.random.uniform(0,1,[20,])\\...\n",
       "12270    [test=[]\\r\\ndata=np.random.uniform(0,1,[20,])\\...\n",
       "12271    [pytest test_indexing.py --cov=../ --cov-repor...\n",
       "12273    [class Net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "12274    [  ([[[[1., 3.],\\r\\n      [9., 11.],\\r\\n\\r\\n  ...\n",
       "12275    [  ([[[[1., 3.],\\r\\n      [9., 11.],\\r\\n\\r\\n  ...\n",
       "12276    [libtorch.a, /home/me/pytorch/torch/lib, CMake...\n",
       "12277    [plot_model(), graphviz, torchviz, x = torch.z...\n",
       "12278    [(venv) PS &gt; python train_rcnn.py --data_pa...\n",
       "12279    [images, X, y = train_sequence[idx]  \\r\\n\\r\\ni...\n",
       "12280    [import torch.nn as nn\\r\\nclass Model(nn.Modul...\n",
       "12282    [torch.squeeze, (n_batch, channel, x, y, 1), (...\n",
       "12283    [.clamp(min=0), nn.functional.relu(), .clamp, ...\n",
       "12284    [False, requires_grad, requires_grad = False, ...\n",
       "12285    [oarsub -l /host=1/gpu=1,walltime=2:00:00 './t...\n",
       "12286    [python3 train.py --model_def config/yolov3.cf...\n",
       "12287    [python3 train.py --model_def config/yolov3.cf...\n",
       "12288    [python3 train.py --model_def config/yolov3.cf...\n",
       "12289    [import torch\\r\\n\\r\\nelements = torch.rand(5,1...\n",
       "12290    [import torch\\r\\n\\r\\nelements = torch.rand(5,1...\n",
       "12291    [classes = [‘airplane’, ‘automobile’, ‘bird’, ...\n",
       "12292                                           [backward]\n",
       "12293    [import torch\\r\\nfrom torch import nn\\r\\n\\r\\n\\...\n",
       "12294    [output = [1,0,4,10]\\r\\ntarget = [1,2,4,15]\\r\\...\n",
       "12295    [    resnet18 = models.resnet18(pretrained=Tru...\n",
       "12296    [value = torch.tensor([\\r\\n\\r\\n    [[0, 0, 0],...\n",
       "12297    [TypeError: forward() missing 1 required posit...\n",
       "12298    [TypeError: forward() missing 1 required posit...\n",
       "12299    [CODE 1:  BertModel.from_pretrained\\r\\nCODE 2:...\n",
       "12300    [classes = os.listdir(train_folder)\\r\\nclasses...\n",
       "12301    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "12302    [print(data.shape, label.shape)\\r\\n, # Creatin...\n",
       "12303    [S, N, H = 9, 7, 4\\r\\n\\r\\na = torch.randn(S, N...\n",
       "12304    [import numpy as np\\r\\nimport torch\\r\\n\\r\\n# e...\n",
       "12305    [# load network\\r\\nnetwork_pkl = misc.locate_n...\n",
       "12306    [values = torch.tensor([5., 4., 8., 3.])\\r\\n, ...\n",
       "12307    [values = torch.tensor([5., 4., 8., 3.])\\r\\n, ...\n",
       "12308    [values = torch.tensor([5, 3, 2, 8])\\r\\n, inde...\n",
       "12309                                           [torch.nn]\n",
       "12310    [class Discriminator(nn.Module):\\r\\n    def __...\n",
       "12311    [layer, nn.Module, forward, layer, layer, auto...\n",
       "12312    [def round_filters(filters, width_coefficient,...\n",
       "12313    [N=32  \\r\\n\\r\\nclass CNNGenerator(nn.Module):\\...\n",
       "12314    [\"\"\" `UNet` class is based on https://arxiv.or...\n",
       "12315    [[n, 60], [n, 1], [n, 60], class Model(nn.Modu...\n",
       "12316    [import numpy as np\\r\\nfrom scipy import signa...\n",
       "12317    [import numpy as np\\r\\nfrom scipy import signa...\n",
       "12318    [import numpy as np\\r\\nfrom scipy import signa...\n",
       "12319    [torch.tensor(batch_size, 1000), [batch_size],...\n",
       "12321    [sample, rsample, import torch, seaborn as sns...\n",
       "12322    [forward, class MyCell(torch.nn.Module):\\r\\n  ...\n",
       "12323    [forward, class MyCell(torch.nn.Module):\\r\\n  ...\n",
       "12324    [#Choosing our pretrained network model\\r\\npre...\n",
       "12325    [estimator = sagemaker.model.FrameworkModel(\\r...\n",
       "12326    [    def forward(self, x, hidden=None):\\r\\n   ...\n",
       "12327    [import numpy as np\\r\\nA = np.random.rand(16,1...\n",
       "12328                                     [forward, .view]\n",
       "12329    [input_a = Variable(torch.stack(a1, dim=0), re...\n",
       "12331    [from transformers import BertJapaneseTokenize...\n",
       "12333    [ndf = 128\\r\\nz_size = 512\\r\\n\\r\\n# define the...\n",
       "12334    [ndf = 128\\r\\nz_size = 512\\r\\n\\r\\n# define the...\n",
       "12335    [import numpy as np\\r\\nimport torch as th\\r\\nc...\n",
       "12336    [class BaselineModel(nn.Module):\\r\\n    def __...\n",
       "12337    [frcnn_model = fasterrcnn_resnet50_fpn(pretrai...\n",
       "12338    [i = 0\\r\\nj = 6\\r\\nbase = feat.size(0)//2\\r\\nf...\n",
       "12339    [i = 0\\r\\nj = 6\\r\\nbase = feat.size(0)//2\\r\\nf...\n",
       "12340    [import io\\r\\nimport torch\\r\\nimport torchvisi...\n",
       "12341    [DataLoader, networkx, dataset, DataLoader, #i...\n",
       "12342    [def train_and_validate(model, loss_criterion,...\n",
       "12343    [backward(), n_epochs = 2\\r\\nbatch_size = 100\\...\n",
       "12344    [PyTorch, forward,     def forward(self, x, hi...\n",
       "12345    [class AutoEncoder(nn.Module):\\r\\n\"\"\"Autoencod...\n",
       "12346    [self.fc.weight, m = alpha * n + (1 - alpha) *...\n",
       "12347    [    def __init__(self, feature_dim=15, hidden...\n",
       "12348    [    def __init__(self, feature_dim=15, hidden...\n",
       "12350    [transform = transforms.Compose([\\r\\n    trans...\n",
       "12351    [transform = transforms.Compose([\\r\\n    trans...\n",
       "12352    [model.parameters(), class NetWithODE(torch.nn...\n",
       "12353    [(bactch_size, 1, 3000), class CDAutoEncoder(n...\n",
       "12354    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12355    [        a = htilde_t (N, H)\\r\\n\\r\\n        b ...\n",
       "12357    [File \"main.py\", line 144, in &lt;module&gt;\\r...\n",
       "12358    [        class NNet(torch.nn.Module):\\r\\n\\r\\nd...\n",
       "12360    [class BaselineModel(nn.Module):\\r\\n    def __...\n",
       "12361    [Epoch: [0] Total time: 0:00:06 (0.2223 s / it...\n",
       "12362    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12363    [class BaselineModel(nn.Module):\\r\\n    def __...\n",
       "12364    [batch_size, import torch\\r\\nimport torch.nn a...\n",
       "12365    [batch_size, import torch\\r\\nimport torch.nn a...\n",
       "12366    [batch_size, import torch\\r\\nimport torch.nn a...\n",
       "12367    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12368    [tensorflow_datasets.load('glue/mrpc'), model....\n",
       "12369    [tensorflow_datasets.load('glue/mrpc'), model....\n",
       "12370    [tensorflow_datasets.load('glue/mrpc'), model....\n",
       "12371    [tensorflow_datasets.load('glue/mrpc'), model....\n",
       "12372    [forward(), forward(), return_embeddings:, if ...\n",
       "12373    [wordImages, my_dataset, demo_data = RawDatase...\n",
       "12374    [z, x, y, [N_samples, S, N_feats], [N_samples,...\n",
       "12375    [from transformers.tokenization_gpt2 import GP...\n",
       "12376    [reshaped_data2 = data2.unsqueeze(0)\\r\\nnew_la...\n",
       "12377    [RuntimeError: Expected object of scalar type ...\n",
       "12379    [tp, fn, tn, fp, tp#2 - tp#1 = -91, fn#2 - fn#...\n",
       "12380    [convertinf, cartpole, tensor([0.1205, 0.1207,...\n",
       "12381    [convertinf, cartpole, tensor([0.1205, 0.1207,...\n",
       "12382    [class ConvNet(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "12383    [dataloaders_train = torch.utils.data.DataLoad...\n",
       "12384    [---&gt; 52         x = x.view(x.size(0), 5 * ...\n",
       "12385    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12386    [import torchvision\\r\\nresnet18 = torchvision....\n",
       "12387    [array([[ 2, 4, 5, 3],\\r\\n       [ 1, 6, 8, 9]...\n",
       "12388    [array([[ 2, 4, 5, 3],\\r\\n       [ 1, 6, 8, 9]...\n",
       "12389    [array([[ 2, 4, 5, 3],\\r\\n       [ 1, 6, 8, 9]...\n",
       "12390    [torch::Tensor a = torch::randn({30000, 80});\\...\n",
       "12391    [class MyFct(Function):\\r\\n\\r\\n   @staticmetho...\n",
       "12392    [def loss_fn_distillation(outputs, soft_labels...\n",
       "12393    [\\r\\n        self.model.add(Bidirectional(LSTM...\n",
       "12394    [Profit, R&amp;D, url =https://raw.githubuserc...\n",
       "12395    [\\r\\nself.rnn = nn.LSTM(...)\\r\\n\\r\\ndef forwar...\n",
       "12396    [import pandas as pd\\r\\nimport torch\\r\\nimport...\n",
       "12397    [pytorch, pytorch, a, a\\r\\n&gt;&gt; torch.tens...\n",
       "12398    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12399    [conv1 = torch.nn.Conv2d(in_channels = 1, out_...\n",
       "12400    [class L2Norm(nn.Module):\\r\\n    def __init__(...\n",
       "12401    [class L2Norm(nn.Module):\\r\\n    def __init__(...\n",
       "12403    [DataLoader, X1, X2, X1, X2, y, (n_observation...\n",
       "12404    [train_loader, another_loader = get_loaders()\\...\n",
       "12405    [loss.backward(),             loss, outputs = ...\n",
       "12406    [output_size = (input_size - kernel_size + 2*p...\n",
       "12408    [x=torch.Tensor([[1,0,0],[0,1,0]]) # 2*3\\r\\ny=...\n",
       "12409    [Dataset, Dataloader,     train_dataset = Tens...\n",
       "12410    [Dataset, Dataloader,     train_dataset = Tens...\n",
       "12411    [ 1  2  3  4\\r\\n 5  6  7  8\\r\\n 9 10 11 12\\r\\n...\n",
       "12412    [ 1  2  3  4\\r\\n 5  6  7  8\\r\\n 9 10 11 12\\r\\n...\n",
       "12413    [    X_train, X_test, y_train, y_test = train_...\n",
       "12414    [epochs = 1000\\r\\nfrom pylab import plt\\r\\nplt...\n",
       "12415    [a_list, b_list, [(tens1, tens2), ...], tens1,...\n",
       "12416    [a_list, b_list, [(tens1, tens2), ...], tens1,...\n",
       "12417    [a_list, b_list, [(tens1, tens2), ...], tens1,...\n",
       "12418    [import torch\\r\\nfrom fairseq.models.wav2vec i...\n",
       "12419    [import torch\\r\\nfrom fairseq.models.wav2vec i...\n",
       "12420    [fftconvolve, conv1d, conv1d, conv1d, convolve...\n",
       "12421    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "12422    [Expected object of device type cuda but got d...\n",
       "12423    [0000,   0.68 ,   0.61 ,   0.24 \\r\\n0001,   0....\n",
       "12424    [few-show-vid2vid, ffmpeg, dlib, CustomDataset...\n",
       "12425    [[[0, 1], [2,2], [0,1]], [1, 2, 3], [0,1], M[0...\n",
       "12427    [pxs = torch.linspace(-1, 1, 32)\\r\\npys = torc...\n",
       "12428    [class FullyConnectedAutoencoder(nn.Module):\\r...\n",
       "12429    [import torch\\r\\n\\r\\na = torch.tensor(\\r\\n    ...\n",
       "12430    [class Autoencoder(nn.Module):\\r\\n  def __init...\n",
       "12431    [      class NN(nn.Module):\\r\\n\\r\\n         de...\n",
       "12432    [pre_classifier, BERT2 = torch.nn.Sequential(*...\n",
       "12433    [# to measure run-time\\r\\n\\r\\n# for csv datase...\n",
       "12434    [  /pytorch/aten/src/ATen/native/cuda/IndexKer...\n",
       "12435    [def Scramble_acton(net, ort, inputs, dpinda, ...\n",
       "12436    [# Get all hidden layers' weights\\r\\nfor i in ...\n",
       "12437    [class CustomDataset(torch.utils.data.Dataset)...\n",
       "12438    [[L_i, 3], L_i, 3, L_i, [B, L, 3], L, L_i, [L_...\n",
       "12439    [input, indices, input, input[i], j_1&lt;...&l...\n",
       "12440    [input, indices, input, input[i], j_1&lt;...&l...\n",
       "12441    [import os\\r\\nimport torch\\r\\nimport utils\\r\\n...\n",
       "12442    [model.train()\\r\\nfor images, targets in data_...\n",
       "12443    [model.train()\\r\\nfor images, targets in data_...\n",
       "12444    [model.train()\\r\\nfor images, targets in data_...\n",
       "12445    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12446    [import matplotlib\\r\\nmatplotlib.use(\"Agg\")\\r\\...\n",
       "12447    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12448                       [model.fit(), model.forward()]\n",
       "12450    [def complex_mult(x, y):\\r\\n  a, b = x[:, :, :...\n",
       "12451    [setattr, import torch\\r\\nbefore_write = torch...\n",
       "12452    [train_split = 0.70 # Defines the ratio of tra...\n",
       "12453    [import torch\\r\\nx = torch.rand(10, 3)\\r\\ny = ...\n",
       "12454    [pytorch 1.3.1, python3.7.4, import torch\\r\\n\\...\n",
       "12455    [\\r\\ntrainset = datasets.ImageFolder(path_trai...\n",
       "12456    [\\r\\ntrainset = datasets.ImageFolder(path_trai...\n",
       "12457    [get_grads(), None, import torch\\r\\nimport tor...\n",
       "12458    [get_grads(), None, import torch\\r\\nimport tor...\n",
       "12459    [self.net = models.vgg19(pretrained=True), url...\n",
       "12461    [def sum_of_CE_lost(input):\\r\\n    L = 0\\r\\n  ...\n",
       "12462    [eta = torch.tensor([0.5], requires_grad=True)...\n",
       "12463                               [copy_initial_weights]\n",
       "12464                               [copy_initial_weights]\n",
       "12465    [\\r\\ndata_transforms = {\\r\\n    'train' : tran...\n",
       "12466    [\\r\\ndata_transforms = {\\r\\n    'train' : tran...\n",
       "12467    [for epoch in range(max_epoch):\\r\\n\\r\\n    run...\n",
       "12468    [Cuda, Pytorch:1.4.0, BATCH_SIZE, CUDA out of ...\n",
       "12469    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "12470    [class Net3(torch.nn.Module):\\r\\n    def __ini...\n",
       "12471    [import sklearn\\r\\n    from sklearn.datasets i...\n",
       "12472    [class DeepSequentialModel(nn.Module):\\r\\ndef ...\n",
       "12473    [ResNet, UNet, csv, dataloader, X = list(df['i...\n",
       "12474    [net = CustomClassInheritingFromModuleWithDefi...\n",
       "12475    [class RotateDataset(Dataset):\\r\\n    def __in...\n",
       "12476    [# Load data\\r\\nmean = 0.5\\r\\nstd = 0.5\\r\\nbat...\n",
       "12477    [[espresso] [Espresso::handle_ex_plan] excepti...\n",
       "12478    [Cuda, Pytorch:1.4.0, batch_size, CUDA out of ...\n",
       "12479    [class Net(nn.Module):\\r\\n\\r\\ndef __init__(sel...\n",
       "12480    [tmp = [torch.tensor([1]),torch.tensor([2,3])]...\n",
       "12481    [2   | 34, 64, 2243, 55678, 323, 778, 4454, 23...\n",
       "12482    [torch.Tensor, Sentence Transformer, embedding...\n",
       "12483    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12484    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12485    [Epoch 1/30\\r\\n----------\\r\\n-----------------...\n",
       "12486    [######### ERROR #######\\r\\n\\r\\n        An att...\n",
       "12488    [for i, data in enumerate(train_loader, 0):\\r\\...\n",
       "12489    [tensor([[[0.4588, 0.4588, 0.4588,  ..., 0.498...\n",
       "12490    [torch.Tensor, dtype, torch.uint8, nn.Conv2d, ...\n",
       "12491                               [torch.svd(), u, s, v]\n",
       "12493    [op = torch._C._jit_get_operation(qualified_op...\n",
       "12496    [from torch.multiprocessing import Pool, set_s...\n",
       "12497    [ByteLevelBPETokenizer, Exception has occurred...\n",
       "12498    [import torch\\r\\n\\r\\nimport transformers\\r\\nfr...\n",
       "12499    [MaxPool2D, PyTorch, padding=1, import torch\\r...\n",
       "12500    [npx.sequence_mask(), a = torch.randn(2, 2, 4)...\n",
       "12501    [npx.sequence_mask(), a = torch.randn(2, 2, 4)...\n",
       "12502    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12503    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12504    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12505    [import pickle\\r\\n\\r\\noutput_features = []\\r\\n...\n",
       "12506    [import pandas as pd\\r\\nimport os\\r\\nfrom torc...\n",
       "12507    [!pip install --upgrade torch-scatter\\r\\n!pip ...\n",
       "12508    [!pip install --upgrade torch-scatter\\r\\n!pip ...\n",
       "12509    [!pip install --upgrade torch-scatter\\r\\n!pip ...\n",
       "12510    [!pip install --upgrade torch-scatter\\r\\n!pip ...\n",
       "12511    [!pip install --upgrade torch-scatter\\r\\n!pip ...\n",
       "12512    [    import torchvision, torch, time\\r\\n    mo...\n",
       "12513    [from transformers import XLNetTokenizer, XLNe...\n",
       "12514    [    for c in range(self.n_class):\\r\\n        ...\n",
       "12515    [L = th.cholesky(Xt.bmm(X))\\r\\n, catch, continue]\n",
       "12516    [L = th.cholesky(Xt.bmm(X))\\r\\n, catch, continue]\n",
       "12517    [L = th.cholesky(Xt.bmm(X))\\r\\n, catch, continue]\n",
       "12518    [from sentence_transformers import SentenceTra...\n",
       "12519    [os.environ['PYTHONHASHSEED'] = str(args.seed)...\n",
       "12520    [ankita@ankita-HP-Laptop-15-bs0xx:~$ free -h\\r...\n",
       "12521    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12522    [RuntimeError: invalid argument 4: Index tenso...\n",
       "12523    [transforms.RandomRotation(degrees=(90, -90))\\...\n",
       "12524    [class Tem(torch.nn.Module):\\r\\n    def __init...\n",
       "12525    [x, torch.Size([500, 50, 1]), x = x[lengths - ...\n",
       "12526    [x, torch.Size([500, 50, 1]), x = x[lengths - ...\n",
       "12527    [gradslist = []\\r\\nfor data_epoch in interval_...\n",
       "12528    [print(model), from torchsummary import summar...\n",
       "12529    [t, t = torch.randn(3,8)\\r\\nprint(t)\\r\\ntensor...\n",
       "12530    [[1 2 3], [2 4 6], dataloader, class AudioData...\n",
       "12532    [def denoise_train(x: DataLoader):\\r\\n    loss...\n",
       "12533    [transformers, \"dccuchile/bert-base-spanish-ww...\n",
       "12534    [class NumbersDataset(Dataset):\\r\\n    def __i...\n",
       "12535    [class GraphConvLayer(torch.nn.Module):\\r\\n   ...\n",
       "12536    [    x[1] = [\\r\\n    # Input features at times...\n",
       "12539    [1, 0, from torch.autograd import Variable\\r\\n...\n",
       "12540    [   filename\\r\\n1  a.jpg\\r\\n\\r\\n2  b.jpb\\r\\n, ...\n",
       "12541    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12542    [model = torchvision.models.resnet18(pretraine...\n",
       "12543    [# Import resources\\r\\n%matplotlib inline\\r\\n%...\n",
       "12544    [input = torch.tensor([12, 56, 45, 37], dtype=...\n",
       "12545    [cross_entropy, CrossEntropyLoss, LogSoftmax, ...\n",
       "12546    [Pytorch’s LSTM expects all of its inputs to b...\n",
       "12547    [out = torch.Tensor(3, 4, 5)\\r\\n, out[:,0,:], ...\n",
       "12549    [python run_summarization.py \\\\r\\n    --docume...\n",
       "12550    [def split_MNIST(mnist_set, digits):\\r\\n    ds...\n",
       "12551                            [torch.Size([118160, 1])]\n",
       "12552                            [torch.Size([118160, 1])]\n",
       "12554    [.forward, PyCharm 2019.3.3 (Professional Edit...\n",
       "12555    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "12557    [conda create -n myenv python=3.5 pytorch=0.3....\n",
       "12558    [def load_dataset():\\r\\n    data_path = 'C:/ex...\n",
       "12559    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12560    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12561    [!pip install transformers\\r\\n, !git clone htt...\n",
       "12562    [epoch = 800\\r\\nPATH = 'vgg16_epoch{}.pth'.for...\n",
       "12570    [x = [ 1 , 2], y, (i,j), (x[i] - x[j]), y[0,:]...\n",
       "12571    [Refused to execute script from 'http://localh...\n",
       "12572    [import numpy as np\\r\\nimport scipy.io as sio\\...\n",
       "12573    [S = torch.zeros((batch_size, C, H, W))\\r\\nfor...\n",
       "12574    [S = torch.zeros((batch_size, C, H, W))\\r\\nfor...\n",
       "12575    [def _forward(self, x):\\r\\n    branch1x1 = sel...\n",
       "12576    [X, y = FashionMNIST\\r\\n, from torchvision.dat...\n",
       "12577    [class GetData(torch.utils.data.Dataset):\\r\\n\\...\n",
       "12578    [import torch\\r\\n\\r\\nfrom models.inception_res...\n",
       "12579    [tensor1 = \\r\\n([[780.8306,  98.1060, 813.8367...\n",
       "12580    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nA =...\n",
       "12581    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nA =...\n",
       "12582    [torch.Size([256, 4, 1181]), torch.Size([256, ...\n",
       "12583    [def fit(epoch,model,data_loader,phase='traini...\n",
       "12584    [transformers, transformers.AdamW, get_linear_...\n",
       "12585    [transformers, transformers.AdamW, get_linear_...\n",
       "12586             [tfrecords, tfrecords, TFRecordsDataset]\n",
       "12587    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12588    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12589    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12590    [torch.cat,  # memory is just a list of events...\n",
       "12591    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12592    [ImageFolder, transforms.Grayscale(num_output_...\n",
       "12593    [ImageFolder, transforms.Grayscale(num_output_...\n",
       "12594    [ImageFolder, transforms.Grayscale(num_output_...\n",
       "12599    [   x_norm = (x**2).sum(1).view(-1, 1)\\r\\n   i...\n",
       "12600    [import torch \\r\\nimport numpy as np\\r\\nfrom t...\n",
       "12601    [import torch \\r\\nimport numpy as np\\r\\nfrom t...\n",
       "12602    [torch.max(), ... loading model\\r\\ninput = tra...\n",
       "12603    [from numba import jitclass, int32\\r\\nimport t...\n",
       "12604    [conda create -n facenet37_2 python=3.7\\r\\n, P...\n",
       "12605    [transforms.Normalize(), torch.view(C, -1).mea...\n",
       "12606    [transforms.Normalize(), torch.view(C, -1).mea...\n",
       "12607    [RuntimeError: DataLoader worker (pid(s) 15332...\n",
       "12608    [RuntimeError: DataLoader worker (pid(s) 15332...\n",
       "12609    [RuntimeError: DataLoader worker (pid(s) 15332...\n",
       "12610    [ def forward(self, x):\\r\\n      outputs = []\\...\n",
       "12611    [caption_feat = [int(x)  if x &lt; 11660  else...\n",
       "12612    [caption_feat = [int(x)  if x &lt; 11660  else...\n",
       "12613    [caption_feat = [int(x)  if x &lt; 11660  else...\n",
       "12614    [class LSTMClassification(torch.nn.Module):\\r\\...\n",
       "12615    [zeros, import torch\\r\\nimport torch.nn as nn\\...\n",
       "12616    [self.l1 = nn.Linear(model.state_dim, 128)\\r\\n...\n",
       "12617    [x,y, [3, 7], [0.28, 0.44, 0.28], [0, 0, 0.28,...\n",
       "12619    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "12620    [rotMat = xmat @ ymat @ zmat\\r\\n, rotMat = tor...\n",
       "12621    [inputs = Input(shape = (64, 64, 1)). # Channe...\n",
       "12622    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "12623    [points, points, (points == elements).nonzero(...\n",
       "12624    [points, points, (points == elements).nonzero(...\n",
       "12626    [Warning: indexing with dtype torch.uint8 is n...\n",
       "12627    [Warning: indexing with dtype torch.uint8 is n...\n",
       "12628    [Warning: indexing with dtype torch.uint8 is n...\n",
       "12629    [BertForSequenceClassification, [CLS], model =...\n",
       "12630    [BertForSequenceClassification, [CLS], model =...\n",
       "12631    [from PIL import Image\\r\\nimport torch\\r\\nimpo...\n",
       "12632    [import torch\\r\\nfrom torchvision.ops import R...\n",
       "12633    [using ! pip install  torch-sparse, Collecting...\n",
       "12634    [import torch as th\\r\\n\\r\\nth.set_grad_enabled...\n",
       "12636    [optimizer = optim.Adam(model.parameters(), lr...\n",
       "12637    [optimizer = optim.Adam(model.parameters(), lr...\n",
       "12638    [root_dir = \"main_dir\"\\r\\n\\r\\nimage_transforms...\n",
       "12639    [torch.onnx.export(model, dummy_input, \"model....\n",
       "12641    [(batch_size, max_length, embedding_dim), (bat...\n",
       "12642    [    x_norm = (x**2).sum(1).view(-1, 1)\\r\\n   ...\n",
       "12643    [[[44, 50, 1, 32],\\r\\n.\\r\\n.\\r\\n.\\r\\n[7, 13, 9...\n",
       "12644    [Unable to display children:Error resolving va...\n",
       "12645    [model = keras.models.Sequential([ keras.layer...\n",
       "12646    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12647    [(4096, 3), (batch_size, 4096, 3), for view_i ...\n",
       "12648    [[1,2,3], w, b, [1*1, 1*2, 1*3, 2*1, 2*2, 2*3,...\n",
       "12649    [from torch.utils.tensorboard import SummaryWr...\n",
       "12650    [C:/w/1/s/windows/pytorch/aten/src/THCUNN/Clas...\n",
       "12652    [model\\r\\n, ResNet(\\r\\n  (conv1): Conv2d(3, 64...\n",
       "12653    [model\\r\\n, ResNet(\\r\\n  (conv1): Conv2d(3, 64...\n",
       "12655    [y_train.dtype\\r\\ntorch.float32\\r\\ny_test.dtyp...\n",
       "12657                                   [.eval(), .eval()]\n",
       "12661    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12662    [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "12663    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12664    [import torch.nn as nn\\r\\n\\r\\nclass Unet(nn.Mo...\n",
       "12665    [RuntimeError: invalid gradient at index 0 - e...\n",
       "12666    [    class Network(nn.Module):\\r\\n    def __in...\n",
       "12667    [scikit-learn, skorch, import torch.nn.functio...\n",
       "12668    [def load_data(path):\\r\\n    data = []\\r\\n    ...\n",
       "12669    [examples/run_lm_finetuning.py, examples/run_l...\n",
       "12670    [conv1 = nn.Conv2Transpose2d(10, 10, kernel_si...\n",
       "12671    [optimizer = torch.optim.RMSprop(model.paramet...\n",
       "12672    [RNN, class RNN_pytorch(nn.Module):\\r\\n    def...\n",
       "12673    [train_dataset = datasets.MNIST('../', downloa...\n",
       "12674    [cuda.select_device(0), cuda.close(), from  nu...\n",
       "12675    [cuda.select_device(0), cuda.close(), from  nu...\n",
       "12676    [cuda.select_device(0), cuda.close(), from  nu...\n",
       "12677    [torch.cholesky, inline Tensor Tensor::cholesk...\n",
       "12678    [data.random_split, train_idx, validate_idx, t...\n",
       "12679    [torch.util.data.Dataset, my_data, {\"words\":[0...\n",
       "12680    [import torch\\r\\nfrom torch.nn import Paramete...\n",
       "12681    [import torch\\r\\nfrom torch.nn import Paramete...\n",
       "12682    [def get_greedy_distribution(model, batch):\\r\\...\n",
       "12683    [W, W, import torch\\r\\nimport torch.sparse\\r\\n...\n",
       "12684    [(n1, n2), f(n1, n2) = f(n2, n1), 2x2, 2x2, f(...\n",
       "12685    [ def foo(input_list):\\r\\n      # input_list i...\n",
       "12686    [import cv2  \\r\\ni = 0\\r\\ncapture = cv2.VideoC...\n",
       "12687    [inputTensor.dataAsFloatArray, bitmap.width*bi...\n",
       "12688    [inputTensor.dataAsFloatArray, bitmap.width*bi...\n",
       "12689    [import cv2  \\r\\ncapture = cv2.VideoCapture(0)...\n",
       "12691    [QAT, Pytorch, (base) marian@u04-2:/mnt/s3user...\n",
       "12692    [import torch\\r\\nimport time\\r\\n\\r\\n@torch.jit...\n",
       "12693    [class NeuralNet(nn.Module):\\r\\n    \"\"\"\\r\\n   ...\n",
       "12694    [    for i, data in tqdm(enumerate(train_loade...\n",
       "12695    [    cnn = CNN1()\\r\\n\\r\\n    cnn.load_state_di...\n",
       "12696    [class MyModule(nn.Module):\\r\\n    def __init_...\n",
       "12699    [class autoencoder(nn.Module):\\r\\ndef __init__...\n",
       "12700    [class autoencoder(nn.Module):\\r\\ndef __init__...\n",
       "12701    [class DataLoaderStego(DataLoader):\\r\\n    def...\n",
       "12702    [     targets = torch.ones(classification.shap...\n",
       "12703    [tens = tensor([[  101,   146,  1176, 21806,  ...\n",
       "12704    [MaxPool2D, ceil_mode, False, 7x7, kernel=2,st...\n",
       "12705    [\\r\\ndef neural_network_neurons(W, B, X):\\r\\n\\...\n",
       "12706    [mu = torch.tensor(0.005)\\r\\nbar = torch.eye(5...\n",
       "12707    [pip3 install torch===1.4.0 torchvision===0.5....\n",
       "12708    [pip3 install torch===1.4.0 torchvision===0.5....\n",
       "12709    [    import torch\\r\\n    from pytorch_pretrain...\n",
       "12710    [32 x 32 x 3, 3 x 192 x 5 x 5, Conv2d(3, 192, ...\n",
       "12711    [Traceback (most recent call last):\\r\\nFile \"/...\n",
       "12712    [Traceback (most recent call last):\\r\\nFile \"/...\n",
       "12713    [cyclical_lr, def cyclical_lr(stepsize, min_lr...\n",
       "12715    [String[] cmd = {\"python3\", \"-i\" , \"AI/Home-Sy...\n",
       "12716    [f(x,y), import torch\\r\\n\\r\\nN, D_in, H, D_out...\n",
       "12717    [f(x,y), import torch\\r\\n\\r\\nN, D_in, H, D_out...\n",
       "12718    [share_memory_(), cuda:0, CUDA_VISIBLE_DEVICES...\n",
       "12719    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "12720    [DataFrame,        dOpen     dHigh      dLow  ...\n",
       "12721    [class BERT(pl.LightningModule):\\r\\ndef __init...\n",
       "12722    [class BERT(pl.LightningModule):\\r\\ndef __init...\n",
       "12723    [0, 1, x = torch.randn(4,3)\\r\\ntensor([[-0.656...\n",
       "12724    [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "12726    [x1, x2, x1, x2, import torch \\r\\nfrom torch.n...\n",
       "12727    [torch_script, cv::Mat amplitudePatch = Assign...\n",
       "12730                                      [AND, NOT, XOR]\n",
       "12731                                      [AND, NOT, XOR]\n",
       "12732                       [fit_generator, fit_generator]\n",
       "12733                       [fit_generator, fit_generator]\n",
       "12735    [def neighbour(x):\\r\\n    result=F.pad(input=x...\n",
       "12737    [x = torch.tensor([[1.5,0,0,0,0]]), [[1.5,-0.5...\n",
       "12738    [x = torch.tensor([[1.5,0,0,0,0]]), [[1.5,-0.5...\n",
       "12739    [x = torch.tensor([[1.5,0,0,0,0]]), [[1.5,-0.5...\n",
       "12740    [x = torch.tensor([[1.5,0,0,0,0]]), [[1.5,-0.5...\n",
       "12741    [ a = 0.9\\r\\n b = torch.tensor(2, dtype=torch....\n",
       "12742    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "12743    [from torch.utils.tensorboard import SummaryWr...\n",
       "12744    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "12746    [import torchvision.models as models\\r\\nfrom P...\n",
       "12747    [from PIL import Image\\r\\nfrom tqdm import tqd...\n",
       "12748    [ x = torch.rand(5, 64, 32)\\r\\n pool = nn.MaxP...\n",
       "12749                                 [[1,97,1], [1,97,2]]\n",
       "12750    [alexnet = torchvision.models.alexnet(pretrain...\n",
       "12751    [max(0, x),  class Net(nn.Module):\\r\\n  ...(in...\n",
       "12752                         [torch.save(), torch.load()]\n",
       "12754    [import numpy as np\\r\\nimport cv2\\r\\nfrom PIL ...\n",
       "12755    [torch.nn.functional.conv2d, conv2d(X, X)\\r\\n,...\n",
       "12756    [forward, import torch\\r\\nfrom torch import nn...\n",
       "12757    [ONNX IR version:  0.0.4\\r\\nOpset version:    ...\n",
       "12758    [collate_fn, def collate_fn(self, batch):\\r\\n ...\n",
       "12759    [    if args.local_rank not in [-1, 0] and not...\n",
       "12760    [pytorch, t = torch.ones((1,1000,1000))\\r\\nt10...\n",
       "12761    [git clone https://github.com/pytorch/vision\\r...\n",
       "12762    [pip3 install torch==1.3.1+cu92 torchvision==0...\n",
       "12763    [pip3 install torch==1.3.1+cu92 torchvision==0...\n",
       "12766    [class LSTM_net(nn.Module):\\r\\ndef __init__(se...\n",
       "12767    [class LSTM_net(nn.Module):\\r\\ndef __init__(se...\n",
       "12768    [torch.Tensor, numpy.ndarray, torch.Tensor, py...\n",
       "12769    [d = net.parameters()\\r\\nprint(len(list(d)))\\r...\n",
       "12770    [gnet = models.googlenet(pretrained=True).cuda...\n",
       "12771    [OS: Windows 10\\r\\nGCC version: (GCC) 3.4.5 (m...\n",
       "12772    [X, Y, Y, X = torch.from_numpy(X)\\r\\nX.require...\n",
       "12774    [import torch\\r\\n\\r\\nX = X.astype(float)\\r\\n\\r...\n",
       "12775    [gender=Tensor([g]), where g =[-1|0|1] for [fe...\n",
       "12776    [from PIL import Image\\r\\nimport matplotlib.py...\n",
       "12778    [tensor_gpu1=tensor_c1.to(device1)\\r\\ntensor_g...\n",
       "12779    [(N, C) where C = number of classes, NLLLoss, ...\n",
       "12780    [(N, C) where C = number of classes, NLLLoss, ...\n",
       "12782    [$ python main.py --hetero\\r\\nCreated director...\n",
       "12783    [A = [[1,2,3],[4,5,6],[7,8,9],[3,3,3]\\r\\nB = [...\n",
       "12784    [A = [[1,2,3],[4,5,6],[7,8,9],[3,3,3]\\r\\nB = [...\n",
       "12785    [m = torch.nn.LogSoftmax(dim=1)\\r\\ninput = tor...\n",
       "12786    [tokenizer = BertTokenizer.from_pretrained('be...\n",
       "12787    [for, name, parameter, weight, bias, block, bi...\n",
       "12788    [w11 = torch.rand((100,2), requires_grad=True)...\n",
       "12789    [x = [[1, 1], [1, 1]]\\r\\ny = x + 2\\r\\nz = 3y^2...\n",
       "12790    [import torch\\r\\nfrom torchvision import trans...\n",
       "12791    [batch_size = 1, batch_size = 1, (x-mean)/vari...\n",
       "12793    [    with open('file.txt',\"r\",encoding = \"ISO-...\n",
       "12794    [Intent_LSTM(\\r\\n(attention): Attention()\\r\\n(...\n",
       "12795    [nn.Module,     torch.save(\\r\\n        obj=mod...\n",
       "12796    [- list of image tensors, each of shape [C, H,...\n",
       "12797    [import torch\\r\\nimport models\\r\\nmodel_names ...\n",
       "12798    [torch::from_blob, -O3,     torch::Tensor tens...\n",
       "12799    [import numpy as np\\r\\nfrom tqdm import tqdm_n...\n",
       "12800    [.onnx, import model\\r\\nimport torch\\r\\n\\r\\nGe...\n",
       "12805    [torch.onnx.export, input = torch.rand(1, 3, 3...\n",
       "12806    [lab_rs = (lab_rs * [100, 255, 255] - [0, 128,...\n",
       "12807    [torch.rand(10).to(torch.device('cuda'))\\r\\n\\r...\n",
       "12808    [nn.Module, forward, torch.utils.tensorboard, ...\n",
       "12809    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12810    [x = tf.placeholder(tf.float32, [708, 256, 3])...\n",
       "12811    [X_train=torch.from_numpy(X_data)\\r\\ny_train=t...\n",
       "12812    [    import torch\\r\\n    from torch import nn\\...\n",
       "12813    [    import torch\\r\\n    from torch import nn\\...\n",
       "12814    [REFERENCE_FACIAL_POINTS, REFERENCE_FACIAL_POI...\n",
       "12815    [forward(), import torch.nn as nn\\r\\nfrom cnn ...\n",
       "12816    [forward(), import torch.nn as nn\\r\\nfrom cnn ...\n",
       "12817    [w1, w2, w3...wn, k*n1, k*n2, k*n3...k*nn, x1,...\n",
       "12818    [class training_set(Dataset):\\r\\n    def __ini...\n",
       "12819    [Epoch: 1  \\r\\nAccuracy: 0.785     Loss: 2.435...\n",
       "12820    [image = process_image(imgpath)\\r\\n\\r\\nindex =...\n",
       "12821    [image = process_image(imgpath)\\r\\n\\r\\nindex =...\n",
       "12822    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12823    [Model ANN( X = [1000,3] , Y = [1000,8] ), Lay...\n",
       "12824    [letters_EMNIST = {0: '0', 1: '1', 2: '2', 3: ...\n",
       "12825    [input_tensor = torch.cuda.FloatTensor(data)\\r...\n",
       "12827    [sal_maps_hf.shape\\r\\n(11, 32, 32, 3)\\r\\n, sal...\n",
       "12828    [import torchvision, \"*Traceback (most recent ...\n",
       "12829    [import torchvision, \"*Traceback (most recent ...\n",
       "12830    [import torchvision, \"*Traceback (most recent ...\n",
       "12831    [def generate_mask(data : list, max_seq_len : ...\n",
       "12833    [[1,32,296,400], [1, 56000, 400, 2], mode=‘bil...\n",
       "12834    [[CLS], import torch\\r\\n\\r\\nimport transformer...\n",
       "12835    [[CLS], import torch\\r\\n\\r\\nimport transformer...\n",
       "12836    [images, labels = next(iter(self.loader))\\r\\ng...\n",
       "12837    [84x84, target, 84x84, True, False, target = t...\n",
       "12838    [Attention = Softmax(matmul(Q,K.T),dim=-1)\\r\\n...\n",
       "12840    [optimizer = optim.SGD(net.parameters(), lr=0....\n",
       "12841    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12842    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "12846    [Traceback (most recent call last):\\r\\n\\r\\nFil...\n",
       "12848    [import requests\\r\\nfrom io import BytesIO\\r\\n...\n",
       "12849    [Module module = Module.load(assetFilePath(thi...\n",
       "12850    [    logits = torch.einsum('bd,nd-&gt;bn', [ov...\n",
       "12851    [def __getitem__(self, index):\\r\\n, def __geti...\n",
       "12852    [fit(), fit(), Variable, zero_grad(), import t...\n",
       "12853    [fit(), fit(), Variable, zero_grad(), import t...\n",
       "12854    [fit(), fit(), Variable, zero_grad(), import t...\n",
       "12855    [device    = torch.device('cuda:0')\\r\\n\\r\\ntra...\n",
       "12856    [(venv) ➜  ParlAI git:(master) pip install tor...\n",
       "12857    [    def trapezoid(self, X):\\r\\n        Y = to...\n",
       "12858    [def __init__(self, window_length, frame_lengt...\n",
       "12859    [embedding = []\\r\\nvgg16 = vgg16.to(device)\\r\\...\n",
       "12860    [input_size = 784\\r\\nhidden_sizes = [128, 64]\\...\n",
       "12861    [input_size = 784\\r\\nhidden_sizes = [128, 64]\\...\n",
       "12862    [def interleave_keys(a, b):\\r\\n    \"\"\"Interlea...\n",
       "12863    [conda install pytorch\\r\\n, raise AssertionErr...\n",
       "12864    [conda install pytorch\\r\\n, raise AssertionErr...\n",
       "12865    [x, y, x, mean, jc, ac, for k in range(x.size(...\n",
       "12866    [device = torch.device('cuda:0')\\r\\nmodel = mo...\n",
       "12868    [tensor([[1, 2, 3],\\r\\n        [1, 2, 3],\\r\\n ...\n",
       "12869    [tensor([[1, 2, 3],\\r\\n        [1, 2, 3],\\r\\n ...\n",
       "12871    [a = np.array([[1, 2, 3], [4, 5, 6]])\\r\\na_ind...\n",
       "12872    [a = np.array([[1, 2, 3], [4, 5, 6]])\\r\\na_ind...\n",
       "12874    [import requests\\r\\nimport cv2\\r\\n\\r\\nbytes = ...\n",
       "12875    [tile_overlay(), row_overlay(), import torch\\r...\n",
       "12876    [B,C,H,W, B,H,W,C, B,C,H,W, np.swapaxes, # Sin...\n",
       "12877    [import torch\\r\\nfrom PIL import Image\\r\\nimpo...\n",
       "12878    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12879    [trainloader = utilsxai.load_data_cifar10(batc...\n",
       "12880    [class model(nn.Module):\\r\\n    def __init__(s...\n",
       "12881    [import os\\r\\nimport cv2\\r\\nimport numpy as np...\n",
       "12882    [LR Finder is complete, type {learner_name}.re...\n",
       "12883    [from torchvision.datasets import Omniglot\\r\\n...\n",
       "12885    [t1_h = torch.tensor(np.arange(100000), dtype=...\n",
       "12886    [callbacks = [EarlyStoppingCallback(learn, mon...\n",
       "12887    [def l1norm_mask(model, pr_value, prune_large=...\n",
       "12888    [    from torchvision import transforms\\r\\n\\r\\...\n",
       "12889    [    from torchvision import transforms\\r\\n\\r\\...\n",
       "12890    [nvidia/cuda:10.1-cudnn7-devel-ubuntu18.04, (P...\n",
       "12891    [    deep_net = models.vgg19(pretrained=True)....\n",
       "12892    [x = torch.tensor([1.], requires_grad=True)\\r\\...\n",
       "12893    [def flatten(t):\\r\\n    t = t.reshape(1, −1)\\r...\n",
       "12894    [cv::Mat TensorToCVMat(torch::Tensor tensor)\\r...\n",
       "12895    [cv::Mat TensorToCVMat(torch::Tensor tensor)\\r...\n",
       "12896    [cv::Mat TensorToCVMat(torch::Tensor tensor)\\r...\n",
       "12897    [[batch_dim, width, height]\\r\\n, nn.Conv2d(1, ...\n",
       "12898    [class ConvDQN(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "12899    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12904    [import argparse\\r\\nimport sys\\r\\nfrom time im...\n",
       "12905    [Traceback (most recent call last):\\r\\n  File ...\n",
       "12906    [  '''\\r\\n   generator = torch.nn.DataParallel...\n",
       "12907    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "12908    [ tensor([[[1,0,0],[0,1,0],[0,0,1]],[[2,0,0],[...\n",
       "12909    [torch, torchvision, PennFudanExample, cd ~\\r\\...\n",
       "12910    [torch.Size([10,1000]), torch.Size([10, 110528...\n",
       "12911    [for e in range(epochs):\\r\\n    for i in batch...\n",
       "12913    [x = torch.tensor([1., 2., 3.], requires_grad=...\n",
       "12914    [    torch.manual_seed(1)\\r\\n    torch.cuda.ma...\n",
       "12915    [def MSE(output,truth,batch_size):\\r\\n   for i...\n",
       "12916    [RuntimeError: invalid argument 8: lda should ...\n",
       "12917    [for idx,(img,target) in enumerate(trainloader...\n",
       "12918    [import torch\\r\\nx = torch.rand(2, 3)\\r\\nprint...\n",
       "12919    [import torch\\r\\nx = torch.rand(2, 3)\\r\\nprint...\n",
       "12920    [from torchtext.datasets import Multi30k\\r\\nfr...\n",
       "12921    [th neural_style.lua -style_image examples/inp...\n",
       "12923    [correct = output.eq(gt.view(1, -1).expand_as(...\n",
       "12925    [torch, torchvision, pip3 install torch torchv...\n",
       "12926    [root:\\r\\n---&gt;RGB:\\r\\n------&gt;img1.png\\r\\...\n",
       "12927    [ class Classifier(nn.Module):\\r\\n        def ...\n",
       "12928    [#############################################...\n",
       "12930    [np.random.choice(), import torch\\r\\n\\r\\npictu...\n",
       "12931    [np.random.choice(), import torch\\r\\n\\r\\npictu...\n",
       "12933    [np.random.choice(), import torch\\r\\n\\r\\npictu...\n",
       "12934    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "12935    [INFO:root:  Name    Type Params\\r\\n0   l1  Li...\n",
       "12936    [INFO:root:  Name    Type Params\\r\\n0   l1  Li...\n",
       "12937    [INFO:root:  Name    Type Params\\r\\n0   l1  Li...\n",
       "12938    [INFO:root:  Name    Type Params\\r\\n0   l1  Li...\n",
       "12939    [INFO:root:  Name    Type Params\\r\\n0   l1  Li...\n",
       "12940    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "12941    [def __init__(self): \\r\\n    super(ResNet18,se...\n",
       "12942    [prediction.py, evaluat_performance.py, evalua...\n",
       "12943    [prediction.py, evaluat_performance.py, evalua...\n",
       "12944    [Scipy, interp1d, interp1d,  a = torch.tensor(...\n",
       "12946    [conda install pytorch torchvision cuda80 -c s...\n",
       "12947    [torch.cuda._initialized=True\\r\\ntorch.cuda.is...\n",
       "12948    [TypeError: can't pickle _thread.lock objects,...\n",
       "12949    [conv1. x.register_hook:, try_grad = nn.Conv2d...\n",
       "12950    [    c:\\users\\samuel\\appdata\\local\\programs\\py...\n",
       "12952    [from transformers import BertTokenizer, BertF...\n",
       "12953    [from transformers import BertTokenizer, BertF...\n",
       "12954    [import torch\\r\\nimport pykeops.torch as pktor...\n",
       "12956    [for img in imgs:\\r\\n   print(img.shpae) -&gt;...\n",
       "12957    [Warning: Device on which events/metrics are c...\n",
       "12958    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "12959    [def load_data_cifar10(batch_size=128,test=Fal...\n",
       "12960    [/usr/include/boost, CMakeLists.txt, find_pack...\n",
       "12961    [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "12962    [   def __init__(self):\\r\\n        super(CNN_m...\n",
       "12963    [model_state = {\\r\\n             'encoder': en...\n",
       "12964    ['''\\r\\nTest GPU Memory Leak\\r\\nDescription: T...\n",
       "12965    [input = torch.randn(3, 5, requires_grad=True)...\n",
       "12966    [roll = yaw = pitch = torch.randn(1,requires_g...\n",
       "12967    [for ite in range(iteration):\\r\\n    print(\"==...\n",
       "12968    [batch_size=200\\r\\nimport torch  \\r\\nfrom torc...\n",
       "12969    [batch_size=200\\r\\nimport torch  \\r\\nfrom torc...\n",
       "12971    [x[x &gt;= 0.2] = 1\\r\\nx[x &lt; 0.2] = 0 \\r\\n,...\n",
       "12972    [import torch\\r\\n\\r\\nk=2\\r\\na =torch.Tensor([1...\n",
       "12973    [data_transforms = {\\r\\n    'train': transform...\n",
       "12974    [data_transforms = {\\r\\n    'train': transform...\n",
       "12975    [ERROR: (gcloud.beta.ai-platform.versions.crea...\n",
       "12976    [ERROR: (gcloud.beta.ai-platform.versions.crea...\n",
       "12977    [ERROR: (gcloud.beta.ai-platform.versions.crea...\n",
       "12978    [import sys\\r\\nimport torch\\r\\nimport warnings...\n",
       "12979    [train_sentences, train_tags, train_data = Seq...\n",
       "12981    [3.7.3, 0.4.1, imgname, names, vinegar_41, img...\n",
       "12982    [3.7.3, 0.4.1, imgname, names, vinegar_41, img...\n",
       "12985                                [requires_grad=False]\n",
       "12986    [ import torch\\r\\n conv = torch.nn.Conv2d(in_c...\n",
       "12987                                           [Cifar 10]\n",
       "12988    [    df = pd.read_csv(r'dataset.csv',  low_mem...\n",
       "12989    [tensor([[[-8.5780, -7.1091, -8.9204,  ..., -8...\n",
       "12990    [tensor([[[-8.5780, -7.1091, -8.9204,  ..., -8...\n",
       "12991    [class DrugModel(nn.Module):\\r\\n    def __init...\n",
       "12992    [class DrugModel(nn.Module):\\r\\n    def __init...\n",
       "12993    [torch.linspace, torch.arange,  start = torch....\n",
       "12994    [tensor.index_select(), tensor[sequence], In [...\n",
       "12996    [step % 1000 == 0,     if step % 1000 ==0:\\r\\n...\n",
       "12997    [Video = cv2.capture (video_source)\\r\\nWhile T...\n",
       "12998    [data_transform = transforms.Compose([\\r\\n    ...\n",
       "12999    [# values\\r\\n[['closed_eye_0003.jpg_face_2.jpg...\n",
       "13000    [False, def train(model, device, iterator, opt...\n",
       "13001    [conda install pytorch torchvision cpuonly -c ...\n",
       "13002    [dataloader = DataLoader(my_dataset, batch_siz...\n",
       "13003    [dataloader = DataLoader(my_dataset, batch_siz...\n",
       "13004    [super(, ,, ).__init__() # init super, class N...\n",
       "13006    [torch.nn.Conv2d, Kernel_H * Kernel_W * C_in *...\n",
       "13007    [tensorboard --logdir=runs, $ tensorboard --lo...\n",
       "13008    [tensorboard --logdir=runs, $ tensorboard --lo...\n",
       "13009    [tensorboard --logdir=runs, $ tensorboard --lo...\n",
       "13010    [tensorboard --logdir=runs, $ tensorboard --lo...\n",
       "13012    [for t, (x, y, indices) in enumerate(dataset['...\n",
       "13013    [self.wi = nn.Embedding(num_embeddings, embedd...\n",
       "13014    [def cross_entropy(ys,ts):\\r\\n    cross_entrop...\n",
       "13015    [tensor([[1, 1],\\r\\n        [2, 2],\\r\\n       ...\n",
       "13016    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13017    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "13018    [EPOCHS = 5\\r\\nSAVE_DIR = 'models'\\r\\nMODEL_SA...\n",
       "13019    [stateful=True, a1, aFull, z1, z2, z3, a2, aFu...\n",
       "13022    [EPOCHS = 40\\r\\nSAVE_DIR = 'models'\\r\\nMODEL_S...\n",
       "13024    [    class test(nn.Module):\\r\\n        def __i...\n",
       "13025    [!pip install custom_transforms, if __name__ =...\n",
       "13026    [$ git clone https://github.com/pytorch/androi...\n",
       "13027    [RuntimeError: Expected object of scalar type ...\n",
       "13028    [RuntimeError: Expected object of scalar type ...\n",
       "13029    [CUDA out of memory, model = Model()\\r\\nsample...\n",
       "13030    [CUDA out of memory, model = Model()\\r\\nsample...\n",
       "13031    [# take all features as an Independant variabl...\n",
       "13032    [def debug_gpu():\\r\\n    # Debug out of memory...\n",
       "13033    [for param in model.parameters():\\r\\n    param...\n",
       "13034    [data, labels = load_dataset()\\r\\nnet = Neural...\n",
       "13035    [ export CUDA_VISIBLE_DEVICES=0,1,2,3\\r\\n, dev...\n",
       "13036    [ export CUDA_VISIBLE_DEVICES=0,1,2,3\\r\\n, dev...\n",
       "13037    [ export CUDA_VISIBLE_DEVICES=0,1,2,3\\r\\n, dev...\n",
       "13038    [import torch    #v1.3.0\\r\\nimport numpy as np...\n",
       "13039    [import torch    #v1.3.0\\r\\nimport numpy as np...\n",
       "13040    [ loss = nn.BCEWithLogitsLoss()\\r\\n input = to...\n",
       "13041    [BLANK_LABEL, blank must be in label range, BL...\n",
       "13042    [    split = int(len(train_dataset) * 0.8)\\r\\n...\n",
       "13043                                              [[UNK]]\n",
       "13044    [@torch.jit.script, \\r\\n, @torch.jit.script\\r\\...\n",
       "13045    [class Data():\\r\\n    def __init__(self):\\r\\n ...\n",
       "13046    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "13047    [Here is my network:\\r\\nIntent_LSTM(\\r\\n  (emb...\n",
       "13048    [train\\r\\n  -1(3600 png)\\r\\n  -2(3600 png)\\r\\n...\n",
       "13050    [dataset = MNIST(path=data_path, download=True...\n",
       "13051    [DATASET_SIZE = 10\\r\\nNUM_BUCKETS = 4\\r\\nbucke...\n",
       "13052    [from torchvision.datasets import VisionDatase...\n",
       "13053    [print(nn_result.shape)\\r\\n# (2433, 2)\\r\\nnp_r...\n",
       "13056    [Traceback (most recent call last):\\r\\nFile \"C...\n",
       "13057    [class LM(nn.Module):\\r\\n    def __init__(self...\n",
       "13059    [def __train__(dp, i, j, net, restarts, epoch=...\n",
       "13060    [import torch\\r\\n\\r\\nfrom torch.multiprocessin...\n",
       "13061    [Weights of BertForMultiLable not initialized ...\n",
       "13062    [LSTM, Pytorch, ShortTensor, class data(Datase...\n",
       "13063    [clamp, import torch\\r\\nfrom torch.autograd im...\n",
       "13064    [#PyTorch packages\\r\\nimport torch\\r\\nfrom tor...\n",
       "13065    [(Batch, 9, 9, 4), (Batch, 9, 9, 4), loss = tf...\n",
       "13067    [autograd, import autograd.numpy as anp\\r\\nfro...\n",
       "13069    [class Model(nn.Module): \\r\\n\\r\\n    def __ini...\n",
       "13070    [nan = float(\"nan\")\\r\\nt = th.Tensor([[nan, na...\n",
       "13071    [# assume that hidden_size = 3\\r\\n\\r\\nclass En...\n",
       "13072    [C:/Users/nn/Desktop/BERT/transformers-master,...\n",
       "13073    [import torch\\r\\nfrom torchvision import datas...\n",
       "13074    [import torch\\r\\nfrom torchvision import datas...\n",
       "13078    [from torch.distributions import Uniform, Norm...\n",
       "13079    [from torch.distributions import Uniform, Norm...\n",
       "13080    [(base) C:\\Users\\Sean\\Desktop\\Project\\Test\\Tut...\n",
       "13081    [tensor([[-3.0462, -4.0106, -0.6096],\\r\\n[-4.8...\n",
       "13082    [def downsample_and_noise_map(input, sigma):\\r...\n",
       "13083    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "13084    [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "13085    [W1 = tf.Variable(xavier_init([135, 128]))\\r\\n...\n",
       "13086    [can't convert np.ndarray of type numpy.bool_....\n",
       "13088    [...\\r\\n    if write and is_train:\\r\\n        ...\n",
       "13089    [pip3 install torch==1.3.1+cpu torchvision==0....\n",
       "13090    [class GeneratorNet(torch.nn.Module):\\r\\n    \"...\n",
       "13091    [(40000, 64, 64, 3), (15000, 64, 64, 3), modul...\n",
       "13092    [def init_weights(net):\\r\\n    if type(net) ==...\n",
       "13093    [for i=1:N:\\r\\n  X = torch.Tensor([[1,2,3], [3...\n",
       "13094    [Torch 1.3.1 CUDA 10.1.243\\r\\n\\r\\nnvcc: NVIDIA...\n",
       "13095    [Torch 1.3.1 CUDA 10.1.243\\r\\n\\r\\nnvcc: NVIDIA...\n",
       "13096    [Torch 1.3.1 CUDA 10.1.243\\r\\n\\r\\nnvcc: NVIDIA...\n",
       "13097    [Torch 1.3.1 CUDA 10.1.243\\r\\n\\r\\nnvcc: NVIDIA...\n",
       "13098    [mypy==0.750\\r\\npylint==2.4.4\\r\\npytest==5.3.1...\n",
       "13099    [mypy==0.750\\r\\npylint==2.4.4\\r\\npytest==5.3.1...\n",
       "13100    [def convcheck():\\r\\n    torch.manual_seed(123...\n",
       "13101    [def convcheck():\\r\\n    torch.manual_seed(123...\n",
       "13102    [[\\r\\n    (tensor([1, 2, 3]),  tensor([4, 5, 6...\n",
       "13103    [import torch\\r\\n\\r\\nts = torch.rand((10, 4)) ...\n",
       "13104    [nn.CrossEntropyLoss, nn.CrossEntropyLoss, yha...\n",
       "13105    [Y = [[0,1,0,0],\\r\\n     [1,0,0,0],\\r\\n     [0...\n",
       "13106    [gen_y = torch.tensor(gen_y,requires_grad=True...\n",
       "13107    [##Attaching label to correct file names\\r\\n\\r...\n",
       "13108    [##Attaching label to correct file names\\r\\n\\r...\n",
       "13109    [DistributedDataParallel, class A(nn.module):\\...\n",
       "13110    [p3.2xlarge, RuntimeError: CUDA out of memory....\n",
       "13114    [import PIL, torch, torchvision\\r\\n# Load and ...\n",
       "13115    [base_model = InceptionV3(weights='imagenet', ...\n",
       "13116    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13117    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13118    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13119    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13120    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13121    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13122    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13123    [RuntimeError: CUDA out of memory. Tried to al...\n",
       "13124    [Torch, nn.SpatialConvolution, Pytorch, torch....\n",
       "13128    [pretrained_dict = {k: v for k, v pretrained_d...\n",
       "13129    [pretrained_dict = {k: v for k, v pretrained_d...\n",
       "13130    [(10,3,448,448), (10,245), class CNN(nn.Module...\n",
       "13131    [keras.layers.Flatten(), pytorch, import numpy...\n",
       "13132    [keras.layers.Flatten(), pytorch, import numpy...\n",
       "13133    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13134    [from torch.utils.tensorboard import SummaryWr...\n",
       "13135    [class AE(nn.Module):\\r\\n    def __init__(self...\n",
       "13136    [coco = untar_data(URLs.COCO_TINY)\\r\\npath=coc...\n",
       "13138    [class CustomDatasetFromCSV(Dataset):\\r\\n    d...\n",
       "13139    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "13140    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "13142    [import torch\\r\\nfrom torchvision.datasets imp...\n",
       "13144    [class SimpleNN(nn.Module):\\r\\n    def __init_...\n",
       "13145    [global gpu, device\\r\\nif torch.cuda.is_availa...\n",
       "13146    [def confusion_matrix(preds, labels, conf_m, s...\n",
       "13147    [def confusion_matrix(preds, labels, conf_m, s...\n",
       "13148    [def confusion_matrix(preds, labels, conf_m, s...\n",
       "13149    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13150    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13151    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13152    [# Main validation loop\\r\\nvalid_accuracy = 0....\n",
       "13153    [state_dict = torch.load(model_path)['state_di...\n",
       "13154    [state_dict = torch.load(model_path)['state_di...\n",
       "13155    [A, A = \\r\\ntensor([[  4,   3,   3,  ...,   0,...\n",
       "13156    [A, A = \\r\\ntensor([[  4,   3,   3,  ...,   0,...\n",
       "13157    [Traceback (most recent call last):\\r\\n  File ...\n",
       "13159    [import torch\\r\\n\\r\\na = torch.tensor(1)\\r\\nb ...\n",
       "13160    [Traceback (most recent call last):\\r\\nFile \"t...\n",
       "13161    [Traceback (most recent call last):\\r\\nFile \"t...\n",
       "13162    [import multiprocessing as mp\\r\\n\\r\\n\\r\\ndef o...\n",
       "13163    [with torch.no_grad():\\r\\n    for data in test...\n",
       "13164    [ERROR conda.core.link:_execute(700): An error...\n",
       "13165    [vectors = [token.embedding for token in sente...\n",
       "13166    [vectors = [token.embedding for token in sente...\n",
       "13167    [#############################################...\n",
       "13168    [torchvision.utils.save_image, torchvision.uti...\n",
       "13169    [torchvision.utils.save_image, torchvision.uti...\n",
       "13170    [RuntimeError: transform: failed to synchroniz...\n",
       "13171    [pytorch, cherrypy, cherrypy.tree.mount(MyServ...\n",
       "13173    [ /torch/include\\c10/util/order_preserving_fla...\n",
       "13174    [z ∼ N (μ, σ)\\r\\n, import torch\\r\\nx = torch.r...\n",
       "13175    [def compute_linear_gradient_manually(args,mod...\n",
       "13176    [    hc = model.init_hidden(batch_size=1)\\r\\n ...\n",
       "13177    [    hc = model.init_hidden(batch_size=1)\\r\\n ...\n",
       "13179    [df = df.mask(df=0, -5) \\r\\n,  y = torch.where...\n",
       "13180    [alpha_xy = torch.tensor(3.7, device=device, d...\n",
       "13181    [import torch\\r\\ncamembert = torch.hub.load('p...\n",
       "13182    [import torch\\r\\ncamembert = torch.hub.load('p...\n",
       "13183    [import torch\\r\\ncamembert = torch.hub.load('p...\n",
       "13184    [\"Loading time out\", import torch\\r\\n\\r\\n    t...\n",
       "13185    [import torch\\r\\nx = torch.ones(3, 4)\\r\\nx.nor...\n",
       "13186    [g++ -pthread -mavx2 -mfma ...\\r\\n, #pragma GC...\n",
       "13187    [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "13189    [Traceback (most recent call last):\\r\\n  File ...\n",
       "13190    [Sentiment_LSTM(\\r\\n  (embedding): Embedding(5...\n",
       "13191    [class loss(Function):\\r\\n    @staticmethod\\r\\...\n",
       "13192    [optim = torch.optim.SGD([{'params': model.con...\n",
       "13193    [optim = torch.optim.SGD([{'params': model.con...\n",
       "13195    [torchvision.dataset.MNIST, transformer, trans...\n",
       "13196    [ext/build.py build_ext develop, python suppor...\n",
       "13197    [model.fc = nn.Sequential(nn.Linear(2048, 512)...\n",
       "13198    [ class NeuralNet(nn.Module):\\r\\n    def __ini...\n",
       "13199    [optim.SGD([{'params': model.base.parameters()...\n",
       "13201    [pip install torch\\r\\n, pip3 install torch===1...\n",
       "13202    [pip install torch\\r\\n, pip3 install torch===1...\n",
       "13203    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13205    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13206    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13208    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13210    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13211    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "13212    [Total time: 5.4545 s\\r\\nFunction: load_model ...\n",
       "13213    [    def encode(words):\\r\\n        max_l = max...\n",
       "13214    [training_left_eyes = torch.utils.data.DataLoa...\n",
       "13215    [def train_neural_network(data_train_X, data_t...\n",
       "13216    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "13217    [import gym\\r\\nimport torch\\r\\nimport torch.nn...\n",
       "13218    [splIndices, selected_, \\r\\nsplIndices = [45, ...\n",
       "13220    [import torch\\r\\nimport torch.nn  as nn\\r\\n\\r\\...\n",
       "13221    [class NeuralNet(nn.Module):\\r\\n  def __init__...\n",
       "13222    [dataframe = pd.read_csv(\"training_facial_keyp...\n",
       "13223    [import torch.nn.init as init\\r\\nclass Encoder...\n",
       "13224    [x_train, torch.Size([45000, 784]), y_train, t...\n",
       "13225    [x_train, torch.Size([45000, 784]), y_train, t...\n",
       "13226    [x_train, torch.Size([45000, 784]), y_train, t...\n",
       "13227    [# Let's say I have a list of points in R^3, f...\n",
       "13228    [300x1, for item in embeddingLists:    # embed...\n",
       "13229    [net = torchvision.models.inception_v3(pretrai...\n",
       "13230    [    -----------------------------------------...\n",
       "13231    [    -----------------------------------------...\n",
       "13232    [tensor([[[ 7.3478, -1.8058, -2.6140,  ..., -0...\n",
       "13233     [maskrcnn_benchmark/modeling/backbone/resnet.py]\n",
       "13234    [pip3 install ax-platform\\r\\n, from ax.plot.co...\n",
       "13235    [test_string = 'text with percentage%'\\r\\n, im...\n",
       "13236    [class Net(nn.Module):\\r\\n    def __init__():\\...\n",
       "13237    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "13238    [nn.LPPool2d(norm_type=xxx), norm_type, norm_t...\n",
       "13239    [\\r\\nclass RoBERTaLSTMClassifier(nn.Module):\\r...\n",
       "13240    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "13241    [assert(type(images) == list)\\r\\nassert(type(i...\n",
       "13242    [import numpy as np\\r\\nfrom timeit import defa...\n",
       "13243    [    for itr in range(1, args.niters + 1):\\r\\n...\n",
       "13245    [  net = []\\r\\n  class Net(torch.nn.Module):\\r...\n",
       "13246    [import torch, torchvision\\r\\nfrom torchvision...\n",
       "13247    [import torch\\r\\nfrom torch import nn, tensor\\...\n",
       "13248    [     class BaseLRScheduler(_LRScheduler):\\r\\n...\n",
       "13249    [pip install torch, Collecting torch\\r\\nUsing ...\n",
       "13250    [transforms.Normalize, train_transform = trans...\n",
       "13252    [class Net(nn.Module)\\r\\n, w0, w1, w0, w1, the...\n",
       "13254    [class tryLSTM(nn.moduleList):\\r\\n    def __in...\n",
       "13255    [class NetModel(nn.Module):\\r\\n    def __init_...\n",
       "13256    [class LSTMLM(torch.nn.Module):\\r\\n  def __ini...\n",
       "13258    [Root/\\r\\n    Class0/image0_view0.png\\r\\n    C...\n",
       "13259    [Root/\\r\\n    Class0/image0_view0.png\\r\\n    C...\n",
       "13260    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "13261    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "13262              [pytorch, import torch, pytorch, conda]\n",
       "13263    [def vis_tensor(data):\\r\\n    data  =data.data...\n",
       "13264    [ValueError: The truth value of an array with ...\n",
       "13265    [error: \"RuntimeError: The size of tensor a (1...\n",
       "13266    [error: \"RuntimeError: The size of tensor a (1...\n",
       "13267    [p.data.add_(-group['lr'], d_p), -lr * grads, ...\n",
       "13268    [        pFunc_init = PyObject_GetAttrString(p...\n",
       "13269    [class NewModule(torch.nn.Module):\\r\\n    def ...\n",
       "13270    [class NewModule(torch.nn.Module):\\r\\n    def ...\n",
       "13271    [class NewModule(torch.nn.Module):\\r\\n    def ...\n",
       "13272    [class NewModule(torch.nn.Module):\\r\\n    def ...\n",
       "13273    [preds_df = pd.DataFrame()   \\r\\nclass_labels ...\n",
       "13274    [net_input, output, net_input, output, net_inp...\n",
       "13275    [for idx, sample in enumerate(self.train_data)...\n",
       "13276    [fastai, pip install fastai, AttributeError: m...\n",
       "13277    [# from: https://pytorch.org/tutorials/beginne...\n",
       "13278    [NotImplementedError Traceback (most recent ca...\n",
       "13279    [Pathlib.Path, TypeError: expected str, bytes ...\n",
       "13280    [net = torchvision.models.resnet18(pretrained=...\n",
       "13281    [random.shuffle(), import numpy as np\\r\\nimpor...\n",
       "13282    [test.py, '--batch_size', launch.json, \"args\":...\n",
       "13285    [THCudaCheck FAIL file=..\\aten\\src\\THC\\THCCach...\n",
       "13286    [ModuleNotFoundError: No module named 'torch',...\n",
       "13287    [ModuleNotFoundError: No module named 'torch',...\n",
       "13288    [ModuleNotFoundError: No module named 'torch',...\n",
       "13289    [f, axarr = plt.subplots(2,2, figsize=(20,20))...\n",
       "13290    [class image_Dataset(Dataset):\\r\\n    '''\\r\\n ...\n",
       "13291    [ import torch\\r\\n device = torch.device(\"cuda...\n",
       "13292    [ import torch\\r\\n device = torch.device(\"cuda...\n",
       "13293    [ import torch\\r\\n device = torch.device(\"cuda...\n",
       "13294    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13295    [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "13297    [Total Image: 500, Class A 300; Class B 200\\r\\...\n",
       "13298    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13299    [# Suppose we have two correctly initialized n...\n",
       "13300                   [drop_last=True, idx, __getitem__]\n",
       "13301    [class baseBlock(torch.nn.Module):\\r\\n  expans...\n",
       "13304    [249561, 80, 1, (249561, 2), def __init__(self...\n",
       "13305    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "13306    [    transform = transforms.Compose([transform...\n",
       "13307    [(minibatch_size=32, rows=100, columns=41), __...\n",
       "13308                 [local_rank, local_rank, local_rank]\n",
       "13309                 [local_rank, local_rank, local_rank]\n",
       "13310    [hidden_size = 32  \\r\\nnum_layers = 1\\r\\nnum_c...\n",
       "13311    [--ipc=host, ERROR: Unexpected bus error encou...\n",
       "13312    [--ipc=host, ERROR: Unexpected bus error encou...\n",
       "13313    [..................................x.............\n",
       "13316                       [(2**N, N), dtype=torch.float]\n",
       "13317    [class LC_small(nn.Module):\\r\\n    def __init_...\n",
       "13318                                 [pool.apply_async()]\n",
       "13320    [conda install pytorch torchvision cudatoolkit...\n",
       "13321    [nn.Linear, nn.Conv2d(3, **32**, kernel_size=7...\n",
       "13322    [torchvision: 0.3.0\\r\\ntorch: 1.1.0\\r\\nfastai:...\n",
       "13323    [gensim, hidden_size = 32  \\r\\nnum_layers = 1\\...\n",
       "13324    [class MSE_loss(nn.Module):\\r\\n    \"\"\" \\r\\n   ...\n",
       "13325    [class MSE_loss(nn.Module):\\r\\n    \"\"\" \\r\\n   ...\n",
       "13326    [class MSE_loss(nn.Module):\\r\\n    \"\"\" \\r\\n   ...\n",
       "13327    [class MSE_loss(nn.Module):\\r\\n    \"\"\" \\r\\n   ...\n",
       "13328    [class FFNet(torch.nn.Module):\\r\\n    def __in...\n",
       "13329    [nn.Module, def init_weights(m):\\r\\n    if typ...\n",
       "13330    [batch_size = 10\\r\\nimage_size = 128\\r\\n\\r\\nne...\n",
       "13331    [ResNet 18 model, torchvision.models.resnet, C...\n",
       "13332    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13333    [self.lstm = nn.GRU(params.vid_embedding_dim, ...\n",
       "13334    [a = torch.randn(1,3)\\r\\na\\r\\n\\r\\n&gt;&gt; ten...\n",
       "13335    [import torch\\r\\n\\r\\nunet = my_unet(in_ch=5, o...\n",
       "13336    [import gensim\\r\\nimport numpy as np\\r\\nimport...\n",
       "13337    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "13338    [nn, num_embeddings, embedding_dim, import tor...\n",
       "13339    [### input Image size [batch,seq,colorch,hight...\n",
       "13340    [w = 5 # input width\\r\\nh = 5 # output height\\...\n",
       "13341    [Hugos-MacBook-Pro-2:project hugokitano$ pip3 ...\n",
       "13342    [Hugos-MacBook-Pro-2:project hugokitano$ pip3 ...\n",
       "13343    [/usr/local, $&gt; ls /usr/local\\r\\nbin  cuda ...\n",
       "13345    [correct = 0\\r\\ntotal = 0\\r\\nwith torch.no_gra...\n",
       "13347    [CUDA_LAUNCH_BLOCKING = 1\\r\\n\\r\\nstart = time....\n",
       "13348    [sdkmanager --cli downloadonly --user $NV_USER...\n",
       "13349    [model.eval(), model.eval(), model.eval(), BN,...\n",
       "13350    [model.x = model.x.clamp(min=0.0, max=1.0), re...\n",
       "13351    [import torch \\r\\nfrom torch.distributions imp...\n",
       "13352    [tensor1, tensor2, import torch.nn as nn\\r\\nim...\n",
       "13353    [torch.utils.data.dataloader, pin_memory=True,...\n",
       "13354    [/tmp/pip-req-build-58y_cjjl/torch/csrc/autogr...\n",
       "13355    [self.global = nn.Sequential(Conv2d(3, 16, 9, ...\n",
       "13356    [def fgsm_attack(inputs, model, epsilon, attac...\n",
       "13357    [    from torch.nn.modules.transformer import ...\n",
       "13358    [import torch\\r\\npredictions = torch.tensor([ ...\n",
       "13359    [(base) (3.8.0/envs/my_virtual_env-3.8.0) marc...\n",
       "13360    [(base) (3.8.0/envs/my_virtual_env-3.8.0) marc...\n",
       "13362    [class Generator(nn.Module):\\r\\ndef __init__(s...\n",
       "13363    [class subnet1():\\r\\n    def __init__()\\r\\n\\r\\...\n",
       "13364    [ import torch\\r\\n target1 = torch.tensor([5])...\n",
       "13365    [class Network(nn.Module):\\r\\n   def __init__(...\n",
       "13366    [RuntimeError: Expected object of backend CPU ...\n",
       "13367    [DataLoader, enumerate(train_loader), class GR...\n",
       "13368    [word_to_idx =  {'I': 0, 'have': 1, 'used': 2,...\n",
       "13369    [train_transform = transforms.Compose([transfo...\n",
       "13370    [from torch.utils.tensorboard import SummaryWr...\n",
       "13371    [from torch.utils.tensorboard import SummaryWr...\n",
       "13372    [from torch.utils.tensorboard import SummaryWr...\n",
       "13373    [from torch.utils.tensorboard import SummaryWr...\n",
       "13374    [import matplotlib\\r\\nimport matplotlib.pyplot...\n",
       "13375    [int len = Input.size(0);\\r\\nat::Tensor output...\n",
       "13376    [raw_data = pd.read_csv(\"final.csv\")\\r\\ntrain_...\n",
       "13377    [Net(\\r\\n  (layer1): Sequential(\\r\\n    (0): C...\n",
       "13378                   [(5, 1, 44, 44), (5, 1, 224, 224)]\n",
       "13380    [aug_transforms, \\r\\n!pip install git+https://...\n",
       "13383    [import numpy as np\\r\\nfrom PIL import Image\\r...\n",
       "13384    [import numpy as np\\r\\nfrom PIL import Image\\r...\n",
       "13385    [A, Nx3, B, C, Mx3, BC, A, BC, B, Mx3, C, Mx3,...\n",
       "13386    [dataset_for_augmentation.listDataset(train_li...\n",
       "13387    [dataset_for_augmentation.listDataset(train_li...\n",
       "13388                               [nn.Sequential(*list)]\n",
       "13389    [loss.backward(), TypeError: 'NoneType' object...\n",
       "13390    [def forward(self, src_tokens=None, src_length...\n",
       "13391    [def forward(self, src_tokens=None, src_length...\n",
       "13392    [import torch\\r\\nimport segmentation_models_py...\n",
       "13393    [class LSTM(nn.Module):\\r\\ndef __init__(self, ...\n",
       "13394    [$docker run -it --[name] -p 8888:8888 [docker...\n",
       "13396    [Pytorch, torch::Tensor, double[], double arra...\n",
       "13397    [Pytorch, torch::Tensor, double[], double arra...\n",
       "13398    [Pytorch, torch::Tensor, double[], double arra...\n",
       "13400    [outputs, &gt;&gt; outputs[2][0][0,:,:]\\r\\nOut...\n",
       "13401    [outputs, &gt;&gt; outputs[2][0][0,:,:]\\r\\nOut...\n",
       "13402    [DataLoader, import numpy as np\\r\\nimport torc...\n",
       "13403    [import torch\\r\\n\\r\\nmu = torch.ones((2,), req...\n",
       "13404    [transforms.Resize(), transforms.Normalize((0....\n",
       "13405    [transforms.Resize(), transforms.Normalize((0....\n",
       "13406    [Model1: input_1 -&gt; encoder -&gt; decoder_1...\n",
       "13407    [Model1: input_1 -&gt; encoder -&gt; decoder_1...\n",
       "13408    [pytorch, torch::save(lstmNetwork, 'model.pt')...\n",
       "13409    [conv2d, import torch \\r\\n\\r\\ndef conv2D(X, K)...\n",
       "13410    [n = torch.zeros_like(x)\\r\\nfor i in range(x.s...\n",
       "13411    [optim = torch.optim.Adam([\\r\\n{'params': A.pa...\n",
       "13412    [tensor([121., 241., 125.,   1., 108., 238., 1...\n",
       "13413    [tensor([121., 241., 125.,   1., 108., 238., 1...\n",
       "13417    [backward(), [0.1, 1.0, 0.0001], backward(), [...\n",
       "13418    [&gt;&gt; i = 3\\r\\n&gt;&gt; j = 5\\r\\n&gt;&gt; ...\n",
       "13419    [def plot_confusion_matrix(cm, classes,\\r\\n   ...\n",
       "13420    [def dropout(input, p=0.5, training=True, inpl...\n",
       "13421    [\\r\\n#attention def and class\\r\\n\\r\\ndef clone...\n",
       "13422    [(batch_size,features), o1 = self.a1(x), impor...\n",
       "13423    [(batch_size,features), o1 = self.a1(x), impor...\n",
       "13424    [class FNNModule(nn.Module):\\r\\n    def __init...\n",
       "13425    [    for epoch in range(283,args.epochs):\\r\\n\\...\n",
       "13426    [&gt;&gt; outputs\\r\\ntensor([[-0.1260,  0.0463...\n",
       "13427    [---------------------------------------------...\n",
       "13428    [---------------------------------------------...\n",
       "13429    [---------------------------------------------...\n",
       "13430    [---------------------------------------------...\n",
       "13431    [for i in range(samples):\\r\\ndataset[i] = [val...\n",
       "13432    [for i in range(samples):\\r\\ndataset[i] = [val...\n",
       "13433    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13434    [\\r\\ndef msfe(ys, ts):\\r\\n    ys=ys.detach().n...\n",
       "13435    [from __future__ import print_function\\r\\nimpo...\n",
       "13436    [torch.save(the_model.state_dict(), PATH)\\r\\n,...\n",
       "13438    [class Trend(nn.Module):\\r\\n    \"\"\"\\r\\n    Bro...\n",
       "13439    [- extract the forward and backward last hidde...\n",
       "13440    [cuda = True if torch.cuda.is_available() else...\n",
       "13441    [(A -&gt; size = 250.000), A = [0, 3, 2, 4, 3]...\n",
       "13442    [(A -&gt; size = 250.000), A = [0, 3, 2, 4, 3]...\n",
       "13443    [(A -&gt; size = 250.000), A = [0, 3, 2, 4, 3]...\n",
       "13444    [x_batch = torch.tensor([[-0.3, -0.7], [0.3, 0...\n",
       "13445    [x_batch = torch.tensor([[-0.3, -0.7], [0.3, 0...\n",
       "13446    [def Net_One():\\r\\n    conv2d\\r\\n    conv2d\\r\\...\n",
       "13447    [t_shape = [4, 1]\\r\\ndata = torch.rand(t_shape...\n",
       "13448    [import torch.nn as nn  \\r\\nnn.Sequential(nn.C...\n",
       "13449    [torch.nn.modules.transformer.Transformer, enc...\n",
       "13450    [a = tensor(\\r\\n[[0.2215, 0.5859, 0.4782, 0.74...\n",
       "13451    [torch.ge, import torch\\r\\nimport torch.nn as ...\n",
       "13452    [train_dataset = dsets.MNIST(root='./data', \\r...\n",
       "13453    [sex, age, sex, 0, 1, age, 25, 60, 0, 1, class...\n",
       "13454    [    w = torch.tensor([2.,1.,3.], requires_gra...\n",
       "13455    [X = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11...\n",
       "13456    [X = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11...\n",
       "13457    [# input array\\r\\nimg = torch.randn(2, 2)\\r\\np...\n",
       "13458    [# input array\\r\\nimg = torch.randn(2, 2)\\r\\np...\n",
       "13459    [# input array\\r\\nimg = torch.randn(2, 2)\\r\\np...\n",
       "13460    [os.system('python3 extract_features.py \\\\r\\n ...\n",
       "13461    [torch, input_embedding, [tensor([-0.8264,  0....\n",
       "13462    [torch, input_embedding, [tensor([-0.8264,  0....\n",
       "13464    [nn.MaxPool2d(kernel_size, stride), nn.functio...\n",
       "13465    [nvidia-docker run -it --rm --shm-size=2g -v /...\n",
       "13466    [import torch\\r\\nfrom torch import autograd \\r...\n",
       "13468    [3.7.4\\r\\n, torch           1.3.0+cpu\\r\\ntorch...\n",
       "13469    [model.train()\\r\\nfor e in range(num_epochs):\\...\n",
       "13470    [0, 9, idx_to_class = {0: \"0\", 1: \"1\", 2: \"2\",...\n",
       "13471    [# Load &amp; transform image\\r\\nori_img = Ima...\n",
       "13472    [target, targets, train_iterator, dev_iterator...\n",
       "13473    [import torch \\r\\n\\r\\ninput_dim, hidden_dim = ...\n",
       "13474    [Image.open, from PIL import Image\\r\\nimport m...\n",
       "13475    [self.a = nn.Parameter(torch.ones(8))\\r\\nself....\n",
       "13476    [train.py, srun, srun python train.py\\r\\n, sru...\n",
       "13477    [  File \"xlnet/train_config.py\", line 318, in ...\n",
       "13478    [/usr/local/lib/python3.6/dist-packages/gpytor...\n",
       "13479    [       [[[ 0,  0,  2,  ...,  0,  0,  0],\\r\\n ...\n",
       "13480    [from torch.autograd import Variable\\r\\nfrom t...\n",
       "13482                                       [index_select]\n",
       "13483    [torch.manual_seed(1)\\r\\nmodel = ConvNet(num_c...\n",
       "13484    [nan, batch_size = 36\\r\\ndevice = 'cuda'\\r\\n# ...\n",
       "13485    [torchvision.datasets.ImageFolder, num_workers...\n",
       "13486    [for epoch in range(1, args.epochs + 1):\\r\\n  ...\n",
       "13487    [for epoch in range(1, args.epochs + 1):\\r\\n  ...\n",
       "13488    [loss = model(b_input_ids, token_type_ids=None...\n",
       "13489    [train_data = torchvision.datasets.ImageFolder...\n",
       "13490    [u[i][j] = multiplier*NORM(Q.column(i)-Q.colum...\n",
       "13491    [def strategy(self, state):\\r\\n    # Explore o...\n",
       "13492    [def strategy(self, state):\\r\\n    # Explore o...\n",
       "13493    [data_dir = 'data/hymenoptera_data'\\r\\nimage_d...\n",
       "13494    [model.save_pretrained('/saved_model/')\\r\\ntor...\n",
       "13495    [x = torch.zeros(1000)\\r\\ny = torch.zeros(1000...\n",
       "13496    [dataloader type =  &lt;class 'torch.utils.dat...\n",
       "13498    [AttributeError                            Tra...\n",
       "13500    [from torch.autograd import Variable\\r\\n\\r\\nda...\n",
       "13502    [from torch.nn._functions.thnn import rnnFused...\n",
       "13503    [A: size k x m\\r\\n\\r\\nB: size m x n\\r\\n, k x n...\n",
       "13504    [A: size k x m\\r\\n\\r\\nB: size m x n\\r\\n, k x n...\n",
       "13505    [\\r\\nepochs = 100 \\r\\nlosses = [] \\r\\nfor i in...\n",
       "13507    [import torch\\r\\nimport torchvision as tv\\r\\ni...\n",
       "13508    [import numpy as np\\r\\ndata = [pd.DataFrame(np...\n",
       "13510    [torch.nn.Functional, loss = torch.nn.function...\n",
       "13511    [X = tensor([[50.7500, 44.0000],\\r\\n        [4...\n",
       "13512    [X = tensor([[50.7500, 44.0000],\\r\\n        [4...\n",
       "13513    [input -&gt; 128x (separate fully connected la...\n",
       "13514    [__init__, self.encode_this = nn.Embedding(sel...\n",
       "13515    [torch.hub, numpy==1.17.2\\r\\nhttps://download....\n",
       "13516    [torch.hub, numpy==1.17.2\\r\\nhttps://download....\n",
       "13517    [class LargeNet(nn.Module):\\r\\n    def __init_...\n",
       "13518    [ConcatDataset, DataSet, DataLoader, DataLoade...\n",
       "13519    [def custom_function(torch.autograd.Function):...\n",
       "13520    [&gt;&gt;import torch\\r\\n&gt;&gt;import torchv...\n",
       "13521    [&gt;&gt;import torch\\r\\n&gt;&gt;import torchv...\n",
       "13522    [&gt;&gt;import torch\\r\\n&gt;&gt;import torchv...\n",
       "13523    [N = 20\\r\\nC = 100\\r\\nL = 40\\r\\nm = nn.Instanc...\n",
       "13524    [def softmax(x):\\r\\n    exp_x = torch.exp(x)\\r...\n",
       "13525    [def softmax(x):\\r\\n    exp_x = torch.exp(x)\\r...\n",
       "13526                                   [[100, 1, 32, 32]]\n",
       "13528                                   [[100, 1, 32, 32]]\n",
       "13529    [X, y, from tensorflow.keras.models import Seq...\n",
       "13531    [    data_path = 'C:/Users/.../Train/'\\r\\n    ...\n",
       "13532    [        input = torch.rand(1, 3, 300, 300, dt...\n",
       "13533    [import os\\r\\nimport numpy as np\\r\\nimport arg...\n",
       "13534    [torch.randn(input.data.size()), from StyleCNN...\n",
       "13535    [fairseq-preprocess --source-lang zh --target-...\n",
       "13536    [ import torch\\r\\n torch.cuda.is_available()\\r...\n",
       "13537    [ import torch\\r\\n torch.cuda.is_available()\\r...\n",
       "13538    [        pred=pred.reshape([512,512]).astype('...\n",
       "13539    [\\r\\nmodel = Model().double()   # Model is def...\n",
       "13540    [\\r\\nmodel = Model().double()   # Model is def...\n",
       "13541    [(base) C:\\Users\\murali\\Desktop\\yolov3&gt;pyth...\n",
       "13543    [class FeedForward(nn.Module):\\r\\n    def __in...\n",
       "13546    [import cv2\\r\\nimport torch\\r\\nimport torch.nn...\n",
       "13547    [    data = bytes(self.Download(\"https://www.d...\n",
       "13548    [requires_grad = False, autoencoder(\\r\\n  (gen...\n",
       "13549    [dnn_regressor = DNNRegressor(n_feature=datase...\n",
       "13551    [class SimpleCNN(nn.Module):\\r\\n\\r\\n    def __...\n",
       "13552    [import gym\\r\\nimport random\\r\\nimport math\\r\\...\n",
       "13553    [from sklearn.datasets import load_boston\\r\\nf...\n",
       "13554    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13555    [(20,48), import torch.nn.functional as F\\r\\ni...\n",
       "13556    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nind...\n",
       "13557    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nind...\n",
       "13558    [---- Evaluating Model ----\\r\\nDetecting objec...\n",
       "13559    [import random\\r\\nfrom collections import dequ...\n",
       "13560    [# Sample indices\\r\\ndef sample_idx(m, n):\\r\\n...\n",
       "13561    [a = np.ones(5)\\r\\nb = torch.from_numpy(a)\\r\\n...\n",
       "13562    [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "13563    [# Retrieving model parameters from checkpoint...\n",
       "13564    [pytorch-pretained-bert, tokenized_text = toke...\n",
       "13565    [(100, 40), 1 x 2, 4 x 1, 1 x 2, 1 x 2, 1 x 1,...\n",
       "13566    [(100, 40), 1 x 2, 4 x 1, 1 x 2, 1 x 2, 1 x 1,...\n",
       "13567    [(100, 40), 1 x 2, 4 x 1, 1 x 2, 1 x 2, 1 x 1,...\n",
       "13568    [\\r\\n# Model definition\\r\\nclass BlockWiseCSRN...\n",
       "13569    [$ source activate GNN\\r\\n(GNN) $ python\\r\\n i...\n",
       "13571    [state_dicts, state_dict, optimizer.param_grou...\n",
       "13572    [print(\"All modules\")\\r\\nfor child in net.chil...\n",
       "13573    [print(\"All modules\")\\r\\nfor child in net.chil...\n",
       "13574    [print(\"All modules\")\\r\\nfor child in net.chil...\n",
       "13575    [print(\"All modules\")\\r\\nfor child in net.chil...\n",
       "13576    [print(\"All modules\")\\r\\nfor child in net.chil...\n",
       "13578                          [torch.Size([3, 480, 480])]\n",
       "13579    [import torch\\r\\n\\r\\nngpu = torch.cuda.device_...\n",
       "13580    [import numpy as np\\r\\nx = np.array([[0], [0, ...\n",
       "13581    [def mg(x):\\r\\n\\r\\n    c = 1.33\\r\\n    b = 0.4...\n",
       "13583    [# coding: utf-8\\r\\n\\r\\n# In[5]:\\r\\n\\r\\n\\r\\nim...\n",
       "13584    [EnsembleVoteClassifier, mlxtend.classifier, X...\n",
       "13585    [learn.predict(), Sequential(\\r\\n  (0): Sequen...\n",
       "13586    [learn.predict(), Sequential(\\r\\n  (0): Sequen...\n",
       "13587    [error loading the model\\r\\nCannot initialize ...\n",
       "13589    [def update(): \\r\\n  y_hat = x@a  \\r\\n  loss =...\n",
       "13590    [def update(): \\r\\n  y_hat = x@a  \\r\\n  loss =...\n",
       "13592    [learn.fit_one_cycle(5)\\r\\n, preds_test, _ = l...\n",
       "13593    [_img = Image.open(self.images[index]).convert...\n",
       "13594    [metrics=[\"accuracy\"], criterion = nn.MSELoss(...\n",
       "13595    [for epoch in range(epochs):\\r\\n    x, y = som...\n",
       "13596    [class mymodel(nn.Module):\\r\\n    def __init__...\n",
       "13597    [i, t = i, t = i + 91, import torch\\r\\nimport ...\n",
       "13598    [x = torch.randn(100, 100).to(device)\\r\\nx = t...\n",
       "13599    [self, self.res1 = 1\\r\\nself.res2 = 2\\r\\nself....\n",
       "13601    [NotImplementedError: uint8\\r\\n, from keras.da...\n",
       "13602    [dataset = pd.read_csv('mlb_games_overview.csv...\n",
       "13603    [contractive autoencoder, import datetime\\r\\ni...\n",
       "13604    [contractive autoencoder, import datetime\\r\\ni...\n",
       "13605    [contractive autoencoder, import datetime\\r\\ni...\n",
       "13606    [nn.module, reset_(), reset_(), reset_(), \\r\\n...\n",
       "13607     [[B, 3, 128, 128], [B, 4, 3, 32, 32], [B, 4, 4]]\n",
       "13608    [\\r\\n    class BuildModel(nn.Module):\\r\\n     ...\n",
       "13609    [C:/w/1/s/windows/pytorch/aten/src/ATen/native...\n",
       "13610    [C:/w/1/s/windows/pytorch/aten/src/ATen/native...\n",
       "13611    [ID: 5000686\\r\\nAge of Home: 34\\r\\nZip Code: 4...\n",
       "13612    [training_sentences = open(path + \"train.en\" ,...\n",
       "13613    [training_sentences = open(path + \"train.en\" ,...\n",
       "13614    [self._hyperparameters(config)    # redefines ...\n",
       "13615    [self.opt = TrainOptions().parse()\\r\\ndata_loa...\n",
       "13616    [class MRDataset(data.Dataset):\\r\\n    def __i...\n",
       "13617    [h_0_contig = self.h_0.expand(1,size,self.rnn....\n",
       "13618    [random seed,     data_gen_args = dict(feature...\n",
       "13619    [random seed,     data_gen_args = dict(feature...\n",
       "13620    [random seed,     data_gen_args = dict(feature...\n",
       "13621    [        # Create LSTM Model\\r\\nclass LSTMMode...\n",
       "13623    [for epoch in range(num_epochs):\\r\\n    # Assu...\n",
       "13624    [import torch.nn as nn\\r\\n\\r\\n\\r\\nclass AE(nn....\n",
       "13625    [cuda, torch.cuda.manual_seed(11)\\r\\n, torch.m...\n",
       "13626    [model, mu, sigma, model.sample_noise()\\r\\nout...\n",
       "13628    [class OurModule(nn.Module):\\r\\n    def __init...\n",
       "13629    [class OurModule(nn.Module):\\r\\n    def __init...\n",
       "13630    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13632    [X, n, m == X.shape, torch.pinverse, X_p = tor...\n",
       "13633    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "13634    [tensor([[ 0.7646,  0.5573,  0.4000,  0.2188, ...\n",
       "13635    [project/\\r\\n  main.py\\r\\n  sigmoid.cpp\\r\\n, f...\n",
       "13636    [# read the csv file\\r\\n\\r\\nclassfile = pd.rea...\n",
       "13637    [name2id = {v:k for k,v in enumerate(classes)}...\n",
       "13639    [torch.cuda.is_available(), nvidia-smi, CUDA_V...\n",
       "13640    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13641    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13642    [psi = torch.zeros(512).normal_(0., 1.).requir...\n",
       "13643    [psi = torch.zeros(512).normal_(0., 1.).requir...\n",
       "13644    [class FFNNModel(nn.Module):\\r\\n    def __init...\n",
       "13645    [class FFNNModel(nn.Module):\\r\\n    def __init...\n",
       "13646    [class FFNNModel(nn.Module):\\r\\n    def __init...\n",
       "13647    [sum(􏰀i=1,M) 􏰀sum(j=1,M) indicator[i̸=j](viT v...\n",
       "13648    [model_1 = RegressionModel()\\r\\nW = torch.zero...\n",
       "13649    [class G(nn.Module): # We introduce a class to...\n",
       "13650    [optimizer = optim.Adam(model_pyt.parameters()...\n",
       "13651    [a = tensor([[0, 0, 0, 0],\\r\\n            [0, ...\n",
       "13652    [a = tensor([[0, 0, 0, 0],\\r\\n            [0, ...\n",
       "13653    [print(self.netG(self.real_A)-self.netG(self.r...\n",
       "13654    [print(self.netG(self.real_A)-self.netG(self.r...\n",
       "13655    [mean = [0.485, 0.456, 0.406], std = [0.229, 0...\n",
       "13656    [mean = [0.485, 0.456, 0.406], std = [0.229, 0...\n",
       "13659    [for name, p in model.named_parameters():\\r\\n ...\n",
       "13661    [for i in range(a.shape[1]):\\r\\n    for j in r...\n",
       "13662    [for i in range(a.shape[1]):\\r\\n    for j in r...\n",
       "13663    [import sys\\r\\nfrom tqdm import tqdm\\r\\nimport...\n",
       "13664    [1, torch.nonzero(a == 1).squeeze(), tensor([1...\n",
       "13665    [1, torch.nonzero(a == 1).squeeze(), tensor([1...\n",
       "13666    [1, torch.nonzero(a == 1).squeeze(), tensor([1...\n",
       "13667    [1, torch.nonzero(a == 1).squeeze(), tensor([1...\n",
       "13668    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13669    [source activate env_name, conda install pytor...\n",
       "13670    [source activate env_name, conda install pytor...\n",
       "13671    [import torchvision, libcudart.so.9.0: cannot ...\n",
       "13672    [import torchvision, libcudart.so.9.0: cannot ...\n",
       "13673    [import torchvision, libcudart.so.9.0: cannot ...\n",
       "13674    [import torchvision, libcudart.so.9.0: cannot ...\n",
       "13675    [A = [{'boxes': tensor([[ 142.1232,  142.9373,...\n",
       "13677    [nn.Softmax(), nn.CrossEntropyLoss, nn.CrossEn...\n",
       "13678    [import torch\\r\\ny = torch.rand(100, 1)\\r\\nbat...\n",
       "13679    [import torch\\r\\ny = torch.rand(100, 1)\\r\\nbat...\n",
       "13680    [class Net(nn.Module):\\r\\n\\r\\n  def __init__(s...\n",
       "13681    [n_masks, image_height, image_width, image_hei...\n",
       "13682    [def channel_var(image_dataset):\\r\\n    res = ...\n",
       "13683    [Train Epoch:1[655200/655800(100%)] loss:26.49...\n",
       "13684    [mean_nums = [0.485, 0.456, 0.406]\\r\\nstd_nums...\n",
       "13685    [mean_nums = [0.485, 0.456, 0.406]\\r\\nstd_nums...\n",
       "13686    [import torch\\r\\nfrom torch.utils import data\\...\n",
       "13687    [Main_folder\\r\\n - Good\\r\\n - Bad \\r\\n, Main_f...\n",
       "13688    [Main_folder\\r\\n - Good\\r\\n - Bad \\r\\n, Main_f...\n",
       "13689    [Main_folder\\r\\n - Good\\r\\n - Bad \\r\\n, Main_f...\n",
       "13690    [b (batch size), d (depth), h (hight) and w (w...\n",
       "13691    [nn.Linear(in_features=self.cfg.lstm.lstm_num_...\n",
       "13692    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13693    [for m in model.parameters():\\r\\n    print(m.d...\n",
       "13694    [for m in model.parameters():\\r\\n    print(m.d...\n",
       "13695    [nn.TransformerEncoder(), nn.LSTM(), nn.Transf...\n",
       "13696    [spacy-pytorch-transformer, embed(complex), 1/...\n",
       "13697    [python file.py, Traceback (most recent call l...\n",
       "13698    [spacy 2.1.8, spacy-pytorch-transformers 0.4.0...\n",
       "13699    [batch_size=1, precompute_to_masks, def precom...\n",
       "13700    [self.encoder = nn.Sequential(\\r\\n    nn.Conv2...\n",
       "13701    [self.encoder = nn.Sequential(\\r\\n    nn.Conv2...\n",
       "13703    [torch.nn.CrossEntropyLoss(), multi-target not...\n",
       "13704    [state = torch.load(f, flair.device)\\r\\n, mode...\n",
       "13706    [torch.autograd.grad, a = torch.rand(2, requir...\n",
       "13707    [torch.autograd.grad, a = torch.rand(2, requir...\n",
       "13708    [class CNN_MNIST(nn.Module):\\r\\ndef __init__(s...\n",
       "13709    [x = torch.tensor([[3, 4, 2], [0, 1, 5]])\\r\\n,...\n",
       "13710    [self.encoder = nn.Sequential(\\r\\n    nn.Conv2...\n",
       "13711    [# custom class neural network \\r\\nclass Fashi...\n",
       "13713    [numpy, Pytorch, class Noise(object):\\r\\n  def...\n",
       "13714    [#10x50 + 5*100\\r\\noriginalTensor = torch.rand...\n",
       "13715    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "13716    [learning rates = [2e-5, 3e-5, 4e-5, 5e-5], de...\n",
       "13717    [shape=(1,2), shape=(1,2), dim=1, stack(),  im...\n",
       "13718    [10000x10000, float, F = (I - Q)^-1 * R\\r\\n, t...\n",
       "13719    [networkx, ['A', 'B', 'C', 'D', 'E', 'F', 'G',...\n",
       "13720    [A, B = getAB(X_train)\\r\\nX_train = transform(...\n",
       "13721    [TruncatedSVD, scikit-learn,  class ImgEmb(nn....\n",
       "13722    [TruncatedSVD, scikit-learn,  class ImgEmb(nn....\n",
       "13723    [a = np.array([[1.0, 1.1],[2.1,2.0]])\\r\\nnp.ar...\n",
       "13724    [a = np.array([[1.0, 1.1],[2.1,2.0]])\\r\\nnp.ar...\n",
       "13725    [import torch\\r\\ntorch.cuda.FloatTensor([1.])\\...\n",
       "13726    [from skimage.util.shape import view_as_blocks...\n",
       "13727    [correct = 0\\r\\ntotal = 0\\r\\nincorrect_classif...\n",
       "13728    [z = tensor([[1., 1., 1., 1.],\\r\\n            ...\n",
       "13729    [z = tensor([[1., 1., 1., 1.],\\r\\n            ...\n",
       "13730    [class MLP(nn.Module):\\r\\n    def __init__(sel...\n",
       "13731    [from pytorch_transformers import BertTokenize...\n",
       "13732    [from pytorch_transformers import BertTokenize...\n",
       "13733    [from pytorch_transformers import BertTokenize...\n",
       "13734    [1 2\\r\\n3 4\\r\\n5 6\\r\\n7 8\\r\\n, 0 0 0 0\\r\\n0 1 ...\n",
       "13735    [1 2\\r\\n3 4\\r\\n5 6\\r\\n7 8\\r\\n, 0 0 0 0\\r\\n0 1 ...\n",
       "13736    [idx, [0, 1, 0, 2, 3, 1], data, [[0,  1,  2],\\...\n",
       "13738    [wget http://developer.download.nvidia.com/com...\n",
       "13739    [output (type) = torch.Size([4]) tensor([0.448...\n",
       "13740    [output (type) = torch.Size([4]) tensor([0.448...\n",
       "13742    [torch.multiprocessing.Pool, import torch.mult...\n",
       "13743    [foo, setuptools, from torch.utils.cpp_extensi...\n",
       "13744    [ (5, 10)\\r\\n(10, 10)\\r\\n(32, 10)\\r\\n(2, 10)\\r...\n",
       "13745    [for epoch in range(n_epochs):\\r\\n    for i, (...\n",
       "13746    [0, 1, or 2, [0.3,0.4,0.3], loss = criterion(o...\n",
       "13747    [S, BxD, D, KL, BxB, KL[i,j] = KL-DIVERGENCE(S...\n",
       "13748    [def my_collate(batch):\\r\\ndata = [item[0] for...\n",
       "13749    [C:\\Users\\User&gt;pip install pytorch, Collect...\n",
       "13750    [C:\\Users\\User&gt;pip install pytorch, Collect...\n",
       "13751    [params = {'batch_size': 32, 'shuffle': True, ...\n",
       "13752    [torch.cuda.is_available(), false, import torc...\n",
       "13753    [#turn ndarray of features and labels into ten...\n",
       "13755    [epochs = 5\\r\\nmax_grad_norm = 1.0\\r\\n\\r\\nfor ...\n",
       "13756    [matrix &lt;- matrix(rep(1:3,each=5),nrow=3,nc...\n",
       "13757    [[[ 2.25, 2345123.23],\\r\\n [ 1.13, 234565.11],...\n",
       "13758    [        if self.actor.calibrating:\\r\\n       ...\n",
       "13760    [N,C,H,W = input.size()\\r\\nCout=4*C\\r\\nHout=H/...\n",
       "13761    [class DatasetProcessing(Dataset):\\r\\n\\r\\n    ...\n",
       "13762    [requires_grad = False, discriminator.requires...\n",
       "13763    [requires_grad = False, discriminator.requires...\n",
       "13764    [pd.DataFrame, import torch\\r\\nimport pandas a...\n",
       "13765    [pd.DataFrame, import torch\\r\\nimport pandas a...\n",
       "13767    [class SSMDataset(Dataset):\\r\\n    songs_list ...\n",
       "13768    [x = torch.tensor(3)\\r\\nlist = torch.tensor([1...\n",
       "13769    [[2019-09-14 02:57:15,574 INFO]  * src vocab s...\n",
       "13770    [[2019-09-14 02:57:15,574 INFO]  * src vocab s...\n",
       "13771    [errD = errD_real + errD_fake, errD_real = cri...\n",
       "13772    [errD = errD_real + errD_fake, errD_real = cri...\n",
       "13773    [tgt, [12, 32, 1], sequence_length, batch_size...\n",
       "13774    [ self.decoder[0].weight = self.encoder[0].wei...\n",
       "13775    [ self.decoder[0].weight = self.encoder[0].wei...\n",
       "13776    [tensor([-0.1635, -0.1510, -0.1455,  ..., -0.3...\n",
       "13777    [import torch\\r\\nfrom torchvision import datas...\n",
       "13778    [import torch\\r\\nfrom torchvision import datas...\n",
       "13781    [def __init__(self,embedding_dim,hidden_size,b...\n",
       "13782    [class YourSampler(torch.utils.data.sampler.Sa...\n",
       "13783    [class YourSampler(torch.utils.data.sampler.Sa...\n",
       "13784    [class YourSampler(torch.utils.data.sampler.Sa...\n",
       "13785    [class YourSampler(torch.utils.data.sampler.Sa...\n",
       "13786    [ImportError: cannot import name 'parameter_pa...\n",
       "13787    [net=CRAFT(), net.eval(), def copyStateDict(st...\n",
       "13788    [ls some-directory/\\r\\n      added_tokens.json...\n",
       "13789    [ls some-directory/\\r\\n      added_tokens.json...\n",
       "13790    [ls some-directory/\\r\\n      added_tokens.json...\n",
       "13791    [ls some-directory/\\r\\n      added_tokens.json...\n",
       "13792    [A, [M, N], B, [M, K, N], B[:, k, :], A, K, to...\n",
       "13794    [A, [M, N], B, [M, K, N], B[:, k, :], A, K, to...\n",
       "13796    [A, [M, N], B, [M, K, N], B[:, k, :], A, K, to...\n",
       "13797    [n, k, (q, k), q, (128:256, k), (32, q, k), Te...\n",
       "13798    [n, k, (q, k), q, (128:256, k), (32, q, k), Te...\n",
       "13799    [#Load pre-trained model (weights)\\r\\nmodel = ...\n",
       "13800    [cycle() and zip(),   File \"/home/Desktop/exam...\n",
       "13801    [\\r\\nclass PzConv2d(nn.Module):\\r\\n    \"\"\" Con...\n",
       "13802    [# create int8\\r\\nfeatures = torch.zeros(*dims...\n",
       "13803    [# create int8\\r\\nfeatures = torch.zeros(*dims...\n",
       "13804    [gamma, beta, def bn_drop_lin(n_in:int, n_out:...\n",
       "13805    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13806    [#================Function that defines the CN...\n",
       "13812    [    if use_cuda:\\r\\n            [[[model = nn...\n",
       "13813    [python3 setup.py bdist_wheel, CMake Error at ...\n",
       "13814    [python3 setup.py bdist_wheel, CMake Error at ...\n",
       "13815    [prob, np.random.choice, import numpy as np\\r\\...\n",
       "13819    [model, model, model.cuda(), model, CUDA out o...\n",
       "13820    [def __init__(self, mean, std, inplace=False):...\n",
       "13821    [requires_grad, b, c, True, requires_grad, d, ...\n",
       "13822    [(pred[:, 2:4] &gt; min_wh).all(1), ().all(1),...\n",
       "13823    [criterion = nn.CrossEntropyLoss()\\r\\n, torch....\n",
       "13824    [optimizer = torch.optim.Adam(model.parameters...\n",
       "13825    [def loss_func(y_pred, batch):\\r\\n    y_true =...\n",
       "13826    [model = Network()\\r\\n, Network(\\r\\n  (hidden)...\n",
       "13827    [model = Network()\\r\\n, Network(\\r\\n  (hidden)...\n",
       "13828    [UnsatisfiableError: The following specificati...\n",
       "13829    [UnsatisfiableError: The following specificati...\n",
       "13830    [UnsatisfiableError: The following specificati...\n",
       "13831    [M, [BxLxD], idx, [B,1], (0, L-1), N, [BxD], N...\n",
       "13832    [def predict(model, image_path, topk=5):\\r\\n''...\n",
       "13833    [def predict(model, image_path, topk=5):\\r\\n''...\n",
       "13834    [DataLoader, Imagefolder, class bsds_dataset(D...\n",
       "13836    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "13837    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13838    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13839    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13840    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13841    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13842    [class DataSet():\\r\\n     def __init__(self, e...\n",
       "13843    [python setup.py install\\r\\n, libavutil/motion...\n",
       "13844    [python setup.py install\\r\\n, libavutil/motion...\n",
       "13845    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13846    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13847    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13848    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13849    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13850    [PyTorch, 1.2.0,     raise AssertionError(\"Tor...\n",
       "13851    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13852    [# Create LSTM Model\\r\\nclass LSTMModel(nn.Mod...\n",
       "13853    [class DenseNet121(nn.Module):\\r\\n    \"\"\"Model...\n",
       "13854    [class DenseNet121(nn.Module):\\r\\n    \"\"\"Model...\n",
       "13855    [torch.optim, from ignite.engine import Events...\n",
       "13856    [torch.optim, from ignite.engine import Events...\n",
       "13857    [class VGG16(nn.Module):\\r\\n    def __init__(s...\n",
       "13859    [import torch\\r\\npytorchGPUDirectCreateWEmpty ...\n",
       "13861    [\\r\\nimport torch\\r\\n\\r\\na = torch.Tensor(2,2,...\n",
       "13862    [def elastic_transform(image, alpha=1000, sigm...\n",
       "13864    [class ConvNet(nn.Module):\\r\\n  def __init__(s...\n",
       "13865                 [keras.preprocessing.text.Tokenizer]\n",
       "13867    [hook(), register_forward_pre_hook, def get_fe...\n",
       "13869    [class ImageTransformationNetwork(nn.Module):\\...\n",
       "13870    [A_vec = np.random.normal(mu, sigma, (1, n_d))...\n",
       "13871    [A[0, 1] = 1\\r\\nA[1, 2] = 1\\r\\nA[2, 0] = 1\\r\\n...\n",
       "13872    [A[0, 1] = 1\\r\\nA[1, 2] = 1\\r\\nA[2, 0] = 1\\r\\n...\n",
       "13873    [print(‘Epoch [{}/{}], Step [{}/{}], Loss: {:....\n",
       "13874    [self.classifier, def __init__(self, config, n...\n",
       "13876    [Keras, Pytorch, from keras.layers import Inpu...\n",
       "13878    [pytorch_total_params = sum(p.numel() for p in...\n",
       "13879    [dim1 = 2\\r\\ndim2 = 3\\r\\ndim3 = 4\\r\\nsource = ...\n",
       "13880    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13881    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "13882    [model.parameters(), 1.  Conv layer: weight  b...\n",
       "13883    [\"\"\"Defines the neural network, losss function...\n",
       "13884    [import torch, ModuleNotFoundError: No module ...\n",
       "13885    [import torch, ModuleNotFoundError: No module ...\n",
       "13886    [import torch, ModuleNotFoundError: No module ...\n",
       "13887    [import torch, ModuleNotFoundError: No module ...\n",
       "13888    [import torch, ModuleNotFoundError: No module ...\n",
       "13889    [import torch, ModuleNotFoundError: No module ...\n",
       "13891    [torch.utils.data.DataLoader, DataLoader, tf.d...\n",
       "13892    [torch.utils.data.DataLoader, DataLoader, tf.d...\n",
       "13893    [x = torch.randn(2, 3)\\r\\nx.shape # (2, 3)\\r\\n...\n",
       "13895    [x,  x = torch.tensor([3])\\r\\n print(x)\\r\\nten...\n",
       "13898    [import torch\\r\\nimport torch.nn.functional as...\n",
       "13899    [Traceback (most recent call last):\\r\\n  File ...\n",
       "13900    [Traceback (most recent call last):\\r\\n  File ...\n",
       "13901    [predicted, target, torch.Size([6890, 3]) torc...\n",
       "13902    [predicted, target, torch.Size([6890, 3]) torc...\n",
       "13903    [predicted, target, torch.Size([6890, 3]) torc...\n",
       "13905    [import argparse\\r\\nfrom average_meter import ...\n",
       "13906    [ValueError: Traceback (most recent call last)...\n",
       "13907    [for i, j, k in zip(X, Y, Z):\\r\\n    A[:, i, j...\n",
       "13908    [data_transforms = transforms.Compose([transfo...\n",
       "13909    [def predict(image_path, model, topk=5):\\r\\n  ...\n",
       "13910    [    transform_test = transforms.Compose([\\r\\n...\n",
       "13911    [from pytorch2keras.converter import pytorch_t...\n",
       "13912    [[ 1/10] train_loss: 1.56952 valid_loss: 1.545...\n",
       "13913    [nn.Module, import torch\\r\\nimport torch.nn as...\n",
       "13914    [nn.Module, import torch\\r\\nimport torch.nn as...\n",
       "13916    [  class BasicBlock(nn.module):\\r\\n  ...\\r\\n\\r...\n",
       "13917    [ValueError: Expected input batch_size (288) t...\n",
       "13918    [        for height in range(len(img_as_np_arr...\n",
       "13919    [%reset -s -f\\r\\n\\r\\nimport numpy as np\\r\\nimp...\n",
       "13920    [%reset -s -f\\r\\n\\r\\nimport numpy as np\\r\\nimp...\n",
       "13921    [import math\\r\\n\\r\\nimport stream\\r\\nfrom src ...\n",
       "13922    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13923    [pytorch, libtorch.so, libgomp-753e6e92.so.1, ...\n",
       "13924    [pytorch, libtorch.so, libgomp-753e6e92.so.1, ...\n",
       "13925    [import torch\\r\\nfrom torch.utils.tensorboard ...\n",
       "13928    [requires_grad, True, False, z = torch.rand([2...\n",
       "13929    [def consine_distance_byrow(f1, f2):\\r\\n    fe...\n",
       "13930    [a = torch.Tensor([[1, 2, 3], [1, 2, 3]])\\r\\nb...\n",
       "13931    [shuffle=True, shuffle=False, __getitem__(), c...\n",
       "13932    [class ModelOne(nn.Module):\\r\\n  def __init__(...\n",
       "13933    [def augment_data(batch_size):\\r\\n\\r\\n\\r\\n    ...\n",
       "13934    [def seed_everything(seed=42):\\r\\n    random.s...\n",
       "13936    [train_path = 'data/train/'\\r\\ntest_path = 'da...\n",
       "13937    [device = torch.device(\"cuda:0\") #0 device is ...\n",
       "13938    [class LoadingDataset(Dataset):\\r\\n  def __ini...\n",
       "13939    [99x1x7, 99x1x2, model = nn.RNN(input_size=7, ...\n",
       "13940    [sm=Var(torch.randn(20,1),requires_grad=True)\\...\n",
       "13941    [for i:\\r\\n   if check(rate[i]):\\r\\n      rate...\n",
       "13942    [class FocalLoss(nn.Module):\\r\\n    def __init...\n",
       "13943    [Event statistics for runs/tf_druggability/cla...\n",
       "13944    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "13945    [   sys:1: RuntimeWarning: Traceback of forwar...\n",
       "13946    [   sys:1: RuntimeWarning: Traceback of forwar...\n",
       "13947    [!kaggle competitions download -c dogs-vs-cats...\n",
       "13948    [l = [torch.randn(2,3), torch.randn(2,4),torch...\n",
       "13949    [PyTorch, out_probs, out_probs=F.softmax(out_d...\n",
       "13951    [tensor([[[[-0.8467]],\\r\\n\\r\\n         [[-0.09...\n",
       "13952    [Traceback (most recent call last):\\r\\n  File ...\n",
       "13953    [transforms.CenterCrop(size) or transforms.Ran...\n",
       "13955    [class Network(nn.Module):\\r\\n    def __init__...\n",
       "13956    [total_set = datasets.ImageFolder(PATH)\\r\\nKF_...\n",
       "13957    [sent                      class\\r\\n'the fox i...\n",
       "13958    [sent                      class\\r\\n'the fox i...\n",
       "13959    [ def forward(self, x, y=None, criterion=None,...\n",
       "13960    [torch.nn.DataParallel(), model = SNModel()\\r\\...\n",
       "13961    [features, labels, torch.from _numpy(features....\n",
       "13964    [X, [0.1, 0.5, -1.0, 0, 1.2, 0], filter_positi...\n",
       "13965    [X, [0.1, 0.5, -1.0, 0, 1.2, 0], filter_positi...\n",
       "13967    [from hausdorff import hausdorff\\r\\n,     from...\n",
       "13968    [tensor.item(), tensor.cpu().data.numpy(), opt...\n",
       "13969    [myField = Field(tokenize= x_tokenize, use_voc...\n",
       "13970    [pip install nibabel\\r\\n, ImportError: No modu...\n",
       "13973    [a = torch.tensor([0, 1, 2, 3, 4])\\r\\na[-2:] =...\n",
       "13974    [u @ v, detach(), import torch\\r\\nfrom torch i...\n",
       "13975    [import torch\\r\\n\\r\\nfrom pytorch_transformers...\n",
       "13976    [batch x sentence length x embedding dim, a = ...\n",
       "13977    [.to(torch.device('cuda')),     #...\\r\\n    de...\n",
       "13979    [x = torch.randn(1, 1, 0)\\r\\n\\r\\ny = torch.ran...\n",
       "13980    [epochs = 100\\r\\nfor epoch in range(epochs):\\r...\n",
       "13981    [epochs = 100\\r\\nfor epoch in range(epochs):\\r...\n",
       "13982    [def double_conv(in_channels, out_channels):\\r...\n",
       "13983    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "13984    [total_set = datasets.ImageFolder(ROOT, transf...\n",
       "13986    [Running loss :  59102027776.0\\r\\n  0%|       ...\n",
       "13987    [state_dict(destination=None, prefix='', keep_...\n",
       "13988    [RuntimeError: size mismatch, m1: [7 x 2092500...\n",
       "13989    [mean_pix, std_pix, import torch\\r\\nfrom torch...\n",
       "13990    [print(\"CUDA available: \", torch.cuda.is_avail...\n",
       "13991    [def crop_and_concat(self, upsampled, bypass, ...\n",
       "13992    [predict, bert.py, nltk.word_tokenize(), def m...\n",
       "13993    [__constants__, class Linear(Module):, __const...\n",
       "13995    [class data_from_xlsx(Dataset):\\r\\n    def __i...\n",
       "13996    [class data_from_xlsx(Dataset):\\r\\n    def __i...\n",
       "13997    [keras, Cropping3D, torchvision.transforms.Cen...\n",
       "13998    [a=Var(torch.randn(20,1),requires_grad=True), ...\n",
       "13999    [pytorch, class Net(torch.nn.Module):\\r\\n    d...\n",
       "14000    [# Based on Robert Guthrie tutorial\\r\\n\\r\\nimp...\n",
       "14001                               [tf.dynamic_partition]\n",
       "14002    [def __init__(self, data_root, transform=None,...\n",
       "14003    [batch_size = 5\\r\\nepochs = 10\\r\\nsize = 15\\r\\...\n",
       "14004    [/home/ivory/anaconda3/lib/python3.7/site-pack...\n",
       "14006    [def test_epoch(net,test_loader):\\r\\n y_test =...\n",
       "14007    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14008    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14009    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14010    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14011    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14012    [pip3 install torch==1.2.0 torchvision==0.4.0 ...\n",
       "14013    [ import gc\\r\\n import GPUtil\\r\\n import torch...\n",
       "14014    [ import gc\\r\\n import GPUtil\\r\\n import torch...\n",
       "14015    [ import gc\\r\\n import GPUtil\\r\\n import torch...\n",
       "14016    [git clone https://github.com/pytorch/pytorch....\n",
       "14017    [jupyter notebook, import torch\\r\\nfrom torch ...\n",
       "14018    [# define the model class for a neural net wit...\n",
       "14019    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "14020    [import torch\\r\\n​\\r\\n​\\r\\ndef conv3d_example(...\n",
       "14021    [conda install -c conda-forge openmpi, mpiexec...\n",
       "14023    [en_pytt_bertbaseuncased_lg, nlp = spacy.load(...\n",
       "14024    [transformations, PyTorch, data_transforms = t...\n",
       "14026    [for, torch.stack(), for, \\r\\nclass TurnMLP(nn...\n",
       "14027    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14028    [# Initial Transition matrix as shown in page ...\n",
       "14029    [   import torch\\r\\n   from torch.models impor...\n",
       "14030    [class BaseModelV0p2(nn.Module):\\r\\n\\r\\n    de...\n",
       "14031    [class BaseModelV0p2(nn.Module):\\r\\n\\r\\n    de...\n",
       "14032    [class BaseModelV0p2(nn.Module):\\r\\n\\r\\n    de...\n",
       "14033    [# This works well\\r\\n img, _ = dataset_test[3...\n",
       "14034    [pytorch, lossfunc = nn.NLLLoss(ignore_index=0...\n",
       "14035    [pytorch, lossfunc = nn.NLLLoss(ignore_index=0...\n",
       "14036    [ $source activate pytorch\\r\\n\\r\\n $python run...\n",
       "14037    [enter code here:\\r\\nEPOCH = 20\\r\\nBATCH_SIZE ...\n",
       "14038    [\\r\\nclass DataLoader(data.DataLoader):\\r\\n   ...\n",
       "14040    [    from torch.utils.tensorboard import Summa...\n",
       "14041    [def get_lr(optimizer):\\r\\n    for param_group...\n",
       "14042    [import torch.nn.functional as F\\r\\nimport tor...\n",
       "14043    [import cv2\\r\\nimport torch\\r\\nimport os\\r\\nos...\n",
       "14044    [start_epoch=0\\r\\nfor epoch in range(num_epoch...\n",
       "14045    [tmp = torch.tensor([[1,2,3,2,4],[0,5,6,7,2],[...\n",
       "14046                                 [Linear, LogSoftMax]\n",
       "14047    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14048    [import torch\\r\\nimport models\\r\\nfrom collect...\n",
       "14049    [nn.ConvTranspose2d, H, W, [[0,0],[0,0],[0,1],...\n",
       "14051    [torch.nn.functional.nll_loss(outputs.mean(0),...\n",
       "14052    [class Recurrent_block(nn.Module):\\r\\n    def ...\n",
       "14053    [torch.save, torchvision, model = torchvision....\n",
       "14054    [torch.save, torchvision, model = torchvision....\n",
       "14055    [opt.swap_swa_sgd(), # it means, in my idea\\r\\...\n",
       "14056    [opt.swap_swa_sgd(), # it means, in my idea\\r\\...\n",
       "14057    [\\r\\ndef predict(model, device, inputs, batch_...\n",
       "14059    [model_ft = models.resnet18(pretrained=True)\\r...\n",
       "14060    [    def Append_files():\\r\\n\\r\\n        train_...\n",
       "14061    [x_trains=[]\\r\\ny_trains=[]\\r\\n\\r\\nnum_tasks=2...\n",
       "14062    [{0:\"&lt;s&gt;,1:\"&lt;e&gt;\",2:\"AAA\",3:\"BBB\",....\n",
       "14063    [use_cuda = torch.cuda.is_available()\\r\\n\\r\\nB...\n",
       "14064    [epoch = 22\\r\\nsteps = 0\\r\\nprint_every_step =...\n",
       "14066    [dataloader = torch.utils.data.DataLoader(data...\n",
       "14068    [psfm_s, psfm_s=Var(torch.randn(12,20),require...\n",
       "14069    [import torch\\r\\nv = torch.rand(6)\\r\\n, tensor...\n",
       "14070    [C:\\Users\\Toothless&gt;pip install torchvision...\n",
       "14071    [C:\\Users\\Toothless&gt;pip install torchvision...\n",
       "14072    [C:\\Users\\Toothless&gt;pip install torchvision...\n",
       "14073    [C:\\Users\\Toothless&gt;pip install torchvision...\n",
       "14074    [losses, grads = [], []\\r\\nfor i in range(X_po...\n",
       "14075    [class Net(torch.nn.Module):\\r\\ndef __init__(s...\n",
       "14076    [x, x, y = (x, 2x, x^2), dy/dx = (1,2,x), impo...\n",
       "14077    [text = \"[CLS] Who was Jim Henson ? [SEP] Jim ...\n",
       "14078    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14079    [from __future__ import print_function\\r\\nimpo...\n",
       "14080    [    \\r\\nclass Classifier(nn.Module):\\r\\n    d...\n",
       "14081    [    self.encoder = nn.Sequential (\\r\\n       ...\n",
       "14083    [(Pdb) self.W_di\\r\\nLinear(in_features=68, out...\n",
       "14084    [class Decoder(nn.Module):\\r\\n    def __init__...\n",
       "14085    [sum, y=torch.sum(x**2), sum, y, .backward(), ...\n",
       "14086    [sum, y=torch.sum(x**2), sum, y, .backward(), ...\n",
       "14087    [forward, nn.Sequential, class MyModule(nn.Mod...\n",
       "14088    [class KaggleAmazonDataset(Dataset):\\r\\n    \"\"...\n",
       "14089    [Pool(), import os\\r\\nfrom multiprocessing imp...\n",
       "14090    [a = torch.tensor([1,2,0,1,2]), b, a, \\r\\nb = ...\n",
       "14091    [a = torch.tensor([1,2,0,1,2]), b, a, \\r\\nb = ...\n",
       "14092    [--framework='SCIKIT_LEARN', {\\r\\n  \"error\": \"...\n",
       "14093    [class Model(torch.nn.Module):\\r\\n    def __in...\n",
       "14094    [model = keras.applications.densenet.DenseNet1...\n",
       "14095    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "14096    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "14097    [class Network(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "14098    [class Network(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "14099    [def get_cnn(C, out_filters=[14,13,12,3], kern...\n",
       "14100    [def __getitem__(self, idx):\\r\\n\\r\\n        qu...\n",
       "14101    [parameter(), Python 3.7.3\\r\\nattrs== 19.1.0\\r...\n",
       "14102    [parameter(), Python 3.7.3\\r\\nattrs== 19.1.0\\r...\n",
       "14108    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14109    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14110    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14111    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14112    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14113    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14114    [fast-ai, fast-ai, load_learner, state = pickl...\n",
       "14115    [torch.nn.BCELoss(), RuntimeError: the derivat...\n",
       "14116    [torch.nn.BCELoss(), RuntimeError: the derivat...\n",
       "14117    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14118    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14119    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14120    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14121    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14122    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14123    [!git clone https://github.com/NVIDIA/apex\\r\\n...\n",
       "14124    [from torch.nn import functional as f\\r\\nimpor...\n",
       "14125    [optim.zero_grad()\\r\\nloss(m, op).backward()\\r...\n",
       "14126    [optim.zero_grad()\\r\\nloss(m, op).backward()\\r...\n",
       "14127    [CoreferenceResolver, import torch\\r\\nfrom all...\n",
       "14128    [temp = tensor(16,6,36,36)\\r\\n, temp[:,:3,:,:]...\n",
       "14129    [temp = tensor(16,6,36,36)\\r\\n, temp[:,:3,:,:]...\n",
       "14130    [While copying the parameter named \"conv1_7x7_...\n",
       "14131    [warmup_linear, ImportError: cannot import nam...\n",
       "14132    [warmup_linear, ImportError: cannot import nam...\n",
       "14133    [----&gt; 9 image = data.numpy()[0].transpose(...\n",
       "14134    [def _model(self):\\r\\n    model = Sequential()...\n",
       "14135    [class AutoEncoder(torch.nn.Module):\\r\\n    de...\n",
       "14136    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "14137    [loss.backward(), criterion = nn.NLLLoss()\\r\\n...\n",
       "14138    [torch.save(learned_model, \"model_path\")\\r\\n, ...\n",
       "14142    [RuntimeError                              Tra...\n",
       "14143    [RuntimeError                              Tra...\n",
       "14144    [RuntimeError                              Tra...\n",
       "14145    [ x = torch.tensor([1, 2, 3, 4])\\r\\n torch.uns...\n",
       "14146    [ x = torch.tensor([1, 2, 3, 4])\\r\\n torch.uns...\n",
       "14147    [ x = torch.tensor([1, 2, 3, 4])\\r\\n torch.uns...\n",
       "14148    [ x = torch.tensor([1, 2, 3, 4])\\r\\n torch.uns...\n",
       "14149    [model = CRNN().to(device)\\r\\nmodel = model.ty...\n",
       "14151    [.flatten(), .view(-1), .flatten(), .view(-1),...\n",
       "14152    [.flatten(), .view(-1), .flatten(), .view(-1),...\n",
       "14153    [torchvision, torch, conda install pytorch tor...\n",
       "14154    [torchvision, torch, conda install pytorch tor...\n",
       "14155    [torchvision, torch, conda install pytorch tor...\n",
       "14156    [train_dataset = dsets.MNIST(root='./data', \\r...\n",
       "14157    [import torch.nn.functional as F\\r\\nloss = F.n...\n",
       "14158    [## mdl5, from cifar10 tutorial\\r\\nmdl5 = nn.S...\n",
       "14159    [\\r\\ndevice = torch.device(\"cuda\" if torch.cud...\n",
       "14160    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14161    [l1, l2, opt1, opt2, x, x, opt1, opt2, x, grad...\n",
       "14162    [\\r\\n# TRAINING DATA\\r\\n\\r\\ntrain_dataset = da...\n",
       "14163    [BCEWithLogitsLoss, 310000 x 3, class CustomDa...\n",
       "14166    [lo = torch.Tensor(([1., 1., 0.],\\r\\n         ...\n",
       "14167    [lo = torch.Tensor(([1., 1., 0.],\\r\\n         ...\n",
       "14168    [a = torch.tensor([1,2])\\r\\nb = torch.tensor([...\n",
       "14169    [a = torch.tensor([1,2])\\r\\nb = torch.tensor([...\n",
       "14170    [a = torch.tensor([1,2])\\r\\nb = torch.tensor([...\n",
       "14171    [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "14172    [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "14173    [Platform : ubuntu 16.04\\r\\nPython version: 3....\n",
       "14174    [import onmt\\r\\nimport onmt.inputters\\r\\nimpor...\n",
       "14175    [ A = torch.tensor([[1,2,3],[4,5,6]])\\r\\n indi...\n",
       "14177    [channel_1_range = [8, 16, 32, 64]\\r\\nchannel_...\n",
       "14178    [Parameter, x = torch.nn.Parameter(torch.Tenso...\n",
       "14181    [model20 = FourLayerConvNetWithPool()\\r\\nmodel...\n",
       "14182    [torch.nn.Sequential, requires_grad = False, c...\n",
       "14183    [X, model1, model2, Variable,     y1 = model1(...\n",
       "14184    [X, model1, model2, Variable,     y1 = model1(...\n",
       "14185    [torch.nn.conv2d(), (Batch_size, n_channels, i...\n",
       "14186    [n_pts = 500\\r\\nX, y = datasets.make_circles(n...\n",
       "14187    [n_pts = 500\\r\\nX, y = datasets.make_circles(n...\n",
       "14188    [x = torch.FloatTensor([\\r\\n                  ...\n",
       "14189    [x = torch.FloatTensor([\\r\\n                  ...\n",
       "14190    [x = torch.FloatTensor([\\r\\n                  ...\n",
       "14191    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "14192    [drive_path = 'drive/My Drive/Colab Notebooks/...\n",
       "14193    [drive_path = 'drive/My Drive/Colab Notebooks/...\n",
       "14194    [class RNNModel1(nn.Module):\\r\\n\\r\\n    def fo...\n",
       "14195    [X, Y, (H,W,12), H = []\\r\\nfor i in range(12):...\n",
       "14196    [False, def batch_loss(encoder, decoder, X, Y,...\n",
       "14197    [nn.Linear, nn.Linear, X = torch.randn((20,20,...\n",
       "14198                                       [unfold, fold]\n",
       "14199                                       [unfold, fold]\n",
       "14200                                       [unfold, fold]\n",
       "14201    [pip install torch==0.4.1 -f https://download....\n",
       "14202    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "14203    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "14204    [ from flair.data import Sentence\\r\\n from fla...\n",
       "14205    [PyTorch, test.py, PyInstaller, UPX, from torc...\n",
       "14206    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "14207    [FROM ubuntu:16.04\\r\\n\\r\\nRUN apt-get update &...\n",
       "14210    [DCGAN, GAN, BatchNorm, Discriminator, Generat...\n",
       "14211    [import torch\\r\\n\\r\\ndef padding_batched_embed...\n",
       "14212    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "14213    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14214    [import glob\\r\\nfrom tqdm import tqdm\\r\\nimpor...\n",
       "14215    [tensor([[[0.7185, 0.2953, 0.6841, 0.1045]],\\r...\n",
       "14216    [GoogleNews-vectors-negative300.bin, Vector, b...\n",
       "14218    [ a = torch.rand(3,5)\\r\\n a\\r\\ntensor([[0.3356...\n",
       "14219    [IOError: Traceback (most recent call last):\\r...\n",
       "14220    [class XLM_BiLSTM_CRF(nn.Module):\\r\\n    def _...\n",
       "14221    [(14,3), (13,3), (12,3), (11,3), (10,3), (9,3)...\n",
       "14222    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "14223    [number_of_inputs = 4\\r\\nhidden_layer = 64\\r\\n...\n",
       "14224    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "14225    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14226    [torch.__version__\\r\\ntorch.load('featurs.pkl'...\n",
       "14227    [torch.__version__\\r\\ntorch.load('featurs.pkl'...\n",
       "14228    [TypeError: img should be PIL Image. Got &lt;c...\n",
       "14229    [TypeError: img should be PIL Image. Got &lt;c...\n",
       "14231    [\\r\\n    class GRU(nn.Module):\\r\\n        def ...\n",
       "14232    [        class RNN(nn.Module):\\r\\n\\r\\n        ...\n",
       "14233    [import os, keras\\r\\nfrom keras.datasets impor...\n",
       "14234    [tf.gather, [minibatch, 60, 2], [minibatch, 8]...\n",
       "14235    [from fastai.conv_learner import *\\r\\nfrom fas...\n",
       "14236    [I-frame model, time python test.py --arch res...\n",
       "14237    [I-frame model, time python test.py --arch res...\n",
       "14238    [zero = torch.from_numpy(np.zeros(len(cos)))\\r...\n",
       "14239    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14240    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14241    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14242    [predicted = torch.tensor([4, 4, 4, 1, 1, 1, 1...\n",
       "14243    [jsonpickle, jsonpickle.decode(my_json_string)...\n",
       "14244    [PicklingError: Can’t pickle &lt;function pad3...\n",
       "14245    [a, b, class MyNetwork(nn.Module):\\r\\n    def ...\n",
       "14246    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "14247    [TypeError: object of type 'type' has no len()...\n",
       "14248    [trainer_ = Trainer(network = network,\\r\\n    ...\n",
       "14249    [trainer_ = Trainer(network = network,\\r\\n    ...\n",
       "14250    [def forward(self, x, y=None):\\r\\n    x = self...\n",
       "14251    [def forward(self, x, y=None):\\r\\n    x = self...\n",
       "14252    [import os\\r\\nfrom datetime import datetime\\r\\...\n",
       "14253    [\\r\\nclass Net(torch.nn.Module):\\r\\n    def __...\n",
       "14254    [270, BCEWithLogitsLoss(), pos_weight, pos_wei...\n",
       "14255    [270, BCEWithLogitsLoss(), pos_weight, pos_wei...\n",
       "14256    [270, BCEWithLogitsLoss(), pos_weight, pos_wei...\n",
       "14257    [270, BCEWithLogitsLoss(), pos_weight, pos_wei...\n",
       "14258    [ ~/miniconda3/bin/python3 trainval_net.py --d...\n",
       "14259    [class Model(nn.Module):\\r\\ndef __init__(self,...\n",
       "14260    [self.layer1.weight = torch.nn.Parameter(torch...\n",
       "14261    [model_outputs, target_outputs, numerator = to...\n",
       "14262    [np.random.randn, torch.randn, x, y, np.random...\n",
       "14263    [m, n, d = 10000, 1000, 2\\r\\nx = torch.Tensor(...\n",
       "14264    [\\r\\nclass ToTensor(object):\\r\\n    \"\"\"Convert...\n",
       "14265    [def weighted_mse_loss(input_tensor, target_te...\n",
       "14266    [import argparse\\r\\nimport os\\r\\nimport sys\\r\\...\n",
       "14267    [import torch\\r\\nimport os\\r\\nimport torch.nn ...\n",
       "14268    [import pretrainedmodels \\r\\n\\r\\ndef resnext50...\n",
       "14269    [final_in_features = googlenet.fc.in_features\\...\n",
       "14270    [final_in_features = googlenet.fc.in_features\\...\n",
       "14271    [final_in_features = googlenet.fc.in_features\\...\n",
       "14272    [from syft.frameworks.torch.differential_priva...\n",
       "14273    [/usr/local/lib/python3.6/dist-packages/torch/...\n",
       "14274    [# First example, integer selector ==&gt; Ok\\r...\n",
       "14275    [# First example, integer selector ==&gt; Ok\\r...\n",
       "14276    [data = pd.read_csv(\"../myFile.csv\")\\r\\ninput ...\n",
       "14277    [data = pd.read_csv(\"../myFile.csv\")\\r\\ninput ...\n",
       "14278    [# a is a big tensor of size (128, 64, 1, 1)\\r...\n",
       "14279    [class DQN(nn.Module):\\r\\n    def __init__(sel...\n",
       "14280    [backbone = torchvision.models.detection.backb...\n",
       "14281    [import torch\\r\\nfrom torchvision import datas...\n",
       "14282    [def gaussian_blur(img):\\r\\n    image = cv2.Ga...\n",
       "14283    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14284    [B x C x W x H, B x M, M = C*W*H, B, B, C,W,H,...\n",
       "14285    [B x C x W x H, B x M, M = C*W*H, B, B, C,W,H,...\n",
       "14286    [def activation(x):\\r\\nreturn (1/(1+torch.exp(...\n",
       "14287    [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "14288    [[5,1,100,100], batch_size x dims x ht x wd, [...\n",
       "14289    [whereis python3, pip3 freeze, numpy, 1.15.4, ...\n",
       "14290    [whereis python3, pip3 freeze, numpy, 1.15.4, ...\n",
       "14291                [tf.contrib.distributions.percentile]\n",
       "14293                [tf.contrib.distributions.percentile]\n",
       "14294    [Bucketiterator, torchtext, pytorch, train_ite...\n",
       "14295    [builtins.ValueError\\r\\n\\r\\nValueError: badly ...\n",
       "14296    [nn.Sequential, nn.Sequential, use_sequential,...\n",
       "14298    [ File \"/Users/MYK/anaconda3/lib/python3.6/sub...\n",
       "14299    [import gym\\r\\nimport time\\r\\nimport torch\\r\\n...\n",
       "14300    [from numpy import array\\r\\nfrom numpy import ...\n",
       "14301    [c++ API, int myints[] = {10, 20, 30, 40, 50, ...\n",
       "14302    [c++ API, int myints[] = {10, 20, 30, 40, 50, ...\n",
       "14303    [Converting to Torch Script via Tracing\\r\\nTo ...\n",
       "14304    [Converting to Torch Script via Tracing\\r\\nTo ...\n",
       "14305    [create your optimizer\\r\\noptimizer = optim.SG...\n",
       "14306    [X=[[1,2],[3,4],[5,6]], Y=[[1,1],[2,2]], [[3, ...\n",
       "14308    [X=[[1,2],[3,4],[5,6]], Y=[[1,1],[2,2]], [[3, ...\n",
       "14309    [torch.equal(x_valid[0], x_valid[:1]), False, ...\n",
       "14310    [DATA_SIZE = 1000\\r\\n\\r\\nsimulated_daily_deman...\n",
       "14312    [y = Variable(torch.tensor((0, 0, 0, 1, 1,1), ...\n",
       "14313    [def Conv2D(name, input_dim, output_dim, filte...\n",
       "14314    [ERROR: Could not find a version that satisfie...\n",
       "14315    [ERROR: Could not find a version that satisfie...\n",
       "14316    [ERROR: Could not find a version that satisfie...\n",
       "14317    [ERROR: Could not find a version that satisfie...\n",
       "14318                    [torch.sparse.mm(), torch.spmm()]\n",
       "14319    [predict, unsqueeze_(0), \\r\\n    # Imports her...\n",
       "14321    [nn.Module, class Model(nn.Module):\\r\\n    def...\n",
       "14322    [nn.Module, class Model(nn.Module):\\r\\n    def...\n",
       "14323    [eb.use_eb(False,True)\\r\\nimportlib.reload(tor...\n",
       "14324    [sklearn.metrics.classification_report\\r\\n,  f...\n",
       "14325    [###Defining class\\r\\nclass continuousImgDatas...\n",
       "14327    [idx,     class_name = [item for item in loade...\n",
       "14328    [\\r\\nToTensor = torchvision.transforms.ToTenso...\n",
       "14329    [(4), import torch\\r\\n\\r\\nW = torch.nn.Paramet...\n",
       "14330    [torch, pip install torch\\r\\n, from tools.nnwr...\n",
       "14335    [torch, pip install torch\\r\\n, from tools.nnwr...\n",
       "14343    [in_seq1 = array([10, 20, 30, 40, 50, 60, 70, ...\n",
       "14344    [in_seq1 = array([10, 20, 30, 40, 50, 60, 70, ...\n",
       "14345    [in_seq1 = array([10, 20, 30, 40, 50, 60, 70, ...\n",
       "14346    [def select_next(X, gains, current_values, mas...\n",
       "14347    [tensor(58)\\r\\ntensor([57.3895])\\r\\n, torch.Si...\n",
       "14349    [tensor(58)\\r\\ntensor([57.3895])\\r\\n, torch.Si...\n",
       "14350                            [model.cuda(), nn.Module]\n",
       "14352    [def main(server_ip,server_port,local_rank,no_...\n",
       "14354    [class pytorchLSTM(nn.Module):\\r\\n    def __in...\n",
       "14355    [class pytorchLSTM(nn.Module):\\r\\n    def __in...\n",
       "14356    [class Architect () :\\r\\n    def __init__(self...\n",
       "14357    [def forward(self, x):\\r\\n    #neural network ...\n",
       "14358    [# !/usr/bin/python\\r\\n\\r\\n\\r\\nimport os\\r\\nim...\n",
       "14359    [MTL, import torch\\r\\nimport torch.nn as nn\\r\\...\n",
       "14360    [MTL, import torch\\r\\nimport torch.nn as nn\\r\\...\n",
       "14361    [A, [N1, N2, N3/2, 2, N4, N5], B, [N1, N2, N3/...\n",
       "14362    [from collections import OrderedDict\\r\\n\\r\\nim...\n",
       "14363    [def false_pos_neg_rate(outputs, truths):\\r\\n ...\n",
       "14364    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14365    [trainset = torch.utils.data.DataLoader(\\r\\n  ...\n",
       "14366    [trainset = torch.utils.data.DataLoader(\\r\\n  ...\n",
       "14367    [trainset = torch.utils.data.DataLoader(\\r\\n  ...\n",
       "14368    [class Dim(IntEnum):\\r\\n    batch = 0\\r\\n    s...\n",
       "14369    [[1996/2139] Building CXX object caffe2\\torc.....\n",
       "14370    [import random\\r\\nimport numpy as np\\r\\nnp.ran...\n",
       "14371    [import random\\r\\nimport numpy as np\\r\\nnp.ran...\n",
       "14372    [backward, with torch.no_grad(), with torch.no...\n",
       "14373    [backward, with torch.no_grad(), with torch.no...\n",
       "14374    [backward, with torch.no_grad(), with torch.no...\n",
       "14375    [(  5,7,3) and (  5,7,3) -&gt; (  5,7,3), (5,3...\n",
       "14376    [# Define the model\\r\\nmodel = torch.nn.Sequen...\n",
       "14377    [class net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "14378    [class net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "14379    [[batch_size, channel, depth, height, width], ...\n",
       "14380    [from torch.utils.ffi import create_extension\\...\n",
       "14381    [import torch\\r\\nimport datetime\\r\\n\\r\\ntorch....\n",
       "14382    [import torch\\r\\nimport datetime\\r\\n\\r\\ntorch....\n",
       "14383    [Building wheel torch-1.2.0a0+f13fadd\\r\\n-- Bu...\n",
       "14384    [Building wheel torch-1.2.0a0+f13fadd\\r\\n-- Bu...\n",
       "14385    [x = Variable(2*torch.ones(2, 2), requires_gra...\n",
       "14387    [import torch.onnx\\r\\ncheckpoint = torch.load(...\n",
       "14388    [train_data = ImageDataset(train_file_list, tr...\n",
       "14389    [ REF = data.Field(lower=True, tokenize=tokeni...\n",
       "14390    [Using standard convolution..........\\r\\nTotal...\n",
       "14391    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "14392    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "14393    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "14394    [def train(n_epochs, loaders, model, optimizer...\n",
       "14395    [def train(n_epochs, loaders, model, optimizer...\n",
       "14396    [ train = torchvision.datasets.ImageFolder(roo...\n",
       "14397    [ train = torchvision.datasets.ImageFolder(roo...\n",
       "14398    [ train = torchvision.datasets.ImageFolder(roo...\n",
       "14399    [vgg.forward = forward\\r\\n, def forward(self,x...\n",
       "14400    [model_ft = models.resnet18(pretrained=True)\\r...\n",
       "14401    [model = FCN()\\r\\nstate_dict = torch.load('/co...\n",
       "14403    [torch.save({'iteration': iter,\\r\\n           ...\n",
       "14405    [X     --&gt; torch.Size([10, 1, 572, 572])\\r\\...\n",
       "14406    [ x = torch.tensor([1.0, np.NaN])\\r\\n y = torc...\n",
       "14407    [ x = torch.tensor([1.0, np.NaN])\\r\\n y = torc...\n",
       "14408    [tensor.item(), class_correct[target] += c[i]....\n",
       "14409    [!wget -c https://repo.continuum.io/archive/An...\n",
       "14412    [learning_rate = 0.005\\r\\n\\r\\ncriterion = nn.N...\n",
       "14413    [def style_noise(self, y, style):\\r\\n    n = t...\n",
       "14414    [def style_noise(self, y, style):\\r\\n    n = t...\n",
       "14416    [max_pool = nn.MaxPool2d(3, stride=2)\\r\\nmax_p...\n",
       "14417    [max_pool = nn.MaxPool2d(3, stride=2)\\r\\nmax_p...\n",
       "14418    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "14419    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "14420    [GPU = False                                  ...\n",
       "14421    [GPU = False                                  ...\n",
       "14422    [for i in t:\\r\\n    model.zero_grad()\\r\\n\\r\\n ...\n",
       "14423    [self.weight +=  self.learning_rate * hidden_l...\n",
       "14424    [TypeError: pic should be PIL Image or ndarray...\n",
       "14425    [TypeError: pic should be PIL Image or ndarray...\n",
       "14426    [TypeError: pic should be PIL Image or ndarray...\n",
       "14427    [TypeError: pic should be PIL Image or ndarray...\n",
       "14428    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14429    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14430    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14431    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14432    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14433    [y_pred = model(X_trainTensor), # Hyper-parame...\n",
       "14434    [ # The model is a simple fully connected netw...\n",
       "14435    [torch.Size([8, 512, 16, 16]), torch.Size([8, ...\n",
       "14436    [torch.nn.ReLU(), # ...\\r\\nself.fc1 = nn.Linea...\n",
       "14437    [torch.nn.ReLU(), # ...\\r\\nself.fc1 = nn.Linea...\n",
       "14438    [def __init__(self, vocab, hidden_size, latent...\n",
       "14439        [y = x1 + x1*x2 + x1*x3\\r\\n, 1 + x2 + x3\\r\\n]\n",
       "14440        [y = x1 + x1*x2 + x1*x3\\r\\n, 1 + x2 + x3\\r\\n]\n",
       "14441    [        for ft in self.categorical_fts:\\r\\n  ...\n",
       "14442    [    type    posts\\r\\n0   INFJ    'http://www....\n",
       "14443    [img = img.crop([10, 10, 118, 118])\\r\\nimg = i...\n",
       "14444    [img = img.crop([10, 10, 118, 118])\\r\\nimg = i...\n",
       "14445    [img = img.crop([10, 10, 118, 118])\\r\\nimg = i...\n",
       "14446    [#kwargs is empty because I don't use cuda\\r\\n...\n",
       "14447    [\"built-in method numpy of Tensor object at 0x...\n",
       "14449    [tf.data.experimental.CsvDataset, def parse_da...\n",
       "14450    [import numpy as np\\r\\n\\r\\nsignal_length=36000...\n",
       "14451    [import torch\\r\\nimport torchvision.models as ...\n",
       "14452    [out = x.sign()*torch.pow(x.abs(), alpha)\\r\\n,...\n",
       "14453    [tokenizer = BertTokenizer.from_pretrained('be...\n",
       "14454    [criterion = nn.CrossEntropyLoss()\\r\\noptimize...\n",
       "14455    [def draw(n, distr):\\r\\n    return np.concaten...\n",
       "14456    [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "14457    [import torchvision\\r\\nfrom torchvision import...\n",
       "14458    [import torchvision\\r\\nfrom torchvision import...\n",
       "14459    [tensor[:,:2], x = torch.tensor([[-1.4673,  0....\n",
       "14460    [tensor[:,:2], x = torch.tensor([[-1.4673,  0....\n",
       "14461    [\"Type\",\"Class\",\"Path\"\\r\\n\"train\",\"A\",\"./path1...\n",
       "14462    [Py_Initialize();\\r\\nPyRun_SimpleString(\"impor...\n",
       "14463    [dropout = get_fixed_dropout()\\r\\nfor sequence...\n",
       "14464    [Class MyNet(nn.Module):\\r\\n    def __init__(s...\n",
       "14465    [Class MyNet(nn.Module):\\r\\n    def __init__(s...\n",
       "14466    [h_n, output, (Pdb) rnn_output\\r\\ntensor([[[ 0...\n",
       "14467    [h_n, output, (Pdb) rnn_output\\r\\ntensor([[[ 0...\n",
       "14468    [ self.conv1 = nn.Conv2d(3,10,kernel_size = 5,...\n",
       "14469    [log(1 + exp(x)), x, inf,  x = torch.tensor([0...\n",
       "14470    [def custom_cross(my_pred,true,batch_size=BATC...\n",
       "14471    [Fashion-MNIST, Conv2d, Maxpool, Linear, in_fe...\n",
       "14472    [Fashion-MNIST, Conv2d, Maxpool, Linear, in_fe...\n",
       "14473    [layout = torch.strided, torch.rand(*sizes, ou...\n",
       "14474    [layout = torch.strided, torch.rand(*sizes, ou...\n",
       "14475    [layout = torch.strided, torch.rand(*sizes, ou...\n",
       "14477    [torchaudio, \"conda install -c derickl torchau...\n",
       "14478    [torch.nn.Module, __init__, forward, forward, ...\n",
       "14479    [class GPRegressionModel(gpytorch.models.Exact...\n",
       "14480    [\\r\\ntorch.gather(input, dim, index, out=None,...\n",
       "14483    [seq_len = 5\\r\\nbatch_size= 3\\r\\ncols_num = 10...\n",
       "14484    [imports ***\\r\\n\\r\\ntrainloader = torch.utils....\n",
       "14485    [imports ***\\r\\n\\r\\ntrainloader = torch.utils....\n",
       "14486    [    import fastai\\r\\n    print(fastai.__versi...\n",
       "14487    [for epoch in range(n_epochs):\\r\\n    model.tr...\n",
       "14490    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14491    [NameError: name 'nn' is not defined\\r\\n, nn, ...\n",
       "14492    [\\r\\nclass Agent():\\r\\n    \"\"\"Interacts with a...\n",
       "14493    [val_acc,  from __future__ import print_functi...\n",
       "14494    [[4, 4], [2,2], P = [ 1 1 2 2\\r\\n      1 1 2 2...\n",
       "14495    [[4, 4], [2,2], P = [ 1 1 2 2\\r\\n      1 1 2 2...\n",
       "14496    [[4, 4], [2,2], P = [ 1 1 2 2\\r\\n      1 1 2 2...\n",
       "14497    [[4, 4], [2,2], P = [ 1 1 2 2\\r\\n      1 1 2 2...\n",
       "14498    [[4, 4], [2,2], P = [ 1 1 2 2\\r\\n      1 1 2 2...\n",
       "14499    [[4,4], [2,2], [9, 9, 9, 9,\\r\\n 8, 8, 8, 8,\\r\\...\n",
       "14500    [[4,4], [2,2], [9, 9, 9, 9,\\r\\n 8, 8, 8, 8,\\r\\...\n",
       "14501    [class Network(nn.Module):\\r\\ndef __init__(sel...\n",
       "14502    [pip install torch==0.2.0_4 -f https://downloa...\n",
       "14503    [pip install torch==0.2.0_4 -f https://downloa...\n",
       "14504    [output = model(SOC[13])\\r\\n\\r\\n# Three output...\n",
       "14505    [output = model(SOC[13])\\r\\n\\r\\n# Three output...\n",
       "14506    [output = model(SOC[13])\\r\\n\\r\\n# Three output...\n",
       "14507    [output = model(SOC[13])\\r\\n\\r\\n# Three output...\n",
       "14508    [data\\r\\n  cat\\r\\n    0101.jpg\\r\\n    0201.jpg...\n",
       "14509    [data\\r\\n  cat\\r\\n    0101.jpg\\r\\n    0201.jpg...\n",
       "14510    [class FlatDirectoryAudioDataset(tdata.Dataset...\n",
       "14511    [class FlatDirectoryAudioDataset(tdata.Dataset...\n",
       "14512    [def extractpatches( x, patch_size): # x is bs...\n",
       "14514    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "14515    [A\\r\\nB\\r\\n, A, [batch, Width, Height, 3]\\r\\n,...\n",
       "14516    [ import numpy as np\\r\\n a = np.arange(2*3).re...\n",
       "14517    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "14518    [def train():  \\r\\n    #training steps …  \\r\\n...\n",
       "14519    [def train():  \\r\\n    #training steps …  \\r\\n...\n",
       "14520    [        for i in range(self.dim):\\r\\n        ...\n",
       "14521    [    transform = transforms.Compose([\\r\\n\\r\\n ...\n",
       "14522    [pil2tensor(), @app.route('/analyze', methods=...\n",
       "14523    [nn.fucntional.one_hot, n = 24\\r\\none_hot = to...\n",
       "14524    [nn.fucntional.one_hot, n = 24\\r\\none_hot = to...\n",
       "14525    [nn.fucntional.one_hot, n = 24\\r\\none_hot = to...\n",
       "14526    [ImageFolder, torchvision, ImageFolder, def lo...\n",
       "14527    [A   B\\r\\nC   D\\r\\n, A  A  B  B\\r\\nA  A  B  B\\...\n",
       "14528    [A   B\\r\\nC   D\\r\\n, A  A  B  B\\r\\nA  A  B  B\\...\n",
       "14529    [torch.int64, torch.LongTensor, loss = loss_fn...\n",
       "14530    [    def backward(ctx, input):\\r\\n\\r\\n        ...\n",
       "14531    [features_train, features_test, targets_train,...\n",
       "14533    [NE_Conv2d, __getattr__, __getattr__, __getatt...\n",
       "14534    [(1,3, 375, 1242), (1, 3, 384, 1248), target =...\n",
       "14535    [File \"./main.py\", line 317, in &lt;module&gt;...\n",
       "14536    [net.fit(dataset)\\r\\n, start = time.time()\\r\\n...\n",
       "14537    [torch.matmul, adj.size()==[1,3000,3000], s.si...\n",
       "14538    [import torch\\r\\nimport torchvision.models as ...\n",
       "14539    [def nms(bboxes,scores,threshold=0.5):\\r\\n    ...\n",
       "14540    [def nms(bboxes,scores,threshold=0.5):\\r\\n    ...\n",
       "14541    [def nms(bboxes,scores,threshold=0.5):\\r\\n    ...\n",
       "14542    [# Setup\\r\\ndef func(X):\\r\\n    return torch.s...\n",
       "14543    [# Setup\\r\\ndef func(X):\\r\\n    return torch.s...\n",
       "14544    [# Setup\\r\\ndef func(X):\\r\\n    return torch.s...\n",
       "14548    [conda install pytorch torchvision cudatoolkit...\n",
       "14549    [conda install pytorch torchvision cudatoolkit...\n",
       "14550    [model = PyTorchModel(model_data=trained_model...\n",
       "14554    [z = [1, 3, None, 5, 6], torch.tensor(z), torc...\n",
       "14556    [model = torchvision.models.detection.fasterrc...\n",
       "14557    [lengths = [len(cap) for cap in captions]\\r\\n ...\n",
       "14558    [# Class containing the LSTM model initializat...\n",
       "14559    [# (3, 640, 640)\\r\\n[convolutional]\\r\\nbatch_n...\n",
       "14560    [TypeError                                 Tra...\n",
       "14561    [git clone [pytorch git] --recursive\\r\\n, pyth...\n",
       "14562    [model.input_size.weight\\r\\n, input_size = 784...\n",
       "14563    [model.input_size.weight\\r\\n, input_size = 784...\n",
       "14564    [model.input_size.weight\\r\\n, input_size = 784...\n",
       "14565    [model.input_size.weight\\r\\n, input_size = 784...\n",
       "14566    [model.input_size.weight\\r\\n, input_size = 784...\n",
       "14567    [x = torch.ones(n,3) \\r\\nx[:,0].uniform_(-1.,1...\n",
       "14568    [import torch\\r\\n\\r\\nU = torch.zeros([10, 1, 4...\n",
       "14569    [import torch\\r\\n\\r\\nU = torch.zeros([10, 1, 4...\n",
       "14570    [import torch\\r\\n\\r\\nU = torch.zeros([10, 1, 4...\n",
       "14571    [git clone https://github.com/Cysu/open-reid.g...\n",
       "14572    [git clone https://github.com/Cysu/open-reid.g...\n",
       "14573    [def train(model, features, target, epochs=100...\n",
       "14574    [def yolo_layer(inputs, n_classes, anchors, im...\n",
       "14575    [input_x = torch.Tensor([[0.0,0.0], [0.1,0.1],...\n",
       "14577    [import torch\\r\\nimport pickle\\r\\n\\r\\nclass Vo...\n",
       "14578    [import torch\\r\\nimport pickle\\r\\n\\r\\nclass Vo...\n",
       "14579    [class LSTMClassifier(nn.Module):\\r\\n    # LST...\n",
       "14580    [class LSTMClassifier(nn.Module):\\r\\n    # LST...\n",
       "14582    [import torch\\r\\nimport torch.nn.utils.rnn as ...\n",
       "14583    [a = torch.Tensor([[1,2],[3,4]]), a = np.array...\n",
       "14584    [a = torch.Tensor([[1,2],[3,4]]), a = np.array...\n",
       "14585    [conv1d, import numpy as np\\r\\nimport torch\\r\\...\n",
       "14586    [conv1d, import numpy as np\\r\\nimport torch\\r\\...\n",
       "14587    [#This is a dataloader that I have and did nor...\n",
       "14588    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "14589    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "14590    [  File \"/home/shared/virtualenv/dl-torch/lib/...\n",
       "14591    [  File \"/home/shared/virtualenv/dl-torch/lib/...\n",
       "14592    [# 4 - Constructing the undercomplete architec...\n",
       "14593    [class QNet_dropout(nn.Module):\\r\\n\\r\\n    \"\"\"...\n",
       "14597    [def cost(xt, x_goal, u, Q, R):\\r\\n        ret...\n",
       "14598    [learning_rate = 0.01\\r\\nfor f in net.paramete...\n",
       "14599    [ Expected object of scalar type Long but got ...\n",
       "14600    [ Expected object of scalar type Long but got ...\n",
       "14601    [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "14602    [print(features*weights)\\r\\nprint('-----------...\n",
       "14603    [print(features*weights)\\r\\nprint('-----------...\n",
       "14604    [paths = paths[::skip_frame]\\r\\n\\r\\nValueError...\n",
       "14606    [x = torch.arange(0,30,0.05)\\r\\ny = [torch.sin...\n",
       "14607    [torchtext.data.BucketIterator, # All 4 exampl...\n",
       "14608    [class Temp1(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "14609    [x, h_j = w_j^T * x + b_j, max_j{h_j}, w_j, w_...\n",
       "14610    [bias, torch.add, bias = torch.randn(batch_siz...\n",
       "14611    [from lightfm.datasets import fetch_movielens\\...\n",
       "14612    [from lightfm.datasets import fetch_movielens\\...\n",
       "14613    [from lightfm.datasets import fetch_movielens\\...\n",
       "14614    [class AlexNet(nn.Module):\\r\\n    def __init__...\n",
       "14615    [[B,C,H,W], [B,masked_C,H,W], import torch\\r\\n...\n",
       "14617    [model.training = False\\r\\n, for param in mode...\n",
       "14618    [\\r\\nimport torch\\r\\nfrom torchvision import d...\n",
       "14619    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "14620    [free(): invalid pointer\\r\\nAborted (core dump...\n",
       "14621    [observation.to(device)\\r\\n, observation, .to(...\n",
       "14622    [MatA\\r\\nMatB\\r\\n, (256, 512, 3), prod = np.mu...\n",
       "14623    [MatA\\r\\nMatB\\r\\n, (256, 512, 3), prod = np.mu...\n",
       "14624    [RuntimeError: Attempting to deserialize objec...\n",
       "14625    [-np.inf, -np.inf, q = torch.Tensor([np.random...\n",
       "14626    [-np.inf, -np.inf, q = torch.Tensor([np.random...\n",
       "14627    [-np.inf, -np.inf, q = torch.Tensor([np.random...\n",
       "14628    [import torch \\r\\ndevice = torch.device(\"cuda\"...\n",
       "14629    [x_train, y_train, x_valid, y_valid = map(\\r\\n...\n",
       "14630    [import torchvision\\r\\ninput(\"Press key\")\\r\\n,...\n",
       "14631    [import torchvision\\r\\ninput(\"Press key\")\\r\\n,...\n",
       "14632    [import torchvision\\r\\ninput(\"Press key\")\\r\\n,...\n",
       "14633    [numpy.object_, numpy.float, tensor, print(typ...\n",
       "14634    [liba.a, libb.a, libc.a, ..., libz.a, liba.a, ...\n",
       "14635    [import torch\\r\\nimport torchvision.utils as v...\n",
       "14636    [class cust_vgg():\\r\\n    def forward(self, im...\n",
       "14637    [nn.Sequential, net = nn.Sequential()\\r\\nnet.a...\n",
       "14639    [Pytorch, csr_matrix, RuntimeError: [enforce f...\n",
       "14640    [Resnet18, CrossEntropyLoss(), CrossEntropyLos...\n",
       "14643    [in, a x b, a = 9, A1, A2, C2, b, lengths, sum...\n",
       "14644    [in, a x b, a = 9, A1, A2, C2, b, lengths, sum...\n",
       "14645    [AttributeError: 'Field' object has no attribu...\n",
       "14646    [device = torch.device('cuda' if torch.cuda.is...\n",
       "14647    [PyTorch, BucketIterator, torchtext, BPTTItera...\n",
       "14648    [class MusicDataSet(Dataset):\\r\\ndef __init__(...\n",
       "14649    [import torch\\r\\nts = torch.tensor\\r\\nt = ts([...\n",
       "14650    [compiled_model = torch.jit.trace(model,  torc...\n",
       "14651    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14652    [for x, y in dataloaders:\\r\\n    # Do somethin...\n",
       "14653    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "14654    [torch.tensor, cv2.dilate, tensor, tensor, num...\n",
       "14655    [torch.tensor, cv2.dilate, tensor, tensor, num...\n",
       "14657    ['train': transforms.Compose([\\r\\n    transfor...\n",
       "14658    [import torch\\r\\nimport tensorflow as tf\\r\\nim...\n",
       "14659    [vgg_feature = models.vgg13(pretrained=True).f...\n",
       "14660    [from google.colab import files\\r\\nuploaded = ...\n",
       "14661    [C = torch.cat((A,B),1)\\r\\n, A is (1, 128, 128...\n",
       "14663    [Y_train_class = torch.tensor(Y_train_class.va...\n",
       "14664    [Y_train_class = torch.tensor(Y_train_class.va...\n",
       "14665    [            CashIn  CashOut\\r\\nDate        \\r...\n",
       "14666    [  input_ids = input_ids.to(device)\\r\\n  input...\n",
       "14667    [nn.GRU, generate, torch.manual_seed(0)\\r\\ntor...\n",
       "14670    [A = [0,1,2,3,0,0,1,1,2,2,3,3], B = [0,4,5,1,6...\n",
       "14672    [NN_energy = net(Data_in)[0:10,0]\\r\\n, import ...\n",
       "14673    [def load_tocotron_2_model():\\r\\n    model = T...\n",
       "14674    [def kl_loss_compute(logits1, logits2):\\r\\n   ...\n",
       "14675    [import numpy as np\\r\\nfrom scipy.special impo...\n",
       "14676    [pt_tensor_from_list = torch.tensor(pose_trans...\n",
       "14677    [x = np.arange(27).reshape(3,3,3)\\r\\nnp.rot90(...\n",
       "14678    [a = torch.tensor([[1, 2, 3], [1, 2, 3]])\\r\\nb...\n",
       "14679    [RuntimeError: CUDA error: invalid argument, t...\n",
       "14680    [samples = torch.Tensor([\\r\\n    [0.1, 0.1],  ...\n",
       "14681    [samples = torch.Tensor([\\r\\n    [0.1, 0.1],  ...\n",
       "14682    [samples = torch.Tensor([\\r\\n    [0.1, 0.1],  ...\n",
       "14683    [samples = torch.Tensor([\\r\\n    [0.1, 0.1],  ...\n",
       "14684    [--do_predict, /examples/run_classifier.py, --...\n",
       "14685    [torch.save(model.state_dict(), file_name), 0....\n",
       "14686    [torch.save(model.state_dict(), file_name), 0....\n",
       "14687    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "14688    [x1 = torch.randn(3,16)\\r\\nx2 = torch.randn(5,...\n",
       "14689    [from fasterai.visualize import *, -----------...\n",
       "14690    [to(device), Traceback (most recent call last)...\n",
       "14691    [A = 40x1, B = 40x100x384, C = 40x10, D=40x10,...\n",
       "14692    [Parameters: 317052\\r\\n\\r\\nEpoch   Loss(Tr)   ...\n",
       "14693    [Sentence = 'this is a example sentence'\\r\\n, ...\n",
       "14694    [-warnings.warn(\"train_labels has been renamed...\n",
       "14695    [batch_size=5, class_num=6, label =[\\r\\n[1,2,3...\n",
       "14696    [batch_size=5, class_num=6, label =[\\r\\n[1,2,3...\n",
       "14697    [RuntimeError: CUDA error: initialization erro...\n",
       "14698    [    if steps % print_every == 0:\\r\\n        t...\n",
       "14699    [A = [[0,1,2],[2,3,4]], B = [0,1], C = [[5,6,7...\n",
       "14700    [l1 = nn.Tanh(n_in, n_out)\\r\\n, l2 = nn.Linear...\n",
       "14701    [net.load_state_dict(torch.load(path)['model_s...\n",
       "14702    [F:\\test&gt;test D:\\testData.xml D:\\testResult...\n",
       "14703    [model = ResNet(len(CLASSES), pretrained=args....\n",
       "14704    [model = ResNet(len(CLASSES), pretrained=args....\n",
       "14705    [optimizer = optim.Adam(model.parameters(), lr...\n",
       "14706    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14707    [y, x = torch.randn(3, requires_grad=True)\\r\\n...\n",
       "14708    [y, x = torch.randn(3, requires_grad=True)\\r\\n...\n",
       "14710    [import torch\\r\\n\\r\\nfrom PIL import Image\\r\\n...\n",
       "14711    [ print(foo.grad_fn)\\r\\n&lt;AddBackward0 objec...\n",
       "14712    [use_cuda = True\\r\\nif use_cuda and torch.cuda...\n",
       "14713    [class LyricLSTM(nn.Module):\\r\\n    def __init...\n",
       "14714    [|                 | BGD         | BGD with DL...\n",
       "14715    [column = [['Adventure','Animation','Comedy'],...\n",
       "14716    [/opt/conda/bin/uwsgi --ini  /usr/src/web/uwsg...\n",
       "14717    [# model class\\r\\nclass CBOW(nn.Module):\\r\\n\\r...\n",
       "14718                [torch.dist(vector1, vector2, 1)\\r\\n]\n",
       "14720                [torch.dist(vector1, vector2, 1)\\r\\n]\n",
       "14721    [state(input), forward_dqn(), forward_actor(),...\n",
       "14722    [import torch\\r\\ntmp = torch.tensor([[0, 0, 1,...\n",
       "14723    [import torch\\r\\ntmp = torch.tensor([[0, 0, 1,...\n",
       "14724    [import torch\\r\\ntmp = torch.tensor([[0, 0, 1,...\n",
       "14725    [  File \"/home/user/anaconda3/lib/python3.7/ru...\n",
       "14726    [  File \"/home/user/anaconda3/lib/python3.7/ru...\n",
       "14727    [X_train_lmse, (1691, 1, 1), X(t), X(t-1), lst...\n",
       "14728    [# option 1\\r\\nx2 = self.layer1(x1)\\r\\nx3 = se...\n",
       "14729    [tensor([0.2153, 0.2190, 0.0685, 0.2127, 0.214...\n",
       "14730    [a, (2,3,2), b, (2,2), a = [[[1,2],\\r\\n      [...\n",
       "14731    [a, (2,3,2), b, (2,2), a = [[[1,2],\\r\\n      [...\n",
       "14732    [a, (2,3,2), b, (2,2), a = [[[1,2],\\r\\n      [...\n",
       "14733    [a = tf.Variable([1,2,3,4,5], dtype=tf.float32...\n",
       "14734    [a = tf.Variable([1,2,3,4,5], dtype=tf.float32...\n",
       "14735    [def forward(self, example):\\r\\n\\r\\n        ar...\n",
       "14736    [def run(rank_local, rank, world_size, maingp)...\n",
       "14737    [model = CNN(NUM_LAYERS)\\r\\nmodel.to(DEVICE)\\r...\n",
       "14738    [#load pretrained model\\r\\ncheckpoint = torch....\n",
       "14739    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "14740    [torch.save(Model.state_dict(),PATH)\\r\\n, devi...\n",
       "14741    [([[[ 0,  1,  2],\\r\\n [ 3,  4,  5]],\\r\\n\\r\\n[[...\n",
       "14742    [([[[ 0,  1,  2],\\r\\n [ 3,  4,  5]],\\r\\n\\r\\n[[...\n",
       "14743    [def load_net(i):\\r\\n    if not os.path.exists...\n",
       "14744    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "14746    [class BasicCNN(nn.Module):\\r\\n    def __init_...\n",
       "14747    [import cv2\\r\\nfrom fastai.vision import *\\r\\n...\n",
       "14748    [(51, 128, 20100), autoencode_logprob, (51, 20...\n",
       "14749    [RuntimeError: Given groups=1, weight of size ...\n",
       "14750    [x : np.int32 = ...\\r\\ny : np.float64 = ...\\r\\...\n",
       "14751    [ #X and Y are input and target labels respect...\n",
       "14752    [self.layers = nn.ModuleList([\\r\\n        LSTM...\n",
       "14753    [nn.Module, self.embedding = nn.Embedding(para...\n",
       "14754    [nn.Module, self.embedding = nn.Embedding(para...\n",
       "14755    [nn.Module, self.embedding = nn.Embedding(para...\n",
       "14756    [DataSet, transform, import torchvision\\r\\nimp...\n",
       "14757    [class Network(torch.nn.Module):\\r\\n\\r\\n    de...\n",
       "14758    [torchvision.models, import torch\\r\\nfrom torc...\n",
       "14759    [model = torch.load('/home/ofsdms/san_mrc/chec...\n",
       "14762    [filt, im, import pytorch\\r\\n\\r\\nfilt = torch....\n",
       "14763    [filt, im, import pytorch\\r\\n\\r\\nfilt = torch....\n",
       "14764    [[64, 64, 127, 127], [64, 3, 127, 127], [64, 6...\n",
       "14765    [(1224, 15, 23), (15, 23), (batch, channel, x,...\n",
       "14766    [dataset[index], torch.utils.data.distributed....\n",
       "14767    [V1 = torch.tensor([[2, 4], [6, 4], [5, 3]])\\r...\n",
       "14768    [V1 = torch.tensor([[2, 4], [6, 4], [5, 3]])\\r...\n",
       "14769    [def get_confused(model_ft):\\r\\n    nb_classes...\n",
       "14770    [def get_confused(model_ft):\\r\\n    nb_classes...\n",
       "14771    [numpy array, cuda(), forward(), numpy array, ...\n",
       "14772    [import torch\\r\\n\\r\\na = torch.FloatTensor(4,3...\n",
       "14773    [import torch\\r\\n\\r\\na = torch.FloatTensor(4,3...\n",
       "14774    [.npy, model = CNN_Model(batch_size)\\r\\nfilena...\n",
       "14775    [writer.add_scalar(\"loss\", loss.item(), global...\n",
       "14776    [writer.add_scalar(\"loss\", loss.item(), global...\n",
       "14777    [x=sample\\r\\n#Normalized Data\\r\\nnormalized = ...\n",
       "14778    [x=sample\\r\\n#Normalized Data\\r\\nnormalized = ...\n",
       "14779    [x =  torch.Tensor([[1, 2, 3], [1, 2, 3]]).vie...\n",
       "14780    [normA = A.mul(A).sum(dim=1).sum(dim=1).sqrt()...\n",
       "14781    [outputs = model(t_image)\\r\\n\\r\\nfig, (ax1, ax...\n",
       "14783    [import torch\\r\\nfrom torch_baidu_ctc import c...\n",
       "14784    [def gl_norm(model, gl_lambda, num_blk):\\r\\n  ...\n",
       "14785    [Parameter, Tensor, Parameter, parameters(), m...\n",
       "14786    [print(\"Original shape \", x.shape)\\r\\n\\r\\nx = ...\n",
       "14787    [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "14788    [.csv, float32, 1e6 * 512 * 32/4 / 1e9 = 4.1GB...\n",
       "14789    [input = torch.randn((3, 1), requires_grad=Tru...\n",
       "14790    [def train(train_loader, model, optimizer, cri...\n",
       "14791    [# Initiliaze model  \\r\\nclass neural_net_mode...\n",
       "14792    [tensor(10267.6279, device='cuda:0')\\r\\n(0.427...\n",
       "14794    [Wordnet, import spacy\\r\\nimport nltk\\r\\nfrom ...\n",
       "14795    [Wordnet, import spacy\\r\\nimport nltk\\r\\nfrom ...\n",
       "14796    [import torch\\r\\nfrom torch import Tensor\\r\\nf...\n",
       "14797    [THCState *state, state, tensor.cat, void THCT...\n",
       "14799                 [6, 8, (0, 0, 0, 0, 0, 1, 1, 0)\\r\\n]\n",
       "14800                 [6, 8, (0, 0, 0, 0, 0, 1, 1, 0)\\r\\n]\n",
       "14801                 [6, 8, (0, 0, 0, 0, 0, 1, 1, 0)\\r\\n]\n",
       "14802    [output = output.permute(0, 2, 3, 1)\\r\\ntarget...\n",
       "14803    [nll_loss, RuntimeError: _thnn_nll_loss_forwar...\n",
       "14804    [nll_loss, RuntimeError: _thnn_nll_loss_forwar...\n",
       "14805    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14806    [class Model(nn.Module):\\r\\n\\r\\n    def __init...\n",
       "14807    [image, image,     image_yuv_ch = image[:, cha...\n",
       "14808    [array([[5, 7, 7, 4, 5, 8, 6, 9, 7, 9],\\r\\n   ...\n",
       "14809    [array([[5, 7, 7, 4, 5, 8, 6, 9, 7, 9],\\r\\n   ...\n",
       "14810    [_, a b c _ _ _\\r\\nd e f g _ _\\r\\nh i j k l m\\...\n",
       "14811    [torch.save(net.state_dict(), path)\\r\\nnet.loa...\n",
       "14812    [CNNLSTM(                                     ...\n",
       "14813    [Unexpected keys and missing keys,     1 impor...\n",
       "14814    [    reader = YT8MAggregatedFeatureReader()\\r\\...\n",
       "14815    [    reader = YT8MAggregatedFeatureReader()\\r\\...\n",
       "14816    [path = '../input/resized/Resized Dataset.zip/...\n",
       "14817                                             [einsum]\n",
       "14818    [torch.utils.data.DataLoader, azureml.core.Dat...\n",
       "14819    [torch.utils.data.DataLoader, azureml.core.Dat...\n",
       "14820    [ a = np.array([[1,2,3],[4,5,6]])\\r\\n b = np.a...\n",
       "14821    [ a = np.array([[1,2,3],[4,5,6]])\\r\\n b = np.a...\n",
       "14822    [device=0, pad_idx = TGT.vocab.stoi[\"&lt;blank...\n",
       "14823    [device=0, pad_idx = TGT.vocab.stoi[\"&lt;blank...\n",
       "14824    [dE2/dy2 * dy2/dh1 * dh1/dw1 + ..., dE1/dy1 * ...\n",
       "14826    [Example, [ \\r\\n  {\\r\\n    'texts': [\"An examp...\n",
       "14827    [[[1],[0],[2],...], ids, x, ids = torch.argmax...\n",
       "14828    [[[1],[0],[2],...], ids, x, ids = torch.argmax...\n",
       "14829    [[[1],[0],[2],...], ids, x, ids = torch.argmax...\n",
       "14830    [  AttributeError                            T...\n",
       "14832    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14833    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14834    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14835    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14836    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14837    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14838    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14839    [class CNN(nn.Module):\\r\\n  def __init__(self)...\n",
       "14840    [a, (x, n), b, (y, n), y &lt;= x, b, a, a, b, ...\n",
       "14841    [A = [1;2;3;4;5;6;7], B = [2;3;2], B = [2;3;2]...\n",
       "14842    [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "14843    [import torch\\r\\nfrom torch import cuda\\r\\nif ...\n",
       "14844    [torch.utils.data.Dataloader, dict, dataloader...\n",
       "14845    [torch.Size([[30, 8, 9, 64]]), 30, batch_size,...\n",
       "14846    [net.eval()\\r\\n\\r\\nf_image = net.forward(Varia...\n",
       "14847    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "14848    [def function():\\r\\n    seq_dt = SequenceLoade...\n",
       "14849    [class InceptionV4(nn.Module):\\r\\n\\r\\n   def _...\n",
       "14850    [def nll(input, target):\\r\\n    return -input[...\n",
       "14855    [A = [0;0] (sum vector), B = [0,0,1,1] (contri...\n",
       "14856    [A = [0;0] (sum vector), B = [0,0,1,1] (contri...\n",
       "14857    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "14858    [class Encoder(nn.Module):\\r\\n  def __init__(s...\n",
       "14859    [def initilize(self, input):\\r\\n     self.x = ...\n",
       "14861    [pip, import pyro, import pyro\\r\\nTraceback (m...\n",
       "14862    [nn.DataParallel, ----------------------------...\n",
       "14863    [model.eval(), RuntimeError, emb_matrix, emb_d...\n",
       "14864    [self.param, class Custom_RNN(nn.Module):\\r\\n ...\n",
       "14865    [dataloader = torch.utils.data.DataLoader(data...\n",
       "14866    [error: unrecognized arguments, def parse_opts...\n",
       "14867    [error: unrecognized arguments, def parse_opts...\n",
       "14868    [x:, image_datasets = {x: datasets.ImageFolder...\n",
       "14869    [x:, image_datasets = {x: datasets.ImageFolder...\n",
       "14870    [z_proto, class SequencePrototypeTokenClassifi...\n",
       "14871    [z_proto, class SequencePrototypeTokenClassifi...\n",
       "14872    [torch.Tensor, torch.Size([9, 1, 28, 28])), fo...\n",
       "14873    [same_digit_imgs = torch.empty(0, 1, 28, 28)\\r...\n",
       "14874    [import torch\\r\\na=torch.randn(3,4).cuda() # n...\n",
       "14875    [half_the_width = int(img.shape[1] / 2)\\r\\nimg...\n",
       "14879    [(n, 1, h, w), n, h, w, h x w, (m, 2), 0, m - ...\n",
       "14880    [class Mnist_DNN(nn.Module):\\r\\n    def __init...\n",
       "14882    [def gen_adj(A):\\r\\n    D = torch.pow(A.sum(1)...\n",
       "14883    [model = Sequential()\\r\\nmodel.add(LSTM(\\r\\n  ...\n",
       "14884    [ np.fft.fft2(test_cp, axes=(1,2)).shape\\r\\n(1...\n",
       "14885    [#output:\\r\\nKeras:\\r\\nTotal runtime =  18.451...\n",
       "14886    [[\\r\\n    [1,1,1],\\r\\n    [0,1,1],\\r\\n    [1,0...\n",
       "14888    [Loading dataset\\r\\nStart training\\r\\n--------...\n",
       "14890    [torch.Size([100, 1024, 14, 14]), (1024, 14, 1...\n",
       "14891    [torch.Size([100, 1024, 14, 14]), (1024, 14, 1...\n",
       "14892    [torch.Size([100, 1024, 14, 14]), (1024, 14, 1...\n",
       "14893    [import torch\\r\\nimport torch.autograd as auto...\n",
       "14894    [\\r\\nimport numpy as np\\r\\ndata = np.load('/co...\n",
       "14895    [\\r\\nimport numpy as np\\r\\ndata = np.load('/co...\n",
       "14896    [sin(x) * cos(x) + x^2, x = torch.autograd.Var...\n",
       "14897    [from zipfile import ZipFile\\r\\nfile_name = 'd...\n",
       "14898    [z_proto_class_list.append(z_proto_class),    ...\n",
       "14899             [A, B, (b, c, 3), C, A, B, (b, c, 3, 3)]\n",
       "14900    [[[1, 2, 3],\\r\\n [4, 5, 6],\\r\\n [7, 8, 9]]\\r\\n...\n",
       "14901    [a = torch.tensor([[1, 2], [3, 4]])\\r\\nb = new...\n",
       "14903    [indexes_batch  \\r\\n[[28, 633, 1076, 332, 270,...\n",
       "14904    [dtype=object, Tensor, array([\\r\\n   array([0....\n",
       "14906    [in_channels, out_channels, kernel_size, impor...\n",
       "14908    [x.view(*(x.shape[:-2]),-1).mean(-1)`, \\r\\n, x...\n",
       "14911    [Torch.cuda.is_available(), False, torch.cuda-...\n",
       "14913    [import torch\\r\\nfrom torchvision import datas...\n",
       "14914    [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "14915    [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "14916    [class TripletImageLoader(torch.utils.data.Dat...\n",
       "14917    [    #(Numpy Version)\\r\\n    #calculate Kineti...\n",
       "14918    [target_seq = batch.Python.transpose(0,1)\\r\\nt...\n",
       "14919    [target_seq = batch.Python.transpose(0,1)\\r\\nt...\n",
       "14920    [argmax, torch.argmax(input, dim=None, keepdim...\n",
       "14921    [class BasicBlock(nn.Module):\\r\\n    expansion...\n",
       "14922    [class BasicBlock(nn.Module):\\r\\n    expansion...\n",
       "14923    [class BasicBlock(nn.Module):\\r\\n    expansion...\n",
       "14924    [% matlab script test.m\\r\\n\\r\\nclear classes\\r...\n",
       "14925    [ResNet-18, TensorFlow, CrossEntropyLoss, PyTo...\n",
       "14926    [ResNet-18, TensorFlow, CrossEntropyLoss, PyTo...\n",
       "14929    [ResNet-18, TensorFlow, CrossEntropyLoss, PyTo...\n",
       "14931    [ResNet-18, TensorFlow, CrossEntropyLoss, PyTo...\n",
       "14932    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "14933    [nn.CrossEntropyLoss(), nn.Sequential(), impor...\n",
       "14934    [False,         for cur_step in range(1):   \\r...\n",
       "14935    [Traceback (most recent call last):\\r\\n  File ...\n",
       "14936    [import torch\\r\\ntorch.cuda.set_device(0)\\r\\n,...\n",
       "14937    [    def train(model, optimizer, train_loader,...\n",
       "14938    [class ImageDataset(Dataset):\\r\\n    def __ini...\n",
       "14939    [    def build(input_shape, classes):\\r\\n     ...\n",
       "14940    [def center_crop(self, layer, target_size):\\r\\...\n",
       "14941    [(x_train, y_train), (x_test, y_test) = mnist....\n",
       "14942    [(x_train, y_train), (x_test, y_test) = mnist....\n",
       "14943    [(x_train, y_train), (x_test, y_test) = mnist....\n",
       "14944    [source, (bsz x slen1 x nhd), index, (bsz x sl...\n",
       "14945    [source, (bsz x slen1 x nhd), index, (bsz x sl...\n",
       "14949    [def ac_distance(layer):\\r\\n    total = 0\\r\\n ...\n",
       "14950    [AssertionError:\\r\\nFound no NVIDIA driver on ...\n",
       "14951    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "14952    [relu, leakyrelu, inplace, sigmoid, Signature:...\n",
       "14954    [z = torch.linspace(-1, 1, steps=5, requires_g...\n",
       "14955    [z = torch.linspace(-1, 1, steps=5, requires_g...\n",
       "14956    [# pytorch_model to train, caffe_model freezed...\n",
       "14957    [from google.colab import drive\\r\\ndrive.mount...\n",
       "14958    [from google.colab import drive\\r\\ndrive.mount...\n",
       "14959    [np.random.random_sample, sum_bin_label, sum_m...\n",
       "14960    [for index, layer in enumerate(self.model):   ...\n",
       "14961    [for index, layer in enumerate(self.model):   ...\n",
       "14962    [for index, layer in enumerate(self.model):   ...\n",
       "14963    [[ 70%] Building NVCC (Device) object caffe2/C...\n",
       "14964    [device = torch.device(\"cuda:0\")\\r\\n\\r\\ndis = ...\n",
       "14965    [TensorDataset, # convert numpy arrays to pyto...\n",
       "14966    [import torch\\r\\n\\r\\nb = torch.tensor([0, 1, 0...\n",
       "14967    [nn.Linear, class TestModel(nn.Module):\\r\\ndef...\n",
       "14968    [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "14969    [\\r\\n# GRADED FUNCTION: compute_cost \\r\\n\\r\\nd...\n",
       "14970    [Linear, Conv1d, kernel_size=1, MaxPool1d, Con...\n",
       "14971    [Linear, Conv1d, kernel_size=1, MaxPool1d, Con...\n",
       "14972    [x, x[:,:,30:50], indices, x = [[1,2,3,4,5,6],...\n",
       "14973    [x, x[:,:,30:50], indices, x = [[1,2,3,4,5,6],...\n",
       "14974    [x, x[:,:,30:50], indices, x = [[1,2,3,4,5,6],...\n",
       "14975    [x, x[:,:,30:50], indices, x = [[1,2,3,4,5,6],...\n",
       "14976    [sizes = [3, 7, 5, 9]\\r\\nX = torch.ones(sum(si...\n",
       "14977    [labels.size(0), correct = 0\\r\\ntotal = 0\\r\\nw...\n",
       "14978    [labels.size(0), correct = 0\\r\\ntotal = 0\\r\\nw...\n",
       "14979    [SOS_token = 0\\r\\nEOS_token = 1\\r\\n\\r\\n\\r\\ncla...\n",
       "14980    [TypeError: backward() got an unexpected keywo...\n",
       "14981    [pin_memory (bool, optional) – If True, the da...\n",
       "14983    [train_loader = torch.utils.data.DataLoader(tr...\n",
       "14984    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "14985    [from_config, Dict[str, Field] = {ExtraField.T...\n",
       "14986    [from torchtext.data import Field\\r\\nfrom torc...\n",
       "14987    [labels, size, print(labels.size())\\r\\nprint(o...\n",
       "14988    [labels, size, print(labels.size())\\r\\nprint(o...\n",
       "14989    [labels, size, print(labels.size())\\r\\nprint(o...\n",
       "14990    [labels, size, print(labels.size())\\r\\nprint(o...\n",
       "14991    [torch.Size([2, 3, 5])    ⟶ flatten ⟶    torch...\n",
       "14993    [torch.Size([2, 3, 5])    ⟶ flatten ⟶    torch...\n",
       "14995    [0, 1, 2, n x 3, 0, 1, 2, n x 1, [[0.2, 0.1, 0...\n",
       "14998    [in1 = torch.randn(2,2,requires_grad=True)\\r\\n...\n",
       "14999    [inputs = df[['x1', 'x2', 'x3']]\\r\\ntarget = d...\n",
       "15000    [#include &lt;iostream&gt;\\r\\n\\r\\n#include &lt...\n",
       "15001    [#include &lt;iostream&gt;\\r\\n\\r\\n#include &lt...\n",
       "15002    [tensor = torch.rand(12, 512, 768)\\r\\n, [0,2,3...\n",
       "15003    [tensor = torch.rand(12, 512, 768)\\r\\n, [0,2,3...\n",
       "15004    [tensor = torch.rand(12, 512, 768)\\r\\n, [0,2,3...\n",
       "15005    [torch.set_default_tensor_type(torch.DoubleTen...\n",
       "15006    [pack = pack_padded_sequence(conv), RuntimeErr...\n",
       "15007    [tensor([[[-0.2800, -0.6381, -0.1033, -0.4941,...\n",
       "15008    [model = models.get_pose_net(config, is_train=...\n",
       "15009    [batch size, batch size, nn.MSELoss(), import ...\n",
       "15010    [#dis is [torch.cuda.FloatTensor of size 3185x...\n",
       "15011    [ts = torch.tensor([[1,2,3],[4,6,7],[8,9,10]])...\n",
       "15012    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15013    [import numpy as np \\r\\nimport matplotlib.pypl...\n",
       "15014    [import os\\r\\nimport numpy as np\\r\\nfrom flask...\n",
       "15015    [import os\\r\\nimport numpy as np\\r\\nfrom flask...\n",
       "15016    [import os\\r\\nimport numpy as np\\r\\nfrom flask...\n",
       "15017                      [t1, t2, for a,b in zip(t1,t2)]\n",
       "15019                      [t1, t2, for a,b in zip(t1,t2)]\n",
       "15021    [X, (bs, channels, dim, dim), import torch\\r\\n...\n",
       "15022                               [h_{transpose}*M*h, h]\n",
       "15023    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15024    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15025    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15026    [from google.colab import drive\\r\\ndrive.mount...\n",
       "15027    [f['group/subroup'][()], X = f[ID], X = X[()],...\n",
       "15030              [(1, 3, 256, 256, 3), (1, 3, 256, 256)]\n",
       "15031    [conda install pytorch torchvision cudatoolkit...\n",
       "15032      [tensor.numpy(), tensor.cpu().detach().numpy()]\n",
       "15035      [tensor.numpy(), tensor.cpu().detach().numpy()]\n",
       "15037    [x_t, x_k, NxHxW, KxNxHxW, K, x_t, K, x_t, N, ...\n",
       "15038    [\\r\\n'''VGG11/13/16/19 in Pytorch.'''\\r\\nimpor...\n",
       "15039    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "15040    [import pandas as pd\\r\\nfrom sklearn.datasets ...\n",
       "15043    [import torch \\r\\nimport torch.nn as nn \\r\\nim...\n",
       "15044    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15045    [class InputData(Dataset):\\r\\n    '''read data...\n",
       "15046    [/root\\r\\n-- train/\\r\\n---- 001.jpg\\r\\n---- 00...\n",
       "15047    [/root\\r\\n-- train/\\r\\n---- 001.jpg\\r\\n---- 00...\n",
       "15048    [pytorch, linear = nn.Linear(in_features=137, ...\n",
       "15049    [x = A†b, A_pinv = np.linalg.pinv(A)\\r\\nbetas ...\n",
       "15050    [f, 4096X1, theta, 20X1, E, theta = E*f, pytor...\n",
       "15051    [def test(net, STRIDE-16, BATCH_SIZE=20, WINDO...\n",
       "15053    [input_size = 5\\r\\nhidden_size = 10\\r\\nnum_lay...\n",
       "15055    [-1, length-1, import torch\\r\\nfrom torch.nn.u...\n",
       "15056    [-1, length-1, import torch\\r\\nfrom torch.nn.u...\n",
       "15058    [for epoch in range(EPOCHS):\\r\\n    for data i...\n",
       "15059    [...\\r\\n\\r\\n  File \"C:\\python36\\lib\\distutils\\...\n",
       "15060    [import torch.nn as nn \\r\\n\\r\\nembed = nn.Embe...\n",
       "15061    [s, import numpy as np\\r\\nimport torch\\r\\n\\r\\n...\n",
       "15062    [s, import numpy as np\\r\\nimport torch\\r\\n\\r\\n...\n",
       "15063    [device = torch.device('cuda: 0' if torch.cuda...\n",
       "15064    [    ...\\r\\n    def neg_log_likelihood(self, s...\n",
       "15065    [    ...\\r\\n    def neg_log_likelihood(self, s...\n",
       "15066    [0, 60, 120, 180, for i, (inputs) in enumerate...\n",
       "15067    [translate.py, OpenNMT-py, python translate.py...\n",
       "15068    [class SimpleCNN(torch.nn.Module):\\r\\n\\r\\n    ...\n",
       "15069    [➜  ~ pip3 list\\r\\nPackage     Version    \\r\\n...\n",
       "15070                                      [[1,512,50,50]]\n",
       "15072    [if __name__ == '__main__':\\r\\n\\r\\n    opt.sca...\n",
       "15073    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "15074    [forward, model(input), model.forward(input), ...\n",
       "15076    [RuntimeError: binary_op(): expected both inpu...\n",
       "15077    [conda, cmd, python --version, setup.py, pip i...\n",
       "15079    [m.eval()\\r\\n\\r\\ntestset_predictions = []\\r\\nf...\n",
       "15080    [&lt;!DOCTYPE html&gt;\\r\\n&lt;html&gt;\\r\\n&lt;...\n",
       "15081    [forward, RuntimeError: Expected object of bac...\n",
       "15082    [def get_features(image, model):\\r\\n\\r\\n    la...\n",
       "15083    [self.in_embed = nn.Embedding(n_vocab, n_embed...\n",
       "15085    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15086    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15087    [orch.cuda.is_available(), True, CPU, GPU, dev...\n",
       "15088    [(X,Y), 29600, 1, 200, import torch\\r\\nimport ...\n",
       "15089    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15090    [    for x,y in trainData:\\r\\n        optimize...\n",
       "15091    [import torch.nn as nn\\r\\n\\r\\nclass Net(nn.Mod...\n",
       "15092    [import torch.nn as nn\\r\\n\\r\\nclass Net(nn.Mod...\n",
       "15093    [import torch.nn as nn\\r\\n\\r\\nclass Net(nn.Mod...\n",
       "15094    [import torch.nn as nn\\r\\n\\r\\nclass Net(nn.Mod...\n",
       "15095    [y = tensor.new_tensor(x) #a\\r\\n\\r\\ny = x.clon...\n",
       "15096    [y = tensor.new_tensor(x) #a\\r\\n\\r\\ny = x.clon...\n",
       "15097    [y = tensor.new_tensor(x) #a\\r\\n\\r\\ny = x.clon...\n",
       "15098    [class CGAN(object):\\r\\ndef __init__(self, arg...\n",
       "15099    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15100    [self.mask_fc1\\2\\3, import torch\\r\\nimport tor...\n",
       "15101    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15103    [torch.Size([1, 64, 8, 32, 32]), torch.Size([1...\n",
       "15104    [import torch\\r\\n\\r\\nclass MyModule(torch.nn.M...\n",
       "15105    [.sav, sklearn.externals.joblib, pickle, scipy...\n",
       "15108    [def load_tf_model_weights():        \\r\\n\\r\\n ...\n",
       "15109    [9%, def tf_model(graph, init=None):\\r\\n    wi...\n",
       "15110    [scikit-learn, pytorch, 1) pip3 install https:...\n",
       "15111    [def histroy(num_samples=4,look_back=3):\\r\\n  ...\n",
       "15114    [torch, FFT, FFT, timer, cpu, squeezes - done ...\n",
       "15115    [keep[count] = i, tf.while_loop, count, i, kee...\n",
       "15116    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "15117    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "15118    [a,  a = torch.arange(1, 13, dtype=torch.float...\n",
       "15119    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "15120    [a = [0,0]\\r\\nb = [1,1]\\r\\nc = [2]\\r\\nc = [a, ...\n",
       "15121    [nn.ModuleList, loss.backward(),  policy_loss ...\n",
       "15123    [class myLSTM(nn.Module):\\r\\ndef __init__(self...\n",
       "15124    [transforms.Normalize, train_transforms = tran...\n",
       "15125    [transforms.Normalize, train_transforms = tran...\n",
       "15127    [!python3 main.py something RGB \\\\r\\n         ...\n",
       "15129    [w1 = torch.randn(D_in, H, dtype=torch.float, ...\n",
       "15131    [class NetworkRelu(nn.Module):\\r\\n    def __in...\n",
       "15132    [nn.Module, def forward(self, X, **kwargs):\\r\\...\n",
       "15133    [import torch.nn as nn\\r\\nclass _AutoEncoder(n...\n",
       "15134    [test_acc += torch.sum(prediction == labels.da...\n",
       "15135    [Traceback (most recent call last):\\r\\nFile \"c...\n",
       "15136    [torch.onnx.export(pytorch_net, dummyseq, ONNX...\n",
       "15137    [torch.onnx.export(pytorch_net, dummyseq, ONNX...\n",
       "15138    [model = models.vgg16(pretrained = False)\\r\\nc...\n",
       "15140    [ def test(args, model, device, test_loader):\\...\n",
       "15141    [%reset -f\\r\\n\\r\\nimport torch.utils.data as d...\n",
       "15142    [@ptrblck, import torch\\r\\nfrom torch.utils.da...\n",
       "15143    [    t = torch.tensor([\\r\\n        [1,0,0,2],\\...\n",
       "15144    [class Generator(nn.Module):\\r\\n    def __init...\n",
       "15145    [class Generator(nn.Module):\\r\\n    def __init...\n",
       "15146    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nimp...\n",
       "15147    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nimp...\n",
       "15148    [self.input_u = tf.placeholder(tf.int32, [None...\n",
       "15149    [import tensorflow as tf\\r\\n\\r\\n\\r\\nclass Netw...\n",
       "15151    [affine_grid, grid_sample, 255, canvas1 = np.z...\n",
       "15152    [|-content \\r\\n  |-utils\\r\\n    |- parse_confi...\n",
       "15153    [import models as m\\r\\nimport densenet as x\\r\\...\n",
       "15154    [BxNxD, BxNxD, BxMxN, import torch\\r\\nimport n...\n",
       "15155    [RuntimeError: output with shape [1, 28, 28] d...\n",
       "15156    [groups, class depthwise_separable_conv(nn.Mod...\n",
       "15157    [img.unsqueeze_(0)\\r\\n, RuntimeError: Input ty...\n",
       "15158    [img_0000001.jpg\\r\\nimg_0000002.jpg\\r\\nimg_000...\n",
       "15159    [def to_sparse(x):\\r\\n    \"\"\" converts dense t...\n",
       "15160    [(h, ch, w), (h, ch, w, 1), i, cv2.umat, img_w...\n",
       "15161    [(h, ch, w), (h, ch, w, 1), i, cv2.umat, img_w...\n",
       "15162    [ DATAPATH:  ../data/coco/test/val_captions.t7...\n",
       "15163    [nnet = NN(gpu_num=0)\\r\\nnnet1 = NN(gpu_num=1)...\n",
       "15164    [torch.matmul, torch.sum, for i in range((x.sh...\n",
       "15165    [v, p, M, qXr, #size: 2\\r\\nv = [0, 1] \\r\\n#siz...\n",
       "15166    [v, p, M, qXr, #size: 2\\r\\nv = [0, 1] \\r\\n#siz...\n",
       "15167    [v, p, M, qXr, #size: 2\\r\\nv = [0, 1] \\r\\n#siz...\n",
       "15168    [x[0].size() == torch.Size([4, 8])\\r\\nx[1].siz...\n",
       "15169    [x[0].size() == torch.Size([4, 8])\\r\\nx[1].siz...\n",
       "15170    [data = ImageDataBunch.single_from_classes(pat...\n",
       "15171    [target_data, target.data, [batch_size]x13, de...\n",
       "15173    [for epoch in tqdm(range(epochs)):\\r\\n  for i ...\n",
       "15174    [0   24104   27359   6684\\r\\n0   24104   27359...\n",
       "15175    [0   24104   27359   6684\\r\\n0   24104   27359...\n",
       "15176    [0   24104   27359   6684\\r\\n0   24104   27359...\n",
       "15177    [    self.embed1 = nn.Embedding(256, 8)\\r\\n   ...\n",
       "15178    [    self.embed1 = nn.Embedding(256, 8)\\r\\n   ...\n",
       "15179    [    self.embed1 = nn.Embedding(256, 8)\\r\\n   ...\n",
       "15180    [import numpy as np\\r\\na = np.ones(5)\\r\\nb = t...\n",
       "15181    [import numpy as np\\r\\na = np.ones(5)\\r\\nb = t...\n",
       "15182    [    g_feature = 0 \\r\\n    for i in range(self...\n",
       "15183    [from sklearn.datasets import fetch_lfw_people...\n",
       "15184    [ResNet50, imagenet, from keras.applications.r...\n",
       "15186    [import torchvision.models as models\\r\\nimport...\n",
       "15187    [folder_data = glob.glob(\"D:\\\\Neda\\\\Pytorch\\\\U...\n",
       "15188    [folder_data = glob.glob(\"D:\\\\Neda\\\\Pytorch\\\\U...\n",
       "15189    [folder_data = glob.glob(\"D:\\\\Neda\\\\Pytorch\\\\U...\n",
       "15190    [ cos\\r\\n\\r\\ntensor([ 0.3869,  0.2857,  0.4931...\n",
       "15191    [num_samples = 10\\r\\ndef predict(x):\\r\\n    sa...\n",
       "15192    [import torch\\r\\nv = torch.tensor([0., 0., 0.]...\n",
       "15193    [self._modules, self.modules(), self.children(...\n",
       "15194    [self._modules, self.modules(), self.children(...\n",
       "15195    [# Initialize random convolution of size 3:\\r\\...\n",
       "15196    [Darknet, nn.Module, class Darknet(nn.Module),...\n",
       "15197    [import numpy as np\\r\\nfrom sklearn.feature_ex...\n",
       "15199    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nnum...\n",
       "15200    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nnum...\n",
       "15203    [gcsfuse, --implicit-dirs, train.py, gcsfuse, ...\n",
       "15204    [N, D_in, D_out, H = 20, 1, 5, 10\\r\\nX = torch...\n",
       "15205    [# show images\\r\\nimport torch\\r\\nimport torch...\n",
       "15207    [    self.pipe = nn.Sequential(nn.Linear(9, 12...\n",
       "15208    [# A: 3000 x 100 (~2MB)\\r\\n# B: 100 x 100  (~0...\n",
       "15209    [[[3], [1, 2], [4], [0], [2]]\\r\\n, (5, 5), ten...\n",
       "15210    [VGG16.classifier[6], Linear(in_features=25088...\n",
       "15211    [A: 3000x100, B: 100x100, C: 100x3.6MM, A_gpu ...\n",
       "15212    [A: 3000x100, B: 100x100, C: 100x3.6MM, A_gpu ...\n",
       "15213    [A: 3000x100, B: 100x100, C: 100x3.6MM, A_gpu ...\n",
       "15214    [&gt; Net(\\r\\n  (conv1): Conv2d(1, 32, kernel_...\n",
       "15215    [`for i in range(256):\\r\\n    for j in range(2...\n",
       "15216    [def get_affine_transform(center,\\r\\n         ...\n",
       "15217    [self.hidden, import torch.nn as nn\\r\\nimport ...\n",
       "15218    [self.hidden, import torch.nn as nn\\r\\nimport ...\n",
       "15219    [learn = create_cnn(data, models.resnet50, lin...\n",
       "15220    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15221    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15222    [    import torch\\r\\n    import torch.nn as nn...\n",
       "15223    [nn.Conv2d(1, 64, 4, 2, 1),\\r\\n, nn.Conv2d(64,...\n",
       "15224    [extras = ModuleList([\\r\\n    Sequential(\\r\\n ...\n",
       "15225    [/img, /mask, data\\r\\n    img\\r\\n        0.png...\n",
       "15226    [/img, /mask, data\\r\\n    img\\r\\n        0.png...\n",
       "15227    [ from torch.utils.data import Dataset, DataLo...\n",
       "15228                        [torch.utils.data.DataLoader]\n",
       "15229                        [torch.utils.data.DataLoader]\n",
       "15230    [x, x = torch.zeros((2, 2, 2))\\r\\n, y, y = tor...\n",
       "15231    [x, x = torch.zeros((2, 2, 2))\\r\\n, y, y = tor...\n",
       "15233    [class SomeLayer(nn.Module):\\r\\n    def __init...\n",
       "15234    [import skimage.io as io\\r\\nimport torch\\r\\nfr...\n",
       "15235    [[libprotobuf ERROR google/protobuf/text_forma...\n",
       "15236    [import torch\\r\\n\\r\\nclass TestNN(torch.nn.Mod...\n",
       "15237    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "15238    [ROOT_DIR_GMCHALLENGE = r'C:\\Users~~~\\eyedata\\...\n",
       "15239    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15240    [import torch\\r\\n\\r\\nimport torch.legacy.nn\\r\\...\n",
       "15241    [predicted_action(predicted_class),  # creatin...\n",
       "15242    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15243    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15244    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15245    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15246    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15247    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15248    [nn.Sequence, import pretrainedmodels\\r\\n\\r\\nd...\n",
       "15265    [conda install pytorch-cpu torchvision-cpu -c ...\n",
       "15266    [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "15267    [conda install -n myenv, pip install $path:whl...\n",
       "15268    ['',\\r\\n'Structure:',\\r\\n'----------',\\r\\n'pec...\n",
       "15269    [nvidia-smi, d0_model, d0_in_tensor, app = Cel...\n",
       "15270    [import torch\\r\\nX = torch.rand(2, 3, 4, 4)   ...\n",
       "15271    [import torch\\r\\nX = torch.rand(2, 3, 4, 4)   ...\n",
       "15272    [pytorch_36, pytorch_torchvision_neo.ipynb, fr...\n",
       "15274    [data_lm = TextLMDataBunch.from_df(train_df = ...\n",
       "15275    [RegressorNet, RegressionNN, from pathlib impo...\n",
       "15277    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15278    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15279    [from numpy import array\\r\\nfrom keras.models ...\n",
       "15280    [modelList = []\\r\\nthisCNN = NNet()\\r\\n\\r\\nfor...\n",
       "15281    [modelList = []\\r\\nthisCNN = NNet()\\r\\n\\r\\nfor...\n",
       "15282                             [0.003~0.006, 0.5, 0.01]\n",
       "15283    [t = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])...\n",
       "15284    [pytorch==0.4.1, python test.py --name label2c...\n",
       "15285    [    File \"D:\\Julio\\Documents\\Michigan_v2\\CS\\E...\n",
       "15287    [       delta = r_t + gamma * expected_reward_...\n",
       "15288    [import torch\\r\\n\\r\\nx = torch.tensor([1., 2.,...\n",
       "15290    [emodel = ExplicitFactorizationModel(n_iter=15...\n",
       "15291    [DataLoader, class ToTensor(object):\\r\\n    de...\n",
       "15292    [[espresso] [Espresso::ANERuntimeEngine::__for...\n",
       "15293    [dataset, torch.utils.data.Dataset, __get_item...\n",
       "15294    [dataset, torch.utils.data.Dataset, __get_item...\n",
       "15295    [torch.nn.Parameter, parameter, layer, layer, ...\n",
       "15296    [torch.nn.Parameter, parameter, layer, layer, ...\n",
       "15297    [# Staring tensors\\r\\nX = torch.rand(40, requi...\n",
       "15299    [tf.gradients(ys=Y, xs=X), torch.autograd.grad...\n",
       "15300    [tf.gradients(ys=Y, xs=X), torch.autograd.grad...\n",
       "15301    [.npz, Dataset, class MyDataset(Dataset):\\r\\n ...\n",
       "15302    [forward(), Module, nn.Linear, class LinearWit...\n",
       "15303    [forward(), Module, nn.Linear, class LinearWit...\n",
       "15304    [x = np.array([-1,10,3])\\r\\nlow = np.array([0,...\n",
       "15305    [.csv, x1, x2, y, x3, x4\\r\\n05  05  0  00  12\\...\n",
       "15306    [loss.backwward(), gamma*f(n)=f(n)-1, gamma+ga...\n",
       "15307    [    data_dir_path = 'data/images/'\\r\\n    lab...\n",
       "15309    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15310    [data, [128, 4, 150, 150], fake, [128, 1, 150,...\n",
       "15311    [data, [128, 4, 150, 150], fake, [128, 1, 150,...\n",
       "15312    [folder_dataset = dset.ImageFolder(root=Config...\n",
       "15313    [folder_dataset = dset.ImageFolder(root=Config...\n",
       "15314    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "15315    [ import torch\\r\\nTraceback (most recent call ...\n",
       "15316    [torch.randn(), def reparametrize(self, mu, lo...\n",
       "15317    [torch.nn.Linear, forward, @weak_script_method...\n",
       "15319    [result = mynet1(input)\\r\\n\\r\\ncalculated_valu...\n",
       "15321    [torchvision.datasets, N x H x W (uint8), Conv...\n",
       "15322    [nn.Module, net.to(device), encoding = mu + no...\n",
       "15323    [nn.Module, net.to(device), encoding = mu + no...\n",
       "15324    [nn.Module, net.to(device), encoding = mu + no...\n",
       "15325    [nn.Module, net.to(device), encoding = mu + no...\n",
       "15326    [nn.Module, net.to(device), encoding = mu + no...\n",
       "15327    [torch.onnx.symbolic.normal does not exist, re...\n",
       "15328    [Rs.shape = [62x3x3]\\r\\n, Js.shape = [62x3]\\r\\...\n",
       "15329    [forward, at::Tensor, void xyz_forward(\\r\\n   ...\n",
       "15330    [forward, at::Tensor, void xyz_forward(\\r\\n   ...\n",
       "15331    [with, requires_grad, False, net = InceptionRe...\n",
       "15332    [torch.mean(scores == y), tensor(\\r\\n    [[0.3...\n",
       "15333    [out = np.array([[\\r\\n    [\\r\\n        [1.,1, ...\n",
       "15334    [import torch, -------------------------------...\n",
       "15336    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15337    [model1, model2, nn.Module, model1 = Mynet1()\\...\n",
       "15338    [model = MyModelClass(config, shape, x_tr_mean...\n",
       "15340    [module-&gt;forward(batch_frames),  cv::Mat fr...\n",
       "15341    [module-&gt;forward(batch_frames),  cv::Mat fr...\n",
       "15342    [import torch.nn as nn\\r\\nimport torch.functio...\n",
       "15343    [import torch.nn as nn\\r\\nimport torch.functio...\n",
       "15344    [vgg = torchvision.models.vgg16(pretrained=Tru...\n",
       "15345    [pip install pytorch, Collecting pytorch\\r\\n  ...\n",
       "15346    [%matplotlib inline\\r\\n%config InlineBackend.f...\n",
       "15347    [import gensim\\r\\nfrom torch import nn\\r\\n\\r\\n...\n",
       "15348    [.backward(), x, t, z.set_all_gradients_to_zer...\n",
       "15349    [class SubtractedConv(nn.Module):\\r\\n    def _...\n",
       "15350    [import torchvision.transforms as T\\r\\n\\r\\ncla...\n",
       "15351    [from torch.utils.data.dataset import Dataset\\...\n",
       "15352    [pytorch1, (pytorch1) me@comp:~$ conda install...\n",
       "15354    [Epoch 0/3\\r\\n----------\\r\\n100%|██████████| 1...\n",
       "15358    [log_prob, log, dist = Normal(mean, std)\\r\\nsa...\n",
       "15359    [clean, add_noise, model_output, DataLoader, s...\n",
       "15360    [clean, add_noise, model_output, DataLoader, s...\n",
       "15361    [class cifar_clasify(nn.Module):\\r\\n\\r\\n    de...\n",
       "15362    [print(os.listdir('./Dataset/images/')), ./dat...\n",
       "15363    [print(os.listdir('./Dataset/images/')), ./dat...\n",
       "15364    [print(os.listdir('./Dataset/images/')), ./dat...\n",
       "15365    [print(os.listdir('./Dataset/images/')), ./dat...\n",
       "15367    [model.__call__(), # -*- coding: utf-8 -*-\\r\\n...\n",
       "15368    [logical_and, logical_or, logical_not, logical...\n",
       "15370    [torch.nn.functional.max_pool1d, import numpy ...\n",
       "15371    [torch.nn.functional.max_pool1d, import numpy ...\n",
       "15372    [parameters -= (lr * (p.grad*0.1 + p_delta_pre...\n",
       "15374    [import warnings\\r\\nwarnings.filterwarnings('i...\n",
       "15375    [class DecoderLSTMwithBatchSupport(nn.Module):...\n",
       "15376    [### a simple neural network \\r\\nlinear = nn.L...\n",
       "15378    [torch.cuda.is_available(), True, import torch...\n",
       "15379    [logistic_loss = lambda X,y,w: torch.tensor([t...\n",
       "15380    [.cuda(), net = Net(input_size, hidden_size, n...\n",
       "15381    [class model(nn.Module):\\r\\n    def __init__(s...\n",
       "15382    [root_dir=\"./images_masks\"\\r\\ntrain_ds_untrans...\n",
       "15383    [RuntimeError                              Tra...\n",
       "15384    [import torch\\r\\nimport torch.nn as nn\\r\\nconv...\n",
       "15385    [ import torch\\r\\n from torch import nn\\r\\n\\r\\...\n",
       "15386    [from google.colab import files\\r\\n\\r\\ntorch.s...\n",
       "15387    [class convnet(nn.Module):\\r\\ndef __init__(sel...\n",
       "15388    [RuntimeError: Input and hidden tensors are no...\n",
       "15389    [k(x,y) = exp(-||x-y||^2 / (2h)), def A(X, Y, ...\n",
       "15390    [a = torch.tensor([[3,2,2,3], [1,1,2,2])\\r\\n# ...\n",
       "15391    [import torch\\r\\n\\r\\n# initalize an array (not...\n",
       "15392    [import torch\\r\\n\\r\\n# initalize an array (not...\n",
       "15393    [model = nn.Linear(input_size,num_classes),   ...\n",
       "15394    [AttributeError                            Tra...\n",
       "15395    [if torch.cuda.device_count() &gt; 1:\\r\\n    p...\n",
       "15396    [if torch.cuda.device_count() &gt; 1:\\r\\n    p...\n",
       "15397    [layer {\\r\\n  name: \"conv1a\"\\r\\n  type: \"Convo...\n",
       "15398    [(pt_gpu) [martin@A08-R32-I196-3-FZ2LTP2 mlm]$...\n",
       "15399    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "15400    [def char_OneHotEncoding(x):\\r\\n    coded = to...\n",
       "15401    [a1  0  0  0  0 ...\\r\\na2 a1  0  0  0 ...\\r\\na...\n",
       "15403    [A = Tensor of [186,3]\\r\\n, tempTens = torch.t...\n",
       "15405    [A, [n x m x c], B, [1 x 1 x c], 1 x 1 x c, A,...\n",
       "15407    [(Pytorch) C:\\Users\\choib&gt;python\\r\\nPython ...\n",
       "15408    [Learning rate = 0.05;\\r\\ntarget output = 1\\r\\...\n",
       "15409    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "15411    [nn.Linear, (N,*,in_features), (N,*,out_featur...\n",
       "15412    [a, a, a, import torch\\r\\nimport tensorflow as...\n",
       "15413    [net.load_state_dict(torch.load('rnn_x_epoch.n...\n",
       "15414    [# define dataset, dataloader\\r\\ntrain_data = ...\n",
       "15415    [looks   0.007668 -0.011884 -0.009672 0.011174...\n",
       "15417    [N=15, torch, def generate_patch(x, y, w, h, i...\n",
       "15418    [class ResBlock(nn.Module):\\r\\n    def __init_...\n",
       "15419    [    dataset = big_dataframe_flt.values\\r\\n   ...\n",
       "15420    [torch-1.0.0-cp27-cp27m-linux_x86_64.whl is no...\n",
       "15421    [x = torch.Tensor([[0.0], [0.1], [0.2], [0.3],...\n",
       "15422    [from algorithms import Argparser\\r\\nfrom algo...\n",
       "15423    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nP =...\n",
       "15424    [class Network(torch.nn.Module):\\r\\n    def __...\n",
       "15425    [print(x.size())\\r\\nprint(c.size())\\r\\nprint(t...\n",
       "15426    [transform = transforms.Compose([transforms.To...\n",
       "15428    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "15429    [dir_path = '/content/drive/My Drive/Colab Not...\n",
       "15430    [tensor, a = np.random.randn(1, 1, 128, 256)\\r...\n",
       "15431    [class Infinite(Dataset):\\r\\n    def __len__(s...\n",
       "15432    [class Infinite(Dataset):\\r\\n    def __len__(s...\n",
       "15433    [class Infinite(Dataset):\\r\\n    def __len__(s...\n",
       "15434    [pip install https://download.pytorch.org/whl/...\n",
       "15435    [RuntimeError: 'lengths' argument should be a ...\n",
       "15436    [(50500,), # NumPy\\r\\n\\r\\nIn [64]: a = np.aran...\n",
       "15437    [(50500,), # NumPy\\r\\n\\r\\nIn [64]: a = np.aran...\n",
       "15439    [class net_pytorch(torch.nn.Module):\\r\\n    de...\n",
       "15440    [train=True, batch_size, num_workers, batch_si...\n",
       "15441    [train=True, batch_size, num_workers, batch_si...\n",
       "15442    [class inputDataset(Dataset):\\r\\n\\r\\n  def __i...\n",
       "15443    [class inputDataset(Dataset):\\r\\n\\r\\n  def __i...\n",
       "15444    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15445    [backprop, Tensorflow, PyTorch, active_rois = ...\n",
       "15446    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15447    [The dog is _____, but we are happy he is okay...\n",
       "15448    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15449    [x =  Variable(DoubleTensor([1]), requires_gra...\n",
       "15450    [class TransferModel(nn.Module):\\r\\n    def __...\n",
       "15451    [import torch\\r\\nimport numpy as np\\r\\nfrom st...\n",
       "15452    [batch_size, 64, TEXT, LABEL, tokenize = lambd...\n",
       "15453    [batch_size, 64, TEXT, LABEL, tokenize = lambd...\n",
       "15456    [torch.cat, torch.stack, # REINFORCE:\\r\\npolic...\n",
       "15457    [torch.cat, torch.stack, # REINFORCE:\\r\\npolic...\n",
       "15458    [File \"C:\\Users\\Ganesh Bhat\\Desktop\\AI\\Self_Dr...\n",
       "15459    [    import torch\\r\\n    import matplotlib.pyp...\n",
       "15460    [if __name__ == \"__main__\":\\r\\n    for epoch i...\n",
       "15461    [a, b, a, dim, Softmax(), a = torch.rand(10)\\r...\n",
       "15462    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15463               [from torchvision import datasets\\r\\n]\n",
       "15464    [torch, import torch as McLawrence\\r\\nfrom tor...\n",
       "15465    [ xtrain=np.range(0,50,1).reshape(50,1)\\r\\n yt...\n",
       "15466    [    if i &gt; 1:\\r\\n        if D_G_z1 &lt; 0....\n",
       "15467                               [torchtext, torchtext]\n",
       "15468    [from torch import nn\\r\\nimport torch\\r\\n\\r\\nl...\n",
       "15469    [$ lspci | grep VGA\\r\\n03:00.0 VGA compatible ...\n",
       "15470    [$ lspci | grep VGA\\r\\n03:00.0 VGA compatible ...\n",
       "15471    [$ lspci | grep VGA\\r\\n03:00.0 VGA compatible ...\n",
       "15472                                      [WebCamTexture]\n",
       "15473    [torch.Tensor(([1, 2, 3, 4, 3, 3, 4],\\r\\n     ...\n",
       "15474    [torch.Tensor(([1, 2, 3, 4, 3, 3, 4],\\r\\n     ...\n",
       "15476    [project/   \\r\\n--data/  \\r\\n----data.h5  \\r\\n...\n",
       "15477    [x = torch.empty(5, 3)\\r\\n, module 'torch' has...\n",
       "15478    [criterion = nn.NLLLoss()\\r\\noptimizer = optim...\n",
       "15479    [ # Some standard imports\\r\\nimport io\\r\\nimpo...\n",
       "15480    [from torchvision import datasets, transforms\\...\n",
       "15481    [from torchvision import datasets, transforms\\...\n",
       "15482    [from torchvision import datasets, transforms\\...\n",
       "15483    [epochs = 250 \\r\\nbatch_size = 128 \\r\\n\\r\\ncla...\n",
       "15484    [import random\\r\\nimport torch\\r\\n\\r\\nclass Dy...\n",
       "15485    [torch.sqrt(((preds.detach() - labels) ** 2).m...\n",
       "15487    [      x1=np.arange(0,10,1).reshape(10,1)\\r\\n ...\n",
       "15488    [separable_conv2d, normal conv2d, depthwise_co...\n",
       "15489    [X = xor_input = np.array([[0,0], [0,1], [1,0]...\n",
       "15490    [# linear regression\\r\\nclass RegressionModel(...\n",
       "15492    [.cpu(), .cuda(), cuda(device=None)\\r\\nMoves a...\n",
       "15493    [# Hyperparameters for our network\\r\\ninput_si...\n",
       "15495    [from allennlp.nn import util\\r\\nmodel_state =...\n",
       "15496    [for epoch in range(start_epoch, epochs):\\r\\n\\...\n",
       "15497    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nimp...\n",
       "15498    [array, Tensor, X, A, X, A, A, True, import nu...\n",
       "15499    [export GLUE_DIR=/tmp/glue_data\\r\\n\\r\\npython ...\n",
       "15500    [B, gamma, phi_diag, psi, sigma, f_ml, sigma, ...\n",
       "15501    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15502    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "15505    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "15506    [Categorical(probs: torch.Size([12]))), numpy,...\n",
       "15508       [numpy, numpy, np.isnan(), libtorch, C++, NAN]\n",
       "15509    [m, Weight=[]\\r\\nfor layer in m._modules:\\r\\n ...\n",
       "15512    [m, Weight=[]\\r\\nfor layer in m._modules:\\r\\n ...\n",
       "15513    [m, Weight=[]\\r\\nfor layer in m._modules:\\r\\n ...\n",
       "15514    [*tensor_name[0].data&lt;float&gt;(), 0, int, ...\n",
       "15515    [def update_picture():\\r\\n    print('press')\\r...\n",
       "15516    [a = torch.randn(3, 512), for, ans = []\\r\\nres...\n",
       "15518    [    self.model = nn.Sequential()\\r\\n    for i...\n",
       "15519    [    self.model = nn.Sequential()\\r\\n    for i...\n",
       "15520    [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "15521    [d(loss)/d(input),     loss.backward()\\r\\n    ...\n",
       "15522    [nn.L1Loss, corrcoef, RuntimeError: Can’t call...\n",
       "15523    [conda list\\r\\n...\\r\\nfastai                  ...\n",
       "15524    [# Auto Encoder\\r\\n\\r\\n\\r\\nimport numpy as np\\...\n",
       "15525    [   def get_image():\\r\\n    img = _load_and_re...\n",
       "15526    [model = Model()\\r\\nmodel.cuda()\\r\\n, model(X)...\n",
       "15527    [model = Model()\\r\\nmodel.cuda()\\r\\n, model(X)...\n",
       "15528    [c, a = torch.tensor(5)    \\r\\nb = torch.tenso...\n",
       "15529    [import torch\\r\\nx = torch.ones(2, 2, requires...\n",
       "15530    [import torch\\r\\nx = torch.ones(2, 2, requires...\n",
       "15531    [nvcr.io/nvidia/cuda  9.0-cudnn7.1-devel-ubunt...\n",
       "15532    [class FeedforwardNeuralNetModel(nn.Module):\\r...\n",
       "15533    [actor = Sequential()\\r\\n        actor.add(Den...\n",
       "15534    [class MyCustomDataset(Dataset):\\r\\n     def _...\n",
       "15535    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15536    [%reset -f\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "15537    [    self.encoder = nn.Sequential(\\r\\n        ...\n",
       "15538    [np.shape(coords_detached) =  (15969, 8)\\r\\nco...\n",
       "15539                                [view, reshape, view]\n",
       "15540                                [view, reshape, view]\n",
       "15542                       [tf.image.ssim, tf.image.psnr]\n",
       "15544    [output, target, Error message, class Net(nn.M...\n",
       "15546    [---------------------------------------------...\n",
       "15547    [TypeError: forward() missing 1 required posit...\n",
       "15548    [def test_model_works_on_gpu():\\r\\n    with to...\n",
       "15549    [def test_model_works_on_gpu():\\r\\n    with to...\n",
       "15550    [def test_model_works_on_gpu():\\r\\n    with to...\n",
       "15551    [def training(model_conv, learning_rate, wd, n...\n",
       "15552    [def getimage(id):\\r\\n     img = self.coco.loa...\n",
       "15553    [def getimage(id):\\r\\n     img = self.coco.loa...\n",
       "15554    [def load_model(checkpoint_path):\\r\\n  '''\\r\\n...\n",
       "15555    [loss_A = criterion(recov_A, real_A)\\r\\nloss_F...\n",
       "15556    [loss_A = criterion(recov_A, real_A)\\r\\nloss_F...\n",
       "15557    [A = torch.randn((5, 2, 3))\\r\\n_, idx = torch....\n",
       "15558    [A = torch.randn((5, 2, 3))\\r\\n_, idx = torch....\n",
       "15559    [A = torch.randn((5, 2, 3))\\r\\n_, idx = torch....\n",
       "15560    [numpy.array, torch.Tensor, import torch\\r\\nim...\n",
       "15561    [class ResNetGenerator(nn.Module):\\r\\n    def ...\n",
       "15562    [optimizer_G.zero_grad()\\r\\n\\r\\n# Identity los...\n",
       "15564    [`Testing started at 2:14 am..\\r\\nC:\\Users\\CY\\...\n",
       "15567    [Dataset, Dataset, class ImageDataset(Dataset)...\n",
       "15568    [Dataset, Dataset, class ImageDataset(Dataset)...\n",
       "15571    [from AlexNetPytorch import*\\r\\nimport torchvi...\n",
       "15573    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15574    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15575    [def __init__(self, hidden_size_IP=100, hidden...\n",
       "15576    [#one\\r\\nloss1.backward()\\r\\nloss2.backward()\\...\n",
       "15584    [torch.empty(5, 3),  torch.empty(5, 3)\\r\\ntens...\n",
       "15587    [sequences, [8, 12, 2], [8, 2], indices, [8], ...\n",
       "15588    [sequences, [8, 12, 2], [8, 2], indices, [8], ...\n",
       "15589    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15590    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15591    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15594    [optimizer, loss, optimizer.step(loss), loss.b...\n",
       "15595    [optimizer, loss, optimizer.step(loss), loss.b...\n",
       "15596    [optimizer, loss, optimizer.step(loss), loss.b...\n",
       "15598    [one_hot = torch.zeros(18).unsqueeze(0)\\r\\none...\n",
       "15599    [Traceback (most recent call last):\\r\\n  File ...\n",
       "15600    [model.train()\\r\\nfor epo in range(epoch):\\r\\n...\n",
       "15601    [model.train()\\r\\nfor epo in range(epoch):\\r\\n...\n",
       "15602    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "15604    [nn.Sequential, Model = nn.Sequential(x.view(x...\n",
       "15606    [from os.path import exists\\r\\nfrom wheel.pep4...\n",
       "15607    [for epoch in range(1, n_epochs+1):\\r\\n    tra...\n",
       "15608    [...\\r\\n^M100%|█████████▉| 452/453 [1:07:07&lt...\n",
       "15609    [criterion = nn.CrossEntropyLoss(), model = Lo...\n",
       "15610    [criterion = nn.CrossEntropyLoss(), model = Lo...\n",
       "15611    [img.shape # -&gt; (batch x H x W x 3)\\r\\nx.sh...\n",
       "15612    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "15613    [Bx2CxHxW, BxCxHxW, output = ReLU(BN(Conv(x)))...\n",
       "15614    [a = torch.randn([2])\\r\\nb = torch.randn([3])\\...\n",
       "15616    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15617    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15618    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15619    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15620    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15621    [DataLoader, DataSet, PyTorch, DataFrame, np.f...\n",
       "15622    [Random Seed:  999\\r\\n------------------------...\n",
       "15624    [checkpoint = {'epoch': epochs, 'model_state_d...\n",
       "15625    [for epoch in range(0, args.epoches):\\r\\n    f...\n",
       "15626                      [Tensor, list, [1, 2048, 1, 1]]\n",
       "15628                      [Tensor, list, [1, 2048, 1, 1]]\n",
       "15629    [10000_model.pth, class Net(nn.Module):\\r\\n   ...\n",
       "15630    [class MnistPartialDataset(Dataset):\\r\\n    de...\n",
       "15631    [[phung@archlinux SqueezeNet-Pruning]$ python ...\n",
       "15632    [[phung@archlinux SqueezeNet-Pruning]$ python ...\n",
       "15633    [[phung@archlinux SqueezeNet-Pruning]$ python ...\n",
       "15634    [#training the classifier\\r\\ncriterion = nn.Cr...\n",
       "15635    [RuntimeError: the Gloo backend is not availab...\n",
       "15636    [NameError: name 'set_trace' is not defined\\r\\...\n",
       "15638                                 [torchvision.models]\n",
       "15639    [matplotlib, plt.close('all'), gc.collect(), c...\n",
       "15640    [import copy\\r\\nimport torch\\r\\nimport torch.n...\n",
       "15641    [import copy\\r\\nimport torch\\r\\nimport torch.n...\n",
       "15642    [import copy\\r\\nimport torch\\r\\nimport torch.n...\n",
       "15643    [loss = loss_fn(outputs, labels), outputs.shap...\n",
       "15644    [A = [1.3, 0.0, 0.6, 0.7, 0.8], [1.3, 0.0, 2.1...\n",
       "15645    [A = [1.3, 0.0, 0.6, 0.7, 0.8], [1.3, 0.0, 2.1...\n",
       "15646    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15647    [make_classification, double, X, y = make_clas...\n",
       "15648    [# loss1, loss2 belong to the same net\\r\\nnet....\n",
       "15649    [(input -&gt; conv2d -&gt; maxpool2d -&gt; max...\n",
       "15652    [RuntimeError: Expected 4-dimensional input fo...\n",
       "15653    [# load the model\\r\\nimport torch\\r\\nmodel=tor...\n",
       "15654    [j, for epoch in range(2):  # loop over the da...\n",
       "15655    [import torch\\r\\nfrom torchvision import model...\n",
       "15656    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15657    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15658    [def compute_kernel(x, y):\\r\\n    x_size = tf....\n",
       "15659    [class RNNBlock(nn.Module):\\r\\n\\r\\ndef __init_...\n",
       "15660    [    import torch\\r\\n    from torch import nn\\...\n",
       "15661    [import torch\\r\\nW = torch.tensor(([1.0]))\\r\\n...\n",
       "15662    [import torch\\r\\nimport torchvision\\r\\n\\r\\n# A...\n",
       "15663                          [[1.2, 3.2, 43.2], [1,2,3]]\n",
       "15664    [import numpy as np\\r\\nimport torch\\r\\na = tor...\n",
       "15665    [# Imports here\\r\\nimport os\\r\\nimport numpy a...\n",
       "15666    [dataloader = torch.utils.data.DataLoader(...)...\n",
       "15667    [def output_size(w , f , stride , padding) : \\...\n",
       "15668    [F.tanh, nn.Parameter(torch.zeros(action_dim))...\n",
       "15669    [Net(\\r\\n  (conv1): Conv2d(1, 6, kernel_size=(...\n",
       "15670    [Traceback (most recent call last):\\r\\n\\r\\n   ...\n",
       "15671    [class SiameseNetwork(nn.Module):\\r\\n    def _...\n",
       "15672    [transform = transforms.Compose(\\r\\n    [trans...\n",
       "15673    [import cv2\\r\\nmy_img = cv2.imread('testset/im...\n",
       "15674    [train_transform = transforms.Compose(\\r\\n    ...\n",
       "15675    [train_transform = transforms.Compose(\\r\\n    ...\n",
       "15676    [conda install pytorch torchvision cuda100 -c ...\n",
       "15677    [data_transforms = {\\r\\n    'train': transform...\n",
       "15678    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15679    [from fastai import *\\r\\nfrom fastai.text impo...\n",
       "15680    [def Sp_Tokenizer(text): \\r\\n    return [tok.t...\n",
       "15681    [...\\r\\nmodel = models.__dict__['densenet121']...\n",
       "15682    [transform = transforms.Compose(\\r\\n    [trans...\n",
       "15683    [Expected input batch_size (1) to match target...\n",
       "15684    [dataset/train/0/456.jpg\\r\\ndataset/train/1/45...\n",
       "15685    [dataset/train/0/456.jpg\\r\\ndataset/train/1/45...\n",
       "15686    [softmax, import numpy as np\\r\\nimport torch\\r...\n",
       "15689    [class():\\r\\n    def forward(input):\\r\\n      ...\n",
       "15690    [net.to(device) \\r\\n, with torch.no_grad():\\r\\...\n",
       "15691    [[30,512,1024], [30,64,64], DiceLoss, def dice...\n",
       "15693    [test_transform_2= transforms.Compose([transfo...\n",
       "15694    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15695                     [img = Variable(img.cuda())\\r\\n]\n",
       "15697    [x, x.shape=(batch_size,10),  x[i][0] = x[i][0...\n",
       "15698    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "15700                        [tf.gather(matrix1, matrix2)]\n",
       "15701    [ x86_64\\r\\nDISTRIB_ID=LinuxMint\\r\\nDISTRIB_RE...\n",
       "15702    [PyTorch, torch.utils.data.DataLoader, CUDA, m...\n",
       "15703    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15705    [            inputs_reg = Variable(data, requi...\n",
       "15706    [            inputs_reg = Variable(data, requi...\n",
       "15707    [            inputs_reg = Variable(data, requi...\n",
       "15708    [            inputs_reg = Variable(data, requi...\n",
       "15709    [k, [[0, 0, 0], [1, 1, 1], [2, 2, 2]], extend(...\n",
       "15710    [torch.nn.LSTM, num_layers, num_layers=2, hidd...\n",
       "15711    [torch.nn.LSTM, num_layers, num_layers=2, hidd...\n",
       "15712    [conda install pytorch torchvision -c pytorch\\...\n",
       "15713    [0.2, 0.4, torch.cat, from typing import List\\...\n",
       "15715    [yeosiz@apollo:~/YAN/color$ python3 main.py\\r\\...\n",
       "15716    [model.cpu(), model.load_state_dict(checkpoint...\n",
       "15717    [gru, feats_tensor, dec_padded_text,   for epo...\n",
       "15718    [torch.Tensor, numpy.ndarray, torch_tensor.shu...\n",
       "15719    [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "15720    [for index in range(0,len(self.files)):\\r\\n  f...\n",
       "15721    [output, torch.autograd, h, c, inp, h, c, h, t...\n",
       "15722    [def __init__(self, ngpu, input_c, output_c, m...\n",
       "15723    [#Test of PyTorch DataLoader and Visual Studio...\n",
       "15724    [Net, net=Net(), Net, forward(self,X), forward...\n",
       "15725    [mean = 33.318421449829934\\r\\nsd = 78.56749081...\n",
       "15727    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "15728    [def select_action(self, state):\\r\\n    probs ...\n",
       "15729    [image_size = 256, class Generator(nn.Module):...\n",
       "15730    [torch.Tensor([1., 2.], device='cuda'), torch....\n",
       "15731    [self.outputs = nn.Linear(NETWORK_WIDTH, 2) # ...\n",
       "15733           [Tensor, (3, 224, 224), plt.imshow(image)]\n",
       "15737           [Tensor, (3, 224, 224), plt.imshow(image)]\n",
       "15739           [Tensor, (3, 224, 224), plt.imshow(image)]\n",
       "15740    [optimizer.step(), model.parameters(), predict...\n",
       "15741    [[1,2,3], [1,2,3], features = torch.tensor(np....\n",
       "15742    [[1,2,3], [1,2,3], features = torch.tensor(np....\n",
       "15743    [torch.jit.trace, torch::jit::load(), torch::f...\n",
       "15744    [cross entropy, MSE, MSE, from torch import nn...\n",
       "15745    [RuntimeError: Error(s) in loading state_dict ...\n",
       "15746    [import torch\\r\\nfrom torch.nn.modules.distanc...\n",
       "15747    [import torch\\r\\nfrom torch.nn.modules.distanc...\n",
       "15748    [class MSourceDataSet(Dataset):\\r\\n\\r\\n    def...\n",
       "15749    [o=torchfile.load('train.t7')\\r\\nx=tf.convert_...\n",
       "15750    [&gt; mpirun -np 3 -H 192.168.100.101:3 python...\n",
       "15751    [----&gt; 5     for i, data in enumerate(train...\n",
       "15752    [#############################################...\n",
       "15753    [ValueError: Target size (torch.Size([4, 256, ...\n",
       "15754    [from tensorboardX import SummaryWriter\\r\\nwri...\n",
       "15755    [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "15756    [backward(), import torch\\r\\nx = torch.ones(2,...\n",
       "15757    [truth = [N, 1, 224, 224]\\r\\n\\r\\nnet_output = ...\n",
       "15758    [x = torch.randn(batch_size, 2)\\r\\ny_hat = mod...\n",
       "15759                             [DataLoader, DataLoader]\n",
       "15760                             [DataLoader, DataLoader]\n",
       "15761                             [DataLoader, DataLoader]\n",
       "15762                             [DataLoader, DataLoader]\n",
       "15764                             [DataLoader, DataLoader]\n",
       "15765    [.to(), to(), nn.Module, Tensor, to(), nn.Modu...\n",
       "15767    [def answer(x):\\r\\nreturn 3 * x[:,0] + x[:,1] ...\n",
       "15768    [net = model()\\r\\ncopy_net = model()\\r\\n\\r\\nfo...\n",
       "15769    [tensor([0,10,0,16]), tensor([0,1,0,1]), tf.ca...\n",
       "15771    [tensor([0,10,0,16]), tensor([0,1,0,1]), tf.ca...\n",
       "15774    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "15775    [     data_transform = transforms.Compose([tra...\n",
       "15776    [File \"/home/username/anaconda3/lib/python3.6/...\n",
       "15777    [self.filenames.append(fn)\\r\\nAttributeError: ...\n",
       "15778    [[800,60,200], [800,1], class DataCurate(Datas...\n",
       "15779        [[71 32 1], [100 32 1], [29 32 1], [29 32 1]]\n",
       "15780    [import torch\\r\\n\\r\\ndef myFirstFunction(param...\n",
       "15781    [import torch\\r\\n\\r\\ndef myFirstFunction(param...\n",
       "15782    [import torch\\r\\n\\r\\ndef myFirstFunction(param...\n",
       "15784    [8, 6, [ Variable[CUDAFloatType]{8,6} ] \\r\\n  ...\n",
       "15785    [import torch\\r\\nimport random\\r\\nimport panda...\n",
       "15786    [import torch\\r\\n\\r\\n\\r\\ndef make_covariance_m...\n",
       "15787    [\"RuntimeError: size mismatch, m1: [1 x 7744],...\n",
       "15788    [class VAE(torch.nn.Module):\\r\\n\\r\\n def __ini...\n",
       "15789    [y = activation(torch.sum(features*weights) + ...\n",
       "15790    [y = activation(torch.sum(features*weights) + ...\n",
       "15791    [    Layer (type)               Output Shape  ...\n",
       "15792    [torch.Size([2, 5, 32]), channels, batch_size,...\n",
       "15793    [torch.Size([2, 5, 32]), channels, batch_size,...\n",
       "15794    [class MultipleSourceDataSet(Dataset):\\r\\n    ...\n",
       "15795    [last_layer =nn.Linear(n_inputs, len(classes))...\n",
       "15796    [last_layer =nn.Linear(n_inputs, len(classes))...\n",
       "15797    [input = Input(shape=(max_len,))\\r\\nmodel = Em...\n",
       "15798                                                [fc1]\n",
       "15799    [fblualib, ./install_all.sh, fblualib, + echo ...\n",
       "15800                                  [view(), squeeze()]\n",
       "15801    [X, (A, B, C, D), I, (A, B), I, [0, C), Y, (A,...\n",
       "15804    [nn.L1Loss(), class LossV1(nn.Module):\\r\\n    ...\n",
       "15808    [ import torch\\r\\n import numpy as np\\r\\n impo...\n",
       "15810    [def run(rank, size, hostname):\\r\\n    print(\"...\n",
       "15811    [images, labels, trainset = torchvision.datase...\n",
       "15812    [class MyCustomLayer(nn.Module):\\r\\n  def __in...\n",
       "15813    [class MyCustomLayer(nn.Module):\\r\\n  def __in...\n",
       "15814    [nn.Linear(in_dim, out_dim), model.parameters(...\n",
       "15815    [    unet = Unet()\\r\\n    optimizer = torch.op...\n",
       "15816    [Assertion cur_target &gt;= 0 &amp;&amp; cur_t...\n",
       "15817    [class RNNModel(nn.Module):\\r\\n\\r\\ndef __init_...\n",
       "15818    [Dataset, __getitem__(), Dataset(data.Dataset)...\n",
       "15819    [nvcc: NVIDIA (R) Cuda compiler driver\\r\\nCopy...\n",
       "15821    [with torch.no_grad():\\r\\n    &lt;code&gt;\\r\\n...\n",
       "15822    [with torch.no_grad():\\r\\n    &lt;code&gt;\\r\\n...\n",
       "15823    [model.input_shape, model.output_shape, model....\n",
       "15824    [images/T001.jpg \\r\\nimages/T002.jpg \\r\\n...\\r...\n",
       "15825    [X = torch.ones(batch_size, dim)\\r\\nX_ = torch...\n",
       "15826    [(batch_size, step, vec_size), Tensor(32, 64, ...\n",
       "15829    [n, l, l, output_layer_n = self.LinearLayer(ou...\n",
       "15830    [torchtext.data.Dataset, from torchtext import...\n",
       "15831    [torchtext.data.Dataset, from torchtext import...\n",
       "15832    [torchtext.data.Dataset, from torchtext import...\n",
       "15833    [torchtext.data.Dataset, from torchtext import...\n",
       "15834      [torch.nn.Dropout, torch.nn.functional.Dropout]\n",
       "15835      [torch.nn.Dropout, torch.nn.functional.Dropout]\n",
       "15836      [torch.nn.Dropout, torch.nn.functional.Dropout]\n",
       "15837    [    model_ft.eval()\\r\\n    test_data, test_ta...\n",
       "15838    [optimizer.param_groups[0]['lr'], self.optimiz...\n",
       "15839    [lens = [3, 5, 4]\\r\\n, mask = [[1, 1, 1, 0, 0]...\n",
       "15840    [lens = [3, 5, 4]\\r\\n, mask = [[1, 1, 1, 0, 0]...\n",
       "15841    [lens = [3, 5, 4]\\r\\n, mask = [[1, 1, 1, 0, 0]...\n",
       "15842             [Diters, Diters, Diters, Diters, Diters]\n",
       "15843    [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "15844    [  epoch    train_loss    valid_loss     dur\\r...\n",
       "15845    [  epoch    train_loss    valid_loss     dur\\r...\n",
       "15846    [...\\r\\nmodel.cuda()\\r\\ndata_tensor = data_ten...\n",
       "15847    [nn.DataParallel, nn.DistributedDataParallel, ...\n",
       "15849                        [a @ b, a.mm(b), a.matmul(b)]\n",
       "15850    [def dice(input, target,weights=torch.tensor([...\n",
       "15851    [def __init__(self):\\r\\n    super(Net, self)._...\n",
       "15852    [Epoch: [5][0/170]       Time 0.237 (0.237)   ...\n",
       "15853    [a = np.random.randn(2,2,3)\\r\\nb = np.eye(2,2)...\n",
       "15854    [0.4.1, 7.3.0, AMD A8-7410 APU with AMD Radeon...\n",
       "15856    [import torch\\r\\nimport torchvision\\r\\n\\r\\n# d...\n",
       "15857    [import torch\\r\\nimport torchvision\\r\\n\\r\\n# d...\n",
       "15858    [a, a = np.arange(1, 11, dtype = 'float32')\\r\\...\n",
       "15859    [def __init__([...])\\r\\n    [...]\\r\\n    self....\n",
       "15861    [import torchvision as tv\\r\\nimport numpy as n...\n",
       "15862    [import torchvision as tv\\r\\nimport numpy as n...\n",
       "15864    [model.zero_grad()                            ...\n",
       "15865    [model.zero_grad()                            ...\n",
       "15866    [t3, a = np.random.randn(1, 1, 2, 3)\\r\\n\\r\\nt1...\n",
       "15867    [t3, a = np.random.randn(1, 1, 2, 3)\\r\\n\\r\\nt1...\n",
       "15868    [import torch\\r\\nimport time\\r\\n\\r\\n###CPU\\r\\n...\n",
       "15869    [ix, vals, vec = torch.zeros(4, dtype=torch.fl...\n",
       "15871    [up = nn.ConvTranspose2d(3, 128, 2, stride=2)\\...\n",
       "15872    [optimizer.step(), model.step(), import torch\\...\n",
       "15873    [Exception in Thread: ValueError: signal numbe...\n",
       "15874    [Exception in Thread: ValueError: signal numbe...\n",
       "15875    [Exception in Thread: ValueError: signal numbe...\n",
       "15876    [train_iterator = data.BucketIterator.splits(\\...\n",
       "15877    [%matplotlib inline\\r\\nfrom graphviz import Di...\n",
       "15878    [%matplotlib inline\\r\\nfrom graphviz import Di...\n",
       "15879    [%matplotlib inline\\r\\nfrom graphviz import Di...\n",
       "15880    [%matplotlib inline\\r\\nfrom graphviz import Di...\n",
       "15881    [%matplotlib inline\\r\\nfrom graphviz import Di...\n",
       "15882    [x_dat, y_dat, class FunctionDataset(Dataset):...\n",
       "15884    [a = torch.tensor(np.random.randn(), dtype=dty...\n",
       "15885    [x = torch.tensor([4.0, 5.0], requires_grad=Tr...\n",
       "15886    [---------------------------------------------...\n",
       "15887    [---------------------------------------------...\n",
       "15888    [---------------------------------------------...\n",
       "15889    [inputs, targets = torch.tensor(inputs, dtype=...\n",
       "15891    [import fastai.models\\r\\nimport fastai.nlp\\r\\n...\n",
       "15892    [image_data = dset.ImageFolder(root=\"drive/Sem...\n",
       "15893    [image_data = dset.ImageFolder(root=\"drive/Sem...\n",
       "15894    [image_data = dset.ImageFolder(root=\"drive/Sem...\n",
       "15895    [from tensorflow.examples.tutorials.mnist impo...\n",
       "15897                      [self.rnn.flatten_parameters()]\n",
       "15898    [$ lspci | grep NVIDIA\\r\\n, 01:00.0 3D control...\n",
       "15900    [import torch\\r\\nx= torch.empty(5,3) # &lt;===...\n",
       "15901    [import torch\\r\\nX = torch.tensor([[0.5, 0.3, ...\n",
       "15902    [import torch\\r\\nX = torch.tensor([[0.5, 0.3, ...\n",
       "15903    [import torch\\r\\nX = torch.tensor([[0.5, 0.3, ...\n",
       "15904    [def tp_fp_loss(yhat, y):\\r\\n    total_score =...\n",
       "15905    [x = torch.rand(20, 1, 120, 120)\\r\\n, x.squeez...\n",
       "15907    [x = torch.rand(20, 1, 120, 120)\\r\\n, x.squeez...\n",
       "15908    [x = torch.rand(20, 1, 120, 120)\\r\\n, x.squeez...\n",
       "15910    [batch_size =50 #Number of x's we pass through...\n",
       "15912    [import torch\\r\\ntorch.manual_seed(7)\\r\\nfeatu...\n",
       "15913    [x = torch.Tensor([[.5, .3, 2.1]])\\r\\nprint(x)...\n",
       "15914    [for i, (input, target) in enumerate(train_loa...\n",
       "15915    [for i, (input, target) in enumerate(train_loa...\n",
       "15916    [pack_sequence, pack_padded_sequence, PackedSe...\n",
       "15917    [loaded_state = torch.load(model_path+seq_to_s...\n",
       "15918    [train_loader = DataLoader(train_set, batch_si...\n",
       "15919    [# Export the model\\r\\ntorch_out = torch.onnx....\n",
       "15920    [# Export the model\\r\\ntorch_out = torch.onnx....\n",
       "15921    [# Export the model\\r\\ntorch_out = torch.onnx....\n",
       "15922    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15923    [ImportError while importing test module '/hom...\n",
       "15924    [param_groups, for param in child.parameters()...\n",
       "15925    [def forward(self, features, rois):\\r\\n       ...\n",
       "15926    [class FC_Resnet(nn.Module):\\r\\n    def __init...\n",
       "15927    [class FC_Resnet(nn.Module):\\r\\n    def __init...\n",
       "15928    [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "15929    [(256,256), batch_size = 4, (4,64,64), Conv1d(...\n",
       "15930    [input = torch.randn(3, 10)\\r\\nresult = torch....\n",
       "15931    [input = torch.randn(3, 10)\\r\\nresult = torch....\n",
       "15932    [---------------------------------------------...\n",
       "15933    [---------------------------------------------...\n",
       "15934    [net=net.to(device)\\r\\nnet.fc1.weight.type()\\r...\n",
       "15935    [torch.cuda.is_available()\\r\\n, # Name        ...\n",
       "15936    [torch.cuda.is_available()\\r\\n, # Name        ...\n",
       "15937    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "15938    [x = torch.bernoulli(my_data)\\r\\n, import nump...\n",
       "15939    [torch.index_select, class_energy = torch.rand...\n",
       "15940    [model = init_from_scratch(args, train_exs, de...\n",
       "15941    [class autoencoder(nn.Module):\\r\\n    def __in...\n",
       "15942    [out[:,0,:] == out[:,1,:] == out[:, 2, :], # P...\n",
       "15943    [out[:,0,:] == out[:,1,:] == out[:, 2, :], # P...\n",
       "15944    [FloatTensors, FloatTensor, DoubleTensor, clas...\n",
       "15945    [FloatTensors, FloatTensor, DoubleTensor, clas...\n",
       "15946    [import torch\\r\\nmyTensor = torch.randn(2, 2,r...\n",
       "15947    [spyder                    3.3.1  \\r\\nipython ...\n",
       "15948    [torchtext.data.TabularDataset, torchtext.data...\n",
       "15949    [out_a, out_p, out_n = model(data_a), model(da...\n",
       "15951    [import matplotlib.pylab as plt\\r\\nimport nump...\n",
       "15952    [import matplotlib.pylab as plt\\r\\nimport nump...\n",
       "15954    [myTensor3 = torch.arange(torch.numel(myTensor...\n",
       "15955    [lstm = nn.LSTM(5, 100, 1, bidirectional=True)...\n",
       "15956    [lstm = nn.LSTM(5, 100, 1, bidirectional=True)...\n",
       "15957    [class NeuralNet2(nn.Module):\\r\\n    def __ini...\n",
       "15958                                [loss.backward()\\r\\n]\n",
       "15959    [conv2d, stride=2, conv2d, stride=1, import te...\n",
       "15960    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15961    [torch.nn.utils.rnn.pack_padded_sequence(), im...\n",
       "15962    [can't convert np.ndarray of type numpy.object...\n",
       "15966    [(classifier): Sequential(\\r\\n    (0): Linear(...\n",
       "15967    [loss = CrossEntropyLoss()\\r\\ninput = torch.ra...\n",
       "15968    [loss = CrossEntropyLoss()\\r\\ninput = torch.ra...\n",
       "15969    [loss = CrossEntropyLoss()\\r\\ninput = torch.ra...\n",
       "15970    [loss = CrossEntropyLoss()\\r\\ninput = torch.ra...\n",
       "15971    [x, w_in,w_in, w_in=14, x_mapped, w_out,w_out,...\n",
       "15972    [gru = nn.GRU(input_size, hidden_size, num_lay...\n",
       "15973    [gru = nn.GRU(input_size, hidden_size, num_lay...\n",
       "15974    [import torch.onnx\\r\\nimport torch.nn as nn\\r\\...\n",
       "15976    [model = SqueezeNext()\\r\\nmodel = model.to(dev...\n",
       "15978    [import torch\\r\\n\\r\\nx = torch.randn(4, requir...\n",
       "15979    [div_term = torch.exp(torch.arange(0, d_model,...\n",
       "15983    [torch.manual_seed(0)\\r\\na = torch.randn(5,3)\\...\n",
       "15984    [In [1]: import torch\\r\\n\\r\\nIn [2]: a = torch...\n",
       "15985    [In [1]: import torch\\r\\n\\r\\nIn [2]: a = torch...\n",
       "15986    [export Caffe2_DIR=&lt;path to my pytorch&gt;/...\n",
       "15987    [\"\"\"Peform hyperparemeters search\"\"\"\\r\\n\\r\\nim...\n",
       "15989    [grad_h = grad_h_relu.clone(), h = x.mm(w1)\\r\\...\n",
       "15990    [random.seed(seed)\\r\\nnp.random.seed(seed)\\r\\n...\n",
       "15992    [it, import torch\\r\\nit = torch.tensor([0,  0,...\n",
       "15993    [def _mahalanobis(X):\\r\\n    VI = torch.invers...\n",
       "15995    [new_ones(), ones(), x2.new_ones(3,2, dtype=to...\n",
       "15996    [import torch\\r\\nimport numpy, math\\r\\nimport ...\n",
       "15997    [tensor([[[112.,  -1.,  -1.,  -1.,  -1.,  -1.]...\n",
       "15999    [focal_loss_fixed, optimizer = optim.SGD(net.p...\n",
       "16000    [focal_loss_fixed, optimizer = optim.SGD(net.p...\n",
       "16001    [densenet = torch.load(model_path)\\r\\ndensenet...\n",
       "16002    [(Pdb) import os\\r\\n(Pdb) import numpy as np\\r...\n",
       "16004    [from torch.utils.data import DataLoader,Datas...\n",
       "16006    [deviceQuery, Device 0: \"Tesla K40m\"\\r\\n...\\r\\...\n",
       "16007    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16010    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16011    [import pyro as p\\r\\nimport pyro.distributions...\n",
       "16012                     [nn.Conv2d, 0 0 0, 0 1 0, 0 0 0]\n",
       "16014    [Ubuntu 14.04.1\\r\\nPython 3.6.4\\r\\nPytorch 0.4...\n",
       "16015    [In [137]: x = x.new_ones((5, 3), dtype=torch....\n",
       "16016    [ux = torch.tensor(np.array([[255,1,255],[255,...\n",
       "16017    [requirements.txt, docker build -t flask-sampl...\n",
       "16018    [tch.map,  import torch as tch # or numpy\\r\\n\\...\n",
       "16019    [RxR -&gt; R, np.multiply.outer, np.subtract.o...\n",
       "16020    [import torch\\r\\n\\r\\na = torch.tensor([1, 2])\\...\n",
       "16021    [[[0,1],\\r\\n [0,6],\\r\\n [0,7],\\r\\n [1,4],\\r\\n ...\n",
       "16022    [224, transforms.RandomResizedCrop, # transfor...\n",
       "16023    [224, transforms.RandomResizedCrop, # transfor...\n",
       "16024    [which python, /usr/bin/python\\r\\n, ----------...\n",
       "16025    [the_model = torchvision.models.densenet121(pr...\n",
       "16026    [libibverbs: Warning: couldn't open config dir...\n",
       "16027    [torch.nn.DataParallel(model, device_ids= args...\n",
       "16028    [PyTorch, You can do many crazy things with au...\n",
       "16030    [my_optimizer = torch.optim.SGD(my_model.param...\n",
       "16031    [%debug\\r\\n# Create tensors of shape (10, 3) a...\n",
       "16032    [%debug\\r\\n# Create tensors of shape (10, 3) a...\n",
       "16033    [%debug\\r\\n# Create tensors of shape (10, 3) a...\n",
       "16034    [    class Net(torch.nn.Module):\\r\\n        de...\n",
       "16035    [def train(train_loader, model, optimizer, epo...\n",
       "16036    [torchvision.models, ReLU, register_backward_h...\n",
       "16039    [x = torch.rand(32,3,416, 416).cuda()\\r\\nmodel...\n",
       "16040    [def forward(self,x1,x2):\\r\\n    out_conv1a = ...\n",
       "16041    [pip install --user pytorch==0.1.2\\r\\n, Collec...\n",
       "16042    [&gt; # at beginning of the script\\r\\ndevice =...\n",
       "16043      [data.TabularDataset.splits(path='./data')\\r\\n]\n",
       "16044    [import torch\\r\\nimport torchvision\\r\\n\\r\\n# A...\n",
       "16045    [import torch\\r\\n\\r\\nclass NNet(torch.nn.Modul...\n",
       "16046    [import torch\\r\\n\\r\\nclass NNet(torch.nn.Modul...\n",
       "16047    [for i in range(5):\\r\\n  optimizer.zero_grad()...\n",
       "16048    [from torchvision import datasets, transforms,...\n",
       "16049    [from torchvision import datasets, transforms,...\n",
       "16050    [from torchvision import datasets, transforms,...\n",
       "16051    [from torchvision import datasets, transforms,...\n",
       "16052    [torch.autograd.backward(loss_seq, grad_seq), ...\n",
       "16055    [torch.set_default_tensor_type(torch.cuda.Floa...\n",
       "16056    [class UNetResNet(nn.Module):\\r\\n\\r\\ndef __ini...\n",
       "16057    [effective_batchsize= batch_size*iter_size*n_gpu]\n",
       "16059    [print(\"Probability:\", probs)\\r\\nProbability: ...\n",
       "16060    [filters = 256\\r\\nkernel_size = 3\\r\\nstrides =...\n",
       "16061    [class PR(nn.Module):\\r\\n        def __init__(...\n",
       "16062    [class PR(nn.Module):\\r\\n        def __init__(...\n",
       "16063    [stream0 = torch.get_stream()\\r\\nstream1 = tor...\n",
       "16065    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16066    [backwards, retain_graph=True, # Code in file ...\n",
       "16067    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16068    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16069    [input01_train.png, input01_test.png,         ...\n",
       "16070    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16073    [# -*- coding: utf-8 -*-\\r\\n\\r\\nimport torch\\r...\n",
       "16074    [x = torch.ones(2, 2, requires_grad=True)\\r\\ny...\n",
       "16075    [cv2, opencv, !pip install opencv-python\\r\\n, ...\n",
       "16077    [import torch\\r\\nimport datetime\\r\\nprint(torc...\n",
       "16079    [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "16080    [[108416, 3], [108416], 2.2623, optimizer.step...\n",
       "16081    [.jpg, # transforms to apply to the data\\r\\ntr...\n",
       "16082    [.jpg, # transforms to apply to the data\\r\\ntr...\n",
       "16083    [.jpg, # transforms to apply to the data\\r\\ntr...\n",
       "16084    [06:00.0 VGA compatible controller: NVIDIA Cor...\n",
       "16085    [(batch_size X input_features X num_of_one_hot...\n",
       "16086    [img_name = os.path.join(self.root_dir, self.l...\n",
       "16087    [torch.save(agent.qnetwork_local.state_dict(),...\n",
       "16088    [torch.save(agent.qnetwork_local.state_dict(),...\n",
       "16090    [print(torch.__version__), %reset -f\\r\\n\\r\\nim...\n",
       "16091    [deconv(kernel_size=2, stride=2, padding='vali...\n",
       "16092    [s = np.linspace(-1,1,100)\\r\\n#The \"data\"\\r\\nx...\n",
       "16094    [import numpy as np\\r\\n\\r\\na = np.ones((3,3))\\...\n",
       "16095    [input = torch.randn(32, 35)\\r\\n, input2 = tor...\n",
       "16096    [def random_weight(shape):\\r\\n    if len(shape...\n",
       "16097    [torch.Size([batch_size, 9, 5]), torch.Size([3...\n",
       "16099    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16100    [pytorch, torch.multiprocessing, Too many open...\n",
       "16101    [import numpy as np\\r\\na = np.random.randn(5,3...\n",
       "16102    [/home/dex/anaconda3/lib/python3.6/site-packag...\n",
       "16103    [def baseline_als(y, lam, p, niter=10):\\r\\n  L...\n",
       "16104    [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "16105    [Compiled slug size: 789.8M is too large (max ...\n",
       "16107    [pip install fastai\\r\\n, \"Command \"python setu...\n",
       "16108    [N = x.size(0) # number of cnn kernel\\r\\nlower...\n",
       "16109    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16110    [shape = [x,y,z,21], x = batch_size, y = image...\n",
       "16111    [import torch\\r\\nseq = [1,2,3]      # seq of v...\n",
       "16112    [import torch\\r\\nseq = [1,2,3]      # seq of v...\n",
       "16113    [class UNetResNet(nn.Module):\\r\\ndef __init__(...\n",
       "16114    [epochs = 3\\r\\nprint_every = 40\\r\\nsteps = 0\\r...\n",
       "16115    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "16117    [class PyTorchUNet(Model):\\r\\n    ....\\r\\n    ...\n",
       "16118    [model.to('cuda')\\r\\nmodel.eval()\\r\\n\\r\\nfor i...\n",
       "16119    [&lt;bound method Module.state_dict of VGG(\\r\\...\n",
       "16120    [import torch\\r\\ntorch.manual_seed(0)\\r\\nN = 1...\n",
       "16121    [pipeline_network, for train_idx, valid_idx in...\n",
       "16122    [for epoch in range(epochs):\\r\\n    for i, dat...\n",
       "16123    [class UNetResNet(nn.Module):\\r\\n    \"\"\"PyTorc...\n",
       "16124    [DataLoader, '1_1.png', '1_2.png', '1_3.png', ...\n",
       "16125    [def validation(model, testloader, criterion):...\n",
       "16127    [model = models.vgg16(pretrained=True)\\r\\nmode...\n",
       "16128    [model = models.vgg16(pretrained=True)\\r\\nmode...\n",
       "16129    [model = models.vgg16(pretrained=True)\\r\\nmode...\n",
       "16130    [3 x width x height, 0-1, img = io.imread(img_...\n",
       "16131    [netG_1 = torch.load('netG.pth')\\r\\nnetG_2 = t...\n",
       "16132    [from __future__ import print_function\\r\\nimpo...\n",
       "16133    [[1, 2, 3], [[1, 2, 3],\\r\\n[1, 2, 3],\\r\\n[1, 2...\n",
       "16134    [max_norm (float, optional) – If given, will r...\n",
       "16136    [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "16137    [(16, 4096, 3), (16, 32768, 3), dim=1, # a.sha...\n",
       "16138    [(16, 4096, 3), (16, 32768, 3), dim=1, # a.sha...\n",
       "16139    [(16, 4096, 3), (16, 32768, 3), dim=1, # a.sha...\n",
       "16140    [torch.sort, x = torch.tensor([30., 40., 20.])...\n",
       "16141    [torch.topk(input, k, dim=None, largest=True, ...\n",
       "16142    [transform_train = transforms.Compose(\\r\\n    ...\n",
       "16143    [(16, 4096, 3), (16, 32768, 3), dim=1, gather,...\n",
       "16145    [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "16146    [class BatchWrapper:\\r\\n  def __init__(self, d...\n",
       "16148    [a = torch.randint(0,10,[3,3,3,3])\\r\\nb = torc...\n",
       "16149    [pytorch, .to, tensorflow, with tf.device('/de...\n",
       "16150    [ValueError: only one element tensors can be c...\n",
       "16151    [ValueError: only one element tensors can be c...\n",
       "16152    [ValueError: only one element tensors can be c...\n",
       "16153    [import torch\\r\\n\\r\\n# params\\r\\ntte_bins = np...\n",
       "16154    [with torch.set_grad_enabled(phase == 'train')...\n",
       "16155    [with torch.set_grad_enabled(phase == 'train')...\n",
       "16156    [from __future__ import print_function\\r\\nimpo...\n",
       "16157    [self.conv1 = nn.Conv2d(3, 6, 5)\\r\\nself.conv2...\n",
       "16161    [class DownSizePairImageFolder(ImageFolder):\\r...\n",
       "16162    [import torch\\r\\nsample_1, sample_2 = torch.on...\n",
       "16164    [convolution, convolution, relu, train_dataset...\n",
       "16165    [for i in range(10):\\r\\n    for j in range(10)...\n",
       "16167                         [torch.tensor, torch.Tensor]\n",
       "16170                         [torch.tensor, torch.Tensor]\n",
       "16171    [from torchvision import datasets, transforms\\...\n",
       "16172    [from torchvision import datasets, transforms\\...\n",
       "16173    [out.backward(), out.backward(torch.tensor(1))...\n",
       "16174    [pip3 install --no-cache-dir torch\\r\\n, Comman...\n",
       "16175    [datasets.ImageFolder, from torchvision import...\n",
       "16177    [tar.gz, ---\\r\\nCondaHTTPError: HTTP None None...\n",
       "16178    [class QandA(nn.Module):\\r\\n    def __init__(s...\n",
       "16179    [python demo.py, tensorboard --logdir runs, tf...\n",
       "16180    [3x224x224, [3,224,224], Return/Output:\\r\\n(3,...\n",
       "16181    [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "16183    [[packages]\\r\\ntorch = {file = \"http://downloa...\n",
       "16184    [Batch x H x W, Batch x H x W, 0, 1, scipy.ndi...\n",
       "16185    [embed_0_out = embed_0(input_0) # sequence inp...\n",
       "16186    [def __init__(self, csvPath, imageHeight, imag...\n",
       "16187    [allennlp, pip3, allennlp, torch=0.4.0, torch=...\n",
       "16188    [def make_step(model, target_model, optimizer,...\n",
       "16189    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16190    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16191    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16192    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16193    [.pth.tar, model = torch.load('iNat_2018_Incep...\n",
       "16194    [tensor = torch.tensor(df.values)\\r\\ntensor.si...\n",
       "16195    [lstm = nn.LSTM(10, 5, batch_first=True)\\r\\nst...\n",
       "16196    [GoodRam IRDM Pro 240GB SATA3 (IRP-SSDPR-S25B-...\n",
       "16197    [tmp = torch.ones(3, 2, 2, requires_grad=True)...\n",
       "16198    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16199    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16200    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16201    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16202    [0.3.1, my_tensor[i] = 42\\r\\n, # test paramete...\n",
       "16203    [0.3.1, my_tensor[i] = 42\\r\\n, # test paramete...\n",
       "16204    [0.3.1, my_tensor[i] = 42\\r\\n, # test paramete...\n",
       "16205    [def save_checkpoint(state, is_best, filename=...\n",
       "16206    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "16207    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "16208    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "16209    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "16212                      [Module, model, Module, Module]\n",
       "16213                      [Module, model, Module, Module]\n",
       "16214    [from multiprocessing import freeze_support\\r\\...\n",
       "16215    [train = data.TabularDataset(path='./data.csv'...\n",
       "16216    [import torch.nn as nn\\r\\nB = nn.Bilinear(2, 2...\n",
       "16217    [Subset, train, test = torch.utils.data.random...\n",
       "16218    [Subset, train, test = torch.utils.data.random...\n",
       "16219    [Subset, train, test = torch.utils.data.random...\n",
       "16220    [Subset, train, test = torch.utils.data.random...\n",
       "16221    [my_model.load_state_dict(torch.load(PATH)), t...\n",
       "16222    [def main():\\r\\n#Get the time and data\\r\\nnow ...\n",
       "16223    [x1 = self.conv1(inp)\\r\\nx = self.conv2(x)\\r\\n...\n",
       "16225    [tensor_x = torch.stack([torch.Tensor(i) for i...\n",
       "16226    [Tensor, def push_to_tensor(tensor, x):\\r\\n   ...\n",
       "16227    [Tensor, def push_to_tensor(tensor, x):\\r\\n   ...\n",
       "16228                          [param_group, state_dict()]\n",
       "16229    [from multiprocessing import freeze_support\\r\\...\n",
       "16230    [from multiprocessing import freeze_support\\r\\...\n",
       "16231    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "16232    [python train_v2.py, Traceback (most recent ca...\n",
       "16233    [python train_v2.py, Traceback (most recent ca...\n",
       "16234    [python train_v2.py, Traceback (most recent ca...\n",
       "16235    [import torch\\r\\nparameter_vector = torch.tens...\n",
       "16236    [with torch.no_grad():\\r\\n    linear = nn.Line...\n",
       "16239    [with torch.no_grad():\\r\\n    linear = nn.Line...\n",
       "16241    [# Define network architecture\\r\\nclass Net(nn...\n",
       "16242                                [.data, .data, .data]\n",
       "16243                                [.data, .data, .data]\n",
       "16245    [batch_size = 4\\r\\nnumber_of_sentences_in_docu...\n",
       "16246    [pip install git+https://github.com/fastai/fas...\n",
       "16247    [import torch\\r\\nN, D_in, H, D_out = 64, 1000,...\n",
       "16248    [import torch\\r\\nN, D_in, H, D_out = 64, 1000,...\n",
       "16249    [OSError: [Errno 22] Invalid argument:'&lt;C:/...\n",
       "16250    [NeuralNetClassifier, optimizer__params, net =...\n",
       "16251    [for, optimizer.step(), torch.equal(), .detach...\n",
       "16252    [conf_loss = cross_entropy_loss(conf_preds.vie...\n",
       "16253    [with open(\"Data/all_rewards.txt\", \"wb\") as f:...\n",
       "16254    [t = torch.tensor([[1, 0, 0, 0], [0, 0, 1, 0],...\n",
       "16255    [t = torch.tensor([[1, 0, 0, 0], [0, 0, 1, 0],...\n",
       "16256    [t = torch.tensor([[1, 0, 0, 0], [0, 0, 1, 0],...\n",
       "16257    [ model\\r\\nnn.Sequential {\\r\\n  [input -&gt; (...\n",
       "16259    [THCudaCheck FAIL file=/opt/conda/conda-bld/py...\n",
       "16260    [THCudaCheck FAIL file=/opt/conda/conda-bld/py...\n",
       "16261    [THCudaCheck FAIL file=/opt/conda/conda-bld/py...\n",
       "16262    [THCudaCheck FAIL file=/opt/conda/conda-bld/py...\n",
       "16263    [THCudaCheck FAIL file=/opt/conda/conda-bld/py...\n",
       "16264    [ImageNet, inception, Alexnet, Pytorch, incept...\n",
       "16265    [RuntimeError: Expected object of type torch.L...\n",
       "16266    [RuntimeError: Expected object of type torch.L...\n",
       "16267    [data.transforms, data_transforms = {\\r\\n    '...\n",
       "16268    [TypeError: expected torch.LongTensor (got tor...\n",
       "16269    [TypeError: expected torch.LongTensor (got tor...\n",
       "16270    [TypeError: expected torch.LongTensor (got tor...\n",
       "16271    [    from torch.utils.data import Dataset\\r\\n ...\n",
       "16272    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16273    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "16274    [w, rnn, import numpy as np\\r\\nimport torch as...\n",
       "16275    [requires_grad=True, y, y.requires_grad=True, ...\n",
       "16276    [pip3 install http://download.pytorch.org/whl/...\n",
       "16277    [AttributeError: cannot assign module before M...\n",
       "16278    [class RLSTM(nn.Module):\\r\\n    def __init__(s...\n",
       "16279    [import torch\\r\\nimport torchvision\\r\\n\\r\\ndev...\n",
       "16280    [_operators.py, TypeError: Error while convert...\n",
       "16281    [conda update --all, conda install -c pytorch ...\n",
       "16282    [import torch.utils.data as data\\r\\nfrom torch...\n",
       "16283    [import torch.utils.data as data\\r\\nfrom torch...\n",
       "16284    [F(X), F(X + e), e, dF(X)/dX, dF(X)/dX,   grad...\n",
       "16285    [F(X), F(X + e), e, dF(X)/dX, dF(X)/dX,   grad...\n",
       "16286    [    # Loads the images for use with the CNN.\\...\n",
       "16287    [    # Loads the images for use with the CNN.\\...\n",
       "16288    [0, 9, idx_to_class = {0: \"0\", 1: \"1\", 2: \"2\",...\n",
       "16289    [para_k, COV, para_k=torch.tensor([2.0],requir...\n",
       "16290    [import warnings\\r\\nwarnings.filterwarnings('i...\n",
       "16291    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16292    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16293    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16294    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16295    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16296    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16297    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16298    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16299    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16300    [net = Model()\\r\\ncriterion = torch.nn.BCELoss...\n",
       "16301    [4096, fc7, alexnet = models.alexnet(pretraine...\n",
       "16303    [dimensions_input = 10\\r\\nhidden_layer_nodes =...\n",
       "16304    [&gt;conda install -c pytorch pytorch (as inst...\n",
       "16305    [&gt;conda install -c pytorch pytorch (as inst...\n",
       "16306    [&gt;conda install -c pytorch pytorch (as inst...\n",
       "16307    [#The file contains 163780 characters\\r\\n#The ...\n",
       "16308    [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "16309    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16310    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16311    [ loss = F.nll_loss(sigm, trg_, ignore_index=2...\n",
       "16312    [for i, data in enumerate(zip(dataloaders1, da...\n",
       "16313    [for i, data in enumerate(zip(dataloaders1, da...\n",
       "16314    [for i, data in enumerate(zip(dataloaders1, da...\n",
       "16315    [for i, data in enumerate(zip(dataloaders1, da...\n",
       "16316    [for i, data in enumerate(zip(dataloaders1, da...\n",
       "16317                          [t, t.data_ptr(), GPUArray]\n",
       "16318    [[channels = 3, height = 10, width = 10], for,...\n",
       "16320                      [forward(), nn.Module, forward]\n",
       "16323                      [forward(), nn.Module, forward]\n",
       "16325    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16326                      [tf.nn.ctc_beam_search_decoder]\n",
       "16327    [(height, width, 2), def cov(m, y=None):\\r\\n\\r...\n",
       "16328    [PyTorch, CUDA, std::vector&lt;at::Tensor&gt; ...\n",
       "16329    [torch.bernoulli(),  y = torch.Tensor([0.500])...\n",
       "16330    [class ADAMOptimizer(Optimizer):\\r\\n    \"\"\"\\r\\...\n",
       "16331    [checkpoint = torch.load(xxx.ckpt)\\r\\n, Unicod...\n",
       "16333    [nn.Parameter, autograd.Variable, Variable, Pa...\n",
       "16334    [class ModelMain(nn.Module):\\r\\n    def __init...\n",
       "16335    [class ModelMain(nn.Module):\\r\\n    def __init...\n",
       "16336    [torch.add(torch.ones(4,1), torch.randn(4))\\r\\...\n",
       "16337    [torch.add(torch.ones(4,1), torch.randn(4))\\r\\...\n",
       "16338    [data_dir = 'flowers'\\r\\ntrain_dir = data_dir ...\n",
       "16340        [qvalues = qvalues[range(5),[0,1,0,1,0]]\\r\\n]\n",
       "16341    [:class:, class Optimizer(object):\\r\\n    r\"\"\"...\n",
       "16342    [def update_nets(self, transitions):\\r\\n    \"\"...\n",
       "16343    [def update_nets(self, transitions):\\r\\n    \"\"...\n",
       "16344    [i_enc = F.normalize(input =i_batch, p=2, dim=...\n",
       "16347    [torchvision, # STL10 dataset\\r\\ntrain_dataset...\n",
       "16348    [Class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16349    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16350    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16351    [CUDA_VISIBLE_DEVICES=0,1 python xxx.py,  impo...\n",
       "16352    [x_old = torch.randn(20,64,49,49).cuda()\\r\\nim...\n",
       "16355    [0-&gt;[[1,1,1],[0,0,0],[2,2,2]],\\r\\n1-&gt;[[2...\n",
       "16356    [import torch\\r\\nimport torch.nn.functional as...\n",
       "16357    [       P = net.forward(x)\\r\\n       p = torch...\n",
       "16358    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16359                [tensordot, ndarrays, mm, matmul, mm]\n",
       "16360                [tensordot, ndarrays, mm, matmul, mm]\n",
       "16361    [D, C, torch.log2(torch.potrf(C).diag()).sum()...\n",
       "16362    [D, C, torch.log2(torch.potrf(C).diag()).sum()...\n",
       "16363    [train_iter, val_iter, test_iter = BucketItera...\n",
       "16364    [train_iter, val_iter, test_iter = BucketItera...\n",
       "16365    [torch, Pytorch, pip install http://download.p...\n",
       "16366    [### where is data?\\r\\ndata_dir_train = '/home...\n",
       "16367    [BucketIterator, AttributeError, tv_datafields...\n",
       "16368    [    def __init__ (self, ....):\\r\\n        sup...\n",
       "16369    [import torch\\r\\n\\r\\nD_in = 500\\r\\nD_out = 500...\n",
       "16370    [# AND points and labels\\r\\ndata = torch.tenso...\n",
       "16371    [# AND points and labels\\r\\ndata = torch.tenso...\n",
       "16372    [train, test = data.TabularDataset.splits(path...\n",
       "16373    [Conv2d, class AlexNet(nn.Module):\\r\\n\\r\\n    ...\n",
       "16374    [from os import path\\r\\nfrom wheel.pep425tags ...\n",
       "16375    [import torch\\r\\nt = torch.tensor(2,3)\\r\\n, im...\n",
       "16376    [class WrapMemRNN(nn.Module):\\r\\n    def __ini...\n",
       "16377    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "16378    [beam_update, sent_states.data.copy_(\\r\\n     ...\n",
       "16379    [self.conv1=Basic(1024,512,kernel_size=3,strid...\n",
       "16380                    [tensor.permute(), tensor.view()]\n",
       "16381                    [tensor.permute(), tensor.view()]\n",
       "16384    [pytorch, pytorch.empty, pytorch.rand, a = tor...\n",
       "16385    [Jersei  N\\r\\natinge  V\\r\\nmédia   N\\r\\n. PU\\r...\n",
       "16386    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16387              [custom weight initialization, PyTorch]\n",
       "16388              [custom weight initialization, PyTorch]\n",
       "16389    [class ConvNetV0(nn.Module):\\r\\n\\r\\ndef __init...\n",
       "16392    [random_image = []\\r\\nfor x in range(1 , 946):...\n",
       "16393    [def update(output, target):\\r\\n    # target o...\n",
       "16394    [def update(output, target):\\r\\n    # target o...\n",
       "16395    [a = torch.rand(2,3)\\r\\nprint(a)\\r\\n 0.7420  0...\n",
       "16396    [a = torch.rand(2,3)\\r\\nprint(a)\\r\\n 0.7420  0...\n",
       "16397    [a = torch.rand(2,3)\\r\\nprint(a)\\r\\n 0.7420  0...\n",
       "16398    [X = [[a,b],[c,d]]\\r\\n\\r\\nL1_dist = [ [0, |a-b...\n",
       "16399    [start = time.time()\\r\\n\\r\\nfor epoch in range...\n",
       "16400    [%matplotlib inline\\r\\n%config InlineBackend.f...\n",
       "16401    [%matplotlib inline\\r\\n%config InlineBackend.f...\n",
       "16402    [from torchvision import datasets\\r\\nimport to...\n",
       "16403    [batch_first=True, \\r\\n**Error:\\r\\nExpected hi...\n",
       "16405    [Epoch 0/24   \\r\\n    ------------------------...\n",
       "16406    [Epoch 0/24   \\r\\n    ------------------------...\n",
       "16407    [Epoch 0/24   \\r\\n    ------------------------...\n",
       "16408    [Epoch 0/24   \\r\\n    ------------------------...\n",
       "16409    [# Code in file tensor/two_layer_net_tensor.py...\n",
       "16410    [inf, nan,     import torch\\r\\n    import torc...\n",
       "16411    [inf, nan,     import torch\\r\\n    import torc...\n",
       "16412                               [pack_padded_sequence]\n",
       "16413                               [pack_padded_sequence]\n",
       "16414                               [pack_padded_sequence]\n",
       "16418    [def mse_loss(input_, target_):    \\r\\n    ret...\n",
       "16419    [N, B x H, N x B x H, N, N x B, B x H, B, N x ...\n",
       "16420                                       [torch.gather]\n",
       "16421                                       [torch.gather]\n",
       "16422                                       [torch.gather]\n",
       "16423                                       [torch.gather]\n",
       "16424    [magic_combine, a = torch.zeros(1, 2, 3, 4, 5,...\n",
       "16425    [magic_combine, a = torch.zeros(1, 2, 3, 4, 5,...\n",
       "16426    [magic_combine, a = torch.zeros(1, 2, 3, 4, 5,...\n",
       "16427    [magic_combine, a = torch.zeros(1, 2, 3, 4, 5,...\n",
       "16428    [# DATASET\\r\\nclass Word2VecDataset(torch_data...\n",
       "16429    [main.py, import torch\\r\\nif __name__=='__main...\n",
       "16430    [RandomSampler(), sampler = RandomSampler(self...\n",
       "16431    [A, (20, 96, 110), B, (20, 16, 110), B, (20, 1...\n",
       "16432    [Class CNN(nn.Module):...\\r\\n\\r\\nhparams1=[......\n",
       "16433    [Class CNN(nn.Module):...\\r\\n\\r\\nhparams1=[......\n",
       "16434    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "16435    [Segmentation fault, import torch\\r\\nfrom warp...\n",
       "16436    [zero_grad(), nn.conv2d, For example, nn.Conv2...\n",
       "16437    [fit(), fit(), import numpy as np\\r\\nimport to...\n",
       "16438    [if __name__ == \"__main__\":\\r\\n\\r\\n\\r\\n    plt...\n",
       "16439    [data_transforms = {\\r\\n'train': transforms.Co...\n",
       "16440    [conda install pytorch-cpu -c pytorch\\r\\npip i...\n",
       "16441    [conda install pytorch-cpu -c pytorch\\r\\npip i...\n",
       "16444    [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "16445    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16446    [epoch:   0,     loss: 0.1753,   time previous...\n",
       "16447    [from torch.autograd import Variable\\r\\nimport...\n",
       "16448    [from torch.autograd import Variable\\r\\nimport...\n",
       "16449    [Dataloader, Dataloader, \"image\", \"labels\", it...\n",
       "16450    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16451    [# pos contains indices of words in embedding ...\n",
       "16452    [# pos contains indices of words in embedding ...\n",
       "16453    [# pos contains indices of words in embedding ...\n",
       "16455    [class EncoderRNN(nn.Module):\\r\\n    def __ini...\n",
       "16456    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16457    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16458    [class SeqAttnMatch(nn.Module):\\r\\n    \"\"\"Give...\n",
       "16459    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16462    [(N, C, W_in, H_in), (N, C, W_out, H_out), ker...\n",
       "16463    [torch.bmm, attn_applied = torch.bmm(attn_weig...\n",
       "16465    [torch.bmm, attn_applied = torch.bmm(attn_weig...\n",
       "16466    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "16467    [torchvision.datasets.ImageFolder, \"name 'defa...\n",
       "16468    [torch.nn.Sequential, self.conv_layer = torch....\n",
       "16469    [conda install pytorch cuda90 -c pytorch, pip3...\n",
       "16470    [conda install pytorch cuda90 -c pytorch, pip3...\n",
       "16471    [conda install pytorch cuda90 -c pytorch, pip3...\n",
       "16472                                 [opt1, opt2, detach]\n",
       "16474    [trainset = torchvision.datasets.ImageFolder(r...\n",
       "16475    [Pandas time  0.0008931159973144531\\r\\nLoop ti...\n",
       "16476    [Pandas time  0.0008931159973144531\\r\\nLoop ti...\n",
       "16477    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16478    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16479    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16480    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16481    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16482    [-1, view,  a = torch.arange(1, 17)\\r\\n a\\r\\nt...\n",
       "16483    [p=torch.randn(2,3)\\r\\nq=torch.randn(3,4,5)\\r\\...\n",
       "16484    [ RuntimeError: cuda runtime error (10) : inva...\n",
       "16485    [ RuntimeError: cuda runtime error (10) : inva...\n",
       "16486    [---&gt; 13 device = torch.device({\"cuda\"} if ...\n",
       "16488    [def forward(self, x):\\r\\n    x = self.pool(F....\n",
       "16489    [RuntimeError: dimension out of range (expecte...\n",
       "16490    [RuntimeError: dimension out of range (expecte...\n",
       "16491    [0, 1, 2, n x 3, 0, 1, 2, n x 1, [[0.2, 0.1, 0...\n",
       "16492    [optimizer.zero_grad()\\r\\noutputs = net(inputs...\n",
       "16493    [batch_size, time_steps, inputs, instances, [1...\n",
       "16494    [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "16495    [import torch\\r\\nfrom torch.optim import Adam\\...\n",
       "16496    [Step #1: Step 6/9 : ADD requirements.txt /app...\n",
       "16497    [if torch.cuda.is_available():\\r\\nfor epoch in...\n",
       "16498    [x = torch.randn(3, requires_grad=True)\\r\\n\\r\\...\n",
       "16499    [x = torch.randn(3, requires_grad=True)\\r\\n\\r\\...\n",
       "16500    [x = torch.randn(3, requires_grad=True)\\r\\n\\r\\...\n",
       "16502    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16503    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "16505                                          [Embedding]\n",
       "16506                                          [Embedding]\n",
       "16507                                          [Embedding]\n",
       "16508    [x, y1, y2, x, y1, y1.backward(), x, x, y1, y2...\n",
       "16509    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nx =...\n",
       "16510    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16511       [m = list(torch.randn(3), torch.randn(5))\\r\\n]\n",
       "16512       [m = list(torch.randn(3), torch.randn(5))\\r\\n]\n",
       "16513    [for subj, _file in enumerate(filelist):\\r\\n, ...\n",
       "16514    [t = t.resize(1, 2, 3), tensor.resize_(), from...\n",
       "16517    [(Pdb) aa = torch.tensor([[[1,2]], [[3,4]], [[...\n",
       "16518    [(Pdb) aa = torch.tensor([[[1,2]], [[3,4]], [[...\n",
       "16519    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16520    [convert, cml = onnx_coreml.convert(model), # ...\n",
       "16522    [import torch\\r\\nfrom google.colab import file...\n",
       "16523    [batch_size, batch_size=1, batch_size=2, impor...\n",
       "16524    [[idx][:,idx], idx, #constructing sparse matri...\n",
       "16525    [[idx][:,idx], idx, #constructing sparse matri...\n",
       "16526    [from scipy.sparse import coo_matrix\\r\\ncoo = ...\n",
       "16527    [from scipy.sparse import coo_matrix\\r\\ncoo = ...\n",
       "16528    [N, B, N // B, B, N, N // B + 1, B, batches = ...\n",
       "16529    [N, B, N // B, B, N, N // B + 1, B, batches = ...\n",
       "16530    [Z = np.random.rand(100,2)\\r\\ntZ = autograd.Va...\n",
       "16531    [_image = np.array(_image)\\r\\nh, w, c = _image...\n",
       "16532    [torch.size([30, 2, 96, 96, 96]), torch.size([...\n",
       "16533    [Input\\r\\n-&gt; Linear(28 * 28, 120) w/ Pytorc...\n",
       "16534    [class STNLayer(torch.nn.Module):\\r\\n    def _...\n",
       "16535    [class STNLayer(torch.nn.Module):\\r\\n    def _...\n",
       "16536    [class STNLayer(torch.nn.Module):\\r\\n    def _...\n",
       "16537    [000010000\\r\\n000010000\\r\\n100010001\\r\\n000010...\n",
       "16538    [import torch\\r\\nfrom __future__ import print_...\n",
       "16539    [import torch, from torch._C import *\\r\\nImpor...\n",
       "16540    [import torch, from torch._C import *\\r\\nImpor...\n",
       "16543    [def loss_function(recon_x, x, mu, logvar):\\r\\...\n",
       "16544    [index_add_, idx = torch.LongTensor([0,0,0,0,1...\n",
       "16545    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16546    [import numpy as np\\r\\nimport torch.nn as nn\\r...\n",
       "16547    [forward(self, input)\\r\\n    x = self.layer1(i...\n",
       "16549    [class AttnDecoderRNN(nn.Module):\\r\\n    def _...\n",
       "16550    [rnn_output: (1, 1, 256)       # time_step x b...\n",
       "16551    [rnn_output: (1, 1, 256)       # time_step x b...\n",
       "16552    [Epoch 0,    step 0,   Current loss 518.903503...\n",
       "16553    [model = torch.nn.Sequential( \\r\\n     torch.n...\n",
       "16554    [model = torch.nn.Sequential( \\r\\n     torch.n...\n",
       "16555    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16556    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16557    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16558    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16559    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16560    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16561    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "16562    [(doomenv) hybridsyntax@Blacklynx:/mnt/f/_TUTO...\n",
       "16563    [Scanning dependencies of target libvizdoom_st...\n",
       "16564    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16565    [class Net(nn.Module):\\r\\n\\r\\ndef __init__(sel...\n",
       "16566    [Yp = reshape(Yp, (-1,1,1))\\r\\n, Yp[0:2000,0] ...\n",
       "16567    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "16568    [x = x.reshape(N*D, C, H, W), x = x.squeeze(0)...\n",
       "16569    [torch.cuda.is_available() == True, torch.cuda...\n",
       "16571    [torch.cuda.is_available() == True, torch.cuda...\n",
       "16574    [pip install torch==0.3.1, Collecting torch==0...\n",
       "16575    [pip install torch==0.3.1, Collecting torch==0...\n",
       "16576    [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "16577    [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "16578    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16579    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16580    [keras, pytorch, NegativeLogLikelihood, sinc, ...\n",
       "16581    [    self.list_1 = []\\r\\n\\r\\n    for i in rang...\n",
       "16582    [visible = Input(shape=(64,64,1))\\r\\nconv1 = C...\n",
       "16583    [`class WhaleData(Dataset):\\r\\ndef __init__(se...\n",
       "16584    [model = Sequential()\\r\\nmodel.add(Embedding(v...\n",
       "16585    [(Linear(6, 6)(Variable(torch.zeros([10, 6])))...\n",
       "16586    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "16587    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "16589    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "16590    [model_urls = { 'resnet18': 'https://download....\n",
       "16591    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16592    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16593    [RuntimeError: thnn_conv2d_forward is not impl...\n",
       "16594    [RuntimeError: thnn_conv2d_forward is not impl...\n",
       "16595    [from __future__ import division\\r\\nimport num...\n",
       "16596    [matrix_1 = [a b] \\r\\n           [c d] \\r\\nmat...\n",
       "16597    [matrix_1 = [a b] \\r\\n           [c d] \\r\\nmat...\n",
       "16598    [matrix_1 = [a b] \\r\\n           [c d] \\r\\nmat...\n",
       "16599    [matrix_1 = [a b] \\r\\n           [c d] \\r\\nmat...\n",
       "16600    [import numpy as np\\r\\nfrom torchvision import...\n",
       "16601    [import numpy as np\\r\\nfrom torchvision import...\n",
       "16602    [inputs = [&lt;start&gt;, tok1, tok2, tok3, . ...\n",
       "16603    [class DecoderRNN(nn.Module):\\r\\n    def __ini...\n",
       "16604    [class DecoderRNN(nn.Module):\\r\\n    def __ini...\n",
       "16605    [a, (1X11), b, (1X11), torch.stack((a,b),0), (...\n",
       "16606    [(24, 2, 224, 224), [n][0][h][w] + [n][1][h][w...\n",
       "16609    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16610    [x = ag.Variable(torch.ones(1, 1), requires_gr...\n",
       "16611    [    for epoch in range(num_epochs):\\r\\n\\r\\n  ...\n",
       "16612    [import torch.optim as optim\\r\\n\\r\\nmodel = Se...\n",
       "16613    [2018-05-14 12:55:05.525251: E tensorflow/stre...\n",
       "16614    [# gt is a tensor (1, 224, 224)\\r\\ngt = gt.exp...\n",
       "16615    [import torch\\r\\nimport torch.autograd as ag\\r...\n",
       "16616    [import torch\\r\\nimport torch.autograd as ag\\r...\n",
       "16617    [from __future__ import print_function\\r\\nimpo...\n",
       "16618    [from __future__ import print_function\\r\\nimpo...\n",
       "16620    [df, df[\"Target\"], import pandas as pd\\r\\nimpo...\n",
       "16621    [0.4.0, from __future__ import division\\r\\nimp...\n",
       "16622    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16623    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16624    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16627    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16629    [torch.nn.Embedding, # an Embedding module con...\n",
       "16630    [https://anaconda.org/peterjc123/pytorch/files...\n",
       "16631    [https://anaconda.org/peterjc123/pytorch/files...\n",
       "16632    [torchtext, Traceback (most recent call last):...\n",
       "16634    [nn.CrossEntropyLoss, nn.CrossEntropyLoss, nn....\n",
       "16635    [def init_params(layer_sizes, scale=0.1, rs=np...\n",
       "16636    [def init_params(layer_sizes, scale=0.1, rs=np...\n",
       "16637    [class Classifier(nn.Module):\\r\\n    def __ini...\n",
       "16638    [def __init__(self, dim=None):\\r\\n    super(So...\n",
       "16639                             [LSTM, LSTM, LSTM, LSTM]\n",
       "16640                             [LSTM, LSTM, LSTM, LSTM]\n",
       "16641    [   writer.add_scalar('data/disc_cost', disc_c...\n",
       "16642    [   writer.add_scalar('data/disc_cost', disc_c...\n",
       "16643    [###NET  \\r\\nclass CNN(nn.Module):\\r\\ndef __in...\n",
       "16644    [train.py, model.py, model.py, #--------------...\n",
       "16645    [nn.LayerNorm, nn.LSTMCell, nn.LayerNorm, nn.L...\n",
       "16646    [non-trainable, placeholder_net.W = Op( not_tr...\n",
       "16647    [non-trainable, placeholder_net.W = Op( not_tr...\n",
       "16648    [non-trainable, placeholder_net.W = Op( not_tr...\n",
       "16650    [class MyDataset(Dataset):\\r\\n\\r\\n    def __in...\n",
       "16651    [ def stripe(a):\\r\\n\\r\\n    i, j = a.size()\\r\\...\n",
       "16652    [ def stripe(a):\\r\\n\\r\\n    i, j = a.size()\\r\\...\n",
       "16654    [Variable, x, x = Variable(torch.from_numpy(x)...\n",
       "16655    [    from __future__ import print_function\\r\\n...\n",
       "16656    [# base model\\r\\nbase_model = applications.Xce...\n",
       "16657    [class net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16658    [class net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16659    [#This piece of code loads the vectors from a ...\n",
       "16661    [from segnet import SegNet\\r\\nimport torch\\r\\n...\n",
       "16662    [model_enc.linear_3d.weight = model_trained.li...\n",
       "16664    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16665    [data\\r\\n    train\\r\\n        0\\r\\n           ...\n",
       "16666    [data\\r\\n    train\\r\\n        0\\r\\n           ...\n",
       "16667    [#abs_cosine is the matrix\\r\\n#sim_vec is the ...\n",
       "16668    [#abs_cosine is the matrix\\r\\n#sim_vec is the ...\n",
       "16669    [prediction = torch.exp(model(image2))\\r\\nprin...\n",
       "16670    [# Hyper Parameters\\r\\ninput_size = 20\\r\\nhidd...\n",
       "16671    [batch_first, batch_first, (numlayer*direction...\n",
       "16672    [from torch.autograd import Variable\\r\\nimport...\n",
       "16673    [from torch.autograd import Variable\\r\\nimport...\n",
       "16674    [# Data augmentation and normalization for tra...\n",
       "16675    [%matplotlib inline\\r\\n%config InlineBackend.f...\n",
       "16677    [Tanh, CrossEntropyLoss(), RuntimeError       ...\n",
       "16678    [[[ 0  1  2]\\r\\n [ 3  4  5]\\r\\n [ 6  7  8]\\r\\n...\n",
       "16679    [[[ 0  1  2]\\r\\n [ 3  4  5]\\r\\n [ 6  7  8]\\r\\n...\n",
       "16680    [[[ 0  1  2]\\r\\n [ 3  4  5]\\r\\n [ 6  7  8]\\r\\n...\n",
       "16681    [RuntimeError: invalid argument 2: size '[-3 x...\n",
       "16682    [C:\\Users\\74713\\Documents&gt;activate root\\r\\n...\n",
       "16683    [import torch\\r\\nimport torchwordemb\\r\\nimport...\n",
       "16686    [conda install pytorch torchvision -c pytorch,...\n",
       "16687    [conda install pytorch torchvision -c pytorch,...\n",
       "16688    [loss_f, torch.nn.CrossEntropy(), loss = crite...\n",
       "16689    [loss_f, torch.nn.CrossEntropy(), loss = crite...\n",
       "16690    [OrderedDict([('inp.conv1.conv.weight', \\r\\n  ...\n",
       "16691    [OrderedDict([('inp.conv1.conv.weight', \\r\\n  ...\n",
       "16692    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16693    [      input:   NxDxWxH\\r\\n      filters: FxDx...\n",
       "16694          [B = theano.tensor.switch(A &lt; .1, 0, A)]\n",
       "16695          [B = theano.tensor.switch(A &lt; .1, 0, A)]\n",
       "16696    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16697    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16698    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16699    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16700    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16701    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16702    [pip3 install torch torchvision \\r\\n, Command ...\n",
       "16704    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16705    [!pip install torch\\r\\n!pip install torchvisio...\n",
       "16706    [!pip install torch\\r\\n!pip install torchvisio...\n",
       "16707    [map, n, d, h, w = embedding.size()\\r\\npadder ...\n",
       "16708    [output_keep_prob,     with tf.variable_scope(...\n",
       "16712    [.diag(), def train_model(model, criterion, op...\n",
       "16714    [class AutoEncoder(nn.Module):\\r\\n    def __in...\n",
       "16715    [X_train, Y_train = Variable(torch.Tensor(X[:-...\n",
       "16716    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16717    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16718    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16719    [[x1,x2,...,xn], [y1,y2,y3,y4,y5], class FullC...\n",
       "16720    [DATA_FOLDER = './tf_data/plasmodium_photos/'\\...\n",
       "16722    [Tensor, [4, 3, 966, 1296], numpy, imgs = imgs...\n",
       "16724    [Tensor, [4, 3, 966, 1296], numpy, imgs = imgs...\n",
       "16726    [Tensor, [4, 3, 966, 1296], numpy, imgs = imgs...\n",
       "16727    [...\\r\\n\\r\\nfrom torch.autograd import Variabl...\n",
       "16730                                [A x B x C, B x C, A]\n",
       "16731                                [A x B x C, B x C, A]\n",
       "16734    [import numpy as np\\r\\nimport torch \\r\\nimport...\n",
       "16735    [__getitem__, pytorch Dataset, class FaceLandm...\n",
       "16736    [class WordGuesser(nn.Module):\\r\\n    def __in...\n",
       "16737    [python training.py --cuda --emsize 1500 --nhi...\n",
       "16739    [conda env create -f virtual_platform_windows....\n",
       "16740    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16741    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16743    [# RNN Model (Many-to-One)\\r\\nclass RNN(nn.Mod...\n",
       "16745    [ndarray.reshape(), torch.view(...), torch.res...\n",
       "16747    [ndarray.reshape(), torch.view(...), torch.res...\n",
       "16749    [ import torch\\r\\nTraceback (most recent call ...\n",
       "16750    [ import torch\\r\\nTraceback (most recent call ...\n",
       "16751    [pipenv install git+https://github.com/pytorch...\n",
       "16752    [import numpy as np\\r\\nimport scipy.sparse.csg...\n",
       "16754    [PyTorch, torch.utils.data.dataloader.DataLoad...\n",
       "16755    [PyTorch, torch.utils.data.dataloader.DataLoad...\n",
       "16756    [PyTorch, torch.utils.data.dataloader.DataLoad...\n",
       "16757    [class rnn(nn.Module):\\r\\n    def __init__(sel...\n",
       "16758    [class rnn(nn.Module):\\r\\n    def __init__(sel...\n",
       "16759    [import torch.cuda as cutorch\\r\\n\\r\\nfor i in ...\n",
       "16760    [pytorch, DataLoader, num_workers, batch_size,...\n",
       "16761    [import pytorch_translator as pt\\r\\nimport pic...\n",
       "16763    [torch.from_numpy, # At this point dataset is ...\n",
       "16764    [torch.from_numpy, # At this point dataset is ...\n",
       "16765    [Python 3.5.5 |Anaconda custom (64-bit)| (defa...\n",
       "16766    [(p27) [$USER@compute-1-5 faster_rcnn]$ ./make...\n",
       "16767    [import numpy as np\\r\\nimport scipy.sparse.csg...\n",
       "16768    [ctx, self, class LinearFunction(Function):\\r\\...\n",
       "16769    [ctx, self, class LinearFunction(Function):\\r\\...\n",
       "16771    [a = np.zeros((3, 3), int)\\r\\nnp.fill_diagonal...\n",
       "16772    [def make_state(self, converted=False):\\r\\n   ...\n",
       "16773    [#encoding:utf8\\r\\nimport os\\r\\nimport sys\\r\\n...\n",
       "16774    [# Eg: \\r\\nprint(loss.grad_fn)  # MSELoss\\r\\np...\n",
       "16776    [class WaveNet( nn.Module ):    \\r\\n    def __...\n",
       "16777    [torch.nn, nn.Embedding, nn.LSTM, nn.Linear, n...\n",
       "16780    [class NMT(nn.Module):\\r\\n    \"\"\"A sequence-to...\n",
       "16781    [arch=resnet34\\r\\ndata = ImageClassifierData.f...\n",
       "16782    [loss = 0.7437, loss = 0, 1*log(1) = 0, import...\n",
       "16783    [loss = 0.7437, loss = 0, 1*log(1) = 0, import...\n",
       "16784    [loss = 0.7437, loss = 0, 1*log(1) = 0, import...\n",
       "16785    [loss = 0.7437, loss = 0, 1*log(1) = 0, import...\n",
       "16786    [pos(i) = tanh(W.[concat(X[i],Y[i]])\\r\\n#where...\n",
       "16787    [    for i, data in enumerate(trainloader, 0):...\n",
       "16788    [    self.conv1 = nn.Conv2d(1, 10, kernel_size...\n",
       "16789    [class MyModule(nn.Module):\\r\\n\\r\\ndef __init_...\n",
       "16790    [class LoadUniModal(Dataset):\\r\\n    sources =...\n",
       "16791    [( 0 ,.,.) = \\r\\n-0.9944  1.0000  0.0000  ... ...\n",
       "16792    [( 0 ,.,.) = \\r\\n-0.9944  1.0000  0.0000  ... ...\n",
       "16793    [( 0 ,.,.) = \\r\\n-0.9944  1.0000  0.0000  ... ...\n",
       "16794    [Tensor, Variable, Tensor, Variable, Variable,...\n",
       "16795    [import torch\\r\\nimport time\\r\\ndtype = torch....\n",
       "16796    [*=, +=, aa = Variable(torch.FloatTensor([[1,2...\n",
       "16797    [*=, +=, aa = Variable(torch.FloatTensor([[1,2...\n",
       "16798    [Initializing Datasets\\r\\n  [0.000s] Loading c...\n",
       "16799    [for epoch in range(num_epoch):\\r\\nfor i, (img...\n",
       "16800    [def last_timestep(self, unpacked, lengths):\\r...\n",
       "16801    [correct = 0\\r\\n    test_total = 0\\r\\n    for ...\n",
       "16802    [[batch_size, sequence_lengths, hidden_layer_d...\n",
       "16804    [criterion = nn.CrossEntropyLoss()\\r\\nraw_loss...\n",
       "16805                       [tensor.new(..), torch.Tensor]\n",
       "16807    [if use_cuda:\\r\\n    encoder = encoder.cuda()\\...\n",
       "16808    [pytorch, mu, sig, x            = mu + sig*tor...\n",
       "16809    [exp(x_i) / exp(x).sum(), log(exp(x_i) / exp(x...\n",
       "16810    [exp(x_i) / exp(x).sum(), log(exp(x_i) / exp(x...\n",
       "16811    [import torch\\r\\nimport time\\r\\n\\r\\ndef do_som...\n",
       "16812    [Traceback (most recent call last):\\r\\nFile \"t...\n",
       "16814    [nn.LSTM(input_size, hidden_size, num_layers) ...\n",
       "16816    [0, def create_mask(shape, rate):\\r\\n    \"\"\"\\r...\n",
       "16817    [0, def create_mask(shape, rate):\\r\\n    \"\"\"\\r...\n",
       "16818    [0, def create_mask(shape, rate):\\r\\n    \"\"\"\\r...\n",
       "16819    [CrossEntropyLoss, 1 84 84 81 4\\r\\n81 85 85 80...\n",
       "16820    [pack_padded_sequence, a = (([0,1,2], [3,4], [...\n",
       "16821    [pack_padded_sequence, a = (([0,1,2], [3,4], [...\n",
       "16822    [class EncoderRNN(nn.Module):\\r\\ndef __init__(...\n",
       "16824                               [model.count_params()]\n",
       "16825                               [model.count_params()]\n",
       "16826                               [model.count_params()]\n",
       "16829                               [model.count_params()]\n",
       "16832    [python train.py --batch-size 20 --rnn_type GR...\n",
       "16835    [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "16836    [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "16837    [import torch.nn as nn\\r\\nimport torch\\r\\nimpo...\n",
       "16838    [x, import torch\\r\\nimport numpy as np\\r\\nfrom...\n",
       "16839    [from pylab import *\\r\\nimport tensorflow as t...\n",
       "16840    [import torch.nn as nn\\r\\nimport torch\\r\\nfrom...\n",
       "16841    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16842    [import scipy.io as sio\\r\\nimport torch\\r\\n\\r\\...\n",
       "16843    [pip3 install http://download.pytorch.org/whl/...\n",
       "16844    [generator, import torch\\r\\nfrom torch.autogra...\n",
       "16845    [def __init__(self, rnn_type, ntoken, ninp, nh...\n",
       "16846    [def __init__(self, rnn_type, ntoken, ninp, nh...\n",
       "16847    [self.lstm = nn.LSTM(embed_size, hidden_size, ...\n",
       "16848    [test_x = Variable(torch.unsqueeze(test_data.t...\n",
       "16849    [test_x = Variable(torch.unsqueeze(test_data.t...\n",
       "16851    [# Importing the libraries\\r\\n\\r\\nimport numpy...\n",
       "16852    [E, D, latent_vec = E(input) #latent_vector wi...\n",
       "16854    [torch.nn.functional.softmax, input, dim, inpu...\n",
       "16855    [torch.nn.functional.softmax, input, dim, inpu...\n",
       "16856    [torch.nn.functional.softmax, input, dim, inpu...\n",
       "16857    [torch.nn.functional.softmax, input, dim, inpu...\n",
       "16858    [torch.nn.functional.softmax, input, dim, inpu...\n",
       "16859    [import os\\r\\nimport torch\\r\\nfrom PIL import ...\n",
       "16860    [import os\\r\\nimport torch\\r\\nfrom PIL import ...\n",
       "16861    [RuntimeError, element 0 of variables tuple is...\n",
       "16862    [class Net(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "16863    [OpenNMT-py/onmt/modules/GlobalAttention.py:17...\n",
       "16864    [OpenNMT-py/onmt/modules/GlobalAttention.py:17...\n",
       "16865    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "16867    [import torch\\r\\nimport torchvision.datasets a...\n",
       "16868    [for iter in range(0, n_iters, batch_size):\\r\\...\n",
       "16869    [X = np.load(&lt;data path&gt;) #Load dataset ...\n",
       "16870    [gd, [1,0],  import torch\\r\\n cd = [[1, 0]]\\r\\...\n",
       "16871    [[10, 3, 1000]\\r\\n[10, 4, 1000]\\r\\n, [10, 3, 4...\n",
       "16872                                  [x.contiguous(), x]\n",
       "16874                                  [x.contiguous(), x]\n",
       "16875                                  [x.contiguous(), x]\n",
       "16876                                  [x.contiguous(), x]\n",
       "16877                                  [x.contiguous(), x]\n",
       "16878                                  [x.contiguous(), x]\n",
       "16879    [peterjc123, conda install -c peterjc123 pytor...\n",
       "16880    [model = model.eval()\\r\\npredictions =[]\\r\\nfo...\n",
       "16881    [def load_raw(name):\\r\\n  return (np.load(name...\n",
       "16882    [sudo python setup.py install\\r\\n\\r\\nrunning i...\n",
       "16883    [sudo python setup.py install\\r\\n\\r\\nrunning i...\n",
       "16884    [sudo python setup.py install\\r\\n\\r\\nrunning i...\n",
       "16885    [sudo python setup.py install\\r\\n\\r\\nrunning i...\n",
       "16886    [sudo python setup.py install\\r\\n\\r\\nrunning i...\n",
       "16888    [x (len: n), y (len: m), e = x.eq(y.unsqueeze(...\n",
       "16889    [Pool, pytorch, from multiprocessing import Pr...\n",
       "16890    [Pool, pytorch, from multiprocessing import Pr...\n",
       "16891    [transforms.Normalize([0.485, 0.456, 0.406], [...\n",
       "16892    [transforms.Normalize([0.485, 0.456, 0.406], [...\n",
       "16893    [transforms.Normalize([0.485, 0.456, 0.406], [...\n",
       "16895    [Variable data has to be a tensor, but got int...\n",
       "16896    [for each element in the test-set\\r\\n    calcu...\n",
       "16897    [model_conv = torchvision.models.vgg19(pretrai...\n",
       "16898    [inputs = pad(sequences)\\r\\ntrain = DataLoader...\n",
       "16899    [class VGG(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "16900    [class VGG(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "16901    [install_requires=[\\r\\n      'torch'\\r\\n      ...\n",
       "16902    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16903    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16904    [# -*- coding: utf-8 -*-\\r\\nimport torch\\r\\nfr...\n",
       "16905                [SegNet, U-Net, Segnet, U-Net, U-Net]\n",
       "16906                [SegNet, U-Net, Segnet, U-Net, U-Net]\n",
       "16907    [class AttendResistance(nn.Module):\\r\\n       ...\n",
       "16908    [      def __init__(self):\\r\\n\\r\\n            ...\n",
       "16909    [U = torch.zeros(n, m, m)\\r\\nfor i in range(n)...\n",
       "16910    [U = torch.zeros(n, m, m)\\r\\nfor i in range(n)...\n",
       "16911    [class LSTMTaggerAug(nn.Module):\\r\\ndef __init...\n",
       "16912    [MAX_LENGTH, attn -&gt; attn_softmax -&gt; att...\n",
       "16913                        [(30, 35, 49), (30, 35, 512)]\n",
       "16916                        [(30, 35, 49), (30, 35, 512)]\n",
       "16917                        [(30, 35, 49), (30, 35, 512)]\n",
       "16919    [t, t = np.random.rand(2,2,2)\\r\\narray([[[ 0.8...\n",
       "16920    [t, t = np.random.rand(2,2,2)\\r\\narray([[[ 0.8...\n",
       "16921    [from __future__ import division\\r\\nimport num...\n",
       "16922    [3, Fire, net = models.squeezenet1_1(pretraine...\n",
       "16923    [nn.Sequential, import numpy as np\\r\\n\\r\\nimpo...\n",
       "16924    [nn.Sequential, import numpy as np\\r\\n\\r\\nimpo...\n",
       "16925    [nn.Sequential, import numpy as np\\r\\n\\r\\nimpo...\n",
       "16926    [class Seq2Seq(nn.Module):\\r\\ndef __init__(sel...\n",
       "16928    [=============================================...\n",
       "16929    [model.fit, batch_size, sliding_window, step, ...\n",
       "16930    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16931    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16932    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16933    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16935              [model1, model2, model, model1, model2]\n",
       "16936    [# in network declaration:\\r\\ndef forward(self...\n",
       "16937    [\"\"\"\\r\\nX.shape = 2,300 # floats\\r\\ny.shape = ...\n",
       "16938    [# linmodel.py\\r\\nimport torch\\r\\nimport torch...\n",
       "16939    [li, min, li.index(min_el), index, import torc...\n",
       "16940    [from setuptools import find_packages\\r\\nfrom ...\n",
       "16941    [# input numpy array\\r\\nIn [91]: arr = np.aran...\n",
       "16942    [# input numpy array\\r\\nIn [91]: arr = np.aran...\n",
       "16943    [# input numpy array\\r\\nIn [91]: arr = np.aran...\n",
       "16944    [# input numpy array\\r\\nIn [91]: arr = np.aran...\n",
       "16945    [# input numpy array\\r\\nIn [91]: arr = np.aran...\n",
       "16946    [from __future__ import absolute_import\\r\\nfro...\n",
       "16947    [---------------------------------------------...\n",
       "16948    [  Traceback (most recent call last):\\r\\n\\r\\n ...\n",
       "16950    [Pytorch, from setuptools import find_packages...\n",
       "16951    [Pytorch, from setuptools import find_packages...\n",
       "16952    [import torch.utils.data as data\\r\\n\\r\\nclass ...\n",
       "16953    [import torch.utils.data as data\\r\\n\\r\\nclass ...\n",
       "16954    [TypeError: 'collections.OrderedDict' object i...\n",
       "16955    [TypeError: 'collections.OrderedDict' object i...\n",
       "16956    [model_conv = train_model(model_conv, criterio...\n",
       "16957    [lstm = nn.LSTM(3, 3)  # Input dim is 3, outpu...\n",
       "16958    [`class UNet(nn.Module):\\r\\ndef __init__(self,...\n",
       "16959    [`class UNet(nn.Module):\\r\\ndef __init__(self,...\n",
       "16960    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16961    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "16962    [RuntimeError                              \\r\\...\n",
       "16963    [RuntimeError                              \\r\\...\n",
       "16964    [RuntimeError                              \\r\\...\n",
       "16965    [import numpy as np\\r\\na = np.ones(3)\\r\\nb = t...\n",
       "16966    [inceptionV3 = torchvision.models.inception_v3...\n",
       "16967    [(context, query, answer), context, 0, 1, 2, 3...\n",
       "16968    [[&lt;tf.Variable 'bidirectional_1/forward_lst...\n",
       "16969    [def make_conv_bn_relu(in_channels, out_channe...\n",
       "16970    [test, from fastai.conv_learner import *\\r\\nfr...\n",
       "16972    [optim = torch.optim.SGD(model.parameters(), l...\n",
       "16974    [pytorch, nn.GRU, nn.LSTM, nn.LSTMCell, nn.GRU...\n",
       "16979                           [output, h_n, h_n, output]\n",
       "16980                           [output, h_n, h_n, output]\n",
       "16981    [=&gt; Linux/x86_64/Ubuntu/17.04/deb (local)\\r...\n",
       "16982    [def _loss(outputs, session, items):  # `items...\n",
       "16983    [Traceback (most recent call last):\\r\\n  File ...\n",
       "16984    [volatile=True, def validate(self, dev_corpus)...\n",
       "16985    [use_gpu = torch.cuda.is_available()\\r\\n model...\n",
       "16986    [use_gpu = torch.cuda.is_available()\\r\\n model...\n",
       "16987    [use_gpu = torch.cuda.is_available()\\r\\n model...\n",
       "16988    [class IceShipDataset(Dataset):\\r\\n    BAND1='...\n",
       "16993    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16994    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "16995    [class MSELoss(_Loss):\\r\\n    r\"\"\"Creates a cr...\n",
       "16996    [NaN, tf.is_nan, tf.check_numerics, np.isnan(s...\n",
       "17001    [net = SomePytorchModule()\\r\\ntransformer_1 = ...\n",
       "17002                                         [nvidia-smi]\n",
       "17003                                         [nvidia-smi]\n",
       "17004                                         [nvidia-smi]\n",
       "17005                                         [nvidia-smi]\n",
       "17008                                         [nvidia-smi]\n",
       "17010                                         [nvidia-smi]\n",
       "17013                                         [nvidia-smi]\n",
       "17018    [class Encoder(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "17019    [ def reset_parameters(self):\\r\\n        n = s...\n",
       "17020    [prediction, target, idx = torch.randperm(targ...\n",
       "17021    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17022    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17023    [X[a[i],b[i]] = 0 for i in range(len(a)), X[a,b]]\n",
       "17024    [zero_grad(), |  zero_grad(self)\\r\\n|      Set...\n",
       "17026    [zero_grad(), |  zero_grad(self)\\r\\n|      Set...\n",
       "17027    [zero_grad(), |  zero_grad(self)\\r\\n|      Set...\n",
       "17028    [zero_grad(), |  zero_grad(self)\\r\\n|      Set...\n",
       "17029    [t = Variable(torch.randn(5))\\r\\nt =t.cuda()\\r...\n",
       "17030    [autograd, Tensor, Variable, nn, optim, optim,...\n",
       "17031    [conda install pytorch torchvision -c pytorch\\...\n",
       "17032    [conda install pytorch torchvision -c pytorch\\...\n",
       "17033    [class Mymodel(nn.Module):\\r\\n    def __init__...\n",
       "17034    [class Mymodel(nn.Module):\\r\\n    def __init__...\n",
       "17035    [file_path = \"…/database/frameLength100/notOve...\n",
       "17036    [torch.utils.data.DataLoader, d_transforms = [...\n",
       "17037    [ConvTranspose3d, Conv3d, (1,44,68,120), self....\n",
       "17038    [class _netG(nn.Module):\\r\\ndef __init__(self,...\n",
       "17039    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "17040    [#hyperparameters\\r\\nhl = 10\\r\\nlr = 0.01\\r\\nn...\n",
       "17042    [torch.cuda.FloatTensor, (line 41-55), (line 5...\n",
       "17043    [ import torch\\r\\n a = torch.rand(4,4)\\r\\n a\\r...\n",
       "17044    [ import torch\\r\\n a = torch.rand(4,4)\\r\\n a\\r...\n",
       "17046    [a = [1, 2, 3]\\r\\nassert a.index(2) == 1\\r\\n, ...\n",
       "17049    [a = [1, 2, 3]\\r\\nassert a.index(2) == 1\\r\\n, ...\n",
       "17050    [a = [1, 2, 3]\\r\\nassert a.index(2) == 1\\r\\n, ...\n",
       "17052    [a = [1, 2, 3]\\r\\nassert a.index(2) == 1\\r\\n, ...\n",
       "17054    [sips -g all, pixelWidth: 2048\\r\\npixelHeight:...\n",
       "17055    [TextClassifyCnnNet, FlatCnnLayer, FilterLayer...\n",
       "17056    [TextClassifyCnnNet, FlatCnnLayer, FilterLayer...\n",
       "17057    [action, filter, action_size==3, output: [0.1,...\n",
       "17058    [conda create --name my_env python=3.5\\r\\n, ex...\n",
       "17059    [class JSDLoss(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "17060    [    def data_gen(que,PATH,epochs,steps_per_ep...\n",
       "17062    [conda install pytorch=0.3.0 torchvision -c py...\n",
       "17063    [conda install pytorch=0.3.0 torchvision -c py...\n",
       "17064    [library(nnet)\\r\\nx &lt;- sort(10*runif(50))\\r...\n",
       "17065    [    model [Pix2PixHDModel] was created\\r\\n   ...\n",
       "17066    [torch.nn.CrossEntropyLoss(), RuntimeError: mu...\n",
       "17067    [torch.nn.CrossEntropyLoss(), RuntimeError: mu...\n",
       "17068    [trainset = iris.Iris(train=True)\\r\\ntrainload...\n",
       "17071    [trainset = iris.Iris(train=True)\\r\\ntrainload...\n",
       "17072    [python caffe2darknet.py my_prototxt.txt my_ca...\n",
       "17073    [def SpiralLoss():\\r\\n    def spiral_loss(inpu...\n",
       "17074    [net_a = NetworkA()\\r\\nnet_b = NetworkB()\\r\\nn...\n",
       "17075    [net_a = NetworkA()\\r\\nnet_b = NetworkB()\\r\\nn...\n",
       "17076    [net_a = NetworkA()\\r\\nnet_b = NetworkB()\\r\\nn...\n",
       "17078    [vgg_net = load_lua('./vgg_face_torch/VGG_FACE...\n",
       "17079    [use_gpu, import torch\\r\\nfrom torch import au...\n",
       "17080    [[[0, 1, 2, 3],\\r\\n[10, 11, 12, 13],\\r\\n[20, 2...\n",
       "17081    [[[0, 1, 2, 3],\\r\\n[10, 11, 12, 13],\\r\\n[20, 2...\n",
       "17082    [[[0, 1, 2, 3],\\r\\n[10, 11, 12, 13],\\r\\n[20, 2...\n",
       "17083    [python main.py eval --content-image images/co...\n",
       "17084    [class RegularConv(nn.module):\\r\\n    def __in...\n",
       "17085    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "17088    [for batch_idx, (data, target) in enumerate(tr...\n",
       "17089    [class myLSTM(nn.Module):\\r\\n    def __init__(...\n",
       "17090    [data_dir = './train_dog'          # directory...\n",
       "17091    [class ParameterDiffer(object):\\r\\n    def __i...\n",
       "17093    [feedfnn = []\\r\\nfor task_name, num_class in s...\n",
       "17094    [    rH = np.array(rH) # discounted reward\\r\\n...\n",
       "17095    [Features:\\r\\n\\r\\n0.8138  1.2342  0.4419  0.82...\n",
       "17097    [# load libs\\r\\nimport torch\\r\\nimport argpars...\n",
       "17098    [RuntimeError: Assertion `THIndexTensor_(size)...\n",
       "17099    [criterion =nn.CrossEntropyLoss\\r\\noptimizer=o...\n",
       "17100    [criterion =nn.CrossEntropyLoss\\r\\noptimizer=o...\n",
       "17101    [torch.FloatTensor, a = torch.FloatTensor(3,3)...\n",
       "17102    [Epoch 34, Dying Relu, Softplus, Epoch 0\\r\\nEx...\n",
       "17103    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "17104    [&gt;&gt; a = torch.randn(4, 4)\\r\\n&gt;&gt; a\\...\n",
       "17105    [scores.data.masked_fill_(y_mask.data, -float(...\n",
       "17106    [scores.data.masked_fill_(y_mask.data, -float(...\n",
       "17108    [CIFAR10, trainset = torchvision.datasets.CIFA...\n",
       "17109    [CIFAR10, trainset = torchvision.datasets.CIFA...\n",
       "17110    [context, query, (batch_size, context_seq_len,...\n",
       "17111    [1. Load the data and read csv using pandas.\\r...\n",
       "17112    [a = torch.randn(3, 2, 4, 5), (2, :, 0, :), (1...\n",
       "17113    [class dim_lifting(nn.Module):\\r\\n    def __in...\n",
       "17114    [index_in_batch * diag_ele, index_in_batch * M...\n",
       "17115    [index_in_batch * diag_ele, index_in_batch * M...\n",
       "17116    [index_in_batch * diag_ele, index_in_batch * M...\n",
       "17117    [torch.FloatTensor, __init__, import inspect\\r...\n",
       "17118    [D, N, x = (xmax - xmin)*torch.rand(N,D).type(...\n",
       "17119    [class AudioCNN(nn.Module):\\r\\n\\r\\ndef __init_...\n",
       "17120    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "17121    [torch.cuda.FloatTensor, check limits, for i i...\n",
       "17122    [import torch\\r\\nimport torchvision.models as ...\n",
       "17123    [ torch.Tensor(5, 3)\\r\\nTraceback (most recent...\n",
       "17124    [ torch.Tensor(5, 3)\\r\\nTraceback (most recent...\n",
       "17125    [ torch.Tensor(5, 3)\\r\\nTraceback (most recent...\n",
       "17126    [parser.add_argument('--type', default='torch....\n",
       "17127    [parser.add_argument('--type', default='torch....\n",
       "17128    [parser.add_argument('--type', default='torch....\n",
       "17129    [parser.add_argument('--type', default='torch....\n",
       "17130    [RuntimeError: inconsistent tensor size, expec...\n",
       "17131    [x = (xmax - xmin)*torch.rand(pop).dtype + xmi...\n",
       "17132    [torch.FloatTensor, import torch\\r\\nimport tim...\n",
       "17133    [torch.FloatTensor, import torch\\r\\nimport tim...\n",
       "17134    [x1, x2, x2, x1, dtype=torch.cuda.FloatTensor,...\n",
       "17135    [obj1, obj2, class Embedding(nn.Module):\\r\\n\\r...\n",
       "17136    [fit, GPU, PyTorch, Python, fit, import numpy ...\n",
       "17137    [https://github.com/davidsonmizael/gan\\r\\n, cl...\n",
       "17138    [dot(), hid_dim = 32\\r\\ndata = torch.randn(10,...\n",
       "17139    [import torch\\r\\ndtype = torch.cuda.FloatTenso...\n",
       "17140    [    def read_labels(file):\\r\\n      dic = {}\\...\n",
       "17141    [import numpy as np\\r\\nimport random as rand\\r...\n",
       "17142    [&lt;code&gt;\\r\\nclass cust_loss(torch.nn.Modu...\n",
       "17144    [import numpy as np\\r\\nimport random as rand\\r...\n",
       "17145    [a, b, for, a = torch.rand(batch_size, a_len, ...\n",
       "17146    [class Net(nn.Module):\\r\\ndef _init_(self,inpu...\n",
       "17147    [Input: [ [‘who’, ‘is’, ‘this’] ] \\r\\n-&gt; [ ...\n",
       "17148    [Input: [ [‘who’, ‘is’, ‘this’] ] \\r\\n-&gt; [ ...\n",
       "17149    [torch.nn, BatchNorm1d, BatchNorm2d, BatchNorm3d]\n",
       "17150    [torch.nn, BatchNorm1d, BatchNorm2d, BatchNorm3d]\n",
       "17151    [a=[1,2,3];\\r\\ncontext_var = autograd.Variable...\n",
       "17152    [a=[1,2,3];\\r\\ncontext_var = autograd.Variable...\n",
       "17153    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17154    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17155    [import numpy as np\\r\\nfrom scipy.stats import...\n",
       "17156    [import numpy as np\\r\\nfrom sklearn.preprocess...\n",
       "17157    [forward, out, __init__, # Residual Block\\r\\nc...\n",
       "17159    [file_name = \"annotation.csv\"\\r\\nimage_files =...\n",
       "17160    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17161    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17162    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17163    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17164    [real_batchsize = 200\\r\\n\\r\\nfor epoch in rang...\n",
       "17166     [(FloatTensor_A &gt; FloatTensor_B), ByteTensor]\n",
       "17167    [def evaluate(self, data):\\r\\n    correct = 0\\...\n",
       "17168    [def evaluate(self, data):\\r\\n    correct = 0\\...\n",
       "17169    [conda install pytorch, from __future__ import...\n",
       "17170    [print output\\r\\nVariable containing:\\r\\n1.000...\n",
       "17171    [nn.RNN(), seq_len, GO_TOKEN, class Model(nn.M...\n",
       "17172    [regions = np.zeros([107,4], dtype='uint8')\\r\\...\n",
       "17173    [regions = np.zeros([107,4], dtype='uint8')\\r\\...\n",
       "17174    [python -m visdom.server, for res in _socket.g...\n",
       "17175    [                     ---&gt; BinaryOutput_A\\r...\n",
       "17176    [data_loader = torch.utils.data.DataLoader(\\r\\...\n",
       "17177    [class Network(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "17178    [class Network(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "17179    [class Network(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "17180    [img = \\r\\n    [1 1 2 2 2 2 2 3 3]\\r\\n    [1 1...\n",
       "17181    [img = \\r\\n    [1 1 2 2 2 2 2 3 3]\\r\\n    [1 1...\n",
       "17182    [img = \\r\\n    [1 1 2 2 2 2 2 3 3]\\r\\n    [1 1...\n",
       "17183         [V.shape, V.get_shape().as_list(), V.size()]\n",
       "17184         [V.shape, V.get_shape().as_list(), V.size()]\n",
       "17187    [ConvTranspose2d, model.add(Dense(64, input_di...\n",
       "17188    [ConvTranspose2d, model.add(Dense(64, input_di...\n",
       "17190    [retain_variable, retain_graph, class ContentL...\n",
       "17191    [retain_variable, retain_graph, class ContentL...\n",
       "17192    [train_set = dset.MNIST(root=root, train=True,...\n",
       "17193    [output = loss(data, target), &lt;class 'torch...\n",
       "17194    [data = [\\r\\n    [1, 1, 1, 1, 0, 0, 1, 1, 1],\\...\n",
       "17195    [USE_CUDA, import unicodedata\\r\\nimport string...\n",
       "17196    [USE_CUDA, import unicodedata\\r\\nimport string...\n",
       "17197    [USE_CUDA, import unicodedata\\r\\nimport string...\n",
       "17198    [import pickle\\r\\nimport json\\r\\nimport shutil...\n",
       "17199    [# Turn string into list of longs\\r\\ndef char_...\n",
       "17200    [Image  (3d array): 256 x 256 x 3\\r\\nScale  (1...\n",
       "17203    [data_transforms = {\\r\\n    'train': transform...\n",
       "17204    [nn.Module, Glove, class Net(nn.Module):\\r\\n  ...\n",
       "17205    [torch.nn.functional.conv2d, import torch\\r\\ni...\n",
       "17206    [class ActorCritic(torch.nn.Module): #original...\n",
       "17208    [\\r\\nRuntimeError: element 0 of variables tupl...\n",
       "17209    [import torch\\r\\nimport torch.autograd as auto...\n",
       "17210    [.data,  Traceback (most recent call last):\\r\\...\n",
       "17211    [.data,  Traceback (most recent call last):\\r\\...\n",
       "17212    [.data,  Traceback (most recent call last):\\r\\...\n",
       "17214    [    do something\\r\\n    print('log something....\n",
       "17215    [# Data loading code\\r\\nnormalize = transforms...\n",
       "17216    [A, size(N,hl,wl), B=numpy.zeros((N,16,16))\\r\\...\n",
       "17219    [# Loading data\\r\\ntrain_loader, test_loader =...\n",
       "17220    [class _Loss(nn.Module):\\r\\n    def __init__(s...\n",
       "17221    [  File \"/media/data1/iftachg/frame_glimpses/p...\n",
       "17222    [PackedSequence, pad_packed_sequence, pack_pad...\n",
       "17223    [PackedSequence, pad_packed_sequence, pack_pad...\n",
       "17224    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17225    [net1, random.seed(opt.manualSeed)\\r\\ntorch.ma...\n",
       "17227                                   [encoder, decoder]\n",
       "17228    [if os.path.exists(CHECKPOINT_NAME):\\r\\nprint(...\n",
       "17229    [loss.backward(), memnn.py, loss.backward(), [...\n",
       "17230    [UNet, Conv2d(128, 256, kernel_size=(4, 4), st...\n",
       "17231    [UNet, Conv2d(128, 256, kernel_size=(4, 4), st...\n",
       "17232         [conv2d(), VGG19, conv2d(), VGG19, conv2d()]\n",
       "17233    [class LinearRegressionModel(nn.Module):\\r\\n  ...\n",
       "17234    [class LinearRegressionModel(nn.Module):\\r\\n  ...\n",
       "17235    [import torchfile as T\\r\\no = T.load('alexnet_...\n",
       "17236    [#original dataset - 2+million rows\\r\\ndataset...\n",
       "17237                  [softmax_cross_entropy_with_logits]\n",
       "17238                  [softmax_cross_entropy_with_logits]\n",
       "17239                  [softmax_cross_entropy_with_logits]\n",
       "17240                  [softmax_cross_entropy_with_logits]\n",
       "17241    [filename=r’./test/bees/1.jpg’\\r\\nimg = skimag...\n",
       "17242    [import pandas as pd\\r\\nfrom sklearn.datasets ...\n",
       "17244    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nx =...\n",
       "17245    [import torch.nn as nn\\r\\nmodel = nn.Sequentia...\n",
       "17246    [torch.HalfTensor, In [1]: import torch \\r\\nIn...\n",
       "17247    [# some people need these three lines to make ...\n",
       "17248    [# some people need these three lines to make ...\n",
       "17249    [import torch\\r\\nimport torch.nn as nn\\r\\n#fro...\n",
       "17250    [import torch\\r\\nimport torch.nn as nn\\r\\n#fro...\n",
       "17251    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "17252    [def decode_minibatch(\\r\\n    config,\\r\\n    m...\n",
       "17253    [    CRNN (\\r\\n\\r\\n\\r\\n(cnn): Sequential (\\r\\n...\n",
       "17254    [import torchvision\\r\\nvgg = torchvision.model...\n",
       "17255    [C:\\Users&gt;conda install pytorch torchvision...\n",
       "17256    [C:\\Users&gt;conda install pytorch torchvision...\n",
       "17257    [output = [0.7, 0.3, 0.1, 0.9 ... ]\\r\\nlabel =...\n",
       "17258    [output = [0.7, 0.3, 0.1, 0.9 ... ]\\r\\nlabel =...\n",
       "17259    [DataParallel, DistributedDataParallel, import...\n",
       "17260    [DataParallel, DistributedDataParallel, if not...\n",
       "17261    [DataParallel, DistributedDataParallel, if not...\n",
       "17262    [x = torch.randn(3)\\r\\nx = Variable(x, require...\n",
       "17263                           [tf.extract_image_patches]\n",
       "17264                           [tf.extract_image_patches]\n",
       "17265    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17266    [BadFFTFunction, from numpy.fft import rfft2, ...\n",
       "17268    [sub_patch  : [torch.FloatTensor of size 9x9x3...\n",
       "17269    [g2.2xlarge, time python imageNet.py ImageNet2...\n",
       "17270    [pip install http://download.pytorch.org/whl/t...\n",
       "17271    [pip install http://download.pytorch.org/whl/t...\n",
       "17272    [mdl_sgd = torch.nn.Sequential( torch.nn.Linea...\n",
       "17274    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17275    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17276    [main = nn.Sequential()\\r\\nself._conv_block(ma...\n",
       "17277    [main = nn.Sequential()\\r\\nself._conv_block(ma...\n",
       "17278    [a=torch.randn(1), (1L,),  import torch\\r\\n a=...\n",
       "17279    [torch.everything_to_gpu()\\r\\n, dtype = torch....\n",
       "17280    [torch.everything_to_gpu()\\r\\n, dtype = torch....\n",
       "17281    [val_diff = 1\\r\\nacc_diff = torch.FloatTensor(...\n",
       "17282    [preds[4,4]\\r\\nOut[305]: \\r\\nVariable containi...\n",
       "17284    [torch.cuda.FloatTensor, torch.FloatTensor, cl...\n",
       "17285    [torch.cuda.FloatTensor, torch.FloatTensor, cl...\n",
       "17286    [class Net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "17287    [ # B,C,seq,h,w\\r\\n# 4,2, 5,  3,3 \\r\\n\\r\\n x =...\n",
       "17288    [loss = f(x, w)\\r\\ndl_dw = tt.grad(loss, wrt=w...\n",
       "17289    [numpy.tile, a = np.array([[5, 6, 7, 8],\\r\\n  ...\n",
       "17290    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17291    [if USE_CUDA:\\r\\n    encoderchar = encoderchar...\n",
       "17292    [+---------+----------+----------+\\r\\n|Feature...\n",
       "17293    [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "17294    [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "17295    [def train(input_batch, input_batch_length, ta...\n",
       "17296    [ import torch\\r\\n a = torch.Tensor([5,2,11, 1...\n",
       "17297    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17298    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17299    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17300    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17301    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17302    [import numpy as np\\r\\n\\r\\nimport torch\\r\\nfro...\n",
       "17303    [X_train     = rnd.random((300,100))\\r\\nX_val ...\n",
       "17304    [X_train     = rnd.random((300,100))\\r\\nX_val ...\n",
       "17305    [import torch,ipdb\\r\\nimport torch.autograd as...\n",
       "17306    [RuntimeError: matrices expected, got 3D, 2D t...\n",
       "17307    [RuntimeError: matrices expected, got 3D, 2D t...\n",
       "17309    [from __future__ import unicode_literals, prin...\n",
       "17311                                         [b_ih, b_hh]\n",
       "17312                              [\"requires_grad=False\"]\n",
       "17313    [packed = torch.nn.utils.rnn.pack_padded_seque...\n",
       "17314    [var = [[0, 1, -4, 8],\\r\\n       [2, -3, 2, 1]...\n",
       "17315    [var = [[0, 1, -4, 8],\\r\\n       [2, -3, 2, 1]...\n",
       "17316    [var = [[0, 1, -4, 8],\\r\\n       [2, -3, 2, 1]...\n",
       "17317    [var = [[0, 1, -4, 8],\\r\\n       [2, -3, 2, 1]...\n",
       "17318    [nn.functional.batch_norm, nn.BatchNorm2d, nn....\n",
       "17319    [torch.cuda.FloatTensor, TypeError: dot receiv...\n",
       "17320    [Tensor, Variable, XXXXXXXXXXX in mul\\r\\n    a...\n",
       "17321    [dataloader = Data.DataLoader(LSUNClass(db_pat...\n",
       "17323    [torchvision.datasets.MNIST, DataLoader, tr = ...\n",
       "17324    [torchvision.datasets.MNIST, DataLoader, tr = ...\n",
       "17325    [torchvision.datasets.MNIST, DataLoader, tr = ...\n",
       "17326    [pip install torch-0.1.12.post2-cp27-none-linu...\n",
       "17327                   [torch.transpose, tf.transpose, N]\n",
       "17328                   [torch.transpose, tf.transpose, N]\n",
       "17329    [model.py, # one layer\\r\\nself.conv13 = nn.Con...\n",
       "17330    [`   prediction = prediction.data.max(1)[1] #g...\n",
       "17331    [parser = argparse.ArgumentParser()\\r\\nparser....\n",
       "17332    [parser = argparse.ArgumentParser()\\r\\nparser....\n",
       "17333    [if __name__ == \"__main__\":\\r\\n     tmp = torc...\n",
       "17334    [class LSTMTxtGen(nn.Module):\\r\\ndef __init__(...\n",
       "17335                [nn.modules.loss.L1Loss(), L1Penalty]\n",
       "17336                [nn.modules.loss.L1Loss(), L1Penalty]\n",
       "17337                [nn.modules.loss.L1Loss(), L1Penalty]\n",
       "17338                [nn.modules.loss.L1Loss(), L1Penalty]\n",
       "17339    [# numpy mnist data\\r\\nX_train, Y_train = read...\n",
       "17340    [x = [torch.FloatTensor of size 1x3x32x32]\\r\\n...\n",
       "17341    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17342    [numpy array, np.array, truth = torch.from_num...\n",
       "17343    [numpy array, np.array, truth = torch.from_num...\n",
       "17344    [numpy array, np.array, truth = torch.from_num...\n",
       "17345                      [requires_grad = True, forward]\n",
       "17346    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "17347    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "17348    [A=np.array([M]*N) ?\\r\\n, A=torch.autograd.Var...\n",
       "17349    [A=np.array([M]*N) ?\\r\\n, A=torch.autograd.Var...\n",
       "17352    [procs = [mp.Process(target=self.worker_wrappe...\n",
       "17353    [a = numpy.ones((3, 2))\\r\\nb = numpy.ones((2, ...\n",
       "17354    [a = numpy.ones((3, 2))\\r\\nb = numpy.ones((2, ...\n",
       "17355    [a = numpy.ones((3, 2))\\r\\nb = numpy.ones((2, ...\n",
       "17356    [a = numpy.ones((3, 2))\\r\\nb = numpy.ones((2, ...\n",
       "17357                             [torch.LongTensor(x), x]\n",
       "17359    [4 x 6, 4 x 6 x n, [[5, 3, 2, 11, 15, 15],\\r\\n...\n",
       "17360    [4 x 6, 4 x 6 x n, [[5, 3, 2, 11, 15, 15],\\r\\n...\n",
       "17361    [4 x 6, 4 x 6 x n, [[5, 3, 2, 11, 15, 15],\\r\\n...\n",
       "17362    [[[[ 70  82  94]\\r\\n  [ 67  81  93]\\r\\n  [ 66 ...\n",
       "17363    [[[[ 70  82  94]\\r\\n  [ 67  81  93]\\r\\n  [ 66 ...\n",
       "17364    [[[[ 70  82  94]\\r\\n  [ 67  81  93]\\r\\n  [ 66 ...\n",
       "17365    [class Testme(nn.Module):\\r\\n    def __init__(...\n",
       "17366    [self.A = torch.autograd.Variable(random_spars...\n",
       "17367    [class Testme(nn.Module):         ## it _is_ a...\n",
       "17368    [import autograd.numpy as np\\r\\nimport pandas ...\n",
       "17369    [cython, fastText, cython, numpy.asarray, nump...\n",
       "17370    [C =  A^n + B^n, A^n, B^n, with tf.device('/gp...\n",
       "17374    [PyTorch autograd.Variable, numpy, a.numpy(), ...\n",
       "17375     [Image, container, pytorch, anacoda, dockerfile]\n",
       "17376                       [torch.Tensor, [a,b], [r1,r2]]\n",
       "17378                       [torch.Tensor, [a,b], [r1,r2]]\n",
       "17383                       [torch.Tensor, [a,b], [r1,r2]]\n",
       "17385    [nn.Sequential(), class My_Model_1(nn.Module):...\n",
       "17386    [nn.Sequential(), class My_Model_1(nn.Module):...\n",
       "17387    [nn.Sequential(), class My_Model_1(nn.Module):...\n",
       "17388    [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "17389    [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "17390    [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "17391    [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "17392    [x = Variable(torch.FloatTensor([[1,2],[3,4]])...\n",
       "17393    [KeyError: 'unexpected key \"module.encoder.emb...\n",
       "17394    [File \"code/source/main.py\", line 68, in &lt;m...\n",
       "17395    [File \"code/source/main.py\", line 68, in &lt;m...\n",
       "17396    [Number of in-channels: 1, Number of out-chann...\n",
       "17397    [Number of in-channels: 1, Number of out-chann...\n",
       "17398    [Sequential, model = nn.Sequential()\\r\\nmodel:...\n",
       "17399    [Sequential, model = nn.Sequential()\\r\\nmodel:...\n",
       "17400    [Sequential, model = nn.Sequential()\\r\\nmodel:...\n",
       "17401    [import torch\\r\\n\\r\\nC = torch.LongTensor([[1,...\n",
       "17402    [import torch\\r\\n\\r\\nC = torch.LongTensor([[1,...\n",
       "17403    [import torch\\r\\n\\r\\nC = torch.LongTensor([[1,...\n",
       "17404    [training_data, training_data = [\\r\\n    (\"The...\n",
       "17405    [training_data, training_data = [\\r\\n    (\"The...\n",
       "17406    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "17407                                            [dropout]\n",
       "17411    [Traceback (most recent call last):\\r\\nFile \"/...\n",
       "17412    [TypeError: parameters() missing 1 required po...\n",
       "17413    [TypeError: parameters() missing 1 required po...\n",
       "17414    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17415    [import numpy as np\\r\\n\\r\\ninput_size = 10\\r\\n...\n",
       "17416    [training_x, training_y, training_X = torch.fr...\n",
       "17417    [conda install pytorch torchvision cuda80 -c s...\n",
       "17420    [conda install pytorch torchvision cuda80 -c s...\n",
       "17422    [conda install pytorch torchvision cuda80 -c s...\n",
       "17423    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17424    [NO_CUDA=1 python setup.py install, In file in...\n",
       "17425    [ pip install http://download.pytorch.org/whl/...\n",
       "17426    [ pip install http://download.pytorch.org/whl/...\n",
       "17427    [#import\\r\\nimport torch\\r\\nimport torch.nn as...\n",
       "17429    [nn.conv2d(in_channels = 3, out_channels = 64,...\n",
       "17430    [gradients = torch.FloatTensor([0.1, 1.0, 0.00...\n",
       "17431    [gradients = torch.FloatTensor([0.1, 1.0, 0.00...\n",
       "17434    [TypeError, import torch\\r\\nimport torchvision...\n",
       "17435    [TypeError, import torch\\r\\nimport torchvision...\n",
       "17436    [criterion=nn.CrossEntropyLoss()\\r\\n,   - 1.00...\n",
       "17437    [criterion=nn.CrossEntropyLoss()\\r\\n,   - 1.00...\n",
       "17439    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17440    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17441    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17442    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17443    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17444    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17445    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17446    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17447    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17448    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17449    [(5,), (1, 5),  import numpy as np\\r\\n a = np....\n",
       "17450    [if model.config.model == 'LSTM':\\r\\n  File \"/...\n",
       "17451    [\\r\\nResNet (\\r\\n  (conv1): Conv2d(3, 64, kern...\n",
       "17452    [File \"/net/if5/wua4nw/wasi/academic/research_...\n",
       "17453    [/home/ubuntu/nbs/torch_utils.py in &lt;module...\n",
       "17454    [/home/ubuntu/nbs/torch_utils.py in &lt;module...\n",
       "17455    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17456    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17457    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17458    [def conv2d_flipkernel(x, k, name=None):\\r\\n  ...\n",
       "17459    [def conv2d_flipkernel(x, k, name=None):\\r\\n  ...\n",
       "17460    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17461    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17462    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17463    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17464    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17465    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17466    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17467    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17468    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17469    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17470    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17471    [model.summary(), Model Summary:\\r\\n__________...\n",
       "17472         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17473         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17474         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17475         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17477         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17478         [.view(), x, x = x.view(-1, 16 * 5 * 5)\\r\\n]\n",
       "17480    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "17482    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "17483    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "17484                                       [torch.Tensor]\n",
       "17485                                       [torch.Tensor]\n",
       "17486                                       [torch.Tensor]\n",
       "17487    [sjson-3.8.0, pip install --upgrade orjson, py...\n",
       "17488    [from transformers import AutoTokenizer, AutoM...\n",
       "17489    [auto the_tensor = torch::rand({42, 427}).to(d...\n",
       "17490    [num_channels = sig.shape[0]\\r\\n# Resample fir...\n",
       "17493    [import torch\\r\\nimport os.path as osp\\r\\n\\r\\n...\n",
       "17494    [!pip install --pre deepchem\\r\\n\\r\\nimport dee...\n",
       "17495    [import { useState, useEffect, useRef } from \"...\n",
       "17496    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17497    [(image, mask), image, (H,W,3), mask, (H,W,1),...\n",
       "17498    [(image, mask), image, (H,W,3), mask, (H,W,1),...\n",
       "17500    [\\r\\nimport pytorch_lightning as pl\\r\\nfrom to...\n",
       "17501    [Requirement already satisfied: transformers[f...\n",
       "17502    [ In [25]: torch.nn.functional.interpolate(tor...\n",
       "17503    [ In [25]: torch.nn.functional.interpolate(tor...\n",
       "17504    [RuntimeError: Expected 3D (unbatched) or 4D (...\n",
       "17505    [Python 3.8 running on 64bit Amazon Linux 2/3....\n",
       "17506    [conda create --name yolov5 python=3.8.13\\r\\nc...\n",
       "17507    [PS C:\\Users\\ALLO CEDRIC BOLAMBA\\Desktop\\Proje...\n",
       "17508                                 [__iter__, __iter__]\n",
       "17509                                 [__iter__, __iter__]\n",
       "17510    [python special_process.py device\\r\\n, for gro...\n",
       "17511    [learner, with open(), pickle, load_learner(),...\n",
       "17512    [import keras\\r\\nimport tensorflow as tf\\r\\n\\r...\n",
       "17513    [torch::PackedTensorAccessor32&lt;float,2,torc...\n",
       "17514    [\"slow_conv2d_cpu\" not implemented for 'Half',...\n",
       "17515    [ def __getitem__(self,idx): \\r\\n        \\r\\n ...\n",
       "17516    [    public func triggerFlash() {\\r\\n        s...\n",
       "17517    [y_ul.shape = [8, 512, 128, 128], for i, m in ...\n",
       "17519    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17520    [offsets = tf.gather_nd(offsets, kpt_inds, bat...\n",
       "17521    [class MyNetwork(nn.Module):\\r\\n    def __init...\n",
       "17522    [\\r\\n# Load the dataset\\r\\ndataset = TUDataset...\n",
       "17523    [Dict[int, nn.Module], _task_head_models,     ...\n",
       "17524    [lua: init.lua:12: module 'paths' not found:\\r...\n",
       "17525    [Collecting package metadata (current_repodata...\n",
       "17526    [/* Take picture with the camera */\\r\\n/*if(na...\n",
       "17527    [# image is a torch tensors being on the gpu r...\n",
       "17528    [import tensorflow as tf\\r\\nimport tensorflow_...\n",
       "17529    [RUN pip install torch-scatter -f https://data...\n",
       "17530    [import numpy as np\\r\\nimport json\\r\\nimport t...\n",
       "17531    [import os\\r\\nos.environ[\"CUDA_DEVICE_ORDER\"] ...\n",
       "17532    [import torch\\r\\nimport json \\r\\nfrom transfor...\n",
       "17533    [emb = emb[..., None, None]\\r\\ncond_w, cond_b ...\n",
       "17534    [paramDict = {\\r\\n    'epoch': 200,\\r\\n    'ba...\n",
       "17535    [#! /bin/bash\\r\\nCUDA_VISIBLE_DEVICES=2 python...\n",
       "17536    [import torch\\r\\n\\r\\nx_test, y_pred, listInfer...\n",
       "17537    [tensor([[0.9950, 0.6175, 0.1253, 1.3536],\\r\\n...\n",
       "17538    [from torch.utils.data import Dataset, DataLoa...\n",
       "17539    [torch.save(model, 'trained_model')\\r\\n, train...\n",
       "17540    [LXRTModel, [W shape_type_inference.cpp:434] W...\n",
       "17541    [UneXt50, from fastai.vision.all import *\\r\\ni...\n",
       "17542    [result = self.linear(attention).squeeze()\\r\\n...\n",
       "17543    [def get_angles(pos, i, d_model):\\r\\n    angle...\n",
       "17544    [[[1, 1, 0, 1, 0]\\r\\n [1, 1, 1, 0, 0]\\r\\n [0, ...\n",
       "17545    [fastai, (project) daniel@ubuntu-pcs:~/Pycharm...\n",
       "17546    [model.children(), if, list(model.children())\\...\n",
       "17547    [torch.nn.functional.fold, alpha = 0.5\\r\\ninpu...\n",
       "17548    [test, (b1,c,h,w), train, (b2,c,h,w), || test[...\n",
       "17549    [test, (b1,c,h,w), train, (b2,c,h,w), || test[...\n",
       "17551    [device = torch.device('cuda' if torch.cuda.is...\n",
       "17552    [actuator_net_file = \"resources/actuator_nets/...\n",
       "17553    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17554    [requirement.txt, !python train.py --img 416 -...\n",
       "17555    [postprocess, def postprocess(self, data):\\r\\n...\n",
       "17556    [a = torch.tensor([[  101,   101,   101,   101...\n",
       "17558    [pip3 install \"torchx[dev]\", vi my_app.py, # m...\n",
       "17559    [max_encoder_length = 24\\r\\ntraining_cutoff = ...\n",
       "17560    [from torchmetrics import JaccardIndex\\r\\nimpo...\n",
       "17561    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17562    [Colab, Art Generator, Colab, NameError       ...\n",
       "17563    [tensor([[1, 0, 0, 4, 0, 5, 0, 0],\\r\\n        ...\n",
       "17564    [mode ='bilinear', dh = torch.linspace(-1,1, h...\n",
       "17565    [bash install-deps, ==&gt; Installing dependen...\n",
       "17566    [gamma = 0.9\\r\\nTARGET_REPLACE_ITER = 500\\r\\nn...\n",
       "17567    [dnn, onnx, dnn.readNetFromONNX, blobFromImage...\n",
       "17568    [import sda\\r\\nva = sda.VideoAnimator(gpu=-1, ...\n",
       "17569    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17570    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "17571    [hidden_dim = 128\\r\\nr_input        = torch.nn...\n",
       "17572    [text, class, tokenizer = lambda x: re.sub(r\"[...\n",
       "17573    [from transformers import AutoModelForCausalLM...\n",
       "17574    [    points = genfromtxt(path, delimiter='\\t',...\n",
       "17575    [+--------------------------------------------...\n",
       "17577    [def convert(data):\\r\\nnew_data = []\\r\\nfor id...\n",
       "17578    [library(torch)\\r\\nx &lt;- torch_randn(10,2)\\r...\n",
       "17579    [File \"/data/ywj/Anaconda3/envs/torch/lib/pyth...\n",
       "17580    [d_input   = torch.nn.Conv1d(1, 33, 10, stride...\n",
       "17581    [imported torch, import HNN, [libprotobuf FATA...\n",
       "17582    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "17583    [CMD, ENTYPOINT, ...\\r\\nCMD [\"torchserve\", \"--...\n",
       "17584    [InvalidArgument: [ONNXRuntimeError] : 2 : INV...\n",
       "17585    [torch::Tensor DDPRLabeler::compute_pi_loss(co...\n",
       "17586    [self.transformation = transformation.to(self....\n",
       "17587    [class CNN(nn.Module):\\r\\n  def __init__(self,...\n",
       "17589    [func, torch.tensor, /work/aten/src/ATen/MapAl...\n",
       "17590    [class BERT_architecture(nn.Module):\\r\\n\\r\\nde...\n",
       "17591    [torch.distributed.lauch, main.py, python -m t...\n",
       "17592    [C:\\yolov5\\VisionExe\\main\\torch\\_jit_internal....\n",
       "17593    [import pytest\\r\\nimport nvidia_smi\\r\\n\\r\\ndef...\n",
       "17594    [# main.py\\r\\nfrom fastapi import FastAPI\\r\\nf...\n",
       "17595    [my_function, multiprocessing, my_function(), ...\n",
       "17596    [forward().toTensor, libtorch, Eigen::ArrayXXf...\n",
       "17597    [               for epoch in range(start_epoch...\n",
       "17598    [python main.py --config cfgs/cifar10.yaml --r...\n",
       "17599    [---------------------------------------------...\n",
       "17600    [L, (N, N), import torch as pt\\r\\nimport numpy...\n",
       "17601    [data_transforms = {\\r\\n    'train': transform...\n",
       "17602    [class LSTMTagger(nn.Module):\\r\\n\\r\\ndef __ini...\n",
       "17603    [discriminator = nn.Sequential(\\r\\n    # in: 3...\n",
       "17604    [import torch\\r\\n\\r\\ntraining_data = torch.ran...\n",
       "17605    [from torchvision import models\\r\\nnet = model...\n",
       "17606    [from fastbook import load_learner\\r\\n, Module...\n",
       "17608    [import numpy as np\\r\\n#----------------------...\n",
       "17609    [import numpy as np\\r\\n#----------------------...\n",
       "17610    [import numpy as np\\r\\n#----------------------...\n",
       "17611    [class UnknownFuncRLNet(torch.nn.Module):\\r\\n ...\n",
       "17612    [FROM cityflowproject/cityflow\\r\\n\\r\\nWORKDIR ...\n",
       "17613    [torch, c++, Net, struct Net:torch::nn::Module...\n",
       "17614    [Line  Mem usage    Increment    Occurrences L...\n",
       "17615    [3, 5, 7, idx.T, idx = torch.tensor([[3, 3, 3,...\n",
       "17616    [from transformers import AutoTokenizer, AutoM...\n",
       "17617    [    import matplotlib.pyplot as plt\\r\\n    im...\n",
       "17619    [[\\r\\n    [predecessor_node_id, edge_id connec...\n",
       "17620    [tmux, {**os.environ, \"CUDA_VISIBLE_DEVICES\":s...\n",
       "17621    [model = mymodel()\\r\\ndevice = torch.device(\"c...\n",
       "17623    [!add-apt-repository ppa:deadsnakes/ppa\\r\\n!ap...\n",
       "17624            [\"{'label' = [1, 2]}\", {'label' = [1,2]}]\n",
       "17625    [from time import process_time\\r\\n\\r\\nX = torc...\n",
       "17626    [pretrained_path, hyperparams.yaml, from speec...\n",
       "17627    [ mask_idx = np.random.permutation(64)[:32]\\r\\...\n",
       "17628    [pred = output.numpy\\r\\n#PIL.Image(pred)\\r\\nim...\n",
       "17629    [indexes, t = torch.zeros(2, 3, 4)\\r\\nindexes ...\n",
       "17631    [t = [[...], [....], [....] .... ]\\r\\n, indice...\n",
       "17633    [conda install pandas, PackagesNotFoundError: ...\n",
       "17634    [conda install pandas, PackagesNotFoundError: ...\n",
       "17635    [conda install pandas, PackagesNotFoundError: ...\n",
       "17636    [conda install pandas, PackagesNotFoundError: ...\n",
       "17637    [def speech_file_to_array_fn(batch):\\r\\n    sp...\n",
       "17638    [a = tensor([1, 2])\\r\\n\\r\\nb = tensor([3, 4, 5...\n",
       "17639    [def set_seed(seed: int):\\r\\n    \"\"\"\\r\\n    He...\n",
       "17640    [loss = criterion(y_pred, y_batch)\\r\\noptimize...\n",
       "17641    [Training the model...\\r\\nTraceback (most rece...\n",
       "17642    [import torch\\r\\nimport time\\r\\nimport random\\...\n",
       "17644    [pred, val1, val2, def thresh_format(pred, val...\n",
       "17645    [No module named 'torch._C', torch==1.9.1, tra...\n",
       "17646    [x_input_, y_gt_ = datasets.make_regression(n_...\n",
       "17647    [import cv2\\r\\nimport numpy as np\\r\\nfrom elem...\n",
       "17649    [updateOutput(), forward(), updateGradInput(),...\n",
       "17651    [def train():\\r\\n  \\r\\n  model.train()\\r\\n\\r\\n...\n",
       "17652    [def train():\\r\\n  \\r\\n  model.train()\\r\\n\\r\\n...\n",
       "17653    [\\r\\n\\r\\n# (list) Application requirements\\r\\n...\n",
       "17654    [test = [[2,1],[3,2],[4,4],[5,67]]\\r\\nelement ...\n",
       "17655    [def random_sample(feature, pool_idx):\\r\\n    ...\n",
       "17656    [pip install torch==1.4.0\\r\\n\\r\\n\\r\\nERROR: Co...\n",
       "17658    [C:\\Users\\messlaptop\\PycharmProjects\\Source_co...\n",
       "17659    [  File \"/home/jba5337/work/ds440w/EditNTS-Goo...\n",
       "17660    [    This probably means that you are not usin...\n",
       "17661    [artifact_path: model\\r\\ndatabricks_runtime: 8...\n",
       "17662    [import torch\\r\\nimport matplotlib.pyplot as p...\n",
       "17663    [z = cumsum( [ 0, 1, 2, 6, 9 ] ), z = [ 0, 1, ...\n",
       "17664    [z = cumsum( [ 0, 1, 2, 6, 9 ] ), z = [ 0, 1, ...\n",
       "17665    [z = cumsum( [ 0, 1, 2, 6, 9 ] ), z = [ 0, 1, ...\n",
       "17666    [z = cumsum( [ 0, 1, 2, 6, 9 ] ), z = [ 0, 1, ...\n",
       "17667    [z = cumsum( [ 0, 1, 2, 6, 9 ] ), z = [ 0, 1, ...\n",
       "17668    [library(keras)\\r\\n\\r\\n&gt;model &lt;- keras_m...\n",
       "17669    [pip install stoke\\r\\nCollecting stoke\\r\\n  Us...\n",
       "17670    [import numpy as np\\r\\nfrom transformers impor...\n",
       "17672    [class Net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "17673                              [torch, numpy, float64]\n",
       "17676    [mlmodel = ct.converters.convert(\\r\\n  torchsc...\n",
       "17677    [# Load pre-trained model tokenizer (vocabular...\n",
       "17678    [# Load pre-trained model tokenizer (vocabular...\n",
       "17679    [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "17680    [a = tensor([1., 1., 1., 1., 1., 1., 1., 1., 1...\n",
       "17681    [  captureBuilder = mCameraDevice.createCaptur...\n",
       "17682    [import numpy as np\\r\\nimport torch\\r\\n\\r\\ninp...\n",
       "17683    [mat = torch.randint(1, 10, (8,4))\\r\\n, rearra...\n",
       "17684    [logger.debug(f\"action_tensor    = {action_ten...\n",
       "17685    [sudo vi /etc/dphys-swapfile # change swapfile...\n",
       "17687    [install_torch(), Error in cpp_lantern_init(in...\n",
       "17688    [!wget https://developer.download.nvidia.com/c...\n",
       "17689    [torchvision.io.read_image, path, torchvision....\n",
       "17691    [torch, train &lt;- function(x, y, hidden = 4,...\n",
       "17692    [setup.py, sudo python3 setup.py install --plu...\n",
       "17693    [                  excerpt                    ...\n",
       "17694    [for i in range(8):\\r\\n    (tensor_B[i, :] == ...\n",
       "17695    [import networkx as nx\\r\\nimport pandas as pd\\...\n",
       "17696    [ID   Target   Weight   Label\\r\\n1      12    ...\n",
       "17697    [ModuleNotFoundError: No module named 'torch',...\n",
       "17698    [    transform = transforms.Compose(\\r\\n    [\\...\n",
       "17699    [    transform = transforms.Compose(\\r\\n    [\\...\n",
       "17700    [****To save the model I am using :****\\r\\nPAT...\n",
       "17701    [def save_checkpoint(state, is_best,task_id, f...\n",
       "17703    [OWN_FILE = {'audio': 'file.wav'}\\r\\n\\r\\n\\r\\np...\n",
       "17704    [G = to_networkx(data,\\r\\n                node...\n",
       "17706    [!pip install torch_sparse, Collecting torch_s...\n",
       "17707    [!pip install torch_sparse, Collecting torch_s...\n",
       "17708    [!pip install torch_sparse, Collecting torch_s...\n",
       "17709    [!pip install torch_sparse, Collecting torch_s...\n",
       "17710    [!pip install torch_sparse, Collecting torch_s...\n",
       "17711    [torch.multiprocessing, with Pool(1) as p:\\r\\n...\n",
       "17712    [    2021-04-20 18:00:43    INFO    Environmen...\n",
       "17713    [torch.load(\"pthfilename\"), os.environ[\"CUDA_V...\n",
       "17714    [pip3 install torch==1.8.1+cu111 torchvision==...\n",
       "17715    [a = torch.Tensor([1, 2, 3, 4, 5])\\r\\nb = torc...\n",
       "17716    [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "17717    [import easyocr \\r\\nreader = easyocr.Reader(['...\n",
       "17718    [th train.lua -data_file data/demo-train.hdf5 ...\n",
       "17719    [Sys.getenv()\\r\\nCUDA                         ...\n",
       "17720    [model = AutoModel.from_pretrained('/content/d...\n",
       "17721    [javascript, \"ImageCapture is not defined\", //...\n",
       "17727    [grad_fn=&lt;DivBackward0&gt;, tensor([[val]])...\n",
       "17728    [torch, python, import numpy as np\\r\\nimport t...\n",
       "17729    [torch::Tensor, std::vector&lt;torch::Tensor&g...\n",
       "17730    [d_in &lt;- 3\\r\\nd_out &lt;- 1\\r\\nn &lt;- 100\\...\n",
       "17731    [from torchtext.utils import download_from_url...\n",
       "17733    [local M={}\\r\\n\\r\\nrequire 'paths';\\r\\ntorch.m...\n",
       "17734    [from transformers import AlbertTokenizer, Alb...\n",
       "17735    [Traceback (most recent call last):\\r\\nFile \"p...\n",
       "17736    [ModuleNotFoundError                       Tra...\n",
       "17737    [x, with np.printoptions(precision=2, suppress...\n",
       "17738    [remote:        Collecting torch&gt;=1.0.0\\r\\n...\n",
       "17739    [#include &lt;opencv4/opencv2/opencv.hpp&gt;\\r...\n",
       "17740    [results = model(batch)\\r\\n# results is a list...\n",
       "17741    [inp = layers.Input(shape = (386, 1024, 1), dt...\n",
       "17743    [transform = transforms.Compose([\\r\\n    trans...\n",
       "17745    [indexs, indexs = np.array([1, 4, 3, 0, 0, 1, ...\n",
       "17746    [from torch.utils.data import random_split // ...\n",
       "17747    [from torch.utils.data import random_split // ...\n",
       "17752    [import pandas as pd\\r\\nimport torch\\r\\ndf = p...\n",
       "17753    [import pandas as pd\\r\\nimport torch\\r\\ndf = p...\n",
       "17754    [import pandas as pd\\r\\nimport torch\\r\\ndf = p...\n",
       "17755    [import torch\\r\\nprint(torch.__version__)\\r\\n,...\n",
       "17756    [import torch\\r\\nprint(torch.__version__)\\r\\n,...\n",
       "17757    [import torch\\r\\nprint(torch.__version__)\\r\\n,...\n",
       "17758    [import torch\\r\\nprint(torch.__version__)\\r\\n,...\n",
       "17759    [import torch\\r\\nfrom transformers import T5Fo...\n",
       "17760    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "17761    [mnist_train = datasets.MNIST(data_dir, downlo...\n",
       "17762    [args, torch.onnx.export, RuntimeError: Only t...\n",
       "17763    [---------------------------------------------...\n",
       "17765    [!pip install transformers\\r\\n!wget https://us...\n",
       "17766    [a, (1, N, 1), 1, a = torch.from_numpy(np.arra...\n",
       "17767    [ValueError: pic should be 2/3 dimensional. Go...\n",
       "17768    [(N, k, 1), k, N, t, \\r\\nstacked_predictions  ...\n",
       "17769    [usr/bin/ld: CMakeFiles/Lib2_Test.dir/Lib2_Tes...\n",
       "17770    [current_dir = os.path.dirname(__file__) # (1)...\n",
       "17771    [torch.save(model)\\r\\n, .pt, torch.load('PATH_...\n",
       "17772    [torch.save(model)\\r\\n, .pt, torch.load('PATH_...\n",
       "17773    [#here i create a random torch with N matrices...\n",
       "17774    [x = mnist_test.data.reshape(x.shape[0], -1).n...\n",
       "17775    [BytesIO, torch.save(), import torch \\r\\nimpor...\n",
       "17776    [#include &lt;torch/script.h&gt;\\r\\n#include &...\n",
       "17777    [#!/usr/bin/env bash\\r\\n\\r\\ngit fetch\\r\\ngit r...\n",
       "17779    [tacotron2 = torch.load(\"path.tar.gz\") #dont w...\n",
       "17780    [0.01*, offsets.shape: [1, 4, 46, 85]\\r\\nprobs...\n",
       "17781    [torch::from_blob, import cv2\\r\\nimport torch\\...\n",
       "17783    [import torch\\r\\nprint(torch.__path__)\\r\\n\\r\\n...\n",
       "17785    [tfm = np.float32([[A[0, 0], A[1, 0], A[2, 0]]...\n",
       "17786    [torch::Tensor, sizes,     auto t = torch::one...\n",
       "17788    [finfo, libtorch, esp = torch.finfo(torch.floa...\n",
       "17789    [cv::getAffineTransform(), cv::InputArray, tor...\n",
       "17790    [    cout &lt;&lt; history &lt;&lt; endl;\\r\\n ...\n",
       "17791    [pose_body = np.zeros([1,63])\\r\\npose_body[0,0...\n",
       "17792    [np.delete, ids = np.delete( ids, np.concatena...\n",
       "17794    [torch::stack, c10::TensorList, torch::stack, ...\n",
       "17795    [pip install stanza, ERROR: No matching distri...\n",
       "17796    [std::vector&lt;std::vector&lt;double&gt;&gt;,...\n",
       "17797    [std::vector&lt;std::vector&lt;double&gt;&gt;,...\n",
       "17798    [size = 100000\\r\\nanswer_count = 4\\r\\nnum_rang...\n",
       "17799    [self.conv = nn.Conv2d(3, 64, kernel_size=3, s...\n",
       "17800    [    usr/local/torch/install/share/lua/5.2/tre...\n",
       "17801    [x, target, P = torch.ones(x.shape)\\r\\ngamma =...\n",
       "17802    [nvidia-smi, &gt; Failed to initialize NVML: U...\n",
       "17803    [&gt;     lua: train.lua:6: module 'torch' not...\n",
       "17805    [numpy, torch, indices: [[3],[2]] (2x1)\\r\\n\\r\\...\n",
       "17806    [error: use of deleted function â€˜void torch:...\n",
       "17807    [/usr/bin/ld: CMakeFiles/TryGTest_test.dir/tes...\n",
       "17808    [  print ('x',self.head)  \\r\\n  x = Linear(in_...\n",
       "17809    [LongTensor, x = torch.load(filepath)\\r\\n, tor...\n",
       "17810    [(gpu) C:\\Users\\abc&gt;pip install --upgrade -...\n",
       "17811    [VGG(\\r\\n  (features): Sequential(\\r\\n    (0):...\n",
       "17812    [import torch\\r\\nimport torch.nn             a...\n",
       "17813    [def load_data(data_path, batch_size, num_work...\n",
       "17814    [Traceback (most recent call last):\\r\\n  File ...\n",
       "17815    [from transformers import AutoTokenizer, AutoM...\n",
       "17816    [pip install torch===1.5.0 torchvision===0.6.0...\n",
       "17817    [require('torch')\\r\\n\\r\\nrequire('nn')\\r\\n\\r\\n...\n",
       "17819    [pip install -e .\\r\\n, Obtaining file:///E:/Eg...\n",
       "17820    [import torch-cpu, Traceback (most recent call...\n",
       "17821    [torch.CharStorage('hello.txt'), [torch.CharSt...\n",
       "17823    [labels = tf.cast(labels, tf.int64)\\r\\npredict...\n",
       "17825    [    import torch\\r\\n    import torchvision.da...\n",
       "17826    [replicate(x,batch_size), x = x:resize(x:size(...\n",
       "17827    [  File \"&lt;input&gt;\", line 1, in &lt;module...\n",
       "17828    [require('torch')\\r\\ntorch.test()\\r\\n, C:\\torc...\n",
       "17829    [  takePicture() async {\\r\\n    Torch.turnOn()...\n",
       "17830    [---------------------------------------------...\n",
       "17831    [FROM nvidia/cuda:10.2-base-ubuntu18.04\\r\\n\\r\\...\n",
       "17832    [dofile 'Csv.lua'\\r\\n\\r\\nlocal proteinFile = C...\n",
       "17833    [--print-alignment, curl https://dl.fbaipublic...\n",
       "17834    [R: Command errored out with exit status 1:   ...\n",
       "17835    [if log_to_tensorboard: from torch.utils.tenso...\n",
       "17836    [if log_to_tensorboard: from torch.utils.tenso...\n",
       "17837    [[ 1 2 3 4 *0* ]\\r\\n[ 5 1 0 1 *1* ]\\r\\n[ 0 1 0...\n",
       "17838    [import torch, #include &lt;Python.h&gt;\\r\\n\\r...\n",
       "17839    [torch.multiprocessing, import sys\\r\\nimport t...\n",
       "17840    [torch.multiprocessing, import sys\\r\\nimport t...\n",
       "17841    [model = torchvision.models.segmentation.fcn_r...\n",
       "17842    [dataaddress = 'blah/blah' # address where all...\n",
       "17843    [(base) Nicos-MacBook-Pro:src nico$ python3 ge...\n",
       "17844    [data_raw    = {\"mk_reservation\" : [\"i want to...\n",
       "17845    [data_raw    = {\"mk_reservation\" : [\"i want to...\n",
       "17846    [conda install pytorch torchvision cpuonly -c ...\n",
       "17847    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "17848    [tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "17849    [modele.gapbranch:backward(n, loss_grad), /hom...\n",
       "17851    [th style-swap.lua --content images/content/bi...\n",
       "17852    [t[:,:,r:r+s,:] = 0, TypeError: only integer s...\n",
       "17853    [pip list\\r\\nPackage     Version\\r\\n----------...\n",
       "17854    [import torch\\r\\nfrom kymatio import Scatterin...\n",
       "17855    [embeddings=[]\\r\\nembedding_np_array=[]\\r\\nfor...\n",
       "17857    [cd ~/\\r\\ncurl -s https://raw.githubuserconten...\n",
       "17859    [cd ~/\\r\\ncurl -s https://raw.githubuserconten...\n",
       "17863    [x = torch.tensor([1, 2, 3])\\r\\nprint(x)\\r\\n# ...\n",
       "17865    [OSError: [WinError 193] %1 is not a valid Win...\n",
       "17866    [type(x), ndarray, type(x[i]), ndarray, type(x...\n",
       "17867    [ public class Flashlight extends Fragment imp...\n",
       "17868    [ public class Flashlight extends Fragment imp...\n",
       "17869    [from torch.utils.ffi import _wrap_function\\r\\...\n",
       "17871    [(no source code here, just compiler outputs)\\...\n",
       "17872    [import torch.nn as nn\\r\\n\\r\\nloss = nn.MSELos...\n",
       "17874    [import torch.nn as nn\\r\\n\\r\\nloss = nn.MSELos...\n",
       "17875    [ import numpy as np\\r\\n x0=np.random.rand(300...\n",
       "17876    [RuntimeError: bool value of Tensor with more ...\n",
       "17877    [  elif args.data == 'kmnist':\\r\\n      normal...\n",
       "17878    [X_train = np.load(dirpath + 'X_train.npy')\\r\\...\n",
       "17879    [local gauK = image.gaussian(math.ceil(3*sigma...\n",
       "17880    [local gauK = image.gaussian(math.ceil(3*sigma...\n",
       "17881    [ | Epoch: [1][1/88880][1]  Time 4.91  LR 0.01...\n",
       "17882    [function CharSplitLMMinibatchLoader.text_to_t...\n",
       "17883    [conda install lua=5.2 lua-science -c alexbw\\r...\n",
       "17884    [1.0.1.post2, 1.10.1, from tensorlayer.lazy_im...\n",
       "17885    [import torch #works \\r\\n, import torch.nn\\r\\n...\n",
       "17886    [import torch #works \\r\\n, import torch.nn\\r\\n...\n",
       "17887    [roy@roy-Lenovo:~/convert_torch_to_pytorch$ py...\n",
       "17888    [/usr/bin/env: th: No such file or directory, ...\n",
       "17889    [Ubuntu 18.04\\r\\n\\r\\nCUDA-10.0\\r\\n,         In...\n",
       "17890    [pytorch, torch.nn.functional.weight.data.fill...\n",
       "17891    [pytorch, torch.nn.functional.weight.data.fill...\n",
       "17892    [import cv2\\r\\nimport numpy as np\\r\\n\\r\\nmodel...\n",
       "17893    [!th luafile.lua, !th, /bin/bash: th: command ...\n",
       "17894    [Eclipse C++, CMake, torch/torch.h, cmake -G \"...\n",
       "17895    [Eclipse C++, CMake, torch/torch.h, cmake -G \"...\n",
       "17896    [parameters = np.load(\"model\")\\r\\n, Traceback ...\n",
       "17898    [A = array([[0., 1., 0.],\\r\\n          [0., 1....\n",
       "17900    [function fwd_prop_enc(source, source_l, batch...\n",
       "17901    [$./install.sh\\r\\n, CMake Error: The following...\n",
       "17902    [$./install.sh\\r\\n, CMake Error: The following...\n",
       "17903    [$./install.sh\\r\\n, CMake Error: The following...\n",
       "17904    [function classify(txt_dir, img_dir, cls_list)...\n",
       "17905    [function classify(txt_dir, img_dir, cls_list)...\n",
       "17907    [rembuff:floor()\\r\\nError: Attempt to call met...\n",
       "17908    [torch.bmm in inspect.getmembers(torch)\\r\\nFal...\n",
       "17909    [local IcgResample, Parent = torch.class('icgn...\n",
       "17911    [[error] 3726#81246: *19 lua entry thread abor...\n",
       "17912    [$luarocks install cutorch\\r\\n$luarocks instal...\n",
       "17913    [$luarocks install cutorch\\r\\n$luarocks instal...\n",
       "17914    [source ~/.bashrc, %%bash\\r\\nsource ~/.bashrc\\...\n",
       "17915    [source ~/.bashrc, %%bash\\r\\nsource ~/.bashrc\\...\n",
       "17916    [from __future__ import print_function\\r\\n\\r\\n...\n",
       "17918    [System.gc(), object MemoryManager {    \\r\\n  ...\n",
       "17919    [Ubuntu 16.04, ./run.sh, /home/username/torch/...\n",
       "17920    [x:view(x:nElement()),     a, b = x, x\\r\\n    ...\n",
       "17921    [~/torch/extra/cutorch/build/lib/THC/CMakeFile...\n",
       "17923    [if is_pooling then \\r\\nfor k = 1, #color_code...\n",
       "17924    [hdF5, #guess image_name is the string\\r\\nimgn...\n",
       "17925    [if is_pooling then\\r\\n   for k = 1, #color_co...\n",
       "17926    [ if (torch.type(previousModule) == 'cudnn.ReL...\n",
       "17927    [# Residual Block\\r\\nclass ResidualBlock(nn.Mo...\n",
       "17929    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17930    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17931    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17932    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17933    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17934    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17935    [Python 3.5.5 |Anaconda, Inc.| (default, Mar 1...\n",
       "17936    [image=require 'image'\\r\\n-- input: greyscale ...\n",
       "17937    [git clone https://github.com/facebook/fbluali...\n",
       "17938    [/home/ubuntu/torch/install/bin/luajit: /home/...\n",
       "17941    [local torch = require 'torch'\\r\\nlocal nn = r...\n",
       "17943    [net = nn.Sequential()\\r\\nnet:add(cudnn.Spatia...\n",
       "17946    [git clone https://github.com/xianyi/OpenBLAS....\n",
       "17948    [@Override\\r\\nprotected void onResume() {\\r\\n ...\n",
       "17949    [mp3, mp3, bash$ audio.load(/path/to/fullyMerg...\n",
       "17950    [mp3, mp3, bash$ audio.load(/path/to/fullyMerg...\n",
       "17951    [cd fblualib/fblualib/python\\r\\nluarocks make ...\n",
       "17952    [model = nn.Sequential()\\r\\nmodel:add(nn.Linea...\n",
       "17953    [for i = 1,64 do\\r\\n     t = sys.clock();\\r\\n ...\n",
       "17954    [luarocks, [100%] Linking CXX shared module li...\n",
       "17955    [luarocks install https://raw.githubuserconten...\n",
       "17956    [luarocks install https://raw.githubuserconten...\n",
       "17957    [luarocks install cv, CMake Error at CMakeList...\n",
       "17958    [h5_path = opt.save_root..'attention_maps.h5'\\...\n",
       "17962    [aaa = {1, 2, 3, 4}\\r\\n\\r\\nbbb = {0, 0, 0, 1}\\...\n",
       "17963    [dim, t = torch.Tensor([[1,2],[3,4]])\\r\\nprint...\n",
       "17964    [dim, t = torch.Tensor([[1,2],[3,4]])\\r\\nprint...\n",
       "17965    [require 'caffe'\\r\\nnet = caffe.Net('deploy.pr...\n",
       "17966    [.prototxt, .caffemodel, net:forward(input), i...\n",
       "17967                               [SupportCameraManager]\n",
       "17973    [$ python -c \"import torch; import cv2\", $ pyt...\n",
       "17974    [backward, model:updateParameters(&lt;learning...\n",
       "17975    [./install.sh, $ git clone https://github.com/...\n",
       "17976    [self:add( nn.Normalize(2) ), self:add( nn.Vie...\n",
       "17977    [self:add( nn.Normalize(2) ), self:add( nn.Vie...\n",
       "17978    [some_model, nn.Sequential, cudnn.SpatialConvo...\n",
       "17979    [&gt; $ luarocks make hdf5-0-0.rockspec LIBHDF...\n",
       "17980    [branch = nn.Sequential()\\r\\nbranch:add(....) ...\n",
       "17981    [pred, scores, pred, score, pred, nqs=dataset[...\n",
       "17982    [scores, scores, nqs=dataset['question']:size(...\n",
       "17983    [require('image')\\r\\nrequire('nn')\\r\\nrequire(...\n",
       "17984    [qlua cnnmrf.lua -content_name master_entrance...\n",
       "17985    [mlp = nn.Sequential();\\r\\nc = nn.Parallel(1,2...\n",
       "17986    [BatchLoader.init, self, function BatchLoader:...\n",
       "17987    [BatchLoader.init, self, function BatchLoader:...\n",
       "17988    [gesture, 101, 10, 100, 9, userdata, userdata,...\n",
       "17989    [gesture, 101, 10, 100, 9, userdata, userdata,...\n",
       "17990    [include('Conv.lua')\\r\\nmodelTrained = torch.l...\n",
       "17994    [local dpt = nn.DataParallelTable(1, true, tru...\n",
       "17995    [torch[cpuType], batch = torch[cpuType](sz, nC...\n",
       "17996    [clone(), mlp:add(self.transfer:clone())\\r\\n, ...\n",
       "17997    [/Users/Marcel/torch/install/share/lua/5.1/tre...\n",
       "17998    [-- it is common style to mark inputs with ide...\n",
       "17999    [    function ColourCompareHistEMD (imagers)\\r...\n",
       "18000    [  (x): nn.SpatialReflectionPadding(l=1, r=1, ...\n",
       "18001    [local img = image.load(file_name)\\r\\nlocal w,...\n",
       "18003    [net = nn.Sequential()\\r\\nnet:add(nn.SpatialCo...\n",
       "18004    [if argshuffle then \\r\\n    local perm = torch...\n",
       "18005    [if argshuffle then \\r\\n    local perm = torch...\n",
       "18006    [if argshuffle then \\r\\n    local perm = torch...\n",
       "18007    [if argshuffle then \\r\\n    local perm = torch...\n",
       "18008    [torch.ParallelTable, nn.SpatialConvolution, n...\n",
       "18009    [image_representation[0, 1:, :, :] = 0\\r\\n, Ru...\n",
       "18010    [import torch.utils.data as data_utils\\r\\n\\r\\n...\n",
       "18011    [import torch.utils.data as data_utils\\r\\n\\r\\n...\n",
       "18013    [for t = 1, params.num_iterations do\\r\\n  loca...\n",
       "18014    [weight[:] -= lr*mean/(sqrt(variance) + self.e...\n",
       "18015    [weight[:] -= lr*mean/(sqrt(variance) + self.e...\n",
       "18016    [nn graph, local e1 = - nn.SpatialConvolution(...\n",
       "18018    [    function capTo1or0 (Tensor3d)\\r\\n\\r\\n    ...\n",
       "18019    [/home/jaysen/torch/install/bin/luajit: /home/...\n",
       "18020    [&gt; lua -e \"print(\\\"abc\\\")\" | hexdump -c\\r\\n...\n",
       "18021    [net:cuda(), local net = nn.Sequential()\\r\\nne...\n",
       "18022    [net:cuda(), local net = nn.Sequential()\\r\\nne...\n",
       "18023    [Catons-Mac-mini:torch-rnn catons$ th train.lu...\n",
       "18025    [loss(x, class) = -x[class]\\r\\n, loss(x, class...\n",
       "18026    [install.sh, make, [ 75%] Building NVCC (Devic...\n",
       "18027    [install.sh, make, [ 75%] Building NVCC (Devic...\n",
       "18030    [./install.sh\\r\\n, ~/torch, -- Installing: /ho...\n",
       "18032    [CUDA_TOOLKIT_ROOT_DIR, cmake -DCUDA_TOOLKIT_R...\n",
       "18033    [(tf0.12.1) [root@sd-bigdata-gpu-02 deepmask]#...\n",
       "18034    [require 'nn';\\r\\n\\r\\nchar = nn.LookupTable(10...\n",
       "18035    [require \"nn\";\\r\\nrequire \"optim\";\\r\\n\\r\\nloca...\n",
       "18036    [/home/thijser/torch/install/share/lua/5.1/nn/...\n",
       "18037    [  CUDA_BIN_PATH=/path_to_cuda \\r\\n, git clone...\n",
       "18038    [x_at_i = torch.Tensor(1,i), x_at_1 = 1\\r\\nx_a...\n",
       "18039    [paths.mkdir('checkpointsR3')\\r\\nparametersR, ...\n",
       "18041    [th&gt; X = torch.rand(2,4)\\r\\n\\r\\nth&gt; X\\r\\...\n",
       "18042    [X = torch.rand(10000, 3, 50, 50)\\r\\ninds = to...\n",
       "18043    [train = torch.range(1,10), p = torch.randperm...\n",
       "18044    [th&gt; net\\r\\nnn.Sequential {\\r\\n  [input -&g...\n",
       "18045    [torch, linux mint, /etc/linuxmint/info, RELEA...\n",
       "18047    [.t7, train_set.t7, test_set.t7, .t7, ROOT, da...\n",
       "18052    [sudo apt-get -y install lua-sql-postgres\\r\\ns...\n",
       "18053    [sudo apt-get -y install lua-sql-postgres\\r\\ns...\n",
       "18054    [optim, X, In 14 module of nn.Sequential:\\r\\n/...\n",
       "18055    [luarocks install luasql-postgres, Installing ...\n",
       "18056    [CNN, Torch 7, Lua, setmetatable, setmetatable...\n",
       "18057    [CNN, Torch 7, Lua, setmetatable, setmetatable...\n",
       "18058    [fs, require 'torch'\\r\\nrequire 'nn'\\r\\n\\r\\nlo...\n",
       "18060    [tf.device(), cpu_gather = []\\r\\nlabel_batches...\n",
       "18061    [output = net:forward(input)\\r\\nerr = criterio...\n",
       "18062    [import torch\\r\\n\\r\\nx = torch.Tensor([2, 3])\\...\n",
       "18063    [import torch\\r\\n\\r\\nx = torch.Tensor([2, 3])\\...\n",
       "18064    [import torch\\r\\n\\r\\nx = torch.Tensor([2, 3])\\...\n",
       "18065    [unsqueeze(), input = torch.Tensor(2, 4, 3) # ...\n",
       "18066    [unsqueeze(), input = torch.Tensor(2, 4, 3) # ...\n",
       "18067    [    a = torch.zeros(3)\\r\\n    a[1] = 1       ...\n",
       "18068    [saved_models, egg_net_best.h5, input = image....\n",
       "18069    [ minibatch = torch.Tensor(5, 2, 3,5)\\r\\n m = ...\n",
       "18071                   [n x 2A x B x C, n x A x B x C, n]\n",
       "18075    [            var options = new MobileBarcodeSc...\n",
       "18076    [-- The C compiler identification is AppleClan...\n",
       "18077    [{\\r\\n  1 : \\r\\n    {\\r\\n      1 : DoubleTenso...\n",
       "18078    [local image_url = '/home/delpech/mnist/test/5...\n",
       "18079    [#out = output of the neural net and output is...\n",
       "18081    [mCameraSource = builder.setFlashMode(useFlash...\n",
       "18082    [image1.txt := class index of image and featur...\n",
       "18084    [torch.Tensor, -- W and P are of size NxN, r i...\n",
       "18085    [torch.Tensor, -- W and P are of size NxN, r i...\n",
       "18087    [The operation cannot be completed.  See the d...\n",
       "18088    [require 'nn'\\r\\ncriterion = nn.ClassNLLCriter...\n",
       "18089    [./batch-represent/main.lua,     /Users/conor/...\n",
       "18090    [require 'nn'\\r\\n\\r\\n-- the input\\r\\nlocal bat...\n",
       "18091    [-- get top propsals\\r\\nlocal masks,_ = infer:...\n",
       "18092    [function create_DataParallelNetwork(model)\\r\\...\n",
       "18093    [itorch notebook\\r\\n, require 'nn'\\r\\nnn.Seque...\n",
       "18094    [$ luarocks install cunn\\r\\n...\\r\\n...\\r\\n-- I...\n",
       "18095    [require 'dpnn'\\r\\n require 'cunn'\\r\\n\\r\\n loc...\n",
       "18096    [./pretrain.sh seq2seq jobqueries lstm, THCuda...\n",
       "18097    [./Makefile.tail:40: recipe for target 'libs' ...\n",
       "18098    [a=image.load('test.png')\\r\\ninput=torch.Tenso...\n",
       "18102    [local enc = nn.Sequential()\\r\\nenc:add(nn.Loo...\n",
       "18103    [cmd = torch.CmdLine()\\r\\ncmd:text('Training')...\n",
       "18105    [require 'libhashnn', package.loadlib, require...\n",
       "18106    [local function add(a,b)\\r\\n    return (a+b)\\r...\n",
       "18107    [   tack traceback:\\r\\n      [C]: in function ...\n",
       "18108    [import tensorflow as tf\\r\\n\\r\\nclass stacked_...\n",
       "18109    [ local model = loadcaffe.load(\"/home/.../Mode...\n",
       "18110    [  function share_params(cell, src)\\r\\n   if t...\n",
       "18111    [require 'torch'\\r\\nrequire 'nn'\\r\\nrequire 'o...\n",
       "18112    [&lt;Page\\r\\n    x:Class=\"TestApp.MainPage\"\\r\\...\n",
       "18113    [numpy.expand_dims, a = torch.Tensor({{1,2}, {...\n",
       "18114    [(1,1,.,.) = \\r\\n -0.4010 -0.4658 -0.2517 -0.2...\n",
       "18119                                          [draw mask]\n",
       "18120    [  image.save('train100.jpg', trainData[100])\\...\n",
       "18121    [  image.save('train100.jpg', trainData[100])\\...\n",
       "18122    [torch7, Ubuntu14.04, cuda8.0, cudnn5.1, mnist...\n",
       "18123    [/home/ubuntu/torch/install/bin/luajit: .../ub...\n",
       "18125    [numpy.random.permuation, torch.randperm,  imp...\n",
       "18126    [require 'torch'\\r\\nfunction hi_tensor(t)\\r\\n ...\n",
       "18127    [dataset, trainset = {\\r\\n    inputs = {0, 1, ...\n",
       "18128    [require \"nn\"\\r\\nrequire \"nngraph\"\\r\\n\\r\\n-- F...\n",
       "18130    [weigq@weigq-Lenovo-G410:~/torch$ luarocks ins...\n",
       "18131    [first layer, all the others, torch.save, firs...\n",
       "18133    [require 'torch'\\r\\n\\r\\nf = assert(io.open(txt...\n",
       "18134    [ctrl+c, -- threadTester.lua\\r\\nlocal classic ...\n",
       "18135    [ninputs = 22; noutputs = 3\\r\\nhidden =22\\r\\n\\...\n",
       "18136    [network = createNetwork() -- loading a pre-tr...\n",
       "18137    [network = createNetwork() -- loading a pre-tr...\n",
       "18138    [criterion:forward(mlp:forward(input), output)...\n",
       "18139    [require 'torch'\\r\\nrequire 'math'\\r\\nrequire ...\n",
       "18140    [require 'torch'\\r\\nrequire 'math'\\r\\nrequire ...\n",
       "18142    [module = nn.SpatialConvolution(nInputPlane, n...\n",
       "18143    [public class fragment_qrscan extends myFragme...\n",
       "18145    [universal-ctags, exuberant-ctags, &lt;c-]&gt;...\n",
       "18146    [error_log stderr notice;\\r\\ndaemon off;\\r\\n\\r...\n",
       "18147    [require 'neuralconvo' require 'xlua' \\r\\n-- L...\n",
       "18148    [0.55,1,0,1,0,0.29,1,0,1,0.46,1,1,0,0.67,1,0.3...\n",
       "18149    [0.55,1,0,1,0,0.29,1,0,1,0.46,1,1,0,0.67,1,0.3...\n",
       "18151    [-- create closure to evaluate f(X) and df/dX\\...\n",
       "18152    [System:    Host: xxxxxx Kernel: 4.4.0-31-gene...\n",
       "18154    [function attention.recursive_atten_revise(inp...\n",
       "18155    [text(string)\\r\\n\\r\\nLogs a custom text messag...\n",
       "18156    [require('mylib'), require('/path/to/mylib'), ...\n",
       "18157    [require('mylib'), require('/path/to/mylib'), ...\n",
       "18159    [require('cutorch')\\r\\n\\r\\nx = torch.Tensor(3,...\n",
       "18160    [require 'hdf5'\\r\\nlocal myFile = hdf5.open('/...\n",
       "18161    [static int ltest(lua_State* L)\\r\\n{\\r\\n    st...\n",
       "18163    [local MySoftMax, Parent = torch.class('nn.MyS...\n",
       "18166    [nn.DepthConcat, nn.Concat,     def depthconca...\n",
       "18167    [attempt to index a nil value\\r\\n, net:add(Spa...\n",
       "18168    [[I 04:17:34.860 NotebookApp] Kernel started: ...\n",
       "18169    [require 'nn'\\r\\nrequire 'image'\\r\\n, 404, th ...\n",
       "18170    [require 'nn'\\r\\nN = 4\\r\\naaaTensor = torch.ra...\n",
       "18171    [z = cell(10,10)\\r\\n, z{2}{3} = ones(3,1)\\r\\nz...\n",
       "18172    [z = cell(10,10)\\r\\n, z{2}{3} = ones(3,1)\\r\\nz...\n",
       "18174    [clone(), print(), require 'nn'\\r\\nrequire 'nn...\n",
       "18175    [require 'nn'\\r\\nrequire 'nngraph'\\r\\n\\r\\n\\r\\n...\n",
       "18176    [require 'nn'\\r\\nrequire 'nngraph'\\r\\n\\r\\n\\r\\n...\n",
       "18177    [#!/bin/bash\\r\\n\\r\\necho \"####  Starting Job B...\n",
       "18178    [CMake Error at CMakeLists.txt:9 (FIND_PACKAGE...\n",
       "18179    [input = nn.Identity()()\\r\\nnet = nn.Sequentia...\n",
       "18180    [print(ffi.string(torch.data(self.batch.conten...\n",
       "18181    [require 'torch'\\r\\nrequire 'nn'\\r\\nrequire 'c...\n",
       "18182    [OpenCV Error: Assertion failed (type == src2....\n",
       "18183    [for i = 1, n do\\r\\n    local reset = true\\r\\n...\n",
       "18184    [X{                                      Y{ \\r...\n",
       "18185                                  [init_state_global]\n",
       "18186    [200x200, 1x(200x200x3), img1=torch.reshape(im...\n",
       "18188    [input, target, enque, .../torch_distro/instal...\n",
       "18189    [m1, m2 = createModel(8,48), createModel(8,48)...\n",
       "18190    [th&gt; a\\r\\n 0.5058  0.2460  0.9038  0.6348\\r...\n",
       "18191    [th&gt; a\\r\\n 0.5058  0.2460  0.9038  0.6348\\r...\n",
       "18193    [require 'image'\\r\\nrequire 'nn\\r\\nnpy4th = re...\n",
       "18195    [$cmd = system('th neural_style.lua -style_ima...\n",
       "18198    [In [53]: A:size()\\r\\nOut[53]: \\r\\n  3\\r\\n 10\\...\n",
       "18199    [local s_ = 0\\r\\ns_ = s_ + 1; local X_py_1 = f...\n",
       "18200    [local s_ = 0\\r\\ns_ = s_ + 1; local X_py_1 = f...\n",
       "18201    [jeanpat@dip4fish ~]$ whereis gcc-4.9\\r\\ngcc-4...\n",
       "18204    [nn.Sequential {\\r\\n  [input -&gt; (1) -&gt; (...\n",
       "18205    [-- file: myClass.lua\\r\\nlocal myClass = {}\\r\\...\n",
       "18207    [#include &lt;iostream&gt;\\r\\n#include &lt;cst...\n",
       "18209    [os.remove(path_to_dir)\\r\\n, Directory not emp...\n",
       "18210    [os.remove(path_to_dir)\\r\\n, Directory not emp...\n",
       "18212    [local cv = reuqire 'cv'\\r\\nrequire 'cv'\\r\\nre...\n",
       "18214    [    -- The example demonstates the ability to...\n",
       "18215    [N, m, a = {a1, a2, ..., aM},\\r\\nb = {b1, b2, ...\n",
       "18216    [require 'nn'\\r\\nmlp = nn.Sequential() \\r\\ninp...\n",
       "18217    [require('mobdebug').start()    -- for image.d...\n",
       "18219    [nn.MM, nn.Sequential, nn, nn.Module, nn.Modul...\n",
       "18223    [luajit -limage -e \"image.test()\", &gt; requir...\n",
       "18224    [--[[command line arguments]]--\\r\\ncmd = torch...\n",
       "18225    [local function parse_file(path)\\r\\n    -- rea...\n",
       "18226    [local function parse_file(path)\\r\\n    -- rea...\n",
       "18227                     [for i, _ in enumerate(wx):, wx]\n",
       "18231    [torch.Tensor, print('[Clustering all samples....\n",
       "18236    [POST, app = Flask(__name__)\\r\\n@app.route('/c...\n",
       "18237    [Camera camera = Camera.open();\\r\\nCamera.Para...\n",
       "18238    [            if(xxx!=0){\\r\\n                Hi...\n",
       "18239    [-- perceptron\\r\\n\\r\\nrequire 'nn'\\r\\n\\r\\n-- d...\n",
       "18240    [feval = function(x_new)\\r\\n   -- set x to x_n...\n",
       "18241    [feval = function(x_new)\\r\\n   -- set x to x_n...\n",
       "18242    [xTain, nDatax1, xTrain = torch.linspace(-1,1,...\n",
       "18243    [cost = crossEntropyCh[{1, 2}] + l1 * squaredL...\n",
       "18244                                       [torch.Tensor]\n",
       "18245    [ require \"torch\"\\r\\n\\r\\n -- for naming conven...\n",
       "18246                             [Creating cdata Objects]\n",
       "18247    [require 'torch';\\r\\nrequire 'nn';\\r\\nrequire ...\n",
       "18248    [require 'torch';\\r\\nrequire 'nn';\\r\\nrequire ...\n",
       "18250    [iTorch, require nn, [string \"require 'nn'...\"...\n",
       "18251    [ Torch 7.0  Copyright (C) 2001-2011 Idiap, NE...\n",
       "18252    [mnist = require 'mnist'\\r\\n\\r\\ntrainset = mni...\n",
       "18253    [randomkit, luarocks install randomkit, requir...\n",
       "18254    [local RpnData, parent = torch.class('nn.RpnDa...\n",
       "18255                         [:narrow, :resize, :reshape]\n",
       "18256    [= nn.Linear(size1\\r\\nt2h_d.data.module:share(...\n",
       "18258    [self.llstm = LSTM\\r\\nself.rlstm = LSTM\\r\\n\\r\\...\n",
       "18259    [// The subsampling randomly discards frequent...\n",
       "18260    [require 'cunn'\\r\\nrequire 'cutorch'\\r\\n, mode...\n",
       "18261    [f = h5py.File(\"instructions.hdf5\", \"w\")\\r\\nf....\n",
       "18262    [torch.Tensor, local original_tensor = -- outp...\n",
       "18263    [torch.Tensor, local original_tensor = -- outp...\n",
       "18264    [x = tf.placeholder(tf.float32, [None, 784], n...\n",
       "18265    [x = tf.placeholder(tf.float32, [None, 784], n...\n",
       "18266    [x = tf.placeholder(tf.float32, [None, 784], n...\n",
       "18267    [require \"torch\"\\r\\nrequire \"nn\"\\r\\nrequire \"r...\n",
       "18268    [require \"torch\"\\r\\nrequire \"nn\"\\r\\nrequire \"r...\n",
       "18269    [require 'hdf5'\\r\\nlabel = {'a', 'b','c','d'}\\...\n",
       "18270    [th&gt; model=torch.load(\"sequential_5000_1458...\n",
       "18271    [__pairs, test = torch.class('test')\\r\\nfuncti...\n",
       "18273    [test = torch.class('test')\\r\\nfunction test:_...\n",
       "18274    [x = torch.ones(4,5)\\r\\ny = torch.ones(4,3,5)\\...\n",
       "18275    [sudo luarocks install autograd\\r\\n, Missing d...\n",
       "18276    [linLayer = nn.Linear(3,1)\\r\\nsigmoid=nn.Sigmo...\n",
       "18277    [__tostring__, __tostring, print(my_data), __t...\n",
       "18278    [require 'nn'\\r\\nrequire 'cunn'\\r\\n\\r\\nfile = ...\n",
       "18280    [require 'nn'\\r\\nrequire 'image'\\r\\nrequire 't...\n",
       "18281    [local function lstm(x, prev_c, prev_h)\\r\\n  -...\n",
       "18283    [I couldn't find a kernel matching Python 2. P...\n",
       "18284    [[1 2 3\\r\\n 4 5 6\\r\\n 7 8 9]\\r\\n, [1 2 3\\r\\n 1...\n",
       "18285    [kamransiquisMBP:~ khsiddiqui$ th\\r\\n\\r\\n  ___...\n",
       "18289    [test.lua, require 'torch'\\r\\n-- parse command...\n",
       "18290    [linux terminal, torch, th, python, 1+1,      ...\n",
       "18291    [luarocks, $luarocks install hdf5\\r\\nthen I go...\n",
       "18292    [t = require 'torch'\\r\\nrequire 'nn'\\r\\nrequir...\n",
       "18293    [import numpy as np\\r\\n\\r\\na = np.unique([1, 1...\n",
       "18294    [\\r\\nupdateGradInput(input, gradOutput)\\r\\nacc...\n",
       "18295    [CMake Error at install/share/cmake/torch/Find...\n",
       "18296    [ByteTensor, th&gt; a = torch.rand(4)\\r\\n\\r\\nt...\n",
       "18297    [torch.Tensor.float(), require 'nn'\\r\\nrequire...\n",
       "18298    [{\\r\\n  1 : \\r\\n    {\\r\\n      bounding_box : ...\n",
       "18299    [require 'image'\\r\\n\\r\\ni1 = testData.data[2] ...\n",
       "18300    [$ luarocks  install image\\r\\n, &gt; th&gt; re...\n",
       "18301    [require 'nn'\\r\\nnet = nn.Sequential()\\r\\nnet:...\n",
       "18302    [A = torch.rand(10,2)-1\\r\\n, S, sel = torch.ge...\n",
       "18303    [A = torch.rand(10,2)-1\\r\\n, S, sel = torch.ge...\n",
       "18304    [90%, vgg_bn_drop.lua, modelname:forward(image...\n",
       "18305    [cutorch, cunn, luarocks install cutorch\\r\\nlu...\n",
       "18306    [cutorch, cunn, luarocks install cutorch\\r\\nlu...\n",
       "18307    [positive_mask = labels:eq(1)\\r\\nsliced_labels...\n",
       "18308    [function Word2Vec:print_semantic_space()\\r\\n ...\n",
       "18309    [trdata[{ {1,trainData.data:size(1)} }] = trai...\n",
       "18310    [torch.save('t.csv',torch.Tensor({{1,2},{3,4}}...\n",
       "18311    [torch.save('t.csv',torch.Tensor({{1,2},{3,4}}...\n",
       "18312    [git clone https://github.com/torch/distro.git...\n",
       "18313    [git clone https://github.com/torch/distro.git...\n",
       "18314    [Classe 1 : 75%\\r\\nClasse 2 : 10%\\r\\nClasse 3 ...\n",
       "18315    [th neural_style.lua -gpu -1 -print_iter -1\\r\\...\n",
       "18317    [torch.save(params.model_file, model)\\r\\n, loc...\n",
       "18318    [for i in range(#table1)\\r\\n  pprint(table1[i]...\n",
       "18319    [for i in range(#table1)\\r\\n  pprint(table1[i]...\n",
       "18320    [for i in range(#table1)\\r\\n  pprint(table1[i]...\n",
       "18321    [lua_pcall,   lua_getglobal(L, \"debug\");\\r\\n  ...\n",
       "18322    [x, y, theano.tensor.dot(x, y), torch.dot, x *...\n",
       "18323    [torch.save(), torch.load(), -- design model \\...\n",
       "18324    [Threads = require 'threads'\\r\\nThreads.serial...\n",
       "18325    [luarocks make --local, ...\\r\\nScanning depend...\n",
       "18326    [CudaTensor, function fill_0normal(t,sigma)\\r\\...\n",
       "18327    [th&gt; ls = torch.linspace(1, 10, 10)\\r\\n    ...\n",
       "18328    [ByteTensor, 1, a = np.array([1,0,1,0,1])\\r\\nr...\n",
       "18329    [             ⎧ 1 - cos(x1, x2),              ...\n",
       "18330    [# -*- coding: utf-8 -*-\\r\\nfrom subprocess im...\n",
       "18331    [curl -s https://raw.githubusercontent.com/tor...\n",
       "18332    [dofile('donkey.lua')\\r\\nimg = testHook({loadS...\n",
       "18333    [dataset= \\r\\n124.0000   81.6900   64.5000  11...\n",
       "18334    [  **Data**\\r\\n  1914  1993  2386\\r\\n  1909  1...\n",
       "18335    [  **Data**\\r\\n  1914  1993  2386\\r\\n  1909  1...\n",
       "18336    [A = rand(2, 3, 6);\\r\\nB = A(:,:, 1:2:end);\\r\\...\n",
       "18337    [SpatialConvolution.lua,  96 function SpatialC...\n",
       "18339    [gnuplot.figure(1)\\r\\ngnuplot.raw('set termina...\n",
       "18340    [Kernel not found\\r\\nI couldn't find a kernel ...\n",
       "18342     [file:read(\"*all\"), not enough memory, f:read()]\n",
       "18343    [SpatialConvolution, conv1 = nn.SpatialConvolu...\n",
       "18345    [curl -s https://raw.githubusercontent.com/tor...\n",
       "18346    [local http = require('socket.http')\\r\\nlocal ...\n",
       "18347    [local http = require('socket.http')\\r\\nlocal ...\n",
       "18348    [cmd = torch.CmdLine()\\r\\ncmd:option('--foo', ...\n",
       "18349    [   net:add(SpatialConvolution(3, 96, 7, 7, 2,...\n",
       "18350    [torch, libpaths, module 'libpaths' not found:...\n",
       "18351    [local model = torch.load('resnet-101.t7')\\r\\n...\n",
       "18352    [Module.lua, nn, function printTry()\\r\\n  prin...\n",
       "18353    [Module.lua, nn, function printTry()\\r\\n  prin...\n",
       "18354    [nn.Sequential {\\r\\n  [input -&gt; (1) -&gt; (...\n",
       "18355    [/home/arthur/torch/install/bin/luajit: /home/...\n",
       "18358    [for (t = 0; t &lt; nframe; t++)\\r\\n{\\r\\nsum =...\n",
       "18359    [Tensor1\\r\\n  1   2   3   4   5\\r\\n  6   7   8...\n",
       "18360    [/home/a/torch/install/bin/luajit: /home/a/tor...\n",
       "18361    [th&gt; bb\\r\\n 1\\r\\n 2\\r\\n[torch.DoubleTensor ...\n",
       "18362    [th&gt; bb\\r\\n 1\\r\\n 2\\r\\n[torch.DoubleTensor ...\n",
       "18363    [q\\r\\n 1  2  3\\r\\n 2  4  6\\r\\n\\r\\nw\\r\\n 1  2  ...\n",
       "18364    [th&gt; x = torch.rand(2)\\r\\n                 ...\n",
       "18368    [{1,2,3,4}, {1,2,3,4,1,2,3,4,1,2,3,4}\\r\\n{1,1,...\n",
       "18369    [{1,2,3,4}, {1,2,3,4,1,2,3,4,1,2,3,4}\\r\\n{1,1,...\n",
       "18370    [{1,2,3,4}, {1,2,3,4,1,2,3,4,1,2,3,4}\\r\\n{1,1,...\n",
       "18371    [{1,2,3,4}, {1,2,3,4,1,2,3,4,1,2,3,4}\\r\\n{1,1,...\n",
       "18372    [{1,2,3,4}, {1,2,3,4,1,2,3,4,1,2,3,4}\\r\\n{1,1,...\n",
       "18374    [loaded = torch.load(data_file, 'ascii')\\r\\nDa...\n",
       "18375                                             [nn, nn]\n",
       "18376    [input = torch.Tensor (4,2) \\r\\ninput:random(0...\n",
       "18377    [local img_raw = image.load(train_path .. trai...\n",
       "18378    [   net:add(SpatialConvolution(3, 96, 7, 7, 2,...\n",
       "18379    [wget, curl, git, .bashrc, /etc/enviornment, $...\n",
       "18380    [(1 x n x n x n), (1 x s x n x n)\\r\\n(1 x n x ...\n",
       "18381    [nn.Sequential {\\r\\n  [input -&gt; (1) -&gt; (...\n",
       "18383    [git clone https://github.com/clementfarabet/c...\n",
       "18384    [The neurons in a layer will only be connected...\n",
       "18386    [$ Torch: not enough memory: you tried to allo...\n",
       "18387    [a = '01234'\\r\\nb = '12345'\\r\\n, tens = torch....\n",
       "18389    [# added by Anaconda 2.3.0 installer \\r\\nexpor...\n",
       "18390    [[ 0     -1     -3\\r\\n\\r\\n6      5      0\\r\\n\\...\n",
       "18391    [[ 0     -1     -3\\r\\n\\r\\n6      5      0\\r\\n\\...\n",
       "18392    [[ 0     -1     -3\\r\\n\\r\\n6      5      0\\r\\n\\...\n",
       "18393    [a = {}\\r\\ntype(a)\\r\\n&gt; dict\\r\\n, print(voc...\n",
       "18394    [a = {}\\r\\ntype(a)\\r\\n&gt; dict\\r\\n, print(voc...\n",
       "18395    [invalid argument type for argument -model (sh...\n",
       "18396    [apply, A =\\r\\n  1 2 3\\r\\n  4 5 6\\r\\n  7 8 9\\r...\n",
       "18397    [subfolders = {}\\r\\ncounter = 0\\r\\n\\r\\nfor d i...\n",
       "18398    [subfolders = {}\\r\\ncounter = 0\\r\\n\\r\\nfor d i...\n",
       "18399    [parag@parag:~/torch$ sudo luarocks install nn...\n",
       "18400                    [image.display(), image.window()]\n",
       "18401    [criterion = nn.MSECriterion()  \\r\\ntrainer = ...\n",
       "18404    [(2,[...])\\r\\n, (1,[...])\\r\\n, th&gt; x = torc...\n",
       "18405    [(2,[...])\\r\\n, (1,[...])\\r\\n, th&gt; x = torc...\n",
       "18406    [client.ondata(function(data)\\r\\n   print('rec...\n",
       "18412                                  [image.translate()]\n",
       "18414    [[  1,  2,  3,  4;\\r\\n   5,  6,  7,  8;\\r\\n   ...\n",
       "18415    [array = np.zeros(5) # array = [0 0 0 0 0]\\r\\n...\n",
       "18416    [array = np.zeros(5) # array = [0 0 0 0 0]\\r\\n...\n",
       "18417    [array = np.zeros(5) # array = [0 0 0 0 0]\\r\\n...\n",
       "18418    [Input, Output\\r\\n0,1\\r\\n1,1\\r\\n0,0\\r\\n1,0\\r\\n...\n",
       "18419    [th&gt; my_table = {0.1, 0.2, 0.3, ... 0.9}\\r\\...\n",
       "18420    [    guard let camera = camera else {\\r\\n     ...\n",
       "18422    [a x b x c, a x b*c, input = torch.Tensor(a, b...\n",
       "18423    [require 'cutorch'\\r\\n, nvidia-smi, ----------...\n",
       "18424    [require 'cutorch'\\r\\n, nvidia-smi, ----------...\n",
       "18425    [# in a terminal, run the commands\\r\\nsudo apt...\n",
       "18426    [mydata=torch.class('something')\\r\\n, who(), =...\n",
       "18428    [trainLogger:plot(), trainLogger, trainLogger=...\n",
       "18431    [input1 = nn.Identity()()\\r\\ninput2 = nn.Ident...\n",
       "18432    [require 'torch'\\r\\n\\r\\nprint(package.loadlib(...\n",
       "18433    [require 'rnn'\\r\\nrequire 'nn'\\r\\n\\r\\n-- Build...\n",
       "18435    [/opt/zbstudio/bin/linux/x64/lua: /home/dg/tor...\n",
       "18436    [/opt/zbstudio/bin/linux/x64/lua: /home/dg/tor...\n",
       "18437    [youcompleteme, vim-lua-ftplugin, &gt; 处理 func...\n",
       "18438    [/Users/mattsmith/torch/install/bin/luajit: .....\n",
       "18439    [rnn, ------------------ forward pass --------...\n",
       "18440    [Blah = torch.class('Blah')\\r\\nfunction Blah:_...\n",
       "18441    [Blah = torch.class('Blah')\\r\\nfunction Blah:_...\n",
       "18442    [nvcc -o im2col -I/deep/u/ibello/torch/include...\n",
       "18443    [Torch, Numpy, m[begin:end, :], require 'torch...\n",
       "18444    [luarocks install inspect\\r\\n, lua, th, local ...\n",
       "18445    [local data = torch.Tensor(100, 4)\\r\\n--data t...\n",
       "18446                      [require \"trepl\"\\r\\nrepl()\\r\\n]\n",
       "18447    [function mkPrimitive()\\r\\n    local inp  = nn...\n",
       "18448    [iteration = 0;\\r\\na = torch.Tensor(2, 2);\\r\\n...\n",
       "18451    [local tens_a = torch.Tensor({9,8,7,6});\\r\\nlo...\n",
       "18454    [th, th torch_script.lua input_parameter1 inpu...\n",
       "18455    [th, th torch_script.lua input_parameter1 inpu...\n",
       "18456    [th, th torch_script.lua input_parameter1 inpu...\n",
       "18459    [    [C]: at 0x7f17b9dc029\\r\\n    [C]: in func...\n",
       "18460    [cd ~/torch; ./install.sh\\r\\n, [/Users/Definit...\n",
       "18461    [class RNN:\\r\\n  # ...\\r\\n  def step(self, x):...\n",
       "18464    [nn.Sequential {\\r\\n  [input -&gt; (1) -&gt; (...\n",
       "18465    [output = model:forward(inputs[i])\\r\\ndf_do = ...\n",
       "18466    [require 'torch'\\r\\nrequire 'nn'\\r\\n\\r\\ndata =...\n",
       "18467    [luajit neuralnetwork.lua --satEpoch \"somestri...\n",
       "18468    [-- params for the linear layer\\r\\nparams = {\\...\n",
       "18469    [...903/nTorch/Torch7/install/share/lua/5.1/to...\n",
       "18470    [model = nn.Sequential()\\r\\n\\r\\nmodel:add(nn.R...\n",
       "18471    [model = nn.Sequential()\\r\\n\\r\\nmodel:add(nn.R...\n",
       "18472    [ 1\\r\\n 7\\r\\n 5\\r\\n[torch.ByteTensor of size 3...\n",
       "18473    [ 1\\r\\n 7\\r\\n 5\\r\\n[torch.ByteTensor of size 3...\n",
       "18474    [B = torch.Tensor({0.1623, 0.0545})\\r\\nA = tor...\n",
       "18475    [local ffi = require('ffi')\\r\\n\\r\\nffi.cdef([[...\n",
       "18476    [ static int nn_(Tanh_updateOutput)(lua_State ...\n",
       "18477    [mean[i] = trainData.data[{ {},i,{},{} }]:mean...\n",
       "18478    [luarocks --server=https://raw.githubuserconte...\n",
       "18480    [th&gt; perceptron_general\\r\\nnn.Sequential {\\...\n",
       "18482    [file.dat, torch7, gnuplot.raw(\"&lt;command&gt...\n",
       "18483    [completeProfile = {};\\r\\ntable.foreach(firstH...\n",
       "18484    [local features = nn.Sequential()\\r\\n\\r\\nfeatu...\n",
       "18486    [ im4[{1,{},{}}] = im3[{3,{},{}}]\\r\\n im4[{3,{...\n",
       "18488    [data = torch.Tensor{\\r\\n   {40,  6,  4},\\r\\n ...\n",
       "18489    [Linking CXX executable tensor_serialization_t...\n",
       "18490    [local LSTM = {}\\r\\nfunction LSTM.lstm(input_s...\n",
       "18491    [local LSTM = {}\\r\\nfunction LSTM.lstm(input_s...\n",
       "18492    [local LSTM = {}\\r\\nfunction LSTM.lstm(input_s...\n",
       "18493    [nfeats = 3\\r\\nwidth = 200\\r\\nheight = 200\\r\\n...\n",
       "18494    [workers processes 1;\\r\\n\\r\\nerror_log logs/er...\n",
       "18495    [LEARNING_RATE_CONST = 0.01;\\r\\noutput_layer_n...\n",
       "18497    [\"/xxx/xxxx/torch/install/bin/th\": not in exec...\n",
       "18498    [\"/xxx/xxxx/torch/install/bin/th\": not in exec...\n",
       "18500    [require \"image\"\\r\\ninput_image = image.load(a...\n",
       "18501    [func = function(i,j,k)  --i, j is the index o...\n",
       "18502    [long THTensor_(storageOffset)(const THTensor ...\n",
       "18503    [    function MSECriterion:updateOutput(input,...\n",
       "18504    [nn.LogSoftMax, require 'nn'\\r\\nmy_lsm = funct...\n",
       "18505    [dataset[p] = {torch.Tensor(completeTable[p]),...\n",
       "18506    [dataset[p] = {torch.Tensor(completeTable[p]),...\n",
       "18507    [my_mat = magic(3); % returns a 3 by 3 matrix ...\n",
       "18508    [$ luarocks install image, $ luarocks lis, $th...\n",
       "18510    [    nn.Sequential {\\r\\n      [input -&gt; (1)...\n",
       "18512    [sudo port install libjpeg-turbo\\r\\n, ---&gt; ...\n",
       "18514    [model:evaluate()\\r\\n\\r\\n-- test over test dat...\n",
       "18516                                              [str()]\n",
       "18517    [function math.pearson(a)\\r\\n  -- compute the ...\n",
       "18518    [Not updating your shell profile.\\r\\nYou might...\n",
       "18519    [Not updating your shell profile.\\r\\nYou might...\n",
       "18520    [./run_gpu &lt;game name&gt;\\r\\n, ../torch/bin...\n",
       "18521    [require 'caffe'\\r\\nrequire 'image'\\r\\n\\r\\n-- ...\n",
       "18522    [chromNameA  startA  endA    chromNameB  start...\n",
       "18523    [require 'dp'\\r\\nrequire 'csvigo'\\r\\nrequire '...\n",
       "18524    [images = image.load('image.png',1,'float')\\r\\...\n",
       "18525    [lookupTableLayer = nn.LookupTable(vector:size...\n",
       "18526    [  require 'dp'\\r\\n--[[hyperparameters]]--\\r\\n...\n",
       "18527    [    chrName-chrStart-chrEnd,gm12878,h1-hesc,h...\n",
       "18528    [11 38 20 44 11 38 21 44 29 42 30 44 34 38  6 ...\n",
       "18529    [require 'io'\\r\\ncjson = require 'cjson'\\r\\nre...\n",
       "18530    [model:forward(testImageTensor), ...ches/torch...\n",
       "18531    [./install/share/lua/5.1/image/init.lua:   ret...\n",
       "18532    [    input_image = caffe.io.load_image(imgName...\n",
       "18533                                 [image.lena(), help]\n",
       "18534    [Building for: Visual Studio 9 2008, PS C:\\WIN...\n",
       "18535    [Building for: Visual Studio 9 2008, PS C:\\WIN...\n",
       "18536    [ -- Install configuration: \"Release\"\\r\\n-- In...\n",
       "18538                    [Zerobrane, Zerobrane, Zerobrane]\n",
       "18539                        [t1 = torch.Tensor(2, 2)\\r\\n]\n",
       "18541    [from torch.utils.data import DataLoader\\r\\nfr...\n",
       "18542    [torchvision.datasets.UCF101(root: str, annota...\n",
       "18543    [ubantu18.04\\r\\n, pytorch:1.2.0, pytorch, $git...\n",
       "18545    [def box_iou_calc(boxes1, boxes2):\\r\\n    # ht...\n",
       "18547    [RuntimeError: result type Float can't be cast...\n",
       "18549    [---------------------------------------------...\n",
       "18550    [def content_loss(target_conv4_2,content_conv4...\n",
       "18551    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "18552    [transforms, Compose, Image, ConvertImageDtype...\n",
       "18553    [set_target_properties Can not find target to ...\n",
       "18554    [num_epochs = 50\\r\\nvector_row =[] \\r\\nfor epo...\n",
       "18555    [ImportError                               Tra...\n",
       "18556    [pip install medcat\\r\\n, ERROR: Could not find...\n",
       "18559    [C:\\Users\\Dr Shahid\\Desktop\\Microscopy images\\...\n",
       "18560    [transform = transforms.Compose([transforms.To...\n",
       "18561    [MNIST_Perceptron, import numpy as np\\r\\nimpor...\n",
       "18562    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "18563    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "18564    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "18565    [# Load the pretrained model\\r\\nmodel = models...\n",
       "18566    [import torchvision.models as models\\r\\nimport...\n",
       "18567    [from torchvision.models import vgg16\\r\\nvgg_m...\n",
       "18568    [pip install torch===1.4.0 torchvision===0.5.0...\n",
       "18569    [pip install torch===1.4.0 torchvision===0.5.0...\n",
       "18570    [pip install torch===1.4.0 torchvision===0.5.0...\n",
       "18571    [import torchvision\\r\\nimport torch\\r\\nimport ...\n",
       "18572    [downsample_obs = torchvision.transforms.Compo...\n",
       "18573    [torchvision,     Traceback (most recent call ...\n",
       "18574    [conda create -n py36 python=3.6\\r\\nconda acti...\n",
       "18575    [from torchvision import models\\r\\n\\r\\nfcn = m...\n",
       "18576    [3.7.3, 0.4.1, fc_inputs = model.fc.in_feature...\n",
       "18578    [from PIL import Image\\r\\nfrom six.moves impor...\n",
       "18580    [pip install torchvision, ModuleNotFoundError:...\n",
       "18581    [BCELoss, ValueError: Target and input must ha...\n",
       "18583    [import torch\\r\\nfrom torchvision import datas...\n",
       "18584    [‘root’, 'root', './data/FashionMNIST', 'root'...\n",
       "18586    [torchvision.datasets, __getitem__, class MNIS...\n",
       "18587    [import numpy as np\\r\\nfrom glob import glob\\r...\n",
       "18588    [\\r\\n#@markdown If CUDA runs out of memory, tr...\n",
       "18589    [study = optimize_hyperparameters(\\r\\n    trai...\n",
       "18590    [!python3 -m pip install torchvision==0.11.1\\r...\n",
       "18592    [import argparse\\r\\nimport importlib\\r\\nfrom l...\n",
       "18593    [        lr_scheduler_configs = self.lr_schedu...\n",
       "18594    [y, y, predict_step, mutag = ptgeom.datasets.T...\n",
       "18595    [trainer.test, model.test_step, torchmetrics.A...\n",
       "18596    [validation_epoch_end, trainer.validate, train...\n",
       "18597    [torch.nn.TransformerEncoderLayer, Trainer, op...\n",
       "18598    [class BertForSequenceClassification_pl(pl.Lig...\n",
       "18599    [Epoch   Training Loss   Validation Loss Runti...\n",
       "18600    [log_every_n_steps=100, Trainer, check_val_eve...\n",
       "18601    [trainer = pl.Trainer(\\r\\n  logger=logger,\\r\\n...\n",
       "18602    [def validation_epoch_end(self, outputs):\\r\\n ...\n",
       "18603    [{replace_me}, filename, ModelCallback, object...\n",
       "18604    [class T5FineTuner(pl.LightningModule):\\r\\n   ...\n",
       "18605    [# define trainer object\\r\\ntrainer = pl.Train...\n",
       "18608    [trainer.fit(model, data), AttributeError: 'tu...\n",
       "18609    [RuntimeError: Expected 4-dimensional input fo...\n",
       "18610    [!pip install pytorch-lightning==1.2.8 --quiet...\n",
       "18611    [def train_dataloader(self):\\r\\n    train_dir ...\n",
       "18613    [train_loader = DataLoader(train_ds, \\r\\n     ...\n",
       "18614    [import torch\\r\\nfrom pycave.clustering import...\n",
       "18616    [import pytorch_lightning as pl\\r\\nimport torc...\n",
       "18617    [  File \"/home/rschaef/CoCoLab-Pretrained-Repr...\n",
       "18618    [logger = TensorBoardLogger(\"logs\", name = \"mo...\n",
       "18619    [!pip install cloud-tpu-client==0.10 https://s...\n",
       "18620    [!pip install cloud-tpu-client==0.10 https://s...\n",
       "18621    [Trainer, trainer = pl.Trainer(default_root_di...\n",
       "18622    [class ClassifikationTask(pl.LightningModule):...\n",
       "18623    [\\r\\n    import os\\r\\n    os.environ['CUDA_LAU...\n",
       "18624    [tokenizer.save_pretrained('my-t5-qa-legal')\\r...\n",
       "18625    [# omitted until here due to questions volume\\...\n",
       "18626    [class QA_model(pl.LightningModule):\\r\\n  def ...\n",
       "18627    [class LSTM(pl.LightningModule):\\r\\n def __ini...\n",
       "18628    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "18629    [metric_acc = torchmetrics.Accuracy()\\r\\nmetri...\n",
       "18630    [JupyterLab, AWS SageMaker, conda_pytorch_late...\n",
       "18631    [self.log, training_step(), import pytorch_lig...\n",
       "18632                [Jupyter Notebook, log_every_n_steps]\n",
       "18634    [trainer1 = pl.Trainer(gpus=n_gpus, max_epochs...\n",
       "18635    [limit_val_batches=10, val_check_interval=1000...\n",
       "18636    [   loss_criterion = nn.CrossEntropyLoss()\\r\\n...\n",
       "18637    [mlflow.exceptions.RestException: BAD_REQUEST:...\n",
       "18638    [import pytorch_lightning as pl\\r\\n[...]\\r\\n\\r...\n",
       "18639    [class MTmetricDataModule(pl.LightningDataModu...\n",
       "18640    [NumPy, Pytorch Lightning, import numpy as np ...\n",
       "18641    [NumPy, Pytorch Lightning, import numpy as np ...\n",
       "18642    [NumPy, Pytorch Lightning, import numpy as np ...\n",
       "18644    [fit_in_cpu = torch.nn.Embedding(too_big_for_G...\n",
       "18645    [import pytorch_lightning as pl\\r\\npl.seed_eve...\n",
       "18646    [class QAModel(pl.LightningDataModule):\\r\\n\\r\\...\n",
       "18647    [validation_step(), def validation_step(self, ...\n",
       "18648    [writer = torch.utils.tensorboard.SummaryWrite...\n",
       "18649    [writer = torch.utils.tensorboard.SummaryWrite...\n",
       "18650    [    def forward(                             ...\n",
       "18651    [Sequential, self._encoder = nn.Sequential(\\r\\...\n",
       "18652    [Sequential, self._encoder = nn.Sequential(\\r\\...\n",
       "18653    [ from pytorch_lightning.metrics import Confus...\n",
       "18654    [ from pytorch_lightning.metrics import Confus...\n",
       "18655    [ from pytorch_lightning.metrics import Confus...\n",
       "18660    [from pytorch_lightning.loggers import TensorB...\n",
       "18661    [2020-08-14 14:09:07,109 - wandb.wandb_agent -...\n",
       "18662    [2020-08-14 14:09:07,109 - wandb.wandb_agent -...\n",
       "18663    [load_from_checkpoint, lightningModule, VAEXpe...\n",
       "18666    [shuffle, false, data = \".\\data.txt\"\\r\\ndata =...\n",
       "18667    [get_preds(), TypeError: Expected tensor, tupl...\n",
       "18668    [class GraphDataset(Dataset):    \\r\\n   def __...\n",
       "18669    [torch.dataloader, pytorch, trainEncode = MBER...\n",
       "18671    [create_supervised_trainer(), create_supervise...\n",
       "18672    [def train(self, current_epoch=0, is_init=Fals...\n",
       "18673    [\\r\\n\\r\\nfrom torch.utils.data import Dataset,...\n",
       "18674    [pytorch_forecasting, TimeSeriesDataSet, testi...\n",
       "18675    [pytorch_forecasting, TimeSeriesDataSet, testi...\n",
       "18676    [import tensorflow as tf\\r\\nfrom torch.utils.d...\n",
       "18677    [if __name__ == \"__main__\":\\r\\n    num_eval = ...\n",
       "18678    [TEXT = data.Field(lower = True)\\r\\nUD_TAGS = ...\n",
       "18679    [def __init__(self, excel_file, category, tran...\n",
       "18680    [# Image loader\\r\\ntransform = transforms.Comp...\n",
       "18681    [DataLoader, k_trn = self.linear.k_gen(in_trn,...\n",
       "18682    [File \"C:\\Users\\JCout\\AppData\\Local\\Temp/ipyke...\n",
       "18683    [from torch.utils.data import DataLoader\\r\\n\\r...\n",
       "18684    [n_epochs = 6\\r\\nmodel = CNN_Text()\\r\\nloss_fn...\n",
       "18685    [from torchvision import datasets, transforms\\...\n",
       "18686    [image_validator.py, from PIL import Image\\r\\n...\n",
       "18688    [data_transforms = {\\r\\n    'train': transform...\n",
       "18689    [Images\\r\\n|\\r\\n|__img1\\r\\n|   |__img1_b01.tif...\n",
       "18690    [{\"ID\":\"cko5efll9000f3q66q6lmo8li\",\"DataRow ID...\n",
       "18691    [from torch.utils.data import Dataset\\r\\ndef S...\n",
       "18692    [data_dir = \"/home/mhamdan/hamdan/MNIST_muldig...\n",
       "18693    [data_dir = \"/home/mhamdan/hamdan/MNIST_muldig...\n",
       "18694    [KeyError: \"['label'] not found in axis\", impo...\n",
       "18695    [normalize = transforms.Normalize(mean=[0.4914...\n",
       "18696    [normalize = transforms.Normalize(mean=[0.4914...\n",
       "18697    [__getitem__, import torch\\r\\nfrom torch.utils...\n",
       "18698    [#include &lt;torch/torch.h&gt;\\r\\n#include &l...\n",
       "18700    [auto dataset = torch::data::datasets::MNIST(\"...\n",
       "18701    [std::thread, all_episode_steps, all_episode_s...\n",
       "18702    [&gt;, if, 0.5, #include &lt;torch/torch.h&gt;...\n",
       "18703    [&gt;, if, 0.5, #include &lt;torch/torch.h&gt;...\n",
       "18704    [torch::cat, all_step_obs = torch::tensor({});...\n",
       "18705    [torch::Tensor one_T = torch::rand({6, 6});\\r\\...\n",
       "18706    [import sys\\r\\nimport os\\r\\nimport numpy as np...\n",
       "18707    [torch::jit::IValue, auto torch_options = torc...\n",
       "18708    [/usr/bin/ld: CMakeFiles/slam_open3d.dir/examp...\n",
       "18709    [map&lt;string, map&lt;string, torch::Tensor&g...\n",
       "18710    [map&lt;string, map&lt;string, torch::Tensor&g...\n",
       "18711    [#include&lt;torch/torch.h&gt;\\r\\n#include&lt;...\n",
       "18712    [#include &lt;iostream&gt;\\r\\n#include &lt;tor...\n",
       "18714    [/libtorch/include/torch/csrc/jit/api/object.h...\n",
       "18715    [#include &lt;torch/cuda.h&gt;\\r\\n#include &lt...\n",
       "18716    [ld: unknown option: --no-as-needed\\r\\nclang: ...\n",
       "18717    [asmjit.dll, c10.dll, caffe2_detection_ops.dll...\n",
       "18718    [.cuda(), devPtr, int main(void) {\\r\\n  float*...\n",
       "18719    [typedef Eigen::Matrix&lt;float, Eigen::Dynami...\n",
       "18720    [{\\r\\n    \"logging\": {\\r\\n        \"engineLoggi...\n",
       "18721    [    /usr/bin/ld: ../vendor/libtorch/lib/libto...\n",
       "18722    [libtorch, vector, tensor, tensor, std::vector...\n",
       "18723    [torch::Tensor, Mat source_image = imread(imag...\n",
       "18724    [undefined symbol: c10::detail::torchInternalA...\n",
       "18725    [#include&lt;torch/torch.h&gt;\\r\\n#include&lt;...\n",
       "18727    [autograd, sm_i dk_{ij} - sm_i sm_j\\r\\n, dk, g...\n",
       "18728    [LIBRARY-NOTFOUND, link libraries for target \"...\n",
       "18729    [library not found, git clone, $ cmake -DCMAKE...\n",
       "18730    [yolov5s.pt, cv::Mat image = file-&gt;input_im...\n",
       "18732    [    !nvidia-smi\\r\\n,     os.environ['LIBTORCH...\n",
       "18733    [dataset, auto set = MyDataSet(pathToData).map...\n",
       "18734    [undefined symbol: cusparseCreateDnVec, cuspar...\n",
       "18735    [.\\r\\n├── build.sh\\r\\n├── CMakeLists.txt\\r\\n├─...\n",
       "18736    [int main() {\\r\\n    // Do somenting with libt...\n",
       "18737    [import ctypes\\r\\nlib_projn = ctypes.CDLL( \"&l...\n",
       "18738    [OMP_NUM_THREADS=1 python tools/train_net.py -...\n",
       "18739    [libtorch, slots, Aten, slots, torchlib, QT_NO...\n",
       "18740    [template&lt;bool Condition, class ThenCallbac...\n",
       "18741    [torch::Tensor tensor = std::get&lt;1&gt;(max_...\n",
       "18742    [\\r\\n    cmake_minimum_required(VERSION 3.19)\\...\n",
       "18744    [int numel = rows * cols * depth;\\r\\nassert(nu...\n",
       "18745    [Project/build/, ---Project/\\r\\n   ---CMakeLis...\n",
       "18746    [wget https://download.pytorch.org/libtorch/cu...\n",
       "18747    [example-app/\\r\\n     build/\\r\\n     libtorch/...\n",
       "18748    [  int main{\\r\\n        auto ten=torch::randn(...\n",
       "18750    [ LNK2019    无法解析的外部符号 \"__declspec(dllimport) ...\n",
       "18751    [Unhandled exception at 0x00007FFA0B7D3E49 in ...\n",
       "18752    [set(project \"wasm-example\")\\r\\n\\r\\ncmake_mini...\n",
       "18753    [CMake Error at CMakeLists.txt:6 (find_package...\n",
       "18754    [CMake Error at CMakeLists.txt:6 (find_package...\n",
       "18757    [std::vector&lt;std::tuple(std::string, torch:...\n",
       "18758    [BoolTensor, n, one, False, True, src_mask = t...\n",
       "18759    [BoolTensor, n, one, False, True, src_mask = t...\n",
       "18760    [CV_8UC3, at::Tensor, at::Tensor tensor_image ...\n",
       "18761    [torch::tensor, array, for, Eigen::Matrix&lt;d...\n",
       "18762    [**terminate called after throwing an instance...\n",
       "18764    [cmake_minimum_required(VERSION 3.0 FATAL_ERRO...\n",
       "18765    [cmake_minimum_required(VERSION 3.0 FATAL_ERRO...\n",
       "18767    [torch::Tensor loss = torch::nll_loss(predicte...\n",
       "18768    [torch::Tensor loss = torch::nll_loss(predicte...\n",
       "18769    [.pt, cd, mkdir build\\r\\ncd build\\r\\ncmake -DC...\n",
       "18770    [.pt, cd, mkdir build\\r\\ncd build\\r\\ncmake -DC...\n",
       "18771    [int main(){\\r\\n    auto net = std::make_share...\n",
       "18772    [std::cout &lt;&lt; \"Testing LibTorch to Eigen...\n",
       "18773    [C++ Code: \\r\\n\\r\\n#include &lt;torch/torch.h&...\n",
       "18774    [void test(vector&lt;module_type&gt;&amp; mode...\n",
       "18775    [void test(vector&lt;struct comp*&gt;&amp; mod...\n",
       "18776    [Scanning dependencies of target example-app\\r...\n",
       "18777    [TEMPLATE = app\\r\\nCONFIG += console c++11\\r\\n...\n",
       "18778    [#include &lt;torch/torch.h&gt;\\r\\nstruct Deep...\n",
       "18779    [std::vector&lt;torch::nn::Linear&gt; linear_l...\n",
       "18780    [#include &lt;torch/torch.h&gt;\\r\\n#include &l...\n",
       "18781    [#include &lt;torch/torch.h&gt;\\r\\n#include &l...\n",
       "18782    [├── CMakeLists.txt\\r\\n├── compile_commands.js...\n",
       "18783    [pyg.utils.softmax(), N = maybe_num_nodes(inde...\n",
       "18784    [class base_graph(Dataset):\\r\\n    def __init_...\n",
       "18785    [Chameleon, Wisconsin, Texas, Dataset, Planeto...\n",
       "18786    [# install the required packages\\r\\nimport tor...\n",
       "18787    [s, o, p, networkx.DiGraph, (s, p, o), {(s,p),...\n",
       "18790    [num_of_nodes     = 14\\r\\nnum_of_feats     = 1...\n",
       "18792    [Data(x=[20, 1], edge_index=[2, 20], y=[1])\\r\\...\n",
       "18793    [import torch\\r\\n\\r\\ndef format_pytorch_versio...\n",
       "18794    [torch_geometric.nn.to_hetero, from torch.nn i...\n",
       "18795    [Bootstrap: docker\\r\\nFrom: nvidia/cuda:10.1-c...\n",
       "18796    [Ln2\\r\\n[C, C, C, C, C, C, G, I, O, P, P, P, R...\n",
       "18797    [from torch_geometric.datasets import TUDatase...\n",
       "18798    [torch-geometric, HeteroData(), RandomLinkSpli...\n",
       "18799    [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "18800    [torch_geometric.data.Dataset, # Set the rando...\n",
       "18801    [to_networkx, Nodes:  ['3.3375725746154785', '...\n",
       "18802    [t_span = torch.linspace(0, 1, 2)\\r\\nmodel_sub...\n",
       "18803    [def load_pretrained_embedding(words, pretrain...\n",
       "18805    [vocab = Vocab(counter, min_freq = 1, specials...\n",
       "18806    [vocab = Vocab(counter, min_freq = 1, specials...\n",
       "18807    [from torchtext.legacy import data\\r\\n\\r\\nclas...\n",
       "18808    [TEXT = data.Field(tokenize = 'spacy',\\r\\n    ...\n",
       "18809    [RuntimeError: Token second\\team not found and...\n",
       "18810    [AttributeError: 'Field' object has no attribu...\n",
       "18811    [LABEL = data.LabelField()\\r\\nLABEL.build_voca...\n",
       "18813    [```\\r\\nmodel = BERT().to(device)\\r\\noptimizer...\n",
       "18814    [from joblib import Parallel, delayed\\r\\nfrom ...\n",
       "18815    [df[['src', 'trg']].to_csv('dataset.csv', inde...\n",
       "18816    [tokenize=None, ReversibleField, from torchtex...\n",
       "18818    [RNN, text_field = torchtext.data.Field(tokeni...\n",
       "18820    [word_vectors = torch.FloatTensor(spacy_de.voc...\n",
       "18821    [[[1, ..., 2], [3, ..., 4]], [[1, ..., 2], [3,...\n",
       "18822    [ def _mask(prev_generated_seq):\\r\\n        pr...\n",
       "18823    [class Dataset(object):\\r\\n    def __init__(se...\n",
       "18824    [class Dataset(object):\\r\\n    def __init__(se...\n",
       "18825    [import torch\\r\\nimport torchtext\\r\\nfrom torc...\n",
       "18826    [import torchtext as tt\\r\\ncontexts = tt.data....\n",
       "18827    [import cv2\\r\\n\\r\\nimport numpy as np\\r\\n\\r\\ni...\n",
       "18828    [ int main(int argc, const char* argv[]) {\\r\\n...\n",
       "18829    [using namespace std;\\r\\n#include &lt;torch/sc...\n",
       "18830    [question-generation, torchscript, !pip instal...\n",
       "18831    [model, LSTM, score_pos, score_pos_scripted , ...\n",
       "18832    [import os\\r\\nimport torch\\r\\nfrom pytorch3d.i...\n",
       "18834    [v 0.000110 -6.418805 204.660678\\r\\nv 0.000106...\n",
       "18835                                      [_C, pytorch3d]\n",
       "18838    [RuntimeError: !(has_different_input_dtypes &a...\n",
       "18839    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "18840    [        from gpytorch.mlls import ExactMargin...\n",
       "18841    [from sklearn.model_selection import train_tes...\n",
       "Name: qCodePart, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = None\n",
    "temp['qCodePart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-b9e4750892c6>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['ansCode'] = temp['ansCode'].str.replace('<code>', '')\n"
     ]
    }
   ],
   "source": [
    "temp['ansCode'] = temp['ansCode'].str.replace('<code>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-60666576c036>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['ansCode'] = temp['ansCode'].str.replace('</code>', '')\n"
     ]
    }
   ],
   "source": [
    "temp['ansCode'] = temp['ansCode'].str.replace('</code>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-600b422254b5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp['ansCode'] = temp['ansCode'].str.replace('&gt;&gt;&gt;', '')\n"
     ]
    }
   ],
   "source": [
    "temp['ansCode'] = temp['ansCode'].str.replace('&gt;&gt;&gt;', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      NaN\n",
       "1                                                      NaN\n",
       "2                                                      NaN\n",
       "3        [import torch\\r\\nimg_size = 4\\r\\npatch_size = ...\n",
       "4                                                      NaN\n",
       "5                                                      NaN\n",
       "6                                                      NaN\n",
       "7                                                      NaN\n",
       "8                                                      NaN\n",
       "9                                                      NaN\n",
       "11       [img * mean.reshape(1,3,1,1)\\r\\n, mean, img * ...\n",
       "13       [import torch.onnx\\r\\n# Standard ImageNet inpu...\n",
       "14                                                     NaN\n",
       "15                                                     NaN\n",
       "16          [optimizer = torch.optim.Adam(**parameters_1)]\n",
       "17                                                     NaN\n",
       "18                                                     NaN\n",
       "20                                                     NaN\n",
       "21       [pytorch==1.12.1, mamba install pytorch==1.12....\n",
       "22                                                     NaN\n",
       "23                                                     NaN\n",
       "24                                                     NaN\n",
       "25                                                     NaN\n",
       "26                                                     NaN\n",
       "27                                                     NaN\n",
       "28                                                     NaN\n",
       "29       [nn.Conv3d(1,16, 3, stride=1, padding=1), (bat...\n",
       "30       [data_collator = DataCollatorForSeq2Seq(tokeni...\n",
       "31                                                     NaN\n",
       "32                                                     NaN\n",
       "33       [(3, 64, 64),(1), (3, 64, 64),(1,), Tuple, Tup...\n",
       "34       [(32, 10, 3, 32, 32), (batchsize, num frames, ...\n",
       "35                                                     NaN\n",
       "36                                                     NaN\n",
       "37                                                     NaN\n",
       "39       [default_root_dir, trainer = Trainer(default_r...\n",
       "40                                                     NaN\n",
       "41                                                     NaN\n",
       "42                                                     NaN\n",
       "43                                                     NaN\n",
       "44       [DiffSharp-cpu, cuda, lite, #r \"nuget: DiffSha...\n",
       "45                                                     NaN\n",
       "47                                                     NaN\n",
       "49                                                     NaN\n",
       "51                                                     NaN\n",
       "53                                                     NaN\n",
       "54       [import torch\\r\\nimport cv2\\r\\n\\r\\nmodel = tor...\n",
       "55                                                     NaN\n",
       "57                                                     NaN\n",
       "58                                                     NaN\n",
       "60                                                     NaN\n",
       "61       [feature=None,  feature = \"hello\"\\r\\n print(fe...\n",
       "62                                                     NaN\n",
       "63       [train_model, start_epoch, start_epoch, for ep...\n",
       "64                                                     NaN\n",
       "65       [optimizer_ft = optim.SGD(model_ft.parameters(...\n",
       "66                                                     NaN\n",
       "67                                                     NaN\n",
       "70                                                     NaN\n",
       "71                                                     NaN\n",
       "72       [import torch\\r\\n\\r\\n# using the provided samp...\n",
       "74                                                  [.cfg]\n",
       "75       [torch.autograd, requires_grad=True, backward(...\n",
       "76       [Opening, import cv2\\r\\nimport numpy as np\\r\\n...\n",
       "77                                                     NaN\n",
       "80                                                     NaN\n",
       "81       [blurred_img -= blurred_img.min()\\r\\nblurred_i...\n",
       "82                                                     NaN\n",
       "83                                                     NaN\n",
       "84                                [torch.isnan(res).any()]\n",
       "85       [nn.Upsample, upsample = nn.Upsample(scale_fac...\n",
       "86       [jupyter notebook --ip localhost --port 3001 -...\n",
       "88       [log(x) -&gt; replace with log(x + eps) // eps...\n",
       "90                                                     NaN\n",
       "91                                                     NaN\n",
       "92                                                     NaN\n",
       "93                                                     NaN\n",
       "94                                                     NaN\n",
       "95       [def check(a,b):\\r\\n\\r\\n    assert a.size() ==...\n",
       "96                                                     NaN\n",
       "97       [import torch\\r\\nimport torchvision.transforms...\n",
       "98                                                     NaN\n",
       "99                                                     NaN\n",
       "100      [ import torch\\r\\n import coremltools\\r\\n\\r\\n\\...\n",
       "101                                                    NaN\n",
       "102                                                    NaN\n",
       "103      [df_close_scaled = mmscaler.fit_transform(df_c...\n",
       "104                                                    NaN\n",
       "106                                                    NaN\n",
       "107                                                    NaN\n",
       "108                                                    NaN\n",
       "109                                                    NaN\n",
       "110                                                    NaN\n",
       "111                                                    NaN\n",
       "112                                                    NaN\n",
       "113      [load_state_dict, register_module, struct Crit...\n",
       "114                                                    NaN\n",
       "115                                                    NaN\n",
       "116        [HrDataset.py, from HrDataset import HrDataset]\n",
       "117      [ x = img_tensor.repeat(1,3,1,1) # assuming im...\n",
       "119                                                    NaN\n",
       "120                                                    NaN\n",
       "121                                                    NaN\n",
       "122                                                    NaN\n",
       "123                                                    NaN\n",
       "124                                         [Conv1d, init]\n",
       "125                                                    NaN\n",
       "127                                                    NaN\n",
       "128                                                    NaN\n",
       "129                                                    NaN\n",
       "130                                                    NaN\n",
       "132                                                    NaN\n",
       "133                                                    NaN\n",
       "134      [net(test_iter), Y = net(torch.from_numpy(test...\n",
       "135                                                    NaN\n",
       "136                                                    NaN\n",
       "137      [model.eval(), input = torch.randn(batch_size,...\n",
       "139      [ import numpy as np\\r\\n import torch\\r\\n impo...\n",
       "140                                                    NaN\n",
       "141      [nn.Sequential, torch.nn.Unflatten(), nn.Linea...\n",
       "142                     [--runtime=nvidia, docker run ...]\n",
       "143                                       [AL2_x86_64_GPU]\n",
       "144      [hello world\\tHallo Welt\\r\\nhow are you?\\twie ...\n",
       "145      [load_dataset, datasets, from datasets import ...\n",
       "146                                                    NaN\n",
       "147                                                    NaN\n",
       "150                                                    NaN\n",
       "151      [plt.imshow(data_value.numpy()[0], cmap='gray'...\n",
       "152      [class AE(torch.nn.Module):\\r\\n    def __init_...\n",
       "154                                                    NaN\n",
       "155                                                    NaN\n",
       "156      [import timm\\r\\nimport torch\\r\\nfrom PIL impor...\n",
       "157      [trainer = pl.Trainer(\\r\\n    accelerator=\"GPU...\n",
       "158      [pt_x, tf_x, np.isclose,  np.isclose(pt_x.view...\n",
       "160      [plt.plot, numpy, torch.tensor, accHistory, nu...\n",
       "161                                                    NaN\n",
       "162                                                    NaN\n",
       "164      [# find normalized probabilities that sums up ...\n",
       "165                                                    NaN\n",
       "166                                                    NaN\n",
       "167      [grad, InputMatrix1, InputMatrix2, (0,0), x = ...\n",
       "169      [Flatten(), view(),     self.linear = nn.Seque...\n",
       "170                                                    NaN\n",
       "171                  [nn.Linear, nn.CrossEntropyLoss, Net]\n",
       "172                                                    NaN\n",
       "173      [cls, cls, import matplotlib.pyplot as plt\\r\\n...\n",
       "174      [Syntax – torch.utils.draw_bounding_boxes(imag...\n",
       "175      [__len__(self), __getitem__(self, idx), class ...\n",
       "176                                                    NaN\n",
       "177      [requires_grad = True, import torch\\r\\n\\r\\nx =...\n",
       "179      [y_hat, scipy.special.softmax(),  from scipy.s...\n",
       "180                                                    NaN\n",
       "182                                                    NaN\n",
       "183      [torch.gather, target,  out.gather(1, target[:...\n",
       "184                          [letterbox, 960, (1280, 720)]\n",
       "187                                                    NaN\n",
       "188                                                    NaN\n",
       "191      [sliding_window_view,  np.lib.stride_tricks.sl...\n",
       "192                                                    NaN\n",
       "193                                                    NaN\n",
       "194      [GINConv, GCNConv, torch_geometric, nn, torch....\n",
       "195                                                    NaN\n",
       "196                                                    NaN\n",
       "197                                                    NaN\n",
       "198                                                    NaN\n",
       "199                                                    NaN\n",
       "200                                                    NaN\n",
       "201                                                    NaN\n",
       "203                                     [model.eval()\\r\\n]\n",
       "204                                                    NaN\n",
       "205                                                    NaN\n",
       "206      [model, tensorboard, pip install tensorboard\\r...\n",
       "207                                                    NaN\n",
       "208                                                    NaN\n",
       "209      [        if labels is not None:\\r\\n        if ...\n",
       "210                                                    NaN\n",
       "211                                                    NaN\n",
       "212                                                    NaN\n",
       "213      [if torch.cuda.is_available():\\r\\n    torch.cu...\n",
       "214                                                    NaN\n",
       "215                                                    NaN\n",
       "216                                                    NaN\n",
       "217                                                    NaN\n",
       "218                                                    NaN\n",
       "219                                                    NaN\n",
       "220      [docker run, docker run ... nvcr.io/nvidia/pyt...\n",
       "221                                        [Yt_train, out]\n",
       "222      [x, (num_samples, num_classes), y, x, (num_sam...\n",
       "223      [# Create dummy tensors and save them in my_li...\n",
       "224                                                    NaN\n",
       "225                                                    NaN\n",
       "227                                                    NaN\n",
       "228                                                    NaN\n",
       "229                                                    NaN\n",
       "230                                                    NaN\n",
       "231                                                    NaN\n",
       "232      [p, p-q, (p[:, None, ...] - q[:, ...]).shape =...\n",
       "233      [Numpy, Pytorch, import torch\\r\\nimport numpy ...\n",
       "234                                                    NaN\n",
       "236                                                    NaN\n",
       "237                                                    NaN\n",
       "238                                                    NaN\n",
       "239                                                    NaN\n",
       "240                                                    NaN\n",
       "241                                                    NaN\n",
       "243                                                    NaN\n",
       "244      [py::array_t&lt;float&gt; args = py::array_t&l...\n",
       "245      [RuntimeError: Unsupported codec: \"h264_cuvid\"...\n",
       "246      [torchaudio, ffmpegio, pip install ffmpegio\\r\\...\n",
       "247                                                    NaN\n",
       "248      [import tensorflow as tf\\r\\n\\r\\ntext = \"I love...\n",
       "249      [def block_triu_indices(block_sizes=None):\\r\\n...\n",
       "250      [import torch\\r\\nfrom torch.nn.utils.rnn impor...\n",
       "251      [print([n for n, _ in model.model.named_childr...\n",
       "252                                                    NaN\n",
       "254                                                    NaN\n",
       "255               [libtorch, libtorch, libtorch, libtorch]\n",
       "256                                                    NaN\n",
       "257                                                    NaN\n",
       "258                                                    NaN\n",
       "259                                                    NaN\n",
       "260      [torch.Tensor.scatter, source, source, index, ...\n",
       "261      [ret = torch.empty_like(X)\\r\\nret.scatter_redu...\n",
       "262      [AutoModelForMaskedLM, from_pretrained(), mode...\n",
       "264                                                    NaN\n",
       "265                                                    NaN\n",
       "266                                                    NaN\n",
       "267                                                    NaN\n",
       "268                                                    NaN\n",
       "269      [ModuleNotFoundError: No module named 'models'...\n",
       "270      [import torch\\r\\nfrom models.experimental impo...\n",
       "272        [trainer.validate(model, mnist_val_loader)\\r\\n]\n",
       "273                                                    NaN\n",
       "274                                                    NaN\n",
       "276      [fc1, fc2, forward, self.fc1 = nn.Linear(num_f...\n",
       "277                                                    NaN\n",
       "278                                                    NaN\n",
       "279                                                    NaN\n",
       "280                                                    NaN\n",
       "281      [In [1]: model = resnet101()\\r\\nIn [2]: model....\n",
       "282                                                    NaN\n",
       "284                                                    NaN\n",
       "285      [Module, Module, self.model_layer = pretrained...\n",
       "286                                                    NaN\n",
       "287      [F.pad, MaxPool2D, MaxPool2D((2, 2)), ceil_mod...\n",
       "288                                                    NaN\n",
       "289                                                    NaN\n",
       "290      [# your model output\\r\\ny_out = torch.tensor([...\n",
       "291                                                    NaN\n",
       "293                                                    NaN\n",
       "294                                                    NaN\n",
       "295                                                    NaN\n",
       "296      [from typing import Union\\r\\nimport random\\r\\n...\n",
       "297                                                    NaN\n",
       "298                                                    NaN\n",
       "299                                                    NaN\n",
       "300      [__getitem__, __getitem__, trainloader, trains...\n",
       "301      [sklearn, from sklearn.metrics import confusio...\n",
       "302                                                    NaN\n",
       "303                                               [python]\n",
       "304                                                    NaN\n",
       "305                                                    NaN\n",
       "307                                                    NaN\n",
       "309      [data_collator = DataCollatorForLanguageModeli...\n",
       "310      [op = torch.rand((4,3,5))\\r\\ngt = torch.tensor...\n",
       "311                                                    NaN\n",
       "312                                                    NaN\n",
       "313                                                    NaN\n",
       "314                                                    NaN\n",
       "315                                                    NaN\n",
       "316                                                    NaN\n",
       "317                                                    NaN\n",
       "318                                                    NaN\n",
       "319      [&gt; Trainer(gpus=2)\\r\\n&gt; examples, labels...\n",
       "320                                                    NaN\n",
       "322      [[torch.dot(X[0], Y[0]), torch.dot(X[1], Y[1])...\n",
       "323                                     [NCCL_SHM_DISABLE]\n",
       "324                                                    NaN\n",
       "325                                                    NaN\n",
       "326      [# convert arrays to numpy arrays\\r\\ncelsius_a...\n",
       "327                                                    NaN\n",
       "328                                                    NaN\n",
       "329                                                    NaN\n",
       "330                                                    NaN\n",
       "331                                                    NaN\n",
       "332                                                    NaN\n",
       "333                                                    NaN\n",
       "334                                                    NaN\n",
       "335                                                    NaN\n",
       "336      [children, xavier_uniform_, nn.init, __init__,...\n",
       "338      [instances_train2017.json, datasets\\\\coco/anno...\n",
       "339                                                    NaN\n",
       "340      [    def forward(self,x):\\r\\n        return x ...\n",
       "341                                                    NaN\n",
       "344                        [Resize, Resize, DVS128Gesture]\n",
       "346                                                    NaN\n",
       "347                       [torch.cat((a, b)).unique()\\r\\n]\n",
       "348                                                    NaN\n",
       "349                                                    NaN\n",
       "350                                                    NaN\n",
       "351      [cls_score, # lengths = [num1, num2, num3, ......\n",
       "352      [nn.Sequential, *args, len(lengts) - 1, nn.Lin...\n",
       "354                                                    NaN\n",
       "355                                                    NaN\n",
       "358                                                    NaN\n",
       "359                                                    NaN\n",
       "361                                                    NaN\n",
       "363                                                    NaN\n",
       "364                                                    NaN\n",
       "365                                                    NaN\n",
       "366                    [granular_MLP.eval(), breakpoint()]\n",
       "367                                                    NaN\n",
       "368                                                    NaN\n",
       "369                                [nn.functional.one_hot]\n",
       "370      [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "372                                                    NaN\n",
       "373                                                    NaN\n",
       "375      [.to(features), model(features), features, cla...\n",
       "376      [nn.Module, forward, class Model(nn.Module):\\r...\n",
       "378                                                    NaN\n",
       "379      [torch.arange(10).to_dense() # will give same ...\n",
       "380      [my_list = [1, 2, 3, 4]\\r\\n, a, b, c, d = my_l...\n",
       "381      [np.random.permutation, np.random.default_rng(...\n",
       "382                                 [CTCLoss, log_softmax]\n",
       "383      [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "384                                                    NaN\n",
       "385                                                    NaN\n",
       "388      [TrainingMode, from torch.onnx import Training...\n",
       "389                                                    NaN\n",
       "390      [// Load model state dict\\r\\n// Aggregate grad...\n",
       "391      [[[0, 1, 2], [0, 2, 4], [3, 3, 3]], tensor([[1...\n",
       "392                                                    NaN\n",
       "393      [model_type, config_class, import torch.nn as ...\n",
       "394      [from transformers import PretrainedConfig\\r\\n...\n",
       "395      [fs = 44100                # audio sampling fr...\n",
       "396      [import math\\r\\n\\r\\nfps = 60\\r\\nframe_start = ...\n",
       "397      [len(x), len(pfinal),  reps = len(x) // len(pf...\n",
       "398                                                    NaN\n",
       "399                                                    NaN\n",
       "400                                                    NaN\n",
       "401                                                    NaN\n",
       "402      [from PIL import Image\\r\\nimport requests\\r\\n\\...\n",
       "403      [conda install -c conda-forge matplotlib\\r\\n, ...\n",
       "404                                                    NaN\n",
       "405      [RoIPool, __call__, forward, roi_pool = roi_po...\n",
       "406                                                    NaN\n",
       "407                                                    NaN\n",
       "408                                                    NaN\n",
       "409                                    [log(1−prediction)]\n",
       "411                                                    NaN\n",
       "412      [# first, clear all prev gradient info\\r\\nself...\n",
       "413      [q, k, batch, channel, height, width, q, k, q ...\n",
       "414                                                    NaN\n",
       "415                                                    NaN\n",
       "416      [# Get a tensor marking the rank of each weigh...\n",
       "417      [resnet18, import torch\\r\\nfrom torchvision im...\n",
       "418                                                    NaN\n",
       "419      [       box_detections_per_img (int): maximum ...\n",
       "420      [def _laplacian_positional_encoding_th(self, a...\n",
       "422                                                    NaN\n",
       "423                                              [Trainer]\n",
       "424      [model.parameters(), torch.save, import io\\r\\n...\n",
       "425                                                    NaN\n",
       "426                                                    NaN\n",
       "427      [vectors[:,:, None, None], (H, W), channels = ...\n",
       "428      [torch.mm, torch.mul, torch.matmul, torch.mm, ...\n",
       "430      [ray.init, if __name__ == '__main__':\\r\\n  ray...\n",
       "432                                                    NaN\n",
       "433      [CrossEntropyLoss, SoftMax, m = nn.Softmax(dim...\n",
       "434      [ b[a]\\r\\ntensor([ 1.5000,  1.8000, 10.0000,  ...\n",
       "437      [__len__, IterableDataset, IterableDataset, le...\n",
       "438      [X_test, dataset = torch.utils.data.TensorData...\n",
       "439                                                    NaN\n",
       "440      [pip install ultimate-utils, \"\"\"\\r\\n\\r\\ndo che...\n",
       "441      [ImageFolder, CIFAR10, CIFAR100, __getitem__, ...\n",
       "442      [new_idx, dataset, self.concat_datasets, class...\n",
       "443                                                    NaN\n",
       "444                                                    NaN\n",
       "445                                                    NaN\n",
       "446      [nn.ConvTranspose3d, (3, 3, 3), (1, 2, 2), D_o...\n",
       "447                                                    NaN\n",
       "448      [cuda, inputs = inputs.cuda()\\r\\nlabels = labe...\n",
       "449                                                    NaN\n",
       "450                                                    NaN\n",
       "451                                                    NaN\n",
       "453      [auto target_q_T = torch::rand({5, 10, 1});\\r\\...\n",
       "454      [max, max, auto target_q_T = torch::rand({5, 1...\n",
       "455                                                    NaN\n",
       "457      [batch_idx, forward, geom_nn, self.geom_nn, __...\n",
       "458                                                    NaN\n",
       "459                                                    NaN\n",
       "461      [torch.manual_seed(x)\\r\\n, torch.use_determini...\n",
       "462                                                    NaN\n",
       "463      [Trainer, enable_checkpointing, trainer = Trai...\n",
       "464      [BatchNorm2d, affine, True, True, _NormBase, w...\n",
       "465      [import torch_xla.core.xla_model as xm\\r\\ndevi...\n",
       "466                                                    NaN\n",
       "467                                                    NaN\n",
       "468      [at::expand, at::IntArrayRef, auto expanded_st...\n",
       "470                                                    NaN\n",
       "471      [class, class object, # let Classificador with...\n",
       "472      [import cv2\\r\\nfrom pytorch_grad_cam import Ab...\n",
       "473      [win_len = 1024\\r\\nwin_hop = win_len // 4    \\...\n",
       "474      [w, import torch\\r\\nfrom scipy import sparse\\r...\n",
       "476                                                [torch]\n",
       "477                                                    NaN\n",
       "478                                                    NaN\n",
       "479      [nn.AdaptiveAvgPool2d, output_size=1, (N, C, 1...\n",
       "480      [config, config, name: \"ecapatdnn_bangasianeng...\n",
       "481                                                    NaN\n",
       "482                                         [Q = P[A]\\r\\n]\n",
       "483                                   [A, Q = P[A, :]\\r\\n]\n",
       "484                           [final_hidden_state, output]\n",
       "485                                                    NaN\n",
       "486                                                    NaN\n",
       "489      [from TorchCRF import CRF\\r\\n, import argparse...\n",
       "490                                                    NaN\n",
       "491                                                    NaN\n",
       "492      [torch.einsum(\"ii\", A), torch.einsum(\"ii-&gt;\"...\n",
       "493      [T.Compose([..., T.CenterCrop(224), ...]), sel...\n",
       "494                                                    NaN\n",
       "495      [def polynomial(t: torch.Tensor, degree: int =...\n",
       "496      [dgl.adj(), g, adj, g = dgl.graph(([0, 1, 2], ...\n",
       "497                                                    NaN\n",
       "499                                                    NaN\n",
       "500                                    [nn, nn.functional]\n",
       "502                                                    NaN\n",
       "504                                                    NaN\n",
       "505                                                    NaN\n",
       "506                                                    NaN\n",
       "508      [forward(self, x), def forward(self, x):\\r\\n  ...\n",
       "509                                                    NaN\n",
       "510                                                    NaN\n",
       "511                                                    NaN\n",
       "512      [Lambda, transforms_apply = transforms.Compose...\n",
       "513      [*args, **kwargs, NetworkKeys, num_units, args...\n",
       "514                                                    NaN\n",
       "515      [loss, 1/accumulate_step, backward, backward, ...\n",
       "516                                                    NaN\n",
       "517                                                    NaN\n",
       "518      [import torch\\r\\nfrom torchvision import datas...\n",
       "519      [torch.save(), import torch\\r\\nimport torch.nn...\n",
       "520      [TheModelClass is not defined, TheModelClass, ...\n",
       "521      [pptk_subprocess, NamedTemporaryFile, commands...\n",
       "522                                                    NaN\n",
       "523      [f1_score, # Iterate over data.\\r\\ny_true, y_p...\n",
       "524      [import torch\\r\\na = torch.randn(1, 4, require...\n",
       "525                                                    NaN\n",
       "526                                                    NaN\n",
       "527      [COPY --from=submodule-update /opt/pytorch /op...\n",
       "528                                                    NaN\n",
       "529      [.flatmap(), .map(), def optimus_prime(row):\\r...\n",
       "530      [import pandas as pd\\r\\nfrom torch.utils.data ...\n",
       "531                                                    NaN\n",
       "532                                                    NaN\n",
       "533      [data_range, data_range: Range of the image. I...\n",
       "534      [a, b, torch.concat((a, b), dim=2), .to('cuda'...\n",
       "539      [torch.utils.data.DataLoader, torch.utils.data...\n",
       "540      [__iter__, DataLoader, {key: [value1, value2, ...\n",
       "541                                                    NaN\n",
       "542      [torch::NoGradGuard, set_requires_grad(false),...\n",
       "543      [def paddingImage(img, divider=32):\\r\\n    if ...\n",
       "544                                         [unsqueeze(0)]\n",
       "545                                                    NaN\n",
       "547      [eval, eval, time.sleep(), eval(expression[, g...\n",
       "548      [Variants, ROCK, PAPER, tuple, ROCK.value == (...\n",
       "549      [&gt; from variants import Variants from playe...\n",
       "550                                                    NaN\n",
       "551                                                    NaN\n",
       "553                                                    NaN\n",
       "554                                                    NaN\n",
       "555        [FirstSpike = torch.argmax(x != 0, axis=0)\\r\\n]\n",
       "556                                                    NaN\n",
       "557      [torchaudio.io.StreamReader, s = StreamReader(...\n",
       "558                                                    NaN\n",
       "561                                       [Conv2d, Linear]\n",
       "562                                                    NaN\n",
       "563      [DataPipe, open_files, parse_csv, shuffle, def...\n",
       "564      [batch_size, batch_size, log, self.log('train_...\n",
       "565      [O(n logn), O(n^2), def are_columns_paired(mat...\n",
       "566      [def __init__(self, connections, activation):\\...\n",
       "567                                                    NaN\n",
       "568                                                    NaN\n",
       "569      [nn.Sequential, forward, ResModel, torchvision...\n",
       "570      [import torch\\r\\nimport torch.nn as nn\\r\\ndevi...\n",
       "571      [source, model = torch.hub.load('/home/yolov5/...\n",
       "573      [pred=torch.Size([5, 1, 512, 512]), y_true=tor...\n",
       "576      [.apply_(), if, functorch.vmap, np.vectorize()...\n",
       "577                            [UNK_ID, UNK_ID, import, 0]\n",
       "578                                                    NaN\n",
       "579                                                    NaN\n",
       "580                                                    NaN\n",
       "581      [numpy, (N,2), (N,1), torch, load, sig, sr, sr...\n",
       "582                                                    NaN\n",
       "583      [tuple, randint(), def randint(low: _int, high...\n",
       "585                                                    NaN\n",
       "586      [Linear, nn.Linear, class Linear(torch.nn.Line...\n",
       "587                                                    NaN\n",
       "588                                                    NaN\n",
       "591                                                    NaN\n",
       "592                                                    NaN\n",
       "593      [__getitem__(), num_workers, testloader = torc...\n",
       "594                                                    NaN\n",
       "597                                                    NaN\n",
       "598      [.item(), xyxy = [int(e_.item()) for e_ in xyx...\n",
       "599                                                    NaN\n",
       "601      [import torch\\r\\nimport torch.nn.functional as...\n",
       "602      [class MybigNet(nn.Module):\\r\\n    def __init_...\n",
       "603                                                    NaN\n",
       "604                                                    NaN\n",
       "605                                                    NaN\n",
       "607                                                    NaN\n",
       "609      [ points = torch.tensor([[4.0, 1.0], [5.0, 3.0...\n",
       "610                                                    NaN\n",
       "611                                                    NaN\n",
       "612                                                    NaN\n",
       "613                                                    NaN\n",
       "614      [AugMix, ToTensor(), transformation = transfor...\n",
       "615      [torchvision.transforms.AugMix, uint8, torch.T...\n",
       "616                              [loss.backward(), x.grad]\n",
       "617                                                    NaN\n",
       "618      [s0, decay_constant, decay_constant, s0, (s0, ...\n",
       "619                                                    NaN\n",
       "620                                                    NaN\n",
       "621      [torch.utils.data.random_split, torch.utils.da...\n",
       "622                                                    NaN\n",
       "623                                                    NaN\n",
       "624      [Runner.validate(), cfg,     def predict(self,...\n",
       "625                                 [Event.elapsed_time()]\n",
       "626      [torch.tensor(...), torch.tensor, par, require...\n",
       "629                                                    NaN\n",
       "630      [import \"github.com/docker/cli/opts\"\\r\\n\\r\\n//...\n",
       "631      [ input = torch.arange(1, 5, dtype=torch.float...\n",
       "633                                                    NaN\n",
       "634      [padding=0, import torch\\r\\nimport torch.nn.fu...\n",
       "635                                                    NaN\n",
       "637      [model = PPO(\"CnnPolicy\", env, verbose=1, tens...\n",
       "638      [del model\\r\\nppo_path_load = os.path.join('Tr...\n",
       "639                                                    NaN\n",
       "640                                                    NaN\n",
       "641      [.reshape(), data, (32 * 5, 3, 256, 512), (32,...\n",
       "642      [with, nullcontext, from contextlib import nul...\n",
       "643      [def myrunner(myfunc,usecontext=True):\\r\\n    ...\n",
       "644      [Long, weights, Float, import torch\\r\\nimport ...\n",
       "645                      [argmax,  b_labels.argmax(1)\\r\\n]\n",
       "646                                                    NaN\n",
       "647                                                    NaN\n",
       "649      [np.arrays, np.array, float, tensor.item(),  [...\n",
       "650      [requires_grad=True, Variable, var_xs_h = Vari...\n",
       "652      [torch._C._set_grad_enabled(False), save_for_b...\n",
       "653      [def round_values_bob(predictions):\\r\\n    ret...\n",
       "654      [forward, from torch import nn\\r\\nimport torch...\n",
       "656      [assert not torch._C._get_tracing_state()\\r\\n\\...\n",
       "657      [X, m=n, AX - XB = 0, import torch\\r\\n\\r\\ndef ...\n",
       "659      [import torch\\r\\na = torch.rand([8,64,128,128]...\n",
       "660                                                    NaN\n",
       "661                                                    NaN\n",
       "664      [pip install torch==1.10.2\\r\\npip install torc...\n",
       "665      [RandomHorizontalFlip(), class Net(nn.Module):...\n",
       "666      [output = model(csv), csv = torch.utils.data.T...\n",
       "667        [show(), plt.imshow(), interpolation=\"nearest\"]\n",
       "668      [y[0], y[1], grad, a, a, print(a.grad)\\r\\n, te...\n",
       "669      [.retain_grad(), .grad, y.retain_grad(), y, .g...\n",
       "670      [self.fc3 = nn.Linear(84, 10)\\r\\n, self.fc3 = ...\n",
       "671      [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "672                            [.cuda(), .cuda(), .cuda()]\n",
       "673      [data_transforms, [], (), train = get_data(roo...\n",
       "674                                                    NaN\n",
       "675      [torch.gather, torch.gather(b, dim=0, index=in...\n",
       "676      [params, optimizer = optim.SGD(list(efficientN...\n",
       "677      [n, n-1, forward, n, n, class Model(nn.Module)...\n",
       "678      [torch.gather, repeat_interleave, select = tor...\n",
       "679                                                    NaN\n",
       "680                                                    NaN\n",
       "681                               [self.conv1, self.conv3]\n",
       "682                                                    NaN\n",
       "685                                                    NaN\n",
       "686                                     [coremltools==6.0]\n",
       "687      [ parameter_ids = [[id(p) for p in group[\"para...\n",
       "688                                                    NaN\n",
       "689                                                    NaN\n",
       "690                                                    NaN\n",
       "691                                                    NaN\n",
       "693                                                    NaN\n",
       "694                                                    NaN\n",
       "697      [(torch.from_numpy(item).to(device=device, dty...\n",
       "698                                                    NaN\n",
       "699      [for layer in self.moduleList:\\r\\n    out = la...\n",
       "700                                                    NaN\n",
       "701      [batch_size &gt; 1, batch_size = 2  # Need big...\n",
       "702      [N, N, B, b, B, B = N, B, B = 1, N, 10000 x b,...\n",
       "703                                                    NaN\n",
       "704      [ /Advanced/AMD CBS/NBIO Common Options/IOMMU ...\n",
       "705      [torch.normal(mean=mean, std=std)\\r\\n, mean = ...\n",
       "706      [json.dumps, import json\\r\\n\\r\\n...\\r\\n\\r\\npri...\n",
       "707      [import torch\\r\\nfrom torch.utils.mobile_optim...\n",
       "708      [\\r\\nimport cv2\\r\\nimport numpy as np\\r\\nfrom ...\n",
       "709      [import torch\\r\\nimport numpy as np\\r\\nt = tor...\n",
       "711                                                    NaN\n",
       "714                                                  [fc1]\n",
       "715      [import random\\r\\n\\r\\nclass rand_label_transfo...\n",
       "716      [num_workers, for batch_idx, batch_data in dl:...\n",
       "717      [Softmax, x, i, softmax(x_i) = e^{x_i} / sum_j...\n",
       "718      [y_pred = model(x_train)\\r\\n  loss = criteria(...\n",
       "719                             [torch.cuda.empty_cache()]\n",
       "720                                                    NaN\n",
       "721      [predicted, labels, for epoch in range(num_epo...\n",
       "722                                                    NaN\n",
       "723      [0, model.bert.encoder.layer[0].attention.self...\n",
       "725      [torch.distributions, dist = torch.distributio...\n",
       "726                                                    NaN\n",
       "728                                          [num_class=8]\n",
       "729      [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "730      [&gt;&gt; python optimizedSD/optimized_txt2img...\n",
       "731                   [nn.BatchNorm2d(channels*2**6*ifac)]\n",
       "733      [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "734                                                    NaN\n",
       "735      [torch.nn, my_input.shape == (3, 256, 256)\\r\\n...\n",
       "736                                                    NaN\n",
       "737                                                    NaN\n",
       "738      [ordered_keys = torch.tensor([1,5,5,3,1,1])\\r\\...\n",
       "740      [x_0, for i in range(10):\\r\\n   optimizer.zero...\n",
       "741      [Variable, loss = Variable(loss, requires_grad...\n",
       "742            [retain_graph=True, .detach(), net2(predZ)]\n",
       "743                                                    NaN\n",
       "744         [requires_grad, param.pdfvec[self.key], .data]\n",
       "745      [sklearn.metrics.roc_auc_score, y_true, y_scor...\n",
       "746      [# Tested with TensorFlow 2.6.2\\r\\nimport tens...\n",
       "747      [def fast_crop(x, idx1, idx2):\\r\\n    \"\"\"\\r\\n ...\n",
       "748                                                    NaN\n",
       "749      [if __name__ == '__main__', create_shared_memo...\n",
       "751      [model = deeplab_v3plus('resnet101', num_class...\n",
       "752      [from torchvision.models import resnet50, ResN...\n",
       "753               [model, Sequential, model, model, model]\n",
       "754      [a = torch.nn.Parameter(torch.ones(5, 5))\\r\\na...\n",
       "755                              [--mem=32G, gc.collect()]\n",
       "756      [SGD, optimizer = torch.optim.Adam(u_setaNet.p...\n",
       "757                           [nn.Linear(256, output_dim)]\n",
       "758                                                    NaN\n",
       "759      [std, slots_log_sigma = nn.Parameter(abs(torch...\n",
       "760      [torch.int32, from torch import nn\\r\\nimport t...\n",
       "761                                                    NaN\n",
       "763      [nn.Linear, [B,D], B, D, mean_squared_error, y...\n",
       "764      [nn.L1Loss(), nn.CosineEmbeddingLoss(), Execut...\n",
       "765      [input_id, mask, input_id, mask, labels, class...\n",
       "766                                                    NaN\n",
       "767                                                    NaN\n",
       "769      [torch.cdist, torch, scipy.spatial.distance.cd...\n",
       "770      [torch.matrix_rank, tol, torch.linal.matrix_ra...\n",
       "771      [dims, EdgeNeXt, model = EdgeNeXt(depths=[3, 3...\n",
       "772      [self.bert, from transformers import BertForSe...\n",
       "773      [BertForSequenceClassification.from_pretrained...\n",
       "774      [torch.BCELoss, torch.nn.CrossEntropyLoss, x =...\n",
       "775                                                    NaN\n",
       "776                                                    NaN\n",
       "778      [print(type(steps)), steps = int(steps), can c...\n",
       "780                                                    NaN\n",
       "781                                                    NaN\n",
       "782                                                    NaN\n",
       "784        [web_pdp__click_main_banner, 0, 1, &lt;EOS&gt;]\n",
       "785      [layers = [nn.Conv2d(3, 16, 3)]\\r\\nfor _ in ra...\n",
       "786      [relu, outputs, outputs[0], outputs[0].reshape...\n",
       "787                                                    NaN\n",
       "788               [export HSA_OVERRIDE_GFX_VERSION=10.3.0]\n",
       "789               [export HSA_OVERRIDE_GFX_VERSION=10.3.0]\n",
       "790                                                    NaN\n",
       "791                                                    NaN\n",
       "792                                                    NaN\n",
       "793                                         [model.cuda()]\n",
       "794      [ image = skimage.io.imread(image_path), print...\n",
       "795                                                    NaN\n",
       "796                                                    NaN\n",
       "797      [python setup.py build \\r\\npython setup.py ins...\n",
       "798      [nn.Module, class LinearWithZeroDiagonal(nn.Mo...\n",
       "799                                                    NaN\n",
       "800                                                    NaN\n",
       "801      [dim=1, import torch\\r\\nfrom torch import nn\\r...\n",
       "803                                                    NaN\n",
       "804                                                    NaN\n",
       "805                   [torch.rand(1), torch.random.seed()]\n",
       "806      [DataLoader, import torch\\r\\nimport torch.nn a...\n",
       "807                                                    NaN\n",
       "808      [in_features=784, 416x416x3 = 519168, in_featu...\n",
       "809      [train_data, train_target = data[:int(a*len(da...\n",
       "810                                                    NaN\n",
       "811                                                    NaN\n",
       "812                                           [nvidia-smi]\n",
       "813      [a, b, torch.nn.Parameter(), self.weight, self...\n",
       "814      [a, b, SGDmodel, sgd, SGDmodel, sgd = torch.op...\n",
       "815                                   [model.parameters()]\n",
       "817                                                    NaN\n",
       "818                                                    NaN\n",
       "819      [print('count: ', torch.cuda.device_count()), ...\n",
       "820      [print('count: ', torch.cuda.device_count())  ...\n",
       "821      [self.hidden_layers = []\\r\\nself.hidden_layers...\n",
       "822                                                    NaN\n",
       "823                                                    NaN\n",
       "824                                                    NaN\n",
       "826                                                    NaN\n",
       "827      [Bus, car, Zebra, zebra fish, striped shirt, z...\n",
       "828                                                    NaN\n",
       "829        [boxes, boxes.reshape(-1,4)[:,3], print(boxes)]\n",
       "830                         [torch.cuda.empty_cache()\\r\\n]\n",
       "831                                                    NaN\n",
       "832      [loss.backward(), x_tensor, x_tensor.grad, los...\n",
       "833      [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "838                                                    NaN\n",
       "839                                                    NaN\n",
       "842                                                    NaN\n",
       "844      [module, model, self.featureExtractor.module.b...\n",
       "845                                                    NaN\n",
       "846      [def rowwise_in(a,b):\\r\\n  \"\"\" \\r\\n  a - tenso...\n",
       "847      [a,b = torch.tensor([[1,2,3],[3,4,5],[5,6,7]],...\n",
       "848      [__getitem__, from typing import List\\r\\nfrom ...\n",
       "849                                                    NaN\n",
       "850      [torch.softmax, torch.log, torch.log_softmax, ...\n",
       "851                                                    NaN\n",
       "854                                                    NaN\n",
       "855      [linear_assignment, scipy.optimize.linear_sum_...\n",
       "856      [.backward(), def __init__(self):\\r\\n    super...\n",
       "857                                                    NaN\n",
       "858                                                    NaN\n",
       "860      [rotation_in_matrix = torch.tensor([\\r\\n    [c...\n",
       "861                                                    NaN\n",
       "862      [&gt;&gt; i = [[0, 1, 1],\\r\\n     [2, 0, 2]]\\r...\n",
       "864      [self.max_samples_per_ts = (max(len(ts) for ts...\n",
       "865                              [a * b.unsqueeze(-1)\\r\\n]\n",
       "866      [1, shape, a * b.reshape(b.shape + (1,)), None...\n",
       "867                                                    NaN\n",
       "868      [e, e, x.shape = [a,b], replace, y, x, torch.t...\n",
       "869      [def scatter_elements_vec(x, e, y):\\r\\n    ran...\n",
       "870                                                    NaN\n",
       "871                                                    NaN\n",
       "872                                                    NaN\n",
       "873                                                    NaN\n",
       "874      [collate_fn, self.pad_token_id = tokenizer.pad...\n",
       "875      [class MyNeuralNet(nn.Module):\\r\\n    def __in...\n",
       "876      [merge_from_file, cfg = get_cfg()\\r\\ncfg.merge...\n",
       "877                                                    NaN\n",
       "879      [ split = int(0.6*len(dataset))\\r\\n trainSet, ...\n",
       "880      [topk, def mytopk(xs: Tensor, k: int) -&gt; Te...\n",
       "881      [__init__, self.register_buffer('anchors', tor...\n",
       "882      [data.Subset, data.Dataset,  dataset_train = d...\n",
       "883                                                    NaN\n",
       "884      [ x.is_leaf\\r\\nTrue\\r\\n x[0].is_leaf\\r\\nFalse\\...\n",
       "885                                                    NaN\n",
       "887      [# add channel index to indicesRead\\r\\nindices...\n",
       "888                                                    NaN\n",
       "889                                                    NaN\n",
       "890      [total_steps, epochs &amp; steps_per_epoch, to...\n",
       "892      [init_parameters, import torch\\r\\n\\r\\nclass My...\n",
       "893      [0, class ImageNetDataset(Dataset):\\r\\n    def...\n",
       "894                               [Translator, Translator]\n",
       "895                                                    NaN\n",
       "896      [i, 0, batch_size, count, count = 0 # here\\r\\n...\n",
       "897      [i, test_targets[i], cv2.imwrite(f'/content/te...\n",
       "898                                                    NaN\n",
       "899      [reward = 0\\r\\n\\r\\nif(distance &lt; lastDistan...\n",
       "900      [for batch in dataset:\\r\\n    input_A, target_...\n",
       "901      [(input_ids.unsqueeze(dim=0), attention_mask.u...\n",
       "902      [trained_model, Tagger, attention_mask, Tagger...\n",
       "903                                                    NaN\n",
       "905      [import pytorch_lightning as pl\\r\\n\\r\\nclass L...\n",
       "906      [eval, import torch\\r\\ntemp_string = 'tensor([...\n",
       "907      [., import torch\\r\\na = torch.nn.Linear(1, 1)\\...\n",
       "908                                                    NaN\n",
       "910                                                    NaN\n",
       "911                                                    NaN\n",
       "913      [dtype, import torch\\r\\n@torch.cuda.amp.custom...\n",
       "914                                                    NaN\n",
       "915                                                    NaN\n",
       "916                                                    NaN\n",
       "918                                                    NaN\n",
       "919                                                    NaN\n",
       "921      [t * f;\\r\\n, t, f, t::x, t, x, t::x * f;, t::x...\n",
       "922      [typename, template, template&lt;typename T&gt...\n",
       "923      [typename, template, typename, template, typen...\n",
       "924      [typename, typedef, template&lt;typename T&gt;...\n",
       "925      [typedef typename Tail::inUnion&lt;U&gt; dummy...\n",
       "926      [typename, typename, typename, using, typedef,...\n",
       "927      [template &lt;class T&gt;\\r\\nstruct DependentT...\n",
       "928      [template&lt; typename T &gt; void foo( T&amp;...\n",
       "929                                                    NaN\n",
       "930      [import torch\\r\\nfrom typing import Optional, ...\n",
       "931                       [pip install dill --upgrade\\r\\n]\n",
       "932                                                    NaN\n",
       "933                                                    NaN\n",
       "934                                                    NaN\n",
       "935                      [DataLoader, train_data, Dataset]\n",
       "936      [loss = 0\\r\\nfor b in range(BSIZE):\\r\\n    \\r\\...\n",
       "937      [x_gray = ...  # your tensor of shape batch-1-...\n",
       "938                          [Backend worker process died]\n",
       "939                                                    NaN\n",
       "940      [x, \"\"\"\\r\\ninput\\r\\n    x: float tensor of siz...\n",
       "941                                                    NaN\n",
       "942      [ import torch\\r\\n x = torch.sparse_coo_tensor...\n",
       "943      [x = torch.sparse_coo_tensor([[0], [1]], [1.],...\n",
       "944      [features = model_output[0][:,0,:].numpy()\\r\\n...\n",
       "945                                                    NaN\n",
       "946                                                    NaN\n",
       "947      [(3,3), x = torch.ones((3,3)), (3,1,3), x.unsq...\n",
       "948                                                    NaN\n",
       "949      [def reweighted_cross_entropy(my_outputs, my_l...\n",
       "951                                                    NaN\n",
       "952      [import tensorflow as tf\\r\\nimport torch\\r\\nfr...\n",
       "953      [def EasyOcrTextSequence(self,):\\r\\n   reader ...\n",
       "954                                                    NaN\n",
       "955                                                    NaN\n",
       "956                                           [int, float]\n",
       "957      [!pip install kornia\\r\\nimport kornia as K\\r\\n...\n",
       "958      [from typing import Dict, List, Tuple\\r\\nimpor...\n",
       "959      [loss.backward(), l = loss(Y, y_pred), loss.ba...\n",
       "960                                                    NaN\n",
       "961                                                    NaN\n",
       "962      [from torch_scatter import segment_csr\\r\\n\\r\\n...\n",
       "963                                                    NaN\n",
       "964                                                    NaN\n",
       "965      [tabular_model.fit, None, cross_val_score, fit...\n",
       "966      [nn.Module, class Model(nn.Sequential):\\r\\n   ...\n",
       "968                                                    NaN\n",
       "969      [preds, out_logits[stream], .cpu(), require_gr...\n",
       "970                                                    NaN\n",
       "971               [DataLoader, tr_set, test, tr_set, test]\n",
       "972                                                    NaN\n",
       "973                                                    NaN\n",
       "974                                                    NaN\n",
       "975                                                    NaN\n",
       "976      [p.data, p, params, params = t.cat(tuple(t.fla...\n",
       "978                                                    NaN\n",
       "979      [from torchvision import models\\r\\nmodel = mod...\n",
       "980      [import tensorflow as tf\\r\\n\\r\\ntensor = tf.co...\n",
       "981                                                    NaN\n",
       "982                                                    NaN\n",
       "983      [glove.stoi, sentence = \"Hello, How are you?\"\\...\n",
       "984                      [(x == 0).nonzero()\\r\\n, nonzero]\n",
       "985      [torch.where, import torch\\r\\n\\r\\na = torch.ra...\n",
       "986                                                    NaN\n",
       "987      [def on_fit_start(self):\\r\\n    tb = self.logg...\n",
       "988      [logger = Logger() for scalar in scalars: logg...\n",
       "989      [# Filter the DataFrame to only validation dat...\n",
       "990      [requires_grad, # Change the optimizer call\\r\\...\n",
       "991                                                    NaN\n",
       "992                                                    NaN\n",
       "993                                                    NaN\n",
       "994      [def train_fn(config):\\r\\n    # ...\\r\\n, train...\n",
       "995                                                    NaN\n",
       "996      [python -m torch.distributed.launch --nproc_pe...\n",
       "997                                                    NaN\n",
       "998      [t = torch.rand(5, 3)\\r\\ncol_index_to_sort = 2...\n",
       "999      [a = &lt;your tensor&gt;\\r\\nind = a[:,-1].args...\n",
       "1000     [tensor = [[0.8771, 0.0976, 0.8186],\\r\\n      ...\n",
       "1001     [import torch\\r\\n\\r\\ndef adstock_multiple_samp...\n",
       "1002                                                   NaN\n",
       "1003     [original, batch[i][j], blurred, kernel, origi...\n",
       "1005                                                   NaN\n",
       "1006          [seed = 1\\r\\nsample = sample_4_values()\\r\\n]\n",
       "1007     [a = AutoModel.from_pretrained('bert-base-unca...\n",
       "1008     [c, c, c = torch.cat([a[:,:-1] -a[:, 1:] - b[:...\n",
       "1009     [assert y_true.size(0) == y_pred.size(0), y_tr...\n",
       "1010     [print(type(image)), model(image), model.load_...\n",
       "1011     [# logits_mask = model(image.to(DEVICE).unsque...\n",
       "1012     [train_data.pt, ImageFolder, import torch\\r\\nf...\n",
       "1013                                                   NaN\n",
       "1014                                                   NaN\n",
       "1015                                                   NaN\n",
       "1016               [def __int__(self), def __init__(self)]\n",
       "1017               [def __int__(self), def __init__(self)]\n",
       "1018                                                   NaN\n",
       "1019                                       [~/ray_results]\n",
       "1020     [def __init__(self, config):\\r\\n  super(Lightn...\n",
       "1021                                                   NaN\n",
       "1022     [def euc_no_loop(x, y):\\r\\n  # Suppose x has (...\n",
       "1023                                                   NaN\n",
       "1024     [pytorch, anaconda, defaults, channels:\\r\\n  -...\n",
       "1025                                                   NaN\n",
       "1026                                                   NaN\n",
       "1027     [0.01, cross_entropy, softmax, argmax, softmax...\n",
       "1028                                                   NaN\n",
       "1029     [train(), model = TheModelClass(*args, **kwarg...\n",
       "1030     [self.T = t\\r\\n, self.T = nn.Parameter(t)\\r\\n,...\n",
       "1031     [cell_size = width/S #or height/S\\r\\ncx_rcell ...\n",
       "1033                                                   NaN\n",
       "1034     [precision_and_recall = precision_recall(preds...\n",
       "1036                                                   NaN\n",
       "1037     [WeightedRandomSampler, import torch\\r\\nfrom t...\n",
       "1038     [WeightedRandomSampler, c, WeightedRandomSampl...\n",
       "1039     [e = torch.randint(-8,9,(50,1),dtype=torch.flo...\n",
       "1040     [/my_path/to/tb_logs/my_logger/version_0, my_p...\n",
       "1041     [Dataset, Dataloader, import torch\\r\\nfrom tor...\n",
       "1042                       [pip install pytorch 1.4.0\\r\\n]\n",
       "1043                                                   NaN\n",
       "1044                                                   NaN\n",
       "1045                                                   NaN\n",
       "1046     [idx_shard, np.random.choice(idx_shard, 2, rep...\n",
       "1047                                                   NaN\n",
       "1048                      [opencv-python-headless, opencv]\n",
       "1049                                                   NaN\n",
       "1050     [def Iris_Reader(dataset):\\r\\n    train_data, ...\n",
       "1051                                                   NaN\n",
       "1052           [B = B.clone()[batch, replace_ids] = A\\r\\n]\n",
       "1053     [your_tensor.argmax(dim=1), your_tensor.argmax...\n",
       "1054     [torch.argmax, torch.max, dim, torch.topk, k, ...\n",
       "1055     [train_ch3, dl3, to, net.to(device), X.to(devi...\n",
       "1056                                                   NaN\n",
       "1058                                                   NaN\n",
       "1059                                                   NaN\n",
       "1061     [TheModelClass, class TheModelClass(torch.nn.M...\n",
       "1063     ['samplewise': In this case, the statistics ar...\n",
       "1064     [x=1000\\r\\nDEVICE = \"cuda\" if torch.cuda.is_av...\n",
       "1065     [forward, encoded = self.encoder(x)\\r\\ndecoded...\n",
       "1066                                                   NaN\n",
       "1067                    [BinaryCrossEntropy, print(model)]\n",
       "1068     [import tensorflow as tf \\r\\n\\r\\nx = tf.zeros(...\n",
       "1070                                                   NaN\n",
       "1071                 [module, forward, module, forward, h]\n",
       "1072     [encoder, decoder, import torch\\r\\nimport torc...\n",
       "1073                                                   NaN\n",
       "1075     [torch.argmax(input, dim, keepdim=False), pred...\n",
       "1076     [def train(epoch, tokenizer, model, device, lo...\n",
       "1077     [from tqdm import tqdm\\r\\n, next(...), for i i...\n",
       "1078     [type, In [2]: a = torch.tensor([1,2])\\r\\n\\r\\n...\n",
       "1079                                                   NaN\n",
       "1080     [Σ = torch.linalg.cholesky(pos_def_cov) \\r\\n, ...\n",
       "1081                                                   NaN\n",
       "1082     [mask = torch.ones(1024, 64, dtype=torch.float...\n",
       "1084                                                   NaN\n",
       "1085     [def get_singlescale_features(self,image):\\r\\n...\n",
       "1086     [cm = wandb.plot.confusion_matrix(\\r\\n    y_tr...\n",
       "1088                                                   NaN\n",
       "1089                                                   NaN\n",
       "1090     [Z = [[0.5 * torch.norm(torch.matmul(A, torch....\n",
       "1091     [Numba, import plotly.graph_objects as go\\r\\nf...\n",
       "1092          [flip, img_tensor = img_tensor.flip(2);\\r\\n]\n",
       "1093                   [x, pred = model(x[None, ...])\\r\\n]\n",
       "1094     [import streamlit as st\\r\\nfrom PIL import Ima...\n",
       "1095     [nn.Conv2D, conv2d, 64@96x96, 64@10x10, 105x10...\n",
       "1096                              [Hardtanh, ReLU, Linear]\n",
       "1097     [nn.Linear, (FC), num_ftrs = model_conv.fc.in_...\n",
       "1098     [ConvNet, model, model = ConvNet(), model, Con...\n",
       "1099                                                   NaN\n",
       "1100                                                   NaN\n",
       "1101     [True, argsort, import torch\\r\\n\\r\\np = torch....\n",
       "1102                                                   NaN\n",
       "1103     [c = r.pad_sequence([a.T, b.T], batch_first=Tr...\n",
       "1104     [forward, vit = model(...)  # your model with ...\n",
       "1105                                                   NaN\n",
       "1106                                          [torch.load]\n",
       "1107     [for repo in repositories:\\r\\n  for file in re...\n",
       "1108     [ a.repeat_interleave(2,dim=1)\\r\\ntensor([[[[0...\n",
       "1109                                                   NaN\n",
       "1110     [torch.no_grad(), requires_grad=False, w = w -...\n",
       "1111                                                   NaN\n",
       "1112     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1113                                                   NaN\n",
       "1114     [BertForSequenceClassification, from transform...\n",
       "1115     [a &lt; b,  sqrt(a^2 - x^2 - y^2) &lt; z &lt; ...\n",
       "1116     [import boto3\\r\\n\\r\\nclient = boto3.client(\"sa...\n",
       "1117                                                   NaN\n",
       "1120     [checkpoint_callback, checkpoint_callback, che...\n",
       "1122     [if __name__ == '__main__':\\r\\n        freeze_...\n",
       "1123     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "1124     [cfg.MODEL.PIXEL_MEAN = [mean_pixel_values[2],...\n",
       "1125                             [weight_last, [1,3], [3]]\n",
       "1126     [output = model.forward(x)\\r\\nloss = criterion...\n",
       "1127     [inputs = 1 * r, inputs, retain_graph=True, ba...\n",
       "1128     [model_arguments = Seq2SeqTrainingArguments(ou...\n",
       "1129     [Trainer, TensorBoard, TrainingArguments, logg...\n",
       "1131     [.view, requires_grad=False, import torch\\r\\nf...\n",
       "1132     [torch.utils.data.RandomSampler, import torch\\...\n",
       "1133     [obs, OUT_DIM, num_filters * out_dim * out_dim...\n",
       "1134     [apply_along_axis, import torch\\r\\n\\r\\n\\r\\ndef...\n",
       "1135                                                   NaN\n",
       "1136     [i=torch.tensor([[ 0, 1, 2],\\r\\n              ...\n",
       "1137     [import torch\\r\\n\\r\\nv = [\\r\\n        [0,2],\\r...\n",
       "1138                                                   NaN\n",
       "1139     [torch.unfold, data1, nn.Unfold, b, c, ..., nn...\n",
       "1140                                                   NaN\n",
       "1141                                                   NaN\n",
       "1142                                                   NaN\n",
       "1143                                                   NaN\n",
       "1144     [def some_unimportant_function(params):\\r\\n   ...\n",
       "1145                                                   NaN\n",
       "1146           [list, self.layers = torch.nn.ModuleList()]\n",
       "1147     [assign, input_seq[1:, :].assign(tf.convert_to...\n",
       "1148     [\\r\\ndef unpack(params,layers=[(128,8),(64,128...\n",
       "1150     [a = self.image_features(image)\\r\\na = a.view(...\n",
       "1151     [@app.endpoint('/send_weights', methods=['GET'...\n",
       "1153     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1154     [import torch\\r\\n\\r\\nN,d = 10, 10\\r\\n\\r\\n# def...\n",
       "1155     [class A:\\r\\n    def __init__(dim,weights):\\r\\...\n",
       "1156                                                   NaN\n",
       "1157                                                   NaN\n",
       "1158                                                   NaN\n",
       "1159     [torch.topk, torch.Tensor.scatter_, torch.topk...\n",
       "1160     [k, k=2, v0=5, k,  v, _ = x.sort(dim=2)\\r\\n\\r\\...\n",
       "1161                                                   NaN\n",
       "1162     [numpy_dataset = load_data\\r\\nprint(np.ndarray...\n",
       "1163     [max_position_embeddings, tokenizer = BertToke...\n",
       "1164                                                   NaN\n",
       "1165     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "1166     [nn.Flatten(), nn.crossentropy, self.model = n...\n",
       "1167                                                   NaN\n",
       "1168     [kornia, kornia.color.rgb_to_lab(image), tenso...\n",
       "1169     [torch.nn.utils.rnn.pad_sequence([\\r\\n    torc...\n",
       "1170     [tensorflow==2.9, tensorflow as tf\\r\\nimport n...\n",
       "1171                                                   NaN\n",
       "1173     [import pandas as pd\\r\\nimport torch\\r\\n\\r\\ndf...\n",
       "1174     [wget https://nvidia.box.com/shared/static/p57...\n",
       "1175     [from_pretrained(), emb_layer.weight is emb_ba...\n",
       "1176                                                   NaN\n",
       "1177     [torch.isin, out = ~torch.isin(a, torch.tensor...\n",
       "1178                               [conda_tensorflow2_p38]\n",
       "1179                                                   NaN\n",
       "1180                                  [A_sparse.indices()]\n",
       "1181                                                   NaN\n",
       "1182     [low, high = -0.1, 0.1\\r\\ndist = torch.distrib...\n",
       "1183                                                   NaN\n",
       "1184     [torchvision.models.detection, fasterrcnn_resn...\n",
       "1185     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "1186                                                   NaN\n",
       "1187     [list1 = [\\r\\n[10, 25, 75, 10, 50],\\r\\n[25, 30...\n",
       "1189                                                   NaN\n",
       "1190                                                   NaN\n",
       "1191                                                   NaN\n",
       "1192                                                   NaN\n",
       "1193                                                   NaN\n",
       "1194     [import numpy as np\\r\\ndef convolute_full(X, W...\n",
       "1195     [nn.modules.lazy.LazyModuleMixin, torch.nn.Uni...\n",
       "1196                                        [out_channels]\n",
       "1197     [MapDataset&lt;DatasetType, TransformType&gt; ...\n",
       "1198                                                   NaN\n",
       "1199                                                   NaN\n",
       "1200     [metric_for_best_model='f1', from_pretrained('...\n",
       "1201     [r, p6, p10, p10 &lt; p6 &lt; p7 &lt; p8 &lt; ...\n",
       "1202     [import torch\\r\\nfrom torchvision import model...\n",
       "1203                                                   NaN\n",
       "1205     [self.mrnc, class MyDenseNetConv(torch.nn.Modu...\n",
       "1207                                                   NaN\n",
       "1208     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "1209     [self.array1, self.array4, __init__, first = s...\n",
       "1210                                                   NaN\n",
       "1211                                                   NaN\n",
       "1212     [import torch\\r\\n\\r\\np = torch.arange(0, 12, r...\n",
       "1213     [target, critic, critic(next_state), target, t...\n",
       "1214                                                   NaN\n",
       "1215                [batch_size = 2, loss, batch_size x 1]\n",
       "1216                                                   NaN\n",
       "1217                                                   NaN\n",
       "1218                                                   NaN\n",
       "1221     [None, mask = (torch.rand(12) &gt; 0.5).int() ...\n",
       "1222                                                   NaN\n",
       "1223                                                   NaN\n",
       "1225                       [eval_dataset, compute_metrics]\n",
       "1226     [sum(o) + o' + p',  v = o.sum(2, True) + o_pri...\n",
       "1227     [(2,5,5), o_i==p_j, mask = (o.repeat(1,1,p.sha...\n",
       "1228     [model_data=output_path\\r\\nfrom sagemaker.pyto...\n",
       "1229                                                   NaN\n",
       "1231                                                   NaN\n",
       "1232                                                   NaN\n",
       "1233     [net(), nn.linear(1,30), x2 = torch.rand(10,1)...\n",
       "1234     [RUN apt-get update &amp;&amp; apt-get install...\n",
       "1235                                                   NaN\n",
       "1236                                                   NaN\n",
       "1237         [model.load_state_dict(torch.load(path))\\r\\n]\n",
       "1238     [import torchvision.models as models\\r\\nimport...\n",
       "1239     [a, da²/da + d(a+1)²/da, 2a + 2(a+1), 2(2a + 1...\n",
       "1240     [ConvTranspose2d, ConvTranspose3d, NCHW, 2,  c...\n",
       "1241                                                   NaN\n",
       "1242     [librosa.feature.rms, import librosa\\r\\n\\r\\nFI...\n",
       "1243                                                   NaN\n",
       "1244                                                   NaN\n",
       "1245                                                   NaN\n",
       "1246     [def scalarized_dy(X, Y):\\r\\n    dY = grad(f, ...\n",
       "1247                                                   NaN\n",
       "1248                              [jnp, tf, np, mx, torch]\n",
       "1249                                                   NaN\n",
       "1250     [X1, X2, Y_hat1, Y_hat2, X1 = torch.tensor([[1...\n",
       "1251                            [BCELoss(), __getitem__()]\n",
       "1252     [parse_args, def train(args):\\r\\n    args = pa...\n",
       "1253     [class BType(Enum):\\r\\n    A = 0\\r\\n    B = 1\\...\n",
       "1254     [layer.weight.data += plus_weight\\r\\n, import ...\n",
       "1255     [data.Subset, data.Dataset, datasets.CIFAR10, ...\n",
       "1256     [subset, dataset, dataset, print(dict(Counter(...\n",
       "1257                                                   NaN\n",
       "1258                                                   NaN\n",
       "1259                                                   NaN\n",
       "1260     [references/detection/, references/detection/e...\n",
       "1261                                                   NaN\n",
       "1262                                                   NaN\n",
       "1263     [pip install tensorflow, pip install tensorflo...\n",
       "1264     [torch.stack, tensor_input_specs = []\\r\\n\\r\\nf...\n",
       "1265     [Trainer.fit, LightningModule, def fit(self):\\...\n",
       "1266                                                   NaN\n",
       "1268                                                   NaN\n",
       "1269     [torch.rand(2.0), z, create_graph=True, import...\n",
       "1270     [torch.combinations, r, inp, (N, C), N, C, {1,...\n",
       "1271     [indices = torch.randperm(a.size()[0])\\r\\na=a[...\n",
       "1272                                                   NaN\n",
       "1273     [param.requires_grad = False\\r\\n, requires_gra...\n",
       "1275     [nn.Conv2d, in_channels, def input_depth(netwo...\n",
       "1276                                                   NaN\n",
       "1277     [{\"loss\": None}, if train_loss == 0:\\r\\n    tr...\n",
       "1278                                                   NaN\n",
       "1279     [Trainer,  trainer = Trainer()\\r\\n, DataLoader...\n",
       "1280                                                   NaN\n",
       "1281     [ImageDataGenerator, val_images = np.array(val...\n",
       "1282                                                   NaN\n",
       "1283     [build_vocab_from_iterator, build_vocab_from_i...\n",
       "1284     [nn.Module, nn.ModuleList, __init__, embedding...\n",
       "1285                                                   NaN\n",
       "1286                                                   NaN\n",
       "1287                                                   NaN\n",
       "1288     [tf.data.from_tensor_slices, data.TensorDatase...\n",
       "1289                                                   NaN\n",
       "1290                [num_channels, num_groups, num_groups]\n",
       "1291                                                   NaN\n",
       "1292                                                   NaN\n",
       "1293     [# set up default mask\\r\\nm = np.ones(x.shape,...\n",
       "1294     [import numpy as np \\r\\n\\r\\nx = np.array([[0, ...\n",
       "1295     [torch.scatter_add, x.scatter_add(dmi=1, index...\n",
       "1296                                                   NaN\n",
       "1297                                                   NaN\n",
       "1298     [:latest, 763104351884.dkr.ecr.us-east-1.amazo...\n",
       "1299                                                   NaN\n",
       "1301     [nn.BCEWithLogitsLoss, F.binary_cross_entropy_...\n",
       "1302                                                   NaN\n",
       "1304                                                   NaN\n",
       "1307                              [optim.AdamW, Optimizer]\n",
       "1308     [nn.DataParallel,  model = nn.DataParallel(nn....\n",
       "1309     [predict_dataloader(), LightningDataModule, cl...\n",
       "1310                                   [__init__, __int__]\n",
       "1311                                                   NaN\n",
       "1312                                                   NaN\n",
       "1313     [state_dict, def train_function(...):\\r\\n  for...\n",
       "1314     [TSNE, sequence_representations, ndarray, n_sa...\n",
       "1315                                    [pred_tf, pred_pt]\n",
       "1316                                                   NaN\n",
       "1317     [import torch\\r\\n\\r\\nconv = torch.nn.Conv2d(1,...\n",
       "1318                                                   NaN\n",
       "1319     [__call__, self(**data), BaseDetector, __call_...\n",
       "1320                                                   NaN\n",
       "1321     [DataLoader, head1, head2, Datasets, DataLoade...\n",
       "1322                                                   NaN\n",
       "1323                                                   NaN\n",
       "1326                                                   NaN\n",
       "1328                                                   NaN\n",
       "1330     [views.py, os.environ.setdefault(\"DJANGO_SETTI...\n",
       "1331                                              [self.N]\n",
       "1332     [conv, kernel_zise=5, padding=2,         self....\n",
       "1334                                                   NaN\n",
       "1335     [u[0], psi[0] = 2*u[0]\\r\\n, grad_Psi_0 = torch...\n",
       "1336     [y ≥ x, y &gt; x, y &gt; x + k, 1 + k, torch.t...\n",
       "1337     [if epoch == num_epochs + 1:, for epoch in ran...\n",
       "1338     [def load_unet_vgg16(model_path, pretrained=Tr...\n",
       "1339                                          [stage=None]\n",
       "1340     [stage, trainer.{fit,validate,test,predict}, s...\n",
       "1341                                                   NaN\n",
       "1342     [import torch\\r\\nfrom transformers import Bert...\n",
       "1343     [# For initialization of maxpool layer.\\r\\nnn....\n",
       "1344     [import torch.multiprocessing\\r\\ntorch.multipr...\n",
       "1345     [.to('cuda'), 'cpu', .to('cuda'), .to('cuda'),...\n",
       "1347     [def hook_function(module, input, output):\\r\\n...\n",
       "1348                                                   NaN\n",
       "1349                                                   NaN\n",
       "1350     [import os\\r\\nfrom torchvision import transfor...\n",
       "1351                                                   NaN\n",
       "1353                  [A, B, C, A, B, C, A, B, C, A, B, C]\n",
       "1355                                        [nn.Parameter]\n",
       "1356                                                   NaN\n",
       "1357     [Distribution, batch_shape, event_shape, Trans...\n",
       "1358     [nn.Module,  model.model.blocks[4].temporal_at...\n",
       "1359     [-W, python, dowarn.py, import warnings\\r\\nwar...\n",
       "1360                                                   NaN\n",
       "1361                                                   NaN\n",
       "1362                                                   NaN\n",
       "1363     [prune.ln_structured(tmp_module, name=\"weight\"...\n",
       "1364                                                   NaN\n",
       "1365                                                   NaN\n",
       "1366     [DefaultTrainer, build_optimizer, from detectr...\n",
       "1367     [torch.optim.SGD, detectron2/detectron2/solver...\n",
       "1368     [import torch\\r\\nfrom timesformer.models.vit i...\n",
       "1369     [strict = False, load_state_dict(), state_dict...\n",
       "1370                                          [autocast()]\n",
       "1371                                                   NaN\n",
       "1372                                                   NaN\n",
       "1373                                                   NaN\n",
       "1374                                                   NaN\n",
       "1375     [# given y_pred as 1-hot and y-true the multic...\n",
       "1376     [data_dicts = [\\r\\n    {\"image\": image_name, \"...\n",
       "1377                                                   NaN\n",
       "1378     [v = beta1 * v + (1 - beta1) * p.grad.data\\r\\n...\n",
       "1379                                                   NaN\n",
       "1380                                                   NaN\n",
       "1381                          [\"cuda:2\"\\r\\n, \"cuda:0\"\\r\\n]\n",
       "1382                                                   NaN\n",
       "1383     [from einops import reduce as reduce, !pip ins...\n",
       "1384                                                   NaN\n",
       "1385                                                   NaN\n",
       "1388     [selected_img = selected_img.add(1).div(2)[Non...\n",
       "1389                                                   NaN\n",
       "1390                                                   NaN\n",
       "1391     [N, len(a), N*(N+1)/2 = len(a) =&gt; N, numpy,...\n",
       "1392                         [cuda(device=opt.gpu_ids[0])]\n",
       "1395                                                   NaN\n",
       "1396                                            [tools.py]\n",
       "1397     [output = torch.sigmoid(previous_layer_output)...\n",
       "1398     [import torch.nn.functional as F\\r\\n\\r\\n# ...\\...\n",
       "1399                            [net = net.to(device)\\r\\n]\n",
       "1400                                                   NaN\n",
       "1401     [torch.load(\"file.pyth\"), path_to_checkpoint =...\n",
       "1402     [!wget -O mini.sh https://repo.anaconda.com/mi...\n",
       "1403     [torch.nn.utils.rnn.pad_packed_sequence, batch...\n",
       "1404     [torch.Tensor.unfold, import torch\\r\\nx = torc...\n",
       "1405                           [multiprocessing/queues.py]\n",
       "1406                                                   NaN\n",
       "1407                                                   NaN\n",
       "1408                                              [eval()]\n",
       "1409                                                   NaN\n",
       "1411                                                   NaN\n",
       "1412     [rows = torch.arange(tensor_to_change.size(0))...\n",
       "1414     [your_target_value = 0\\r\\nyour_tensor = torch....\n",
       "1415     [self.X[idx], self.regi_no[idx], (512,), (1,),...\n",
       "1416     [torch.utils.model_zoo.load_url, initial_weigh...\n",
       "1417     [nn.Module, __init__, forward, class LinearSof...\n",
       "1418     [torch.isclose,  torch.isclose(out1, out2).flo...\n",
       "1419     [torch.no_grad(), nn.Module.eval, densenet, to...\n",
       "1421                [target, pred, y_true, y_pred, target]\n",
       "1422     [torch.lingalg.lstsq, torch.matmul, torch.ling...\n",
       "1423     [input_size, nn.LSTM, 7, xTrain, (*, feature_t...\n",
       "1424     [torch.nonzero(torch.all(x==torch.tensor([1,2]...\n",
       "1425                                                   NaN\n",
       "1426     [optimizer.zero_grad() # Clears the gradient f...\n",
       "1427     [    loss.backward()\\r\\n    optimizer.step()\\r...\n",
       "1429     [class TorchGenerator(Dataset):\\r\\n\\r\\n# Const...\n",
       "1430     [(bs, c, h, w), orig_img, img, (c, h, w), Five...\n",
       "1432     [img_to_test, HWC, HWC, CHW,  test_x = img_to_...\n",
       "1433     [#This transform is crucial to solve the probl...\n",
       "1434                                                   NaN\n",
       "1435     [torch.cuda.memory_allocated(), vkAllocateMemo...\n",
       "1436     [x = torch.randn(0,0, device='cuda'), x = torc...\n",
       "1438     [C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\re...\n",
       "1439                                                   NaN\n",
       "1440     [torch.multiprocessing.reductions, _share_cuda...\n",
       "1441     [torch.topk, torch.tensor.scatter_, K = torch....\n",
       "1442                                                   NaN\n",
       "1443     [torch.Tensor.sort,  v = x.sort(dim=1, descend...\n",
       "1444                                                   NaN\n",
       "1445                                                   NaN\n",
       "1446     [backward(), torch.autograd.set_detect_anomaly...\n",
       "1447     [from PIL import Image, ImageOps\\r\\n\\r\\nimg = ...\n",
       "1448     [PIL.Image.convert, img.convert(\"1\", dither=Im...\n",
       "1449     [torchvision.transforms.functional.to_tensor, ...\n",
       "1451                                                   NaN\n",
       "1452     [criterion, input, target, torch.nn.functional...\n",
       "1453     [__getitem__, def __getitem__(self, idx):\\r\\n ...\n",
       "1454     [nn.Linear, x, class AE(torch.nn.Module):\\r\\n ...\n",
       "1455     [weight_decay, conv_layer.parameters(), conv_l...\n",
       "1456     [torch.einsum,  o = torch.einsum('acdefg,bshig...\n",
       "1457     [def batch_function(M, kernel_size=21, sf=2):\\...\n",
       "1458                                                   NaN\n",
       "1459                                                   NaN\n",
       "1460                                                   NaN\n",
       "1461     [+=, returns[step] += gamma * returns[step + 1...\n",
       "1462     [from stable_baselines3.common.vec_env import ...\n",
       "1463     [trilinear, bicubic, class Upsample(nn.Module)...\n",
       "1464                                                   NaN\n",
       "1465                                                   NaN\n",
       "1466       [__init__, self.f_connected2, (batch_size,300)]\n",
       "1467                                                   NaN\n",
       "1468                                                   NaN\n",
       "1469     [THCState_getCurrentStream, at::cuda::getCurre...\n",
       "1470                                                   NaN\n",
       "1471                                                   NaN\n",
       "1472     [lr_lambda (function or list) – A function whi...\n",
       "1473     [torch.use_deterministic_algorithms,  a = torc...\n",
       "1474     [import torch\\r\\ndef same_storage(x, y):\\r\\n  ...\n",
       "1475     [import numpy as np\\r\\n\\r\\n\\r\\ndef index_reduc...\n",
       "1476     [index_reduce_, import torch\\r\\n\\r\\narray = to...\n",
       "1477     [pandas groupby agg, indices = [0, 0, 2, 3, 2,...\n",
       "1478                                                   NaN\n",
       "1480                                                   NaN\n",
       "1481                                                   NaN\n",
       "1483     [df = pd.read_csv('interactionsv21test.csv')\\r...\n",
       "1484     [def one_hot(x, num_classes=3):\\r\\n    return ...\n",
       "1485     [class MyNet(NeuralNetRegressor):\\r\\ndef fit(s...\n",
       "1487     [pip3 install torch torchvision torchaudio --e...\n",
       "1488     [import os\\r\\n!git clone https://github.com/py...\n",
       "1489                                                   NaN\n",
       "1490     [pretrained_model_except_last_layer = list(pre...\n",
       "1491                                                   NaN\n",
       "1492     [x, y, osum = x[..., None] + y[:, None, :]\\r\\n...\n",
       "1493     [ x = torch.randint(0,10,(2,4))\\r\\ntensor([[0,...\n",
       "1494     [reduction, batch_loss = (criterion(outputs*ma...\n",
       "1495                                                   NaN\n",
       "1496     [for epoch in range(1):\\r\\n\\r\\n    running_los...\n",
       "1497     [mask = t.isinf().logical_not)()\\r\\n# tensor([...\n",
       "1500      [./runs/models/{model_name}/{data_name}/epoch_0]\n",
       "1501     [tf.nn.softmax(\\r\\n    logits, axis=None, name...\n",
       "1504            [t[[i for i in range(3)], [2, -1, 0]]\\r\\n]\n",
       "1505     [t = torch.tensor(\\r\\n            [[1.0, 1.5, ...\n",
       "1506                                                   NaN\n",
       "1508                                                   NaN\n",
       "1509     [assert torch.all(t[mask==False] == float('-in...\n",
       "1510                                                   NaN\n",
       "1511     [BaselineModel, BaselineModel, import random\\r...\n",
       "1512                                                   NaN\n",
       "1513                                                   NaN\n",
       "1514     [opt = Adam([\\r\\n        {'params': model.part...\n",
       "1515                                                   NaN\n",
       "1516                                                   NaN\n",
       "1520     [Sigmoid, CrossEntropyLoss, self.training == T...\n",
       "1521     [torchmetrics, prec = torchmetrics.Precision(n...\n",
       "1522     [multi_class=True, num_classes=2, torchmetrics...\n",
       "1523     [torch.distributions.gamma.Gamma, import torch...\n",
       "1524                                                   NaN\n",
       "1525     [l = set()\\r\\nfor img in glob.glob('/content/M...\n",
       "1526     [.getdata(), l = []\\r\\nfor img in glob.glob('/...\n",
       "1527                                                   NaN\n",
       "1528     [trainset = SegmentationDataset(train_df, get_...\n",
       "1529                                                   NaN\n",
       "1530     [def reset_tracked_batches_num(model:torch.nn....\n",
       "1531     [ X, = torch.tensor([1, 1.5, 0.5]).shape\\r\\n X...\n",
       "1532                                                   NaN\n",
       "1533                                                   NaN\n",
       "1534                                                   NaN\n",
       "1535     [dice_score += (2 * (preds * y).sum()) / (2 * ...\n",
       "1536                                                   NaN\n",
       "1539                                                   NaN\n",
       "1540                                                   NaN\n",
       "1541                                                   NaN\n",
       "1543     [model.to('mps')\\r\\nlogits = model(X.to('mps')...\n",
       "1545     [model_dir = os.environ.get(\"SM_MODEL_DIR\")\\r\\...\n",
       "1547     [self.set_lay.append(OneInputBasis()), node,  ...\n",
       "1549     [feature_blobs = []\\r\\n\\r\\ndef hook_feature(mo...\n",
       "1550                                                   NaN\n",
       "1551                                                   NaN\n",
       "1552                                                   NaN\n",
       "1553     [nn.BatchNorm2d, momentum, 0.1, 1, 0, Batchnor...\n",
       "1554     [batch_size = 256\\r\\ntime_steps = 224\\r\\nclass...\n",
       "1555     [y_est, (batch_size, classes, time_steps), (ba...\n",
       "1556     [input = torch.randn(1,3,32,32)\\r\\n, input=inp...\n",
       "1557                                                   NaN\n",
       "1558     [ aa = [[1,2,3],\\r\\n          [4,5,6]].T\\r\\n a...\n",
       "1559     [plt.savefig, plt.save(f'label:{label}.png')\\r\\n]\n",
       "1560     [gather_nd(), test1 -&gt; [2, 3], test_ind_col...\n",
       "1561     [Import torch\\r\\na = torch.randn((3,3,2))\\r\\nb...\n",
       "1562     [b, a,  b.view(-1,2).T.flatten()\\r\\ntensor([1,...\n",
       "1563     [torch, In [70]: a=np.array([[1, 4], [2, 5],[3...\n",
       "1565                                                   NaN\n",
       "1566                                                   NaN\n",
       "1567     [utils, /Users/jan/.cache/torch/hub/ultralytic...\n",
       "1568                                   [import plapla\\r\\n]\n",
       "1569                                          [input_size]\n",
       "1571                                                   NaN\n",
       "1572                                                   NaN\n",
       "1573     [torch.arange, torch.meshgrid, torch.stack, de...\n",
       "1574     [CrossEntropyLoss(), NLLLoss(), CrossEntropyLo...\n",
       "1575     [y_train, y_test, LongTensor, FloatTensor, Dou...\n",
       "1576                                                   NaN\n",
       "1577     [summary(model, ((2, dim1),(2,dim2))\\r\\n\\r\\n, ...\n",
       "1578     [ data1[:,:1,:1] + data2[:,:1,:1]\\r\\ntensor([[...\n",
       "1579                                                   NaN\n",
       "1580                                                  [+1]\n",
       "1581                                                   NaN\n",
       "1584     [load_state_dict, state = torch.load('model1.p...\n",
       "1585                                                   NaN\n",
       "1586                                                   NaN\n",
       "1587     [rgb_image = cv2.imread(\"PATH_TO_RGB_IMAGE\",0)...\n",
       "1588     [closure, print, import sys\\r\\nimport torch.op...\n",
       "1590        [collate_fn, data.DataLoader, default_collate]\n",
       "1591     [def __getitem__(self, i):\\r\\n    return torch...\n",
       "1592     [state_dict, nn.Module, forward, forward, clas...\n",
       "1593     [model.eval(), torch.no_grad(), model.train(),...\n",
       "1594                                                   NaN\n",
       "1595     [jacobian, tuple, get_residual, print('Check J...\n",
       "1596     [numpy, argsort, pytorch, def vector_labels(la...\n",
       "1597     [verts /= verts.norm(p=2, dim=1, keepdim=True)...\n",
       "1599     [model = model.to(\"mps\"), import os\\r\\nos.envi...\n",
       "1600                                                   NaN\n",
       "1602     [MG = nx.MultiGraph()\\r\\nMG.add_weighted_edges...\n",
       "1603     [torch.Tensor.chunk, torch.cat, (1, 3, 128, 12...\n",
       "1604                                                   NaN\n",
       "1605     [tokenizer.decode, decoded = [tokenizer.decode...\n",
       "1606     [nn.Dropout, self.fc, p = 0.1 / 0.2 / 0.3, wei...\n",
       "1607     [for name, param in model.named_parameters():\\...\n",
       "1609                                                   NaN\n",
       "1610     [from math import floor, log2\\r\\n\\r\\n\\r\\ndef m...\n",
       "1612                                                   NaN\n",
       "1613     [torch.tanh(x), tanh, torch, x, class Model(to...\n",
       "1614                                                   NaN\n",
       "1615      [np.where, res = no.where(mask, img1, img2)\\r\\n]\n",
       "1616                                                   NaN\n",
       "1617                                                   NaN\n",
       "1618                                                   NaN\n",
       "1619     [torch.Tensor.cuda, img1 = img1.cuda()\\r\\nimg2...\n",
       "1620     [BertLayer, o = model(input_ids, output_hidden...\n",
       "1621     [torch.gather, y[b, t, f] = x[b, i[b, t], f]\\r...\n",
       "1622     [requires_grad, nn.Module, requires_grad_, nn....\n",
       "1623     [proof_conv, proof_conv = nn.ConvTranspose2d(I...\n",
       "1624     [ConvTranspose2D, stride, kernel_size, Conv2D,...\n",
       "1625                                                   NaN\n",
       "1626                                                   NaN\n",
       "1627     [nodes_a_embed, nodes_b_embeds, edge_embeds, n...\n",
       "1628     [encode_image, forward, forward,  model.forwar...\n",
       "1629     [kernel_size, 7, nn.Conv3d, (out_channels=n_fi...\n",
       "1630     [np.allclose, True,  np.allclose(y_torch, y_np...\n",
       "1631                                                   NaN\n",
       "1632                                                   NaN\n",
       "1633                                                   NaN\n",
       "1634                                                   NaN\n",
       "1635                                                   NaN\n",
       "1636     [onehot, (len(target), 8), dim=1, target, 1., ...\n",
       "1638     [__len__, class WeightedBucketSampler(Sampler[...\n",
       "1639                                                   NaN\n",
       "1641                                                   NaN\n",
       "1642     [torch.gather, input, index, input, torch.gath...\n",
       "1643     [class LayerRepeater(torch.nn.Module)\\r\\n   de...\n",
       "1644                                                   NaN\n",
       "1645                                                   NaN\n",
       "1646                                  [cv2.waitKey(0)\\r\\n]\n",
       "1647                                                   NaN\n",
       "1649                                                   NaN\n",
       "1650     [torch, outer, - np.subtract.outer(c.numpy(), ...\n",
       "1651                                                   NaN\n",
       "1652                                                   NaN\n",
       "1653     [fake = generator(noise)\\r\\ndisc_real = disc(r...\n",
       "1654                                                   NaN\n",
       "1656                                                   NaN\n",
       "1657     [new_volumes = [volume[0,...] for volume in vo...\n",
       "1658     [dim=-1, dim=2,  vnew = [v[2:] for v in volume...\n",
       "1659                                                   NaN\n",
       "1660                                                   NaN\n",
       "1663     [torch.utils.data.Dataset, __len__(), __getite...\n",
       "1664     [net.state_dict(), collections.OrderedDict, st...\n",
       "1665     [def zero_injection(initial_weights, trained_w...\n",
       "1666     [z * (1 - z), z, logistic(z), import numpy as ...\n",
       "1668                                                   NaN\n",
       "1669     [nn.Conv2d, [B, C_in, H, W], B, C_in, H, W, [B...\n",
       "1670     [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "1671     [nn_model = Word2VecNegativeSamples(data.num_t...\n",
       "1672                                                   NaN\n",
       "1674     [super().__init__, __init__, NeuralNet, __len_...\n",
       "1675     [import matplotlib.pyplot as plt\\r\\nfrom mpl_t...\n",
       "1676     [import matplotlib.pyplot as plt\\r\\n\\r\\nfig, a...\n",
       "1677     [input_shape, tf.keras.layers.Input, fit, eval...\n",
       "1678                                                   NaN\n",
       "1679     [recs,  recs[edge_index[0], edge_index[1]] = 0...\n",
       "1681     [n, itertools.tee, def pairwise(iterable):\\r\\n...\n",
       "1682         [torch.cdist,  dists = torch.cdist(A, B)\\r\\n]\n",
       "1683     [output_size, input_size, Generator, (batch_si...\n",
       "1684     [MaskableActorCriticPolicy, MlpExtractor, poli...\n",
       "1685     [64, some_integer_number * 64 + 47, batch_size...\n",
       "1686     [nn.Flatten, (64, 128, 3, 3), (64, 1152), 1152...\n",
       "1687                                                   NaN\n",
       "1688     [w-= learning_rate * w.grad\\r\\n, w = w - learn...\n",
       "1689     [python, pytorch, python, A -= B, A = A - B, p...\n",
       "1690     [e1, 16, 16, e2, 128, out_channels, e1, in_cha...\n",
       "1691     [P[i, j, Q[i, j]] = 0\\r\\n, torch.Tensor.scatte...\n",
       "1692                                                   NaN\n",
       "1693     [nn.ModuleList, Patch, Model, nn.Module, class...\n",
       "1695                                [torch.Tensor.grad_fn]\n",
       "1696                                                   NaN\n",
       "1697                                                   NaN\n",
       "1698     [1x28x28, 3x336x336, tensor transform, 3x28x28...\n",
       "1699                                        [torch, torch]\n",
       "1700                                              [labels]\n",
       "1701                              [0.001, [0, 1], [-1, 1]]\n",
       "1702     [from tensorflow.keras.applications import res...\n",
       "1703     [TFBlenderbotForConditionalGeneration, Tensorf...\n",
       "1704     [pytorch_pretrained_bert_inset, from torch imp...\n",
       "1705                                                   NaN\n",
       "1706     [idx=0; export CUDA_VISIBLE_DEVICES=$idx; pyth...\n",
       "1707                                                   NaN\n",
       "1708                                                   NaN\n",
       "1710     [128x3x128x128 (batch_size x channels x image_...\n",
       "1711                         [img = img.to(torch.float32)]\n",
       "1712                                                   NaN\n",
       "1714                                                   NaN\n",
       "1715                                                   NaN\n",
       "1716     [torch multiprocessing, from torch.multiproces...\n",
       "1717     [meters = meters + np.array([kl_div, loss.item...\n",
       "1718     [0,3, 1,2, block = [] #create blocks\\r\\nfor x ...\n",
       "1719                                                   NaN\n",
       "1720     [dataloader, torch tensor, import torch\\r\\nimp...\n",
       "1721                                                   NaN\n",
       "1722     [import torch\\r\\n\\r\\nn = 3\\r\\na = torch.Tensor...\n",
       "1723     [torch.arange(), import torch\\r\\n\\r\\na = torch...\n",
       "1724     [b = []\\r\\nfor i in range(n-1):\\r\\n    b.appen...\n",
       "1725     [data.Dataset, __init__, __getitem__, __len__,...\n",
       "1726     [x = torch.rand(1, 4).unsqueeze(-1)\\r\\n, x = t...\n",
       "1728     [,, import torch\\r\\nimport torch.nn as nn\\r\\ni...\n",
       "1729     [torch.Tensor.clone, input, detach(),  a = tor...\n",
       "1730     [nn.BCELoss, lossFn(outputs, outputs.detach())...\n",
       "1731                                                   NaN\n",
       "1732                                                   NaN\n",
       "1733     [ x = torch.tensor([[10, 11, 12],\\r\\n         ...\n",
       "1734     [transforms.Lambda, transform = transforms.Com...\n",
       "1735     [nn.ParameterList, nn.Parameter, nn.ParameterL...\n",
       "1736                                                   NaN\n",
       "1737     [torch.mean, torch.var, torch.cov, def CCCLoss...\n",
       "1738     [torch.chunk, torch.cat, torch.stack,  chunks ...\n",
       "1739     [custom_loss, def custom_loss(y_pred, y_true):...\n",
       "1740     [import pandas\\r\\nfrom sklearn.preprocessing i...\n",
       "1741     [bbox, x1, y1, x2, y2 = dataset_row[\"bbox\"]\\r\\...\n",
       "1742                                                   NaN\n",
       "1743                                                   NaN\n",
       "1744                                                   NaN\n",
       "1745     [n, torch.repeat_interleave, def split(x, y, k...\n",
       "1746     [coord, dense_volume1, coord, dv, dense_volume...\n",
       "1748     [correct_predictions += torch.sum(preds == tar...\n",
       "1749                                                   NaN\n",
       "1750     [Network.forward(x), self, x, f = Network()\\r\\...\n",
       "1751                                                   NaN\n",
       "1752     [online augmentations, offline augmentations, ...\n",
       "1755                                                   NaN\n",
       "1756                                                   NaN\n",
       "1757                                                   NaN\n",
       "1758                                                   NaN\n",
       "1759     [torch.nn, torch.cat, tf.keras.layers.concaten...\n",
       "1761                                                   NaN\n",
       "1763     [(1,) * (len(x_shape) - 1))\\r\\n, len(x_shape) ...\n",
       "1764     [a, b, dim=1, out[i,j] = a[i, b[i,j]]\\r\\n, [[ ...\n",
       "1765     [model=GraphLevelGNN.load_from_checkpoint(trai...\n",
       "1767     [disable_layers = []\\r\\nfor quantized_layer, _...\n",
       "1769     [torch.nn.functional.kl_div, torch.distributio...\n",
       "1770     [tdist.Normal(...), x = a.sample()\\r\\ny = b.sa...\n",
       "1771     [nn.Linear, class MaskedLinear(nn.Linear):\\r\\n...\n",
       "1773     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "1774     [Conv2d(2,32,kernel_size=3,padding=1)   # 32x1...\n",
       "1775     [def _resnet(arch, block, layers, pretrained, ...\n",
       "1776     [def _resnet(arch, block, layers, pretrained, ...\n",
       "1777     [outputs, hx, cx  = net(inputs, hx.detach(), c...\n",
       "1779         [model, model_ft, outputs = model_ft(inputs)]\n",
       "1780     [__init__, forward, class UNetlike(nn.Module):...\n",
       "1781                                                   NaN\n",
       "1783     [Regnet, here, forward, def forward(self, x: T...\n",
       "1784     [torch.where, torch.isin,  torch.where(torch.i...\n",
       "1785     [eval, no_grad, nn.Module.eval, torch.no_grad,...\n",
       "1786     [T.ToTensor, T.Compose,  transform = T.Compose...\n",
       "1787                                                   NaN\n",
       "1788                                                   NaN\n",
       "1789                                                   NaN\n",
       "1791     [Dataset, DataLoader, import torch\\r\\n\\r\\nclas...\n",
       "1792                                                   NaN\n",
       "1793     [torch.nn.CrossEntropyLoss,  ce_loss = nn.Cros...\n",
       "1794     [preprocess = transforms.Compose([\\r\\n    tran...\n",
       "1795     [torch.nn.Sequential(), append, add_module, fo...\n",
       "1796     [torch.einsum, :, mat_B[x,y,z], (H,), mat_A[z,...\n",
       "1797     [torch.Tensor.size, torch.Tensor.shape, img_lq...\n",
       "1798     [running_corrects += torch.sum(preds == labels...\n",
       "1799     [y_loss[phase].append(epoch_loss.item())\\r\\ny_...\n",
       "1800                                                   NaN\n",
       "1801     [ x = torch.tensor([0,0,0,1,0,0,0,0,1,0,0])\\r\\...\n",
       "1803                                                   NaN\n",
       "1804     [png, jpeg, jpeg, png, tensor_img = torch.wher...\n",
       "1805                                                   NaN\n",
       "1806     [DDP_BACKEND_CHOICES = ChoiceEnum(\\r\\n    [\\r\\...\n",
       "1808     [import torch\\r\\nimport random\\r\\nimport torch...\n",
       "1809     [jacrev(fnet_single, argnums=0)(params, x, y),...\n",
       "1810     [ d = {}; torch.tensor([d.setdefault(tuple(i.t...\n",
       "1811     [unique,  x = np.array([[1,2],[4,3],[1,4],[1,4...\n",
       "1812     [torchvision.transforms.functional.to_tensor, ...\n",
       "1813     [data.DataLoader, collate_fn, default_collate,...\n",
       "1814                                                   NaN\n",
       "1815     [requires_grad=False, nn.Module, requires_grad...\n",
       "1816     [ slices = arr.diff().abs().nonzero().flatten(...\n",
       "1817     [def train_and_evaluate(param, model, trail):\\...\n",
       "1818     [def get_best_parameters(args, Dtr, Val):\\r\\n ...\n",
       "1819                                                   NaN\n",
       "1820                                                   NaN\n",
       "1821     [import tensorflow as tf\\r\\n\\r\\nt = tf.constan...\n",
       "1822                                                   NaN\n",
       "1823                                                   NaN\n",
       "1824                                                   NaN\n",
       "1825     [e = shap.DeepExplainer(\\r\\n        model.to(t...\n",
       "1826     [torch.Tensor.cuda, W_ch1, nn.Parameter -&gt; ...\n",
       "1827     [class CosineLoss(nn.Module):\\r\\n    def __ini...\n",
       "1828     [sklearn, 0.2, n_splits, fnames = np.array([\\r...\n",
       "1829     [a, w,  z = a[...,None]-w[None,None]\\r\\ntensor...\n",
       "1830                                                   NaN\n",
       "1831                   [num_train_epochs, trainer.train()]\n",
       "1832                                                   NaN\n",
       "1833                                                   NaN\n",
       "1835     [return [torch.stack(src_list), torch.stack(ta...\n",
       "1836     [out, out, (ht, ct) = self.lstm_nets(X)\\r\\n, o...\n",
       "1837     [A = tensor([[ 0], [ 2], [ 3], [ 4], [ 5], [ 7...\n",
       "1838                                                   NaN\n",
       "1839     [trainer, trainer = Trainer(\\r\\n    model=mode...\n",
       "1840                                                   NaN\n",
       "1841     [def my_custom_loss(preds, label):\\r\\n    half...\n",
       "1842     [model.myRelu.parameters(), x, class Net(nn.Se...\n",
       "1843                                                   NaN\n",
       "1844                                                   NaN\n",
       "1845                                                   NaN\n",
       "1846     [js(), union, intersection = union[counts &gt;...\n",
       "1847     [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndef...\n",
       "1848     [jaccard_similarity, (45_000, 110, 12), numba,...\n",
       "1849     [FasterRCNN, GeneralizedRCNN, feature,  images...\n",
       "1851     [File \"/usr/local/lib/python3.7/dist-packages/...\n",
       "1852                         [f1, f2, g, I_NCE, g, f1, f2]\n",
       "1853                                       [torch.no_grad]\n",
       "1854     [tim = np.array([[[1, 2, 3],\\r\\n              ...\n",
       "1855     [val = torch.tensor([[1,233],\\r\\n             ...\n",
       "1857                                                   NaN\n",
       "1858     [torch.gather,  val.gather(dim=1, index=ind)\\r...\n",
       "1859     [len(x) / len(y), x, @cuda.jit\\r\\ndef array_fu...\n",
       "1860                                       [torch-scatter]\n",
       "1861                                                   NaN\n",
       "1863                                                   NaN\n",
       "1864                                                   NaN\n",
       "1866     [import torch.nn.functional as nnf\\r\\n\\r\\ndef ...\n",
       "1867                                                   NaN\n",
       "1868                                                   NaN\n",
       "1869     [Desktop/rajesh/pytorch_env/env/lib/python3.8/...\n",
       "1870     [opt.zero_grad()\\r\\nloss.backward()\\r\\nopt.ste...\n",
       "1872     [torch.utils.data.WeightedRandomSampler, # Not...\n",
       "1873                                                   NaN\n",
       "1875                                                   NaN\n",
       "1876     [torchvision.transforms.functional.resize(img,...\n",
       "1877                                                   NaN\n",
       "1878                [-u, python -u my_code.py, flush=True]\n",
       "1879     [la1 = torch.tensor([1,2,3,4,5])\\r\\nla2 = torc...\n",
       "1880     [x_data, torch.utils.data.DataLoader, shuffle=...\n",
       "1881     [validation_split = .2\\r\\nshuffle_dataset = Tr...\n",
       "1882                                                   NaN\n",
       "1883     [torch.argmax, keepdim, True,  x.argmax(0, kee...\n",
       "1884     [RandomResizedCropAndInterpolation, PIL.Image,...\n",
       "1885     [RandomResizedCropAndInterpolation, PIL.Image,...\n",
       "1886     [class Dataset(data.Dataset):\\r\\n    def __ini...\n",
       "1887     [tf.nn.weighted_cross_entropy_with_logits, y_p...\n",
       "1888     [BCEWithLogitsLoss, ignore_index, softmax, sig...\n",
       "1890     [nn.Conv2d, model = nn.Sequential(nn.Conv2d(1,...\n",
       "1891                                                   NaN\n",
       "1892     [tf.nn.softmax, import tensorflow as tf\\r\\nimp...\n",
       "1893                   [view(-1),  y_pred.view(-1, 2)\\r\\n]\n",
       "1894     [eval, timm.create_model(...scriptable=True, e...\n",
       "1895     [index, __getitem__, (batch_size, seq_len, cha...\n",
       "1896                                                   NaN\n",
       "1897                                                   NaN\n",
       "1899     [ import torch\\r\\n\\r\\n if __name__ == '__main_...\n",
       "1900                                                   NaN\n",
       "1901                                                   NaN\n",
       "1902     [    def train_model(model, criterion, optimiz...\n",
       "1903                                                   NaN\n",
       "1904                                                   NaN\n",
       "1905                                                   NaN\n",
       "1906     [disc_gen, backward(), gen_image = gen(low_res...\n",
       "1907                                     [num_classes = 1]\n",
       "1908                                                   NaN\n",
       "1909     [loss.backward(), retain_graph=True, torch.rel...\n",
       "1910                                                   NaN\n",
       "1911                                                   NaN\n",
       "1912                                                   NaN\n",
       "1913     [.to(device), device = torch.device(\"cuda\" if ...\n",
       "1914                                         [.to(device)]\n",
       "1916                                                   NaN\n",
       "1917     [torch.nn.functional.interpolate, class Net(nn...\n",
       "1918                          [shape, 256, new_model, 494]\n",
       "1919     [nn.AdaptiveAvgPool1d(output_size), nn.AvgPool1d]\n",
       "1920     [MaskedLMOutput, loss, logits, hidden_states, ...\n",
       "1921                                                   NaN\n",
       "1922                                                   NaN\n",
       "1923                                                   NaN\n",
       "1924     [pytorch, tensorflow, torch==1.11.0+cpu, tenso...\n",
       "1926     [x, model.parameter(), nn.Parameter(torch.as_t...\n",
       "1927     [conv1, 224x224, class Net(nn.Module):\\r\\n    ...\n",
       "1928                                                   NaN\n",
       "1929     [loss(P, Z) := - SUM_k [ || Z_k - [ SUM_n P_nk...\n",
       "1930     [resnet = InceptionResnetV1(\\r\\n    classify=T...\n",
       "1931                                                   NaN\n",
       "1932     [ohe = pd.get_dummies(data[\"SpType\"], drop_fir...\n",
       "1933     [feature_map, temp, class ConvolutionEncoder(n...\n",
       "1934                                                   NaN\n",
       "1935     [nn.functional.binary_cross_entropy, BCE = F.b...\n",
       "1936                                                   NaN\n",
       "1937                                                   NaN\n",
       "1938     [param_groups, for g in optimizer.param_groups...\n",
       "1939                                                   NaN\n",
       "1940                                                   NaN\n",
       "1941                                                   NaN\n",
       "1942     [feature_dictionary, collate_fn, DataLoader, c...\n",
       "1943     [model = torch.hub.load('ultralytics/yolov5', ...\n",
       "1944                                                   NaN\n",
       "1945     [a.to(\"cpu\"), a.is_cuda(), False, model.to(\"cp...\n",
       "1946     [new_df, predictors, print(new_df[list(predict...\n",
       "1947     [numpy.random.normal, import numpy.random as n...\n",
       "1948                                                   NaN\n",
       "1949     [dataset = [[x for x in range(30)] for j in ra...\n",
       "1950                                                   NaN\n",
       "1951                                                   NaN\n",
       "1952                                                   NaN\n",
       "1953     [torch.Tensor, torch, grad_fn,  x1 = torch.ran...\n",
       "1954                                                   NaN\n",
       "1955                                                   NaN\n",
       "1956     [Data, data_list = []\\r\\nfor i in range(2):\\r\\...\n",
       "1957                                                   NaN\n",
       "1958                                                   NaN\n",
       "1959     [for x,i in enumerate(trainloader):\\r\\n, DataL...\n",
       "1961     [nn.Embedding(), nn.CTCLoss(), nn.Embedding(),...\n",
       "1962                                                   NaN\n",
       "1963     [forward, def forward(self, x):\\r\\n    #conv1 ...\n",
       "1964     [torch.nn.RNN, (output, h_n), activation, outp...\n",
       "1965                            [Outputs: output, h_n\\r\\n]\n",
       "1966     [A\\r\\ntensor([[[1., 2., 3.],\\r\\n         [4., ...\n",
       "1968                            [torch.cuda.empty_cache()]\n",
       "1969                                      [writer.close()]\n",
       "1970     [self(x), y, w'*x, w, w', x, w, loss = -torch....\n",
       "1972     [print([var for var in concrete_fun.trainable_...\n",
       "1973     [.get_layer(), conv1_layer = model.get_layer(\"...\n",
       "1974                                                   NaN\n",
       "1976                                                   NaN\n",
       "1977     [train_generator, DataLoader, torch.from_numpy...\n",
       "1978     [nn.Conv1d, (B, C, L), L=5, C=1, TsDs, __getit...\n",
       "1979                                                   NaN\n",
       "1980                                                   NaN\n",
       "1981     [class_names = ['shape', 'pose', 'texture', 'c...\n",
       "1982     [nn.Linear, nn.Linear(28*28, 512), (28*28)*512...\n",
       "1983     [from torchsummary import summary\\r\\n\\r\\nnet =...\n",
       "1984                                                   NaN\n",
       "1985     [    # get the number of input features \\r\\n  ...\n",
       "1986     [torch.cdist, (B, P, M), (B, R, M), (B, P, R),...\n",
       "1987                                                   NaN\n",
       "1988     [input_data=..., x_train.shape, min(x_train.sh...\n",
       "1989     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "1990     [model.summary, torchsummary, import torch\\r\\n...\n",
       "1991     [    #include &lt;torch/torch.h&gt;\\r\\n    voi...\n",
       "1992      [def __init__, def _init_, neuralnetwork, model]\n",
       "1993                                                   NaN\n",
       "1994     [torch.Tensor.view, how_many_unsqueeze = 3\\r\\n...\n",
       "1995     [a = torch.zeros((4,5,1,1,1))\\r\\n, b = a[:, :,...\n",
       "1997     [torch.cdist(x_all, x_all, p =2)\\r\\n, dist2 = ...\n",
       "1998     [torchvision.datasets.ImageFolder, x = x.permu...\n",
       "1999                                                   NaN\n",
       "2000     [Sigmoid + BCE, torch, F.sigmoid(d0)..., d0......\n",
       "2001               [nvidia -smi, torch.cuda.set_device(1)]\n",
       "2002     [GradScaler(), autocast(), GradScaler(), autoc...\n",
       "2003                                                   NaN\n",
       "2004     [dropout = torch.randint(2, (10,))\\r\\nweights ...\n",
       "2005     [conda, libtorch, project(example-app)\\r\\n\\r\\n...\n",
       "2006     [name: pytorch_latest\\r\\nchannels:\\r\\n  - pyto...\n",
       "2009     [padding=zeros, paddin=zeros, from torch.nn im...\n",
       "2010     [native_functions.yaml, im2col, im2col_cpu, im...\n",
       "2011                                                   NaN\n",
       "2012     [\\n, &lt;br/&gt;,  , &amp;nbsp;, import torch\\...\n",
       "2014         [nn.LSTM(... dropout=0.3), num_layers &gt; 1]\n",
       "2015     [.numpy(), .detach(), forward, print( myTensor...\n",
       "2016                                                   NaN\n",
       "2017                                                   NaN\n",
       "2018                                    [batch_first=True]\n",
       "2019                                                   NaN\n",
       "2020                                                   NaN\n",
       "2021     [from fairseq.models.transformer import Transf...\n",
       "2022                                                   NaN\n",
       "2023                                                   NaN\n",
       "2024     [import torch\\r\\n\\r\\narray = torch.zeros((10, ...\n",
       "2025                                                   NaN\n",
       "2026                                                   NaN\n",
       "2027     [datasets.ImageFolder, @, __getitem__, __getit...\n",
       "2028     [l(xi,yi) = lambda * loss(i) if (xi&gt;0.5==yi...\n",
       "2029     [your_loader.dataset.samples[i], for i, (image...\n",
       "2030                                                   NaN\n",
       "2031                                                   NaN\n",
       "2032     [# first install gcsfuse\\r\\n%%capture\\r\\n!echo...\n",
       "2033     [sys.path, import os, sys\\r\\nfrom google.colab...\n",
       "2034     [def install_library_to_drive(libraries_list):...\n",
       "2035                                                   NaN\n",
       "2036                                                   NaN\n",
       "2037                                                   NaN\n",
       "2038     [class Network(nn.Module), Network, nn.Module,...\n",
       "2039                                                   NaN\n",
       "2040                 [requires_grad, with torch.no_grad()]\n",
       "2042     [self.WeightedTrainer, class MCC(object):\\r\\n ...\n",
       "2043     [Categorical, probs, logits, logits, probs, lo...\n",
       "2044                                                   NaN\n",
       "2045     [0.866 in loss, # !pip install pytorch_lightni...\n",
       "2046                          [shuffle=True, shuffle=True]\n",
       "2047                                                   NaN\n",
       "2048                                                   NaN\n",
       "2049                                                   NaN\n",
       "2050     [# Create the same dataset with untransformed ...\n",
       "2051                                    [model.eval()\\r\\n]\n",
       "2052     [input1 = [\\r\\n    [[1, 1, 1], [2, 2, 2], [3, ...\n",
       "2053     [Softmax, nn.CrossEntropyLoss(), softmax, soft...\n",
       "2054                                                   NaN\n",
       "2055                                                   NaN\n",
       "2056     [cudatoolkit, nvidia, pytorch, cudatoolkit, py...\n",
       "2057     [pytorch::cudatoolkit, name: torch\\r\\nchannels...\n",
       "2058                                                   NaN\n",
       "2059                                                   NaN\n",
       "2061     [import numpy as np\\r\\n\\r\\nmy_val = 15\\r\\nbloc...\n",
       "2062                                                   NaN\n",
       "2063     [serialised_total = 0.1 + 0.1 + 0.1 + 0.1 + 0....\n",
       "2064                                                   NaN\n",
       "2065     [class create_emb_layer( tf.keras.layers.Embed...\n",
       "2068     [backward, torch.Tensor, grad, backward, grad,...\n",
       "2069     [optimizer = optim.Adam(model.parameters())\\r\\...\n",
       "2070                                        [shuffle=True]\n",
       "2071                                                   NaN\n",
       "2072     [model, name (key), feature_layer, for name, p...\n",
       "2073     [for param in mtcnn.parameters():\\r\\n    param...\n",
       "2074     [import tensorflow as tf\\r\\ngpu = tf.config.ex...\n",
       "2075     [import torch\\r\\n\\r\\nA = torch.tensor([0.0316,...\n",
       "2076     [probs = torch.tensor([0.0316, 0.2338, 0.2338,...\n",
       "2077     [A = A*10000\\r\\ntemp = [[i]*A[i] for i in rang...\n",
       "2079                                                   NaN\n",
       "2080                                                   NaN\n",
       "2081     [torch.cat, all_img = []\\r\\nfor object_id in o...\n",
       "2083                                                   NaN\n",
       "2084     [x, y, transpose, reshape,  torch.stack((x,y),...\n",
       "2085                                                   NaN\n",
       "2087     [__init__(), __len__(), __get_item__(), read_h...\n",
       "2088     [hm, (b, k, h, w), fm, (b, c, h, w), einsum,  ...\n",
       "2089     [rand_test, i=0, 3, 0, i=1, 4, 3, i=2, 3, 1, r...\n",
       "2090                                                   NaN\n",
       "2091                                                   NaN\n",
       "2092     [net.parameters, OrderedDict, net.parameters()...\n",
       "2093                                                   NaN\n",
       "2094                                                   NaN\n",
       "2096     [dataset = WineDataset(transform=None)\\r\\ndata...\n",
       "2097                                                   NaN\n",
       "2098     [import torch\\r\\nfrom transformers import Robe...\n",
       "2099                                                   NaN\n",
       "2100                                                   NaN\n",
       "2102         [optimizer.step, optimizer.step(closure)\\r\\n]\n",
       "2103     [loss.backward()\\r\\nnn.utils.clip_grad_norm_(m...\n",
       "2104     [pip list, torch                              ...\n",
       "2105     [VOC_CLASSES = (\\r\\n    \"normal\",\\r\\n    \"mp\",...\n",
       "2106                                                   NaN\n",
       "2107     [.cpu(), .item(), dict = {\\r\\n\\r\\n'train_acc':...\n",
       "2108                                                   NaN\n",
       "2109                                                   NaN\n",
       "2110                                                   NaN\n",
       "2111                                                   NaN\n",
       "2112     [torch.min(), torch.max(), [N, M], M, N, N, to...\n",
       "2113                                                   NaN\n",
       "2114                                                   NaN\n",
       "2115     [self(x), training_step, __call__, forward(), ...\n",
       "2116     [def forward(self, x):\\r\\n    self.feature_ext...\n",
       "2117     [forward(), training_step, training_step, forw...\n",
       "2118                                                   NaN\n",
       "2119                                          [alpha, rho]\n",
       "2120                                                   NaN\n",
       "2121                                                   NaN\n",
       "2122                                     [.to(device)\\r\\n]\n",
       "2123                        [torch.cuda.empty_cache()\\r\\n]\n",
       "2124                                                   NaN\n",
       "2125     [delete, mask= np.ones(t.shape, dtype=bool)\\r\\...\n",
       "2126                                                   NaN\n",
       "2127                                                   NaN\n",
       "2128                                                   NaN\n",
       "2129     [In [1]: import torch\\r\\n  \\r\\nIn [2]: a = tor...\n",
       "2130                              [pip uninstall torch -y]\n",
       "2131     [tensorflow, pytorch, envvars, import tensorfl...\n",
       "2132     [edge_index[:, [i for i in range(edge_index.sh...\n",
       "2133                                                   NaN\n",
       "2134     [X[:, indices] = output # for column replaceme...\n",
       "2135                                    [model.to(device)]\n",
       "2136     [torch.nn.MSELoss, MSELoss, MSELoss, preds, [6...\n",
       "2137                                                   NaN\n",
       "2138     [torch.nn.Linear, import numpy as np\\r\\nimport...\n",
       "2139     [import torch\\r\\nx = torch.arange(2*4).view(2,...\n",
       "2140     [class first:\\r\\n    # this class gives y1 in ...\n",
       "2141     [device = torch.device('cuda')\\r\\n, device = t...\n",
       "2143     [backward(), torch.optim.Optimizer.zero_grad()...\n",
       "2144     [from torchvision.models.feature_extraction im...\n",
       "2145     [conda, pip, torchvision, 0.82, torchvision, pip]\n",
       "2146                                                   NaN\n",
       "2147     [if torch.backends.mps.is_available():\\r\\n    ...\n",
       "2148     [import platform\\r\\nprint(platform.platform())...\n",
       "2149                                                   NaN\n",
       "2150                                                   NaN\n",
       "2151     [tokenizer(example['question'], example['conte...\n",
       "2152                                                   NaN\n",
       "2153                                                [8, 1]\n",
       "2154     [def __init__(self, filename):\\r\\n\\r\\n    #Sto...\n",
       "2155                                                   NaN\n",
       "2156                                                   NaN\n",
       "2158     [resnet18, torch.nn.BatchNorm2d, train, eval, ...\n",
       "2159     [nn.ReLU(), feedforward(), class Block(nn.Modu...\n",
       "2160                                                   NaN\n",
       "2161                                                   NaN\n",
       "2162     [pred, argmax(1), y, argmax, correct += (pred....\n",
       "2163     [ResNet, conv1, stage0, conv1, stage1, layer1,...\n",
       "2164                   [nn.LSTM, images, BxCxHxW, nn.LSTM]\n",
       "2165                                                   NaN\n",
       "2167     [feature_extracture, children, layers = list(b...\n",
       "2168                                                   NaN\n",
       "2169     [torch.Tensor.item, losses.append(loss)\\r\\n, l...\n",
       "2170     [def zero_padding(input_tensor, pad_size: int ...\n",
       "2171                                                   NaN\n",
       "2172                                                   NaN\n",
       "2173     [a = torch.ones((4, 4)).long()\\r\\na = a.reshap...\n",
       "2174     [torch.einsum,  torch.einsum('ijk,ilkm-&gt;ljm...\n",
       "2175     [image_tensor, 50176, 224x224, 32x3x224x224, i...\n",
       "2176                                                   NaN\n",
       "2177                                                   NaN\n",
       "2179                                                   NaN\n",
       "2180                                                   NaN\n",
       "2181     [act = activation if j &lt; len(sizes)-1 else ...\n",
       "2182     [f\"Fake_image-{epoch}-{batch-idx}.png\", epoch,...\n",
       "2183     [del, del, del, torch.nn.Module, del, torch.nn...\n",
       "2184     [nn.functional.one_hot,  C = int(x.max()) + 1\\...\n",
       "2185     [torch, numpy, O(size^dims), O(dims! * size^di...\n",
       "2186     [torchaudio.save('test_1.mp3',\\r\\n            ...\n",
       "2187     [torch.reshape, torch.transpose,  result.resha...\n",
       "2188     [self.calculate_z, self.calculate_z, z_predict...\n",
       "2189                                                   NaN\n",
       "2190     [Seq, Seq, \"\", class myClass:\\r\\n\\r\\n    def _...\n",
       "2191     [change, transforms, partial, functools, from ...\n",
       "2192                                                   NaN\n",
       "2193     [#compute the nearest neighbor of win_pos amon...\n",
       "2194     [cpu, device=\"cpu\", summary(), torchinfo.summa...\n",
       "2195     [CarDataset(), num_workers=0, next(iter(train_...\n",
       "2196     [mydata_1.npz, mydata_100.npz, class Myclass:\\...\n",
       "2197     [class MyClass:\\r\\n    def __init_subclass__(c...\n",
       "2198     [class MaskedHuberLoss(torch.autograd.Function...\n",
       "2199                                                   NaN\n",
       "2200     [argmax, period, sentences_list = []\\r\\nr = to...\n",
       "2201                                                   NaN\n",
       "2202     [dict, keys, my_best_model = torch.load('model...\n",
       "2203     [activation = {}\\r\\ndef get_activation(name):\\...\n",
       "2204     [output, output, prediction, DEFAULT_MODEL_PAT...\n",
       "2205             [whl, pip install file.whl\\r\\n, file.whl]\n",
       "2206     [collate_fn, DataLoader, DataLoader, def my_co...\n",
       "2207     [y.retain_grad(), x = Variable(torch.Tensor([2...\n",
       "2212                                                   NaN\n",
       "2213                                                   NaN\n",
       "2214                                                   NaN\n",
       "2215                                                   NaN\n",
       "2216     [torchvision.models.resnet152, track_running_s...\n",
       "2219                                                   NaN\n",
       "2220                                                   NaN\n",
       "2221                           [trainer.state.log_history]\n",
       "2222       [from your.package.here import GaitDataset\\r\\n]\n",
       "2223     [with Pool(max_pool) as p:\\r\\n    pool_outputs...\n",
       "2224     [torch.tensor(temp_val), temp_val, torch.from_...\n",
       "2227                                              [weight]\n",
       "2229                                                   NaN\n",
       "2230                                                   NaN\n",
       "2231     [## dump previous environment\\r\\nconda env exp...\n",
       "2233     [inputs = torch.Tensor(np.array([input1, input...\n",
       "2234                                                   NaN\n",
       "2235     [dx, d cq(x), d cq(x) = q(x) dx, cq(x), q(x), ...\n",
       "2237                                                   NaN\n",
       "2238                                        [conv1, conv2]\n",
       "2239                                                   NaN\n",
       "2240     [pytorch, torch, pytorch, $ mamba search numpy...\n",
       "2242     [nn.MaxPool2d(2, 2), # output: 512 x 2 x 2\\r\\n...\n",
       "2243                                                   NaN\n",
       "2244     [labels,  loss = (outputs-labels).pow(2).mean(...\n",
       "2245     [labels = torch.tensor([0,1,1,0], dtype = torc...\n",
       "2246     [(N, Cin, Hin, Win), N, Cin, Hin, Win, width, ...\n",
       "2247                                                   NaN\n",
       "2248     [torchinfo, from torchinfo import summary\\r\\n\\...\n",
       "2249                                                   NaN\n",
       "2250                               [optimizer.zero_grad()]\n",
       "2251     [x, torch.stack, torch.vstack,  p = torch.vsta...\n",
       "2252                                                   NaN\n",
       "2253     [requires_grad, requires_grad, conv1.weight.da...\n",
       "2254     [to = TabularPandas(df,\\r\\n                   ...\n",
       "2256                       [dataframe.iterrows(), row[5:]]\n",
       "2258     [output, train_step, output, return {\"loss\": l...\n",
       "2259                                                   NaN\n",
       "2261                                                   NaN\n",
       "2262                                                   NaN\n",
       "2263     [next(iter(dataloader))\\r\\n, next(), for image...\n",
       "2264     [iter(), gen = iter(dataloader)\\r\\nfor i in ra...\n",
       "2265                                                   NaN\n",
       "2266     [torch.nn.functional.normalize, [0, 1], import...\n",
       "2267     [import numpy as np\\r\\nimport jax\\r\\nimport ja...\n",
       "2268     [In [4]: N, C, H, W = 11, 5, 128, 128\\r\\n   .....\n",
       "2269     [out, numba, out, numpy, import numpy as np\\r\\...\n",
       "2270     [N, numpy.kron, a = np.arange(1, 19).reshape((...\n",
       "2272     [dataset = torchvision.datasets.CIFAR10(\"./dat...\n",
       "2273                                                   NaN\n",
       "2274                                                   NaN\n",
       "2275                                                   NaN\n",
       "2276                                                   NaN\n",
       "2277     [import torch\\r\\nimport torch.nn as nn\\r\\n# Ex...\n",
       "2278                                                   NaN\n",
       "2279     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "2280     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "2281     [pip install torchvision==0.10.1\\r\\npip instal...\n",
       "2282     [/opt/homebrew/lib/python3.9/site-packages/tor...\n",
       "2283     [[0,255], data,  train_transform = T.Compose([...\n",
       "2284       [images = images.view(-1, 32, 3*32).cuda()\\r\\n]\n",
       "2285     [M = 4\\r\\nN = 16\\r\\nMINIMUM = 1\\r\\nassert N % ...\n",
       "2286     [torch.sort(), source_len_sorted ,idx = torch....\n",
       "2287     [dim, a = torch.randn(512, 28, 2)\\r\\nb = torch...\n",
       "2289     [A, B, (1, 867, 768), (621, 1, 768),  diff = A...\n",
       "2291     [if, forward, grad_fn, grad_fn, num_pos, 0, ne...\n",
       "2292                        [forward, backward(), if-else]\n",
       "2293                                                   NaN\n",
       "2294                                                   NaN\n",
       "2296     [CUDACXX=/usr/local/cuda-11.7/bin/nvcc cmake -...\n",
       "2297                                                   NaN\n",
       "2298                                                   NaN\n",
       "2299                                                   NaN\n",
       "2300     [def validation_epoch_end(self, val_step_outpu...\n",
       "2301     [model = MyNet(input_dim), forward, # init pas...\n",
       "2302     [torchvision.transforms.Normalize, output[chan...\n",
       "2303     [res_vframes = []\\r\\nfor i in range(len(v_fram...\n",
       "2304     [loss = nn.MSELoss()\\r\\ninput = torch.zeros(64...\n",
       "2305                                                   NaN\n",
       "2306     [.yaml, train: ../OID/dataset/images/train  # ...\n",
       "2307     [weights, weights, grad,  weights.grad =  torc...\n",
       "2308                                                   NaN\n",
       "2309                                                   NaN\n",
       "2310                                                   NaN\n",
       "2311                    [zero_grad, optimizer.zero_grad()]\n",
       "2312     [import os\\r\\nfrom os.path import exists\\r\\n\\r...\n",
       "2315     [train_tensors, dataiter.__next__(), images, l...\n",
       "2316     [    class RNN(nn.Module):\\r\\n    def __init__...\n",
       "2317                                                   NaN\n",
       "2318                                                   NaN\n",
       "2319     [pyinstaller -F ZhongDon.py --collect-all easy...\n",
       "2320                                                   NaN\n",
       "2321     [a, dimension=0, torch.arange, dimension=1, b,...\n",
       "2322     [a = torch.zeros([64,2])\\r\\nb = torch.ones(64)...\n",
       "2323              [optimizer.zero_grad(), loss.backward()]\n",
       "2324                                                   NaN\n",
       "2325                                                   NaN\n",
       "2326                                                   NaN\n",
       "2327     [torchvision, train_dir = \"data/training/\"\\r\\n...\n",
       "2329     [x = x.view(B, C, H*W)\\r\\nm = m.view(B, 1, H*W...\n",
       "2330                                                   NaN\n",
       "2331     [torch.is_floating_point, if torch.is_floating...\n",
       "2332                                                   NaN\n",
       "2333                                                   NaN\n",
       "2334     [nkctv, kvw, nctw, k, v, (n, k, c, t, v, 1), (...\n",
       "2335     [Y = torch.einsum('nkctv,kvw-&gt;nctw', (x, A)...\n",
       "2337                                                   NaN\n",
       "2338                                                   NaN\n",
       "2339                                                   NaN\n",
       "2340     [beat_array=np.pad(beat,start_beat+start_beat,...\n",
       "2341     [nn.BCELossWithLogits, nn.Embedding, (seq_len,...\n",
       "2342     [pip3 install --pre torch torchvision torchaud...\n",
       "2343     [cond = lambda tensor: tensor.gt(value)\\r\\n, n...\n",
       "2344     [out, targets, out, (n_classes, 1), out_labels...\n",
       "2346                [sudo apt-get install ninja-build\\r\\n]\n",
       "2347                               [pip install Ninja\\r\\n]\n",
       "2348                                                   NaN\n",
       "2349     [torch.gather, torch.gather(x, 1, torch.LongTe...\n",
       "2350                                                   NaN\n",
       "2351                                                   NaN\n",
       "2352                                                   NaN\n",
       "2353       [SimpleExperiment, Experiment, ax, ax-platform]\n",
       "2354                                                   NaN\n",
       "2355     [dataloader = ...  # reduce batch size here on...\n",
       "2356               [torch.unsqueeze(x1_input, dim=0).\\r\\n]\n",
       "2360                                                   NaN\n",
       "2361                                                   NaN\n",
       "2362                                                   NaN\n",
       "2364                             [G.grad, loss.backward()]\n",
       "2365                                                   NaN\n",
       "2366     [import torch, time, gc\\r\\n\\r\\n# Timing utilit...\n",
       "2367                                                   NaN\n",
       "2368                                                   NaN\n",
       "2369     [with torch.no_grad(), self.batch_training(tra...\n",
       "2371     [import torch\\r\\nfrom torch.utils.data import ...\n",
       "2372                                                   NaN\n",
       "2373                                                   NaN\n",
       "2374                                                   NaN\n",
       "2375                                                   NaN\n",
       "2376                                                   NaN\n",
       "2377     [import gc\\r\\ngc.collect()\\r\\ntorch.cuda.empty...\n",
       "2378                                                   NaN\n",
       "2381     [forward(data=myarray), def forward(self, inpu...\n",
       "2382     [vocab_size, word_embeds, nn.Embedding, word_e...\n",
       "2383     [torch.onnx.export, torch.onnx.export(model,\\r...\n",
       "2384                                        [T.RandomCrop]\n",
       "2385                                           [variables]\n",
       "2386     [def finetune(self):\\r\\n        self.fine_tune...\n",
       "2388     [results.save(), yolov5/models/common.py, def ...\n",
       "2389     [save_dir, results.save(save_dir='data/output/...\n",
       "2390                                                   NaN\n",
       "2392                                                   NaN\n",
       "2393                                                   NaN\n",
       "2394                                     [truncation_side]\n",
       "2395     [from typing import Tuple\\r\\nfrom transformers...\n",
       "2396                                          [self, view]\n",
       "2397                                                   NaN\n",
       "2398     [sentence = sentence.to(device()), model.to(de...\n",
       "2399     [torch.nn.Module, forward, forward, import tor...\n",
       "2400                          [cuda(), dets = dets.cuda()]\n",
       "2401      [plt.show(), ax.imshow(), break, time.sleep(10)]\n",
       "2402                                                   NaN\n",
       "2403                                                   NaN\n",
       "2404     [grad,  f = nn.Sequential(\\r\\n       nn.Linear...\n",
       "2405                                                   NaN\n",
       "2407                     [pip install torch --upgrade\\r\\n]\n",
       "2408                                                   NaN\n",
       "2409     [@torch.no_grad(), activation_maps(name='conv1')]\n",
       "2410                                                   NaN\n",
       "2411                                                   NaN\n",
       "2412                                                   NaN\n",
       "2413                                                   NaN\n",
       "2414     [class_prob = torch.softmax(out, dim=1)\\r\\n# g...\n",
       "2415     [class InstanceNormAlternative(nn.InstanceNorm...\n",
       "2416     [exec, def, locals, globals, globals, from tex...\n",
       "2417                                                   NaN\n",
       "2418                                                   NaN\n",
       "2419     [x_train_tfr, y_train_tfr, x_train_tfr, src = ...\n",
       "2420     [torch.utils.data.DataLoader, pin_memory, num_...\n",
       "2421                                                   NaN\n",
       "2422                                                   NaN\n",
       "2423                                                   NaN\n",
       "2424     [elif, True, self.dataset, self.path, Train, T...\n",
       "2425                                                   NaN\n",
       "2426     [torch.Tensor.unqueeze,  x.unsqueeze(-1) # gra...\n",
       "2428     [def _log_softmax(self, pred_tensors):\\r\\n    ...\n",
       "2429                                                   NaN\n",
       "2430                                                   NaN\n",
       "2431                                                   NaN\n",
       "2433                                                   NaN\n",
       "2434     [encoder, None, class Encoder(nn.Module):\\r\\n ...\n",
       "2435     [import torch\\r\\nimport torch.nn.functional as...\n",
       "2436     [all_categories = list(set([\"Sweden\", \"Iceland...\n",
       "2437                                                   NaN\n",
       "2438     [print('Full model:',solver_1.head.last_layer....\n",
       "2439                                                   NaN\n",
       "2440     [BatchNorm2d, FCN, self.bn, num_features, Batc...\n",
       "2441     [sound_data_list = []\\r\\nshape_audio = 22050\\r...\n",
       "2442     [torch.Size([119*51, 768])\\r\\n, y, torch.Size(...\n",
       "2443                                                   NaN\n",
       "2444     [for layer in list(torch_model.modules())[1:]:...\n",
       "2445     [nn.Linear(2,512), class NeuralNet(nn.Module):...\n",
       "2446     [mat1 and mat2 shapes cannot be multiplied (61...\n",
       "2448        [NeuralNet, out = self.l3, out = self.l3(out)]\n",
       "2449                                                   NaN\n",
       "2450                                                   NaN\n",
       "2452                                                   NaN\n",
       "2453                                                   NaN\n",
       "2454     [a[b[:,0], b[:,1]]\\r\\n, b, map(), a[tuple(map(...\n",
       "2455     [confidence, --save-conf, python3 detect.py --...\n",
       "2456                                                   NaN\n",
       "2457                                                   NaN\n",
       "2458                                                   NaN\n",
       "2460                                                   NaN\n",
       "2461                                                   NaN\n",
       "2462                                       [\"__version__\"]\n",
       "2463     [        self.fc1 = nn.Linear(self.flatten, 51...\n",
       "2464     [+--------------------------------------------...\n",
       "2465                                           [nvida-smi]\n",
       "2466                                                   NaN\n",
       "2467                                                   NaN\n",
       "2468                                       [get_last_lr()]\n",
       "2470     [torch.cat(), import torch\\r\\na = torch.randin...\n",
       "2471     [bias=False, weight, None, import torch\\r\\nimp...\n",
       "2472     [from pytorch_lightning import Callback\\r\\n\\r\\...\n",
       "2474                                                   NaN\n",
       "2475     [img_to_patch(), H, W, patch_size, H, W, patch...\n",
       "2476     [y=out@W2 +b2\\r\\n, python 3.5, torch.mm(), (1,...\n",
       "2477     [my_model = nn.Sequential(\\r\\n    nn.Linear(5,...\n",
       "2478                                                   NaN\n",
       "2479                                                   NaN\n",
       "2480                                                   NaN\n",
       "2481     [c, c, output_t, target, nn.BCEWithLogitsLoss,...\n",
       "2482     [save_params(), load_params(), net_b.save_para...\n",
       "2483                                                   NaN\n",
       "2484                                                   NaN\n",
       "2485     [print(len(voices_loader))\\r\\n, Loader, for ep...\n",
       "2486                                                   NaN\n",
       "2487     [self.conv4=nn.Conv2d(128,256,5)\\r\\nself.conv5...\n",
       "2488     [conv4, self.conv4=nn.Sequential(\\r\\n         ...\n",
       "2489                                                   NaN\n",
       "2490                                                   NaN\n",
       "2491                                                   NaN\n",
       "2492     [extra_loss, class MyModule:\\r\\n    extra_loss...\n",
       "2493     [nn.Module, import torch.nn as nn\\r\\nact_out =...\n",
       "2495                                                   NaN\n",
       "2496                                                   NaN\n",
       "2497     [torch.save(faces, \"faces.torch\")\\r\\n, img = I...\n",
       "2498          [self.layer3, layer3, 256, self.layer2, 128]\n",
       "2501     [(3, 1280, 720), (3, 200, 200), transform, RNe...\n",
       "2502                                                   NaN\n",
       "2504     [numpy.where, import numpy as np\\r\\ntensor1 = ...\n",
       "2505                                                   NaN\n",
       "2506                                                   NaN\n",
       "2507     [output_from_third, lin, lin = nn.Linear(outpu...\n",
       "2508                                                   NaN\n",
       "2509                                                   NaN\n",
       "2510                                                   NaN\n",
       "2511                                                   NaN\n",
       "2512                                                   NaN\n",
       "2514     [torch.nn.Linear(a,b), (n, a), (n, b), X, (n, ...\n",
       "2515     [[batch_size, hidden_size], hidden_size x num_...\n",
       "2517     [idx, import os\\r\\npath_data = r\"D:\\data\" # He...\n",
       "2518                                                   NaN\n",
       "2519                                                   NaN\n",
       "2520                                                   NaN\n",
       "2521     [torch.nn.utils.rnn.pad_sequence, pad_sequence...\n",
       "2522     [nn.Module,         self.W = torch.nn.Paramete...\n",
       "2523     [def forward(self, input, adj):\\r\\n    b_size ...\n",
       "2524                                                   NaN\n",
       "2525     [pretrained=True, aux1.fc2, aux2.fc2, fc, goog...\n",
       "2526     [pyenv, CMake Error at /opt/homebrew/Cellar/cm...\n",
       "2527     [# CLICK ME\\r\\nfrom fastai.vision.all import *...\n",
       "2528               [model, ls, print(os.system(\"ls\"))\\r\\n]\n",
       "2529                                                   NaN\n",
       "2530                                                   NaN\n",
       "2531      [F.linear(v, self.W.squeeze(), bias=h_bias)\\r\\n]\n",
       "2532                [w = self.W.clone().repeat(10, 1)\\r\\n]\n",
       "2533     [x = x_init.requires_grad_(True)\\r\\nopt = torc...\n",
       "2534     [Conv2d, import torch\\r\\nfrom torch import nn\\...\n",
       "2535     [optimizer = optim.SGD(\\r\\n    [\\r\\n        {\"...\n",
       "2536                 [ABC, nn.Module, ABC, NotImplemented]\n",
       "2537                                                   NaN\n",
       "2538     [transform = transforms.Compose([transforms.To...\n",
       "2539                                                   NaN\n",
       "2540                                                   NaN\n",
       "2542                                                   NaN\n",
       "2543     [def place(a: torch.Tensor, b: torch.Tensor, \\...\n",
       "2544                                                   NaN\n",
       "2545                                                   NaN\n",
       "2546                                                   NaN\n",
       "2547     [import torch\\r\\nx = torch.rand(3,4)\\r\\nx\\r\\nt...\n",
       "2549                                                   NaN\n",
       "2550                                                   NaN\n",
       "2551                                                   NaN\n",
       "2553     [train_transforms = A.Compose(\\r\\n[\\r\\n    A.G...\n",
       "2554     [conda install pytorch==1.5.0 torchvision==0.6...\n",
       "2555                                                   NaN\n",
       "2557     [predicted_loes_score_g = tensor([[-24.9374]],...\n",
       "2558                                                   NaN\n",
       "2559     [center_coordinates = (int(box[0]+(box[2]-box[...\n",
       "2560                                                   NaN\n",
       "2561     [torch.nn.Sequential, torchvision.transforms.C...\n",
       "2562     [optim.lr_scheduler.MultiStepLR(optimizer, [0,...\n",
       "2563     [&lt;&lt; scheduler = lr_scheduler.StepLR(opti...\n",
       "2564     [ sgd_config = {\\r\\n    'params' : net.paramet...\n",
       "2566                                                   NaN\n",
       "2567                                                   NaN\n",
       "2568     [torch.randn, 0, x = torch.randn(1000000,2).nu...\n",
       "2569                                                   NaN\n",
       "2570                                                   NaN\n",
       "2571     [x_train, torch.Size([20]), nn.Linear(1,1), x_...\n",
       "2572     [Length: unspecified [text/html]\\r\\n, from goo...\n",
       "2573     [import torch\\r\\n\\r\\n# variables to work with\\...\n",
       "2574     [y_pred_binary = torch.round(torch.sigmoid(y_p...\n",
       "2575                                                   NaN\n",
       "2576     [%, %, %s, os.path.join(), str(), import os\\r\\...\n",
       "2577                                                   NaN\n",
       "2578                                                   NaN\n",
       "2579                                                   NaN\n",
       "2580     [torch.nn.functional.pad, x = torch.tensor([[1...\n",
       "2581     [hidden = tuple([each.data for each in hidden]...\n",
       "2582     [torch.scatter_reduce, import torch\\r\\na = tor...\n",
       "2583     [Sampler, StopIteration, iter(), def custom_ba...\n",
       "2584                                                   NaN\n",
       "2585     [g++ -g -O2 -std=c++17 \\\\r\\n-pthread \\\\r\\n-mar...\n",
       "2586                                                   NaN\n",
       "2587     [torch.long, y_label = torch.tensor(self.annot...\n",
       "2588     [cal_grad,     return torch.autograd.grad(loss...\n",
       "2589                                                   NaN\n",
       "2590     [# install pip if it's not already installed\\r...\n",
       "2591     [torch.stack(tensors, dim=0, *, out=None) → Te...\n",
       "2592     [#don't want RGB masking, want the whole pixel...\n",
       "2593     [noise, power_vec, # create random noise - not...\n",
       "2594     [/tmp/ipykernel_33/1050848783.py in forward(se...\n",
       "2596                                                   NaN\n",
       "2597                                                   NaN\n",
       "2598                                               [Union]\n",
       "2599                                                   NaN\n",
       "2600     [input_size, batch_first=True, r_input = torch...\n",
       "2601                                                   NaN\n",
       "2602     [pip install torch --pre --extra-index-url htt...\n",
       "2603                                                   NaN\n",
       "2604                                                   NaN\n",
       "2605     [net = Net()\\r\\ncriterion = nn.CrossEntropyLos...\n",
       "2606     [Net, class Net(nn.Module):\\r\\n    def __init_...\n",
       "2607     [loss = self.criterion(pred[0],label.float())\\...\n",
       "2608     [_, cls_hs = self.bert(input_ids, attn_masks, ...\n",
       "2609                                                   NaN\n",
       "2610                                                   NaN\n",
       "2611                                                   NaN\n",
       "2612                   [torch.jit.script, torch.jit.trace]\n",
       "2613                                                   NaN\n",
       "2614     [unique, idx, counts = torch.unique(A, dim=1, ...\n",
       "2615                                                   NaN\n",
       "2617                                                   NaN\n",
       "2618     [new_dummy = Dummy(256, 256, kernel_size=(2, 3...\n",
       "2619     [early_stopping(), 0, __call__(), __init__(), ...\n",
       "2620     [class EarlyStopper:\\r\\n    def __init__(self,...\n",
       "2622     [predict_image = model(image)\\r\\nim_rgb = cv2....\n",
       "2623     [import torch\\r\\nimport pathlib\\r\\n\\r\\nimg_pat...\n",
       "2624                                                   NaN\n",
       "2625                                                   NaN\n",
       "2626                                                   NaN\n",
       "2627                                                   NaN\n",
       "2628                                                   NaN\n",
       "2629     [bincount = lambda inds, arr: torch.scatter_re...\n",
       "2631     [        pbag=pbag.float()\\r\\n        pbag=Var...\n",
       "2632                                                   NaN\n",
       "2634                                                   NaN\n",
       "2635                                                   NaN\n",
       "2636                                                   NaN\n",
       "2637                     [pip install numpy --upgrade\\r\\n]\n",
       "2639                                                   NaN\n",
       "2640     [xlmr_tokenizer = XLMRobertaTokenizer.from_pre...\n",
       "2641                                                   NaN\n",
       "2642                                                   NaN\n",
       "2644     [numpy, torch, In [120]: A = np.random.random(...\n",
       "2645                                                   NaN\n",
       "2646                                                   NaN\n",
       "2647                [patched_features, register_parameter]\n",
       "2648     [torch, scipy.sparse, In [96]: M = sparse.coo_...\n",
       "2649     [padding, torch, padding, keras, stride = 2, X...\n",
       "2650                                                   NaN\n",
       "2652                                                   NaN\n",
       "2653     [self.fc1 = nn.Linear(16 * 5 * 5, 120)\\r\\n, se...\n",
       "2654     [val, torch.Tensor, A, constraint, val, torch....\n",
       "2656                                                   NaN\n",
       "2658                                                   NaN\n",
       "2659     [weights = torch.stack([torch.Tensor(value) fo...\n",
       "2660                                                   NaN\n",
       "2661     [class AUTOMAP_Basic_Model(nn.Module):\\r\\n    ...\n",
       "2663                                                   NaN\n",
       "2664                                                   NaN\n",
       "2665                                                   NaN\n",
       "2667                                                   NaN\n",
       "2668                                           [3x224x224]\n",
       "2669     [data, Img, tf.expand_dims, img = tf.expand_di...\n",
       "2670     [from sklearn import preprocessing\\r\\nfrom skl...\n",
       "2671                                                   NaN\n",
       "2672     [import torchvision\\r\\nfrom PIL import Image, ...\n",
       "2673     [def trainM(epoch):\\r\\n\\r\\n    ...\\r\\n\\r\\n    ...\n",
       "2674     [np.uint8, ...\\r\\ncanvas1 = decode(action, can...\n",
       "2676     [    ## summation\\r\\n    WSum = self.W_1 + sel...\n",
       "2677                                                   NaN\n",
       "2678     [x = x.view(-1,320), x.shape = (batchsize, 128...\n",
       "2679     [target = torch.Tensor(target[64*batch_id:64*(...\n",
       "2680                                                   NaN\n",
       "2681     [detach, loss.backward(), opt.step(), loss += ...\n",
       "2682     [CrossEntropyLoss, y = torch.Tensor([[0,0,1],[...\n",
       "2683                                                   NaN\n",
       "2684     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "2685     [values_mapping = {1: 12, 3: 1, 4: 2, 2: 34, 1...\n",
       "2686     [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "2687     [__init__, c, __init__, self.SEBlock = SE_Bloc...\n",
       "2688     [class myclass(nn.Module):\\r\\n    def __init__...\n",
       "2689     [Dataset, [t, t + window, ... t + n * window],...\n",
       "2690                                                   NaN\n",
       "2691     [torchmetrics.classification.dice_score, torch...\n",
       "2692                                                   NaN\n",
       "2693                                                   NaN\n",
       "2694     [train_loader = torch.utils.data.DataLoader(\\r...\n",
       "2695     [stage=None, def setup(self, stage=None):\\r\\n ...\n",
       "2696                                                   NaN\n",
       "2697     [Q = W_q @ input_query + b_q\\r\\nK = W_k @ inpu...\n",
       "2698                                                   NaN\n",
       "2699                                                   NaN\n",
       "2700     [import torch.nn.functional as F\\r\\nclass mode...\n",
       "2701     [requires_grad=False, for param in self.encode...\n",
       "2702     [self.encoder.requires_grad = False, requires_...\n",
       "2703     [class MNISTModel(LightningModule):\\r\\n    def...\n",
       "2704     [add_library(libName SHARED IMPORTED)\\r\\nset_p...\n",
       "2705                                                   NaN\n",
       "2706                                                   NaN\n",
       "2707     [img = img[:,0:1,:,:]\\r\\n, transforms.ToTensor()]\n",
       "2708     [\\r\\ntest_dataset = ImageFolder('my_digit_imag...\n",
       "2709                                                   NaN\n",
       "2710         [MaxPool2d, [B, 1, H, W], [B, 256, H/4, W/4]]\n",
       "2711                          [pip install --upgrade timm]\n",
       "2712                                                   NaN\n",
       "2713     [nn.MultiheadAttention, attn_output, attn_outp...\n",
       "2714     [1e-1, 1e-4, diff_total, diff, diff_total, epo...\n",
       "2715     [def results_parser(results):\\r\\n  s = \"\"\\r\\n ...\n",
       "2716     [label_list, import pandas as pd\\r\\n\\r\\nlabel_...\n",
       "2717                                                   NaN\n",
       "2718                                                   NaN\n",
       "2719     [sys.stdout, flush, flush=True, print(\"Hello? ...\n",
       "2722                                                   NaN\n",
       "2723                                                   NaN\n",
       "2725     [    def forward(self, x, edge_index, edge_att...\n",
       "2726                                                   NaN\n",
       "2727                                                   NaN\n",
       "2728     [memory_store, t.reward, t, class DQN, update,...\n",
       "2729     [mkRandomBatch(),  return torch.tensor(batch_x...\n",
       "2730                                                   NaN\n",
       "2731     [torch.save({'net': net.state_dict(), 'optim':...\n",
       "2733                                                   NaN\n",
       "2735                                                   NaN\n",
       "2736     [target_transform, torchvision.datasets.STL10(...\n",
       "2738     [forward, class ResNet, self.relu, self.layer2...\n",
       "2739     [class Model(pl.LightningModule)\\r\\n    def __...\n",
       "2740     [loss.backward(), on_before_backward(), on_aft...\n",
       "2741                                                   NaN\n",
       "2742     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "2743                                                   NaN\n",
       "2744     [view, numpy.random.choice, from numpy.random ...\n",
       "2745                                                   NaN\n",
       "2746                                                   NaN\n",
       "2747                                                   NaN\n",
       "2749                                                   NaN\n",
       "2750     [import torch\\r\\nfrom torch import autograd\\r\\...\n",
       "2751     [from joblib import Parallel, delayed\\r\\nimpor...\n",
       "2752                                                   NaN\n",
       "2753                                                   NaN\n",
       "2756     [class first_branch(nn.Module):\\r\\n    ...\\r\\n...\n",
       "2757     [shuffle=False, loader = data.DataLoader(testD...\n",
       "2758     [all_X = []\\r\\nall_y = []\\r\\nfor X, y, ind in ...\n",
       "2759     [- gs://pypl_bkt_prd_row_std_aiml_vertexai/mod...\n",
       "2760                                                   NaN\n",
       "2762                                                   NaN\n",
       "2764                                                   NaN\n",
       "2765                                                   NaN\n",
       "2767                                                   NaN\n",
       "2768                                                   NaN\n",
       "2769     [model = XXXNet()\\r\\n\\r\\nfor names, params in ...\n",
       "2770     [pytorch, numpy, import numpy as np\\r\\n\\r\\nnp_...\n",
       "2771                                                   NaN\n",
       "2772     [loss.backward(), y_pred.grad()\\r\\n, y_pred, t...\n",
       "2773                                                   NaN\n",
       "2776                                                   NaN\n",
       "2777                                                   NaN\n",
       "2778                                                   NaN\n",
       "2780     [ppc64le, ppc64le, conda search, conda search ...\n",
       "2781                                                   NaN\n",
       "2782     [[n, k], [n, 3, k], .reshape, concat2 = concat...\n",
       "2783     [torch.einsum, matmul, c = torch.concat([x, y,...\n",
       "2784                                                   NaN\n",
       "2785                  [        Thearray.cpu().numpy()\\r\\n]\n",
       "2787     [model.toggle_pruning(True), model.toggle_prun...\n",
       "2788                                                   NaN\n",
       "2789                                                   NaN\n",
       "2790                                                   NaN\n",
       "2793                                                   NaN\n",
       "2794                                                   NaN\n",
       "2795                                                   NaN\n",
       "2796     [Cnn, Cnn, __init__, forward, Cnn, # outside o...\n",
       "2797                                                   NaN\n",
       "2798                                                   NaN\n",
       "2799                                                   NaN\n",
       "2800     [for i in x:\\r\\n, for d in range(x.size()[0]):...\n",
       "2801     [gradient = [el.grad for el in model.parameter...\n",
       "2802     [datagen = ImageDataGenerator(rescale=1 / 255....\n",
       "2804                                                   NaN\n",
       "2805                                                   NaN\n",
       "2806                                                   NaN\n",
       "2808     [def invalid_predictions(n=10, images, labels)...\n",
       "2809                                    [optimizer.step()]\n",
       "2810                                                   NaN\n",
       "2811                                                   NaN\n",
       "2812                                                   NaN\n",
       "2813     [conv2d(I,O,(k1,k2)), B x I x H x W, B x O x (...\n",
       "2814     [def sum_var_parts(t, lens):\\r\\n    t_size_0 =...\n",
       "2815     [import torch\\r\\n\\r\\nlens = [3,2,5]\\r\\nt = tor...\n",
       "2816     [torch.nn.utils.rnn.pad_sequence, for, def chu...\n",
       "2817     [.numpy(),  torch_image = torch.rand(3, 224, 2...\n",
       "2818     [nn.Conv1d, (batch_size, num_of_channels, seq_...\n",
       "2819     [ReLU, ReLu, import torch.nn as nn\\r\\n\\r\\nclas...\n",
       "2820     [def backward(self, unet_loss, dis_loss):\\r\\n ...\n",
       "2821     [class Patch(object):\\r\\n    \"\"\"\\r\\n    Create...\n",
       "2822                                                   NaN\n",
       "2823                                                   NaN\n",
       "2824                                                   NaN\n",
       "2825     [torch::tensor&amp; operator=(torch::Tensor rh...\n",
       "2826                                                   NaN\n",
       "2827     [(x == torch.max(x)).nonzero()\\r\\n, nonzero, a...\n",
       "2828     [roc_curve, y_true, y_score, _, pred = torch.m...\n",
       "2829                                                   NaN\n",
       "2830     [-1, line = tuple(map(int, line.strip().split(...\n",
       "2831                                                   NaN\n",
       "2832     [#example on one image\\r\\nmnist_train = torchv...\n",
       "2833                                                   NaN\n",
       "2834                                                   NaN\n",
       "2836                                                   NaN\n",
       "2839     [nvidia-smi, pip install nvidia-ml-py3, import...\n",
       "2841                                                   NaN\n",
       "2842     [for i, (images, labels) in enumerate(training...\n",
       "2843                                                   NaN\n",
       "2844     [state = {'model': model.state_dict(), 'optimi...\n",
       "2845                                                   NaN\n",
       "2846     [\"my_dataset\", register_coco_instances, Datase...\n",
       "2847     [if not hasattr(self,'dataloader_idx'):\\r\\n   ...\n",
       "2848                                  [checkpoint loading]\n",
       "2849     [loss = criterion(output, labels.float()), (ba...\n",
       "2850     [utils.save_image(utils.make_grid(torch.clip(n...\n",
       "2851                                                   NaN\n",
       "2852     [Conda, torch.version.cuda, pip, pip3 install ...\n",
       "2853                                                   NaN\n",
       "2854     [forward, SimpleConvolutionalNetwork, conv1, x...\n",
       "2855     [numexpr, pip install numexpr\\r\\n, import nume...\n",
       "2856                                                   NaN\n",
       "2857     [@task_interface.register_fl_task(model='net_m...\n",
       "2858                                                   NaN\n",
       "2859                                                   NaN\n",
       "2860     [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "2861                                                   NaN\n",
       "2862                                                   NaN\n",
       "2863                                                   NaN\n",
       "2864     [Linear, in_features, model_stats = summary(my...\n",
       "2865     [for i in range(100):\\r\\n  y_pred = ann(x)\\r\\n...\n",
       "2866                                                   NaN\n",
       "2867                                                   NaN\n",
       "2868     [from allennlp.models.archival import load_arc...\n",
       "2869     [i = 1                     # iteration\\r\\ntole...\n",
       "2871     [PATH = 'weights\\kharif_crops_final.pth'\\r\\nst...\n",
       "2872                                                   NaN\n",
       "2874                                                   NaN\n",
       "2875     [timeit, active[active.clone()] = ~terminated\\...\n",
       "2876                                                   NaN\n",
       "2877                                                   NaN\n",
       "2879     [nn.Module, class Generator, __init__, self, g...\n",
       "2880                                                   NaN\n",
       "2881                [_use_new_zipfile_serialization=False]\n",
       "2882     [__iter__(), class MyDataset(Dataset):\\r\\n   d...\n",
       "2883                                                   NaN\n",
       "2884     [def get_model(lr=0.001):\\r\\n    model = tf.ke...\n",
       "2885     [zeros, pad_sequence, def outputAlignment(outp...\n",
       "2886     [import torch\\r\\nx = torch.tensor([0,0,0,1,1,2...\n",
       "2887     [ torch.isin(x,y)\\r\\ntensor([ True,  True,  Tr...\n",
       "2888                                                   NaN\n",
       "2889     [import torch\\r\\n\\r\\ndet = torch.rand(8, 6)\\r\\...\n",
       "2890                                                   NaN\n",
       "2891     [class MLP(nn.Module):\\r\\ndef __init__(self,nu...\n",
       "2892                                                   NaN\n",
       "2893     [model( torch.zeros(11,5) )  --&gt;   model( t...\n",
       "2894     [        'randint': ['def randint(low: _int, h...\n",
       "2895                     [(T), T, int, torch.normal, (T,)]\n",
       "2896                                                   NaN\n",
       "2897                                                   NaN\n",
       "2898                                                   NaN\n",
       "2899     [model._modules[\"features\"][0][0], nn.Conv2d(3...\n",
       "2900     [a = torch.randn((8, 7))\\r\\nmax_a, ids = torch...\n",
       "2901     [PIL Image, predict(), decode(), PIL Image, wi...\n",
       "2902                                                   NaN\n",
       "2903                                                   NaN\n",
       "2904                                                   NaN\n",
       "2905                                                   NaN\n",
       "2906     [x = x.view(-1, x.size(0))\\r\\n, x = x.view([-1...\n",
       "2907     [torch.flip, dims, torch.flip(tensor_a, dims=(...\n",
       "2908     [ a = np.asarray([[1,2,3], [4,5,6]])\\r\\n\\r\\n a...\n",
       "2909                                                   NaN\n",
       "2910     [..., tranforms.ToTensor(), ...\\r\\n, ..., tran...\n",
       "2911                          [remain, Dataset, if remain]\n",
       "2912     [self.initial = nn.Linear(...), # A typical co...\n",
       "2913     [inplace, ptflops, ConvBlock(\\r\\n  0.0 M, 100....\n",
       "2914                                                   NaN\n",
       "2915     [out.shape == (1024, 1), y, (1024, ), (out - y...\n",
       "2916                                                   NaN\n",
       "2917                                [CUDA_LAUNCH_BLOCKING]\n",
       "2918     [def str2slices(s):\\r\\n    d = {True: lambda e...\n",
       "2919     [eval, np.s_, getitem, tuple, In [83]: class F...\n",
       "2920     [model, DeepGraphInfomax, model(), .__call__, ...\n",
       "2921     [import, import torch\\r\\nfrom monai.networks.n...\n",
       "2922                                                   NaN\n",
       "2923                                                   NaN\n",
       "2924                                                   NaN\n",
       "2925     [pad_sequence, batch, def pad_AudioSequence(ba...\n",
       "2926     [repeated_u = u.unsqueeze(dim=0).repeat(indice...\n",
       "2927     [u.shape -- (8, 8), indices.shape -- (2, 8, 8)...\n",
       "2928                                                   NaN\n",
       "2929                                                   NaN\n",
       "2930                                                   NaN\n",
       "2931              [in_channels, self.conv1, (1, 256, 256)]\n",
       "2932                                                   NaN\n",
       "2934     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nm...\n",
       "2935                                                   NaN\n",
       "2936     [#SBATCH --gres=gpu:1, #SBATCH --gres=gpu:4, g...\n",
       "2937     [1.000000015047466e+30f, float, float, 1e30, f...\n",
       "2938     [stack, torch, torch, for, out = [f(ii) for ii...\n",
       "2939                  [nn.CrossEntropyLoss, train_dataset]\n",
       "2940     [out = torch.conv1d(x_batch.unsqueeze(0), y_ba...\n",
       "2941     [torch.nn.functional, conv1d, v1, v2, v1, v2, ...\n",
       "2942     [from torch.utils.cpp_extension import load\\r\\...\n",
       "2943                                                   NaN\n",
       "2944     [@tf.function\\r\\ndef train_step():\\r\\n    with...\n",
       "2945     [ import torch\\r\\n model = torch.nn.Linear(5, ...\n",
       "2946                                                   NaN\n",
       "2947     [padding = (13, 1), stride = (3, 1), kernel_si...\n",
       "2948                                                   NaN\n",
       "2949                                                   NaN\n",
       "2951     [pos_weight, weight,  target = torch.ones([10,...\n",
       "2952                                                   NaN\n",
       "2953     [(H*W, 2), H, W, torch.arange, loc, j, i, leve...\n",
       "2954     [ERROR: No matching distribution found for tor...\n",
       "2957     [optimizer = optim.Adam([{'params':[ param for...\n",
       "2959     [good_gradient = torch.ones(*image_shape) / to...\n",
       "2960                                                   NaN\n",
       "2961     [loss.backward(), loss.backward, running_loss,...\n",
       "2962                                                   NaN\n",
       "2964                                                   NaN\n",
       "2965                                                   NaN\n",
       "2966     [__init__, __len__, __getitem__, __init__, def...\n",
       "2967                                                   NaN\n",
       "2968                                                   NaN\n",
       "2969     [# Imports\\r\\nfrom stable_baselines3.dqn.polic...\n",
       "2970                                                   NaN\n",
       "2971                                                   NaN\n",
       "2972                                                   NaN\n",
       "2973     [[32 x 388 x 388], [32 x 3 x 388 x 388], [32 x...\n",
       "2974                                                   NaN\n",
       "2975                                                   NaN\n",
       "2976                                                   NaN\n",
       "2977     [transforms.Resize((300, 300), interpolation=I...\n",
       "2978     [In [24]: z = torch.zeros(1, 6)\\r\\nIn [27]: t\\...\n",
       "2980     [x, y.backward(), import math\\r\\nimport torch\\...\n",
       "2981     [import torch\\r\\nimport pandas as pd\\r\\n\\r\\ndf...\n",
       "2982                                                   NaN\n",
       "2983                                                   NaN\n",
       "2985                                                   NaN\n",
       "2986                                                   NaN\n",
       "2987     [self.x[index], X_train = np.random.rand(12_00...\n",
       "2988     [index_add_, avg_size = int(t.max().item()) + ...\n",
       "2989                                                   NaN\n",
       "2990                                                   NaN\n",
       "2991                                                   NaN\n",
       "2992                                                   NaN\n",
       "2993                                                   NaN\n",
       "2994                                                   NaN\n",
       "2995                                                   NaN\n",
       "2996           [model_fn, input_fn, predict_fn, output_fn]\n",
       "2997                                                   NaN\n",
       "2998     [import torch\\r\\nx = torch.tensor([[ 1., -5.],...\n",
       "2999     [x, i, torch.matmul, torch.matmul(x, i)\\r\\n\\r\\...\n",
       "3000                                                   NaN\n",
       "3001                                                   NaN\n",
       "3002                                                   NaN\n",
       "3003     [ import numpy as np\\r\\n np.__config__.show()\\...\n",
       "3004     [opt = Optimization(...)\\r\\n, torch.optim.Opti...\n",
       "3006                                                   NaN\n",
       "3007     [class History_dict(LightningLoggerBase):\\r\\n ...\n",
       "3008     [training_epoch_end(self, training_step_output...\n",
       "3009                                                   NaN\n",
       "3010                                                   NaN\n",
       "3011     [map_location=lambda storage, loc: storage.cud...\n",
       "3012                                      [ulimit -n 2048]\n",
       "3013     [numba, (10000,200), import torch\\r\\nimport nu...\n",
       "3014     [b,c = m.nonzero()\\r\\nb = torch.tensor(b)\\r\\nc...\n",
       "3015     [weight, classWeightsPositive = 1 - (numberOfP...\n",
       "3016                                                   NaN\n",
       "3018     [from flask import Flask, jsonify, request, se...\n",
       "3019                                                   NaN\n",
       "3020                                                   NaN\n",
       "3021     [model_fn, model.pt, pytorch_model.deploy, pre...\n",
       "3022     [#include &lt;cmath&gt;\\r\\n#include &lt;iostre...\n",
       "3023                                                   NaN\n",
       "3024                     [torch.sum, torch.sum, torch.sum]\n",
       "3025     [def, int, list, a = [1, 2, 3]\\r\\nb = a\\r\\n, a...\n",
       "3026     [for p in lstm.parameters():\\r\\n    print(p)\\r\\n]\n",
       "3027     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3028                                                   NaN\n",
       "3029     [CNN.eval()\\r\\n, im_resize = im_resize.unsquee...\n",
       "3030     [    def __getitem__(self, idx):\\r\\n        # ...\n",
       "3031     [input1 = torch.full((3, 3), 1)\\r\\ninput2 = to...\n",
       "3032                                                   NaN\n",
       "3033                                                   NaN\n",
       "3034                                                   NaN\n",
       "3035     [imt, imt = np.array(imt)\\r\\n, from torchvisio...\n",
       "3036                                                   NaN\n",
       "3037     [nn.sequential(), nn.Conv2d(self.dim_h * 4, se...\n",
       "3038                                                   NaN\n",
       "3039                       [1, 2, 42, 1.0, 1.1, 1.0, 42.0]\n",
       "3040     [from torch import nn\\r\\nimport torch.nn.funct...\n",
       "3041                                                   NaN\n",
       "3044                                                   NaN\n",
       "3046     [out = torch.zeros((n, oC, oH, oW), dtype=torc...\n",
       "3047               [DivisiblePadd([\"image\", \"label\"], 16)]\n",
       "3048     [y, [3,2,1], x, # all equivalent\\r\\nx * y.unsq...\n",
       "3050     [torch.onnx.export,   arch = models.alexnet();...\n",
       "3051     [img_path = os.path.join(train_dir, os.listdir...\n",
       "3052               [print(output, y_train_tensors[i])\\r\\n]\n",
       "3053                                                   NaN\n",
       "3054     [self.imgs_path = list(dataset_dir.glob('*.png...\n",
       "3055     [mask = torch.any(t.flatten(2, 3) &gt; 0., dim...\n",
       "3056     [import torch\\r\\nfrom torchvision import trans...\n",
       "3057                                                   NaN\n",
       "3058                                                   NaN\n",
       "3059     [number_of_epochs, def train_network(model, op...\n",
       "3060                                                   NaN\n",
       "3061            [cv2.imshow(\"some window title\", results)]\n",
       "3062                                                   NaN\n",
       "3063     [.data, .detach(), torch.no_grad(), a = torch....\n",
       "3064     [conda, conda install pytorch torchvision torc...\n",
       "3065                                                   NaN\n",
       "3066     [PatientPruner, wrapped_pruner=None, import op...\n",
       "3067     [dataloaders = {\\r\\n    x: torch.utils.data.Da...\n",
       "3068                      [Do X with x for x in List \\r\\n]\n",
       "3069     [KeyError, 'segmentation', 'segmentation', # R...\n",
       "3070                                                   NaN\n",
       "3073                                                   NaN\n",
       "3074                                                   NaN\n",
       "3075                                    [dmesg -T, python]\n",
       "3076     [from transformers import TrainingArguments, T...\n",
       "3077     [torch.any(), .nonzero(), .flatten(), torch.an...\n",
       "3078     [where, nonzero, a = torch.Tensor([[15,30,0,2]...\n",
       "3079                                                   NaN\n",
       "3080     [total_epochs = notebook.tqdm(range(no_epochs)...\n",
       "3081     [result = (a[:, None, :] == b[None, :, :]).sum...\n",
       "3082     [a = torch.Tensor([[1, 2, 3], [4, 5, 6]])\\r\\nb...\n",
       "3083     [ij,jk-&gt;ik, a @ b\\r\\ntorch.einsum(\"ij,jk\", ...\n",
       "3085     [import torch\\r\\nimport torch.nn.functional as...\n",
       "3086                                                   NaN\n",
       "3087     [tf.keras.layers.UpSampling2D(size, interpolat...\n",
       "3088                                                   NaN\n",
       "3089                                                   NaN\n",
       "3090                                                   NaN\n",
       "3091                                                   NaN\n",
       "3092                        [reshape, view, reshape, view]\n",
       "3093                                                   NaN\n",
       "3094                                                   NaN\n",
       "3095     [x, y, tempt_x, with x = [[1,2,3,4,5,6],[7,8,9...\n",
       "3096                                                   NaN\n",
       "3097     [data = [b[0][0, 0] for b in batch], data = [b...\n",
       "3098     [requires_grad==True, for param in model.base_...\n",
       "3100                                                   NaN\n",
       "3101     [for sample in trainloader:\\r\\n   print(sample...\n",
       "3102     [A = torch.tensor([1, 2, 3, 4])\\r\\nindices = t...\n",
       "3103     [A[indexes], A = torch.arange(5, 10).repeat(3,...\n",
       "3105     [model.state_dict(), torch.save({'model': mode...\n",
       "3107     [torch.empty.__doc__, print(torch.empty.__doc_...\n",
       "3108     [[i,j,k], G, [i',j',k'], G', n_edges, e, n_nod...\n",
       "3109     [dist.all_gather_object(), torch.cuda.set_devi...\n",
       "3110     [import torchvision.transforms as transforms\\r...\n",
       "3111     [hn = hn[-1, :, :]\\r\\nout = self.classifier(hn...\n",
       "3112                                                   NaN\n",
       "3114                                                   NaN\n",
       "3115                                                   NaN\n",
       "3117     [torchmetrics, import torch\\r\\nimport torchmet...\n",
       "3118     [model.save_pretrained(\"&lt;path_to_dummy_fold...\n",
       "3119                                                   NaN\n",
       "3120     [a, torch.arange,  a = p**torch.arange(len(p))...\n",
       "3121                                                   NaN\n",
       "3122                                                   NaN\n",
       "3123                                                   NaN\n",
       "3124     [batch_mask, batch_output[batch_mask], True, b...\n",
       "3125     [batch_output, batch_mask,  x = torch.rand(3,1...\n",
       "3126     [load_from_checkpoint(), model_test = model_te...\n",
       "3127                                                   NaN\n",
       "3129                                                   NaN\n",
       "3130     [dim=1, torch.tensor_split(x,2), x, [100,1], [...\n",
       "3131                                                   NaN\n",
       "3132     [c:\\users\\anaszafar\\desktop\\train\\adelaidet\\ad...\n",
       "3133     [numpy.vectorize, vectorize, potential, invers...\n",
       "3134                                                   NaN\n",
       "3135                                                   NaN\n",
       "3136     [requires_grad==True, .grad_fn, backward(), ba...\n",
       "3137     [weights, bias, .backward(), backward, valid_a...\n",
       "3138     [BCELoss, BCELossWithLogits, m = nn.Sigmoid()\\...\n",
       "3139                           [CrossEntropyLoss, BCELoss]\n",
       "3140                                                   NaN\n",
       "3141                                                   NaN\n",
       "3142                                                   NaN\n",
       "3144     [output = np.concatenate((output, [0]))\\r\\niob...\n",
       "3145     [index_ = np.array([[False if i in d else True...\n",
       "3146     [np.array, list, np.array([np.concatenate((i[~...\n",
       "3147                                                   NaN\n",
       "3148     [forget_bias=0.0, LSTMBlockFusedCell, import t...\n",
       "3149     [len(data_loaders['train'].dataset), len(data_...\n",
       "3151     [ImageFolder, torch.utils.data.Datasets, __get...\n",
       "3152     [model = models.mobilenet_v2(pretrained=True)\\...\n",
       "3153                                                   NaN\n",
       "3154     [import numpy as np\\r\\nimport torch as th\\r\\n\\...\n",
       "3155                                                   NaN\n",
       "3156                                                   NaN\n",
       "3157                                                   NaN\n",
       "3158                                                   NaN\n",
       "3159     [torch.save(model.state_dict(), PATH)\\r\\n, mod...\n",
       "3160                                                   NaN\n",
       "3161     [t1 = t1.unsqueeze(-1)\\r\\n...\\r\\nt2 = t2.squee...\n",
       "3162     [# example input and output\\r\\nx = torch.ones(...\n",
       "3163                    [to_sparse(), indices(), values()]\n",
       "3164     [list of lists, list comprehension, #  origina...\n",
       "3166     [patch_input, patch_expected, [batch_size x co...\n",
       "3167     [trainer.test(model, test_dataloaders=dm.test_...\n",
       "3168     [train_dataloader = DataLoader(MyData, batch_s...\n",
       "3170     [model_ft = models.resnet18(pretrained=True)\\r...\n",
       "3171     [x, x1, (100,16), torch.cat, cat_x = torch.cat...\n",
       "3172               [cat_x = torch.cat([x, x1], dim=1)\\r\\n]\n",
       "3173                                                   NaN\n",
       "3174     [batch_first, False, True, attention = nn.Mult...\n",
       "3175       [dim, return torch.gather(tensor1, 1, tensor2)]\n",
       "3176                                                   NaN\n",
       "3177     [pip install torch==1.7.1+cu110 torchvision==0...\n",
       "3178                                                   NaN\n",
       "3179                                                   NaN\n",
       "3180                                                   NaN\n",
       "3181     [output[0], 1, seq_length, output[0], for t in...\n",
       "3182     [from torch.nn.utils import weight_norm \\r\\n\\r...\n",
       "3183     [num_classes=0, timm.create_model(), import to...\n",
       "3184     [BatchNorm2d, FrozenBatchNorm2d, torchvision.o...\n",
       "3185                                                   NaN\n",
       "3186                                      [shutil, move()]\n",
       "3188     [__getitem__, Dataset, def __getitem__(self, i...\n",
       "3189     [torch.float, dtype, torch.FloatTensor, Double...\n",
       "3190                                          [max_tokens]\n",
       "3191                                        [running_loss]\n",
       "3192                                                   NaN\n",
       "3193                                                   NaN\n",
       "3194     [torch_geometric.loader.DataLoader, numpy, tor...\n",
       "3195     [DataLoader, model.eval(), train_model, # crit...\n",
       "3196                                                   NaN\n",
       "3197                                                   NaN\n",
       "3198                                                   NaN\n",
       "3200     [(layers, batch_size, hidden_size), hidden_1 =...\n",
       "3201     [class LSTM(nn.Module):\\r\\n    def __init__(se...\n",
       "3202     [pt, # if y=1\\r\\npt_1 = torch.where(truth == 1...\n",
       "3203                                                   NaN\n",
       "3204                                                   NaN\n",
       "3205                            [nvcc, cudatoolkit, conda]\n",
       "3206                                                   NaN\n",
       "3208     [ERROR: Unexpected bus error encountered in wo...\n",
       "3209                   [  \"gradient_checkpointing\": true,]\n",
       "3210     [training_args = TrainingArguments(\\r\\n  outpu...\n",
       "3211                                                   NaN\n",
       "3212                              [batch size, image size]\n",
       "3213     [python3 val.py --weights ./weights/yolov5l-xs...\n",
       "3214        [import torch\\r\\ntorch.cuda.empty_cache()\\r\\n]\n",
       "3215     [f1-score, f1-score, f1 = acc, f1 != acc,  fro...\n",
       "3216     [from sklearn.metrics import accuracy_score as...\n",
       "3217     [view, ft, ft.view(-1, 6)\\r\\nOut[]:\\r\\ntensor(...\n",
       "3218     [view, # setting up\\r\\n import torch\\r\\n impor...\n",
       "3219                                                   NaN\n",
       "3221     [sudo apt-get --purge remove \"*cublas*\" \"cuda*...\n",
       "3222                                      [device_count()]\n",
       "3223                                                   NaN\n",
       "3224                                   [print(a.data)\\r\\n]\n",
       "3225     [import torch, from torch import nn, a=nn.Para...\n",
       "3226                                                   NaN\n",
       "3227     [hidden = (torch.zeros(self.num_layers, self.h...\n",
       "3229                                                   NaN\n",
       "3230                                                   NaN\n",
       "3231                                                   NaN\n",
       "3232     [import torch\\r\\nt = torch.randn((32, 16, 60, ...\n",
       "3233     [waitKey, imshow, waitKey, imshow, waitKey, wa...\n",
       "3234     [cv2.imshow(\"window\", img)\\r\\ncv2.waitKey(1)  ...\n",
       "3235     [import numpy as np\\r\\nmean = np.array([0.485,...\n",
       "3237                                                   NaN\n",
       "3238     [transforms = A.Compose([\\r\\n                A...\n",
       "3239     [import albumentations as A\\r\\nimport cv2 \\r\\n...\n",
       "3240     [import os\\r\\nimport json\\r\\nimport sys\\r\\nimp...\n",
       "3241     [Z ~ Uniform(0,1), a, b, a &lt; b, X = Z * (b ...\n",
       "3242                                                   NaN\n",
       "3243     [import pandas as pd\\r\\nimport torch\\r\\nfrom d...\n",
       "3244                                                   NaN\n",
       "3245     [.cpu(),  with torch.no_grad():\\r\\n        for...\n",
       "3246                                                   NaN\n",
       "3247     [train(train_sampler, model, loss_fn, optimize...\n",
       "3248     [mean = [0.485, 0.456, 0.406], std = [0.229, 0...\n",
       "3249                                                   NaN\n",
       "3250                                                   NaN\n",
       "3253                                                   NaN\n",
       "3254                                                   NaN\n",
       "3255                                                   NaN\n",
       "3256                                                   NaN\n",
       "3257     [self.hidden, torch.tensors, .to(device), to(s...\n",
       "3258                                                   NaN\n",
       "3259                                                   NaN\n",
       "3260                                                   NaN\n",
       "3261                                                   NaN\n",
       "3262                                                   NaN\n",
       "3263     [import torch\\r\\nimport numpy\\r\\nfrom sklearn....\n",
       "3265     [.unsqueeze(0), embed_dim = 4\\r\\nnum_heads = 1...\n",
       "3266                                                   NaN\n",
       "3268     [pos_weight, BCEWithLogitsLoss, pos_weight, to...\n",
       "3269     [data.to(device), 0, cuda, 'cpu') #pass your a...\n",
       "3270                                                   NaN\n",
       "3271     [plt.hist(t, bins=2), t.numpy(), t.tolist(), t...\n",
       "3272     [self.fc2, self.fc2, criterion = nn.BCELoss(),...\n",
       "3273     [torch.cat, torch.reshape, a = torch.rand(8,2)...\n",
       "3274                                                   NaN\n",
       "3275     [state[[0,1]] = state[[1,0]] # in-place operat...\n",
       "3276     [x_train, y_train, from torch.utils.data impor...\n",
       "3277                                                   NaN\n",
       "3278     [argmax, argsort, a = torch.randn(5, 3)\\r\\npre...\n",
       "3279                                                   NaN\n",
       "3280                                                   NaN\n",
       "3281     [print(a+b), torch(a+b), a, b, import torch\\r\\...\n",
       "3282     [print(np.allclose(tf_out.numpy(), pt_out.nump...\n",
       "3283                                                   NaN\n",
       "3284     [step_output, loss = self.forward_to_loss(step...\n",
       "3285                                                   NaN\n",
       "3286                                                   NaN\n",
       "3287     [import torch.nn as nn\\r\\nfrom transformers im...\n",
       "3288                                                   NaN\n",
       "3289     [dist.all_gather, dist.all_gather, def all_gat...\n",
       "3290     [if __name__ == \"__main__\":\\r\\n    uvicorn.run...\n",
       "3292     [output, [[0.25, 0.45, 0.3],\\r\\n [0.45, 0.15, ...\n",
       "3293     [# Create training and validation datasets\\r\\n...\n",
       "3294                                                   NaN\n",
       "3295                                                   NaN\n",
       "3296                                                   NaN\n",
       "3297                                                   NaN\n",
       "3298     [tensor_a / tensor_b.unsqueeze(-1)\\r\\n, -1, se...\n",
       "3299     [tensor_id, for image, target in valid_data_lo...\n",
       "3300                                                   NaN\n",
       "3301     [densenet201, features.norm0.num_batches_track...\n",
       "3302     [__call__, nn.Module, class A():\\r\\n    def __...\n",
       "3303     [.get_device(), nn.Linear, print(next(l.parame...\n",
       "3304     [torch.gather, take_along_axis, idx, x = torch...\n",
       "3305                                                   NaN\n",
       "3306                                                   NaN\n",
       "3307     [self.fc = nn.Linear(in_features=20*18, out_fe...\n",
       "3308                                                   NaN\n",
       "3309     [torch.no_grad, W, b, requires_grad=True, W, b...\n",
       "3310     [forward, y = self.network(x), y = self.layer1...\n",
       "3311     [bin_count=torch.bincount(torch.where(output&g...\n",
       "3313                                                   NaN\n",
       "3314     [iou = torchvision.ops.box_iou(predictions['bo...\n",
       "3315                                         [IoU, python]\n",
       "3316     [layer_1 = model.get_layer( name=\"embedding_la...\n",
       "3318                                                   NaN\n",
       "3319     [def get_mean_std(loader):\\r\\n    # VAR[X] = E...\n",
       "3320     [classification_dataset.target_normalizer.clas...\n",
       "3321     [net_train, outputs,x= net(input_ids, attentio...\n",
       "3322                                                   NaN\n",
       "3323                                                   NaN\n",
       "3324     [def increaseClassifier( m: torch.nn.Linear ):...\n",
       "3325     [torch, import torch\\r\\n\\r\\nx = torch.randn(10...\n",
       "3326     [.backward(), .backward(), .backward(retain_gr...\n",
       "3327     [view(4, 2), t = torch.tensor([[1, 2],\\r\\n    ...\n",
       "3328                                                   NaN\n",
       "3329                                                   NaN\n",
       "3330                                                   NaN\n",
       "3331     [model = BertForSequenceClassification.from_pr...\n",
       "3332     [import torchmetrics\\r\\n\\r\\nfor step, (test_im...\n",
       "3333                                                   NaN\n",
       "3334                                                   NaN\n",
       "3335     [# Train Network\\r\\n  for _ in range(num_epoch...\n",
       "3336                                                   NaN\n",
       "3337     [class MyInterpreter(fx.Interpreter):\\r\\n    d...\n",
       "3338     [.unsqueeze(1), .unsqueeze(1), outputs, labels...\n",
       "3340     [COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_...\n",
       "3342     [u, y, v, x, u, y, v, x, allow_unused=False, t...\n",
       "3343       [configure_optimizer(), configure_optimizers()]\n",
       "3344                     [torchvision.models, torchvision]\n",
       "3345     [torchvision, torch.hub, timm, # list all ViT ...\n",
       "3346                                                   NaN\n",
       "3348                                                   NaN\n",
       "3349                                                   NaN\n",
       "3350     [nn.Conv2d(in_channels, 32, kernel_size= 3, pa...\n",
       "3351                                                   NaN\n",
       "3352                                                   NaN\n",
       "3353     [from torchtext import datasets\\r\\n\\r\\n, from ...\n",
       "3355                                                   NaN\n",
       "3356     [te_data, te_targets, torch.tensor, torch.tens...\n",
       "3357     [forward,   def forward(self, x):\\r\\n    out =...\n",
       "3358     [torch.save(model.state_dict(), filepath)   \\r...\n",
       "3360     [max-pooling, x.squeeze(0), import torch\\r\\nim...\n",
       "3361     [padding, (kernel_size - 1) / 2, kernel_size =...\n",
       "3362                                                   NaN\n",
       "3363                                                   NaN\n",
       "3365     [Z = getUpdatedZ(X, Z), Linear, optimizer.step...\n",
       "3366     [class StructuredParameter(nn.Module):\\r\\n  de...\n",
       "3367                                                   NaN\n",
       "3368                                                   NaN\n",
       "3370     [convert2version5 = True\\r\\nif convert2version...\n",
       "3371     [__init__, class Generator(nn.Module):\\r\\n  de...\n",
       "3372     [def initialise_weights(m):\\r\\n    if isinstan...\n",
       "3373     [class _ConvNd, init.kaiming_uniform_(self.wei...\n",
       "3374                                                   NaN\n",
       "3375     [repeat_interleave, reshape, res = a.repeat_in...\n",
       "3376     [[x for x in model.parameters()], [list(model....\n",
       "3377     [[Nx1], In [1]: import torch\\r\\n\\r\\nIn [2]: a ...\n",
       "3378     [flatten, \\r\\ntvalue=torch.tensor([[-5.6117e-0...\n",
       "3379                                                   NaN\n",
       "3380     [import soundfile as sf\\r\\nimport torch       ...\n",
       "3381                            [pip install -U numpy\\r\\n]\n",
       "3382                                                   NaN\n",
       "3383                                                   NaN\n",
       "3384     [torchvision.transforms, matplotlib.pyplot, to...\n",
       "3385     [docker run --gpus all  -it --entrypoint /bin/...\n",
       "3386     [x = torch.tensor([[1,-12],[0,4]],dtype=torch....\n",
       "3387                        [a[:4]=torch.round(a[:4])\\r\\n]\n",
       "3388     [t = torch.tensor([ 8.5040e+00,  7.3818e+01,  ...\n",
       "3389     [forward, out=out.flatten()\\r\\n, start_dim, ou...\n",
       "3390              [torch.fmod, torch.remainder, .detach()]\n",
       "3391     [y_pred = model(x), forward, Model, y_pred , f...\n",
       "3392     [device = torch.device('cpu')\\r\\nif torch.cuda...\n",
       "3394     [layerlist = []\\r\\nfor i in layers:\\r\\n    lay...\n",
       "3396     [scale_tril, covariance_matrix, scale_tril, co...\n",
       "3397     [torch.transpose, torch.reshape,  stack = torc...\n",
       "3398     [p1 = torch.concat((a,b),axis=1)\\r\\np2 = torch...\n",
       "3400     [onnx == 1.9.0\\r\\nonnxruntime == 1.8.1\\r\\npyto...\n",
       "3402     [data = torch.randn((1, 7, 7, 4))\\r\\ntarget = ...\n",
       "3403                                                   NaN\n",
       "3404                                                   NaN\n",
       "3405     [n, j, reshape, swapaxes, m = torch.tensor([[[...\n",
       "3406     [m = [[2, 3, 5, 7],\\r\\n     [11, 13, 17, 19],\\...\n",
       "3407                                                   NaN\n",
       "3408     [torch.cumsum, f(x,y,z) = x + y + z - z, f, z,...\n",
       "3409     [preds, preds = torch.tensor([[0., 0., 0.]]) #...\n",
       "3410     [def batch_cov(points):\\r\\n    B, N, D = point...\n",
       "3411     [weights = nn.Parameter(torch.rand(1,3))\\r\\nX ...\n",
       "3412                                                   NaN\n",
       "3414                                                   NaN\n",
       "3415     [x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])\\r\\...\n",
       "3416     [root, trainset = ImageFolder(root = '/media/d...\n",
       "3418     [f = open('config.yml','w')\\r\\nf.write(cfg.dum...\n",
       "3419     [x = torch.rand(3, requires_grad=True).reshape...\n",
       "3420     [    self.conv25 = nn.ConvTranspose1d(32, 24, ...\n",
       "3421     [16*54*54, 16*56*56, self.fc1 = nn.Linear(16*5...\n",
       "3422     [nn.Conv, nn.Linear, __init__, class _ConvNd(M...\n",
       "3423                                                   NaN\n",
       "3424                                                   NaN\n",
       "3425                                                   NaN\n",
       "3426     [RuntimeError: mat1 and mat2 shapes cannot be ...\n",
       "3427                [self.parameters, torch.nn.ModuleList]\n",
       "3428                                                   NaN\n",
       "3429                                                   NaN\n",
       "3430     [        t0, t1, mask_gt = batch\\r\\n        ma...\n",
       "3431                                                   NaN\n",
       "3433                                                   NaN\n",
       "3434                                                   NaN\n",
       "3435                                                   NaN\n",
       "3436                                                   NaN\n",
       "3437     [Conv1d, [batch, channels, features], features...\n",
       "3438     [(batch_size, shape), import torch\\r\\nimport t...\n",
       "3439                                                   NaN\n",
       "3440                                                   NaN\n",
       "3441                                                   NaN\n",
       "3442     [self.linear, nn.Linear, nn.Sequential, nn.Lin...\n",
       "3443     [def _make_convo_layers(architecture) -&gt; to...\n",
       "3444     [Precision: TP / (TP + FP)\\r\\nRecall:    TP / ...\n",
       "3445     [predicted_boxes (list): [[train_index, class_...\n",
       "3446     [import numpy as np\\r\\nimport torch\\r\\n\\r\\na =...\n",
       "3447     [map(), a = [[1,1,1], [2,2,2], [3,3,3]]\\r\\nb =...\n",
       "3448     [In [185]: a = [[1, 1, 1], [2, 2, 2], [3, 3, 3...\n",
       "3449     [reshape, permute, x = x.permute((1, 2, 0))\\r\\...\n",
       "3451                                    [cudaLaunchKernel]\n",
       "3452                                                   NaN\n",
       "3453                     [pip install torch-sparse==0.5.1]\n",
       "3454     [v_means, components = torch.IntTensor(torch.a...\n",
       "3455     [Fuses only the following sequence of modules:...\n",
       "3456     [a.grad, backward(), grad, backward(), with to...\n",
       "3457     [torch.argmax,  logits_tensor = torch.rand(191...\n",
       "3458     [%%time\\r\\nimport glob\\r\\nf=glob.glob('/conten...\n",
       "3460     [    pipenv install --extra-index-url https://...\n",
       "3461     [h = g(W1.input1 + V1.input2 + b), import torc...\n",
       "3462     [class NN(nn.Module):\\r\\n    def __init__(self...\n",
       "3463     [C = [[W_1   0]\\r\\n     [0   V_1]]\\r\\n, C = [[...\n",
       "3464     [CustomDataset, __getitem__, CustomDataset, Cu...\n",
       "3465     [nn.BCEWithLogitsLoss, outputs = model(\\r\\n  i...\n",
       "3466     [nn.BCEWithLogitsLoss, float, nn.CrossEntropyL...\n",
       "3467     [def wave_haar(in_t):\\r\\n    hh = nnf.conv2d(i...\n",
       "3468     [hh_k = torch.tensor([hc ,hr])[None, None, ......\n",
       "3469                                                   NaN\n",
       "3470     [truncating = True, def sentiment_analysis(row...\n",
       "3471     [torchvision.transform.Lambda, Lambda, nms_tra...\n",
       "3472     [threshold=0.5, 0.5, 0, num_classes=3, multicl...\n",
       "3473     [subset_accuracy=True, import torch, torchmetr...\n",
       "3475                                                   NaN\n",
       "3476     [wandb.config['my_variable'] = 123\\r\\n, save_h...\n",
       "3477     [x, n, 2, def f1(x):\\r\\n  z = x - x0  # z of s...\n",
       "3478     [class MixModel(nn.Module):\\r\\n    def __init_...\n",
       "3479     [params, to, retain_grad, params.retain_grad()...\n",
       "3480     [.to(), torch.tensor(), import torch\\r\\n\\r\\nde...\n",
       "3481                                                   NaN\n",
       "3482     [ model_state = torch.load(filePath+filename)[...\n",
       "3484     [summary, torchinfo, !pip install torchinfo\\r\\...\n",
       "3485                                                   NaN\n",
       "3486                                                   NaN\n",
       "3487                                                   NaN\n",
       "3488     [conda install ipykernel jupyter numpy pandas ...\n",
       "3489     [conda install nomkl, conda install &lt;packag...\n",
       "3490                                                   NaN\n",
       "3491     [params = list(model.parameters())\\r\\nparams.a...\n",
       "3492                                                   NaN\n",
       "3494     [torch, float32, float64, get_training_data_2,...\n",
       "3495     [import torch\\r\\nfrom torch import nn\\r\\n\\r\\nc...\n",
       "3496     [batch, seq-len, feature-dim, permute, x, batc...\n",
       "3498     [BCEWithLogitLoss, CrossEntropyLoss, #loss = c...\n",
       "3499                                                   NaN\n",
       "3500                                         [output_size]\n",
       "3501     [nn.CosineEmbeddingLoss, target, nn.CosineEmbe...\n",
       "3502     [    def __init__(self,pre_trained='distilbert...\n",
       "3503     [conda create -n (NameOfEnviroment) -c pytorch...\n",
       "3504     [retain_graph=True, create_graph=False, grad, ...\n",
       "3505     [output[target == 0] = 0\\r\\n, output = output ...\n",
       "3506                                                   NaN\n",
       "3507     [nn.Conv2d, import torch.nn.functional as nnf\\...\n",
       "3509     [model.eval(), forward, from typing import Tup...\n",
       "3510     [@torch.no_grad()\\r\\ndef evaluate_loss(model, ...\n",
       "3511     [def evaluate_loss(model, data_loader, device)...\n",
       "3512     [torch.utils.data.Subset, from torchvision imp...\n",
       "3513     [0, 1, train = datasets.MNIST('../data', train...\n",
       "3514                                                   NaN\n",
       "3515                           [(1500, 1), (7,1), softmax]\n",
       "3516                 [frequency domain, Fourier transform]\n",
       "3520     [torch.cumsum, C, B = torch.cat((torch.zeros_l...\n",
       "3521     [model = nn.Sequential(nn.Linear(784, 128),\\r\\...\n",
       "3522     [awk '/download/ {print $NF}' ./cookie, awk '/...\n",
       "3523     [nn.ModuleList, Net, self.hidden, Net, .to(dev...\n",
       "3524                                                   NaN\n",
       "3525     [tensor = torch.Tensor([[1., 0., 0., 0., 0.],\\...\n",
       "3527                                                   NaN\n",
       "3528                                                   NaN\n",
       "3529     [x, lst_tensors, import torch\\r\\nimport numpy ...\n",
       "3530     [ImageFolderWithPaths, datasets.ImageFolder, d...\n",
       "3531                                                   NaN\n",
       "3534     [import ssl\\r\\nssl._create_default_https_conte...\n",
       "3535     [A[:, B]\\r\\n, A[[0, 1, 2], B]\\r\\n, A[range(B.s...\n",
       "3536     [torch.gather,  indexer = B.view(-1, 1, 1).exp...\n",
       "3537                            [num_worker, num_worker=0]\n",
       "3538     [ 29   def validation_step(self, val_batch, ba...\n",
       "3539                                                   NaN\n",
       "3540                                                   NaN\n",
       "3541     [nn.Sequential( # NN architecture, where the m...\n",
       "3542     [torch.utils.data.TensorData, torch.utils.data...\n",
       "3544                                                   NaN\n",
       "3545                                                   NaN\n",
       "3546                   [labels, torch.long, torch.float32]\n",
       "3547     [import torch\\r\\n\\r\\ntorch.set_printoptions(li...\n",
       "3548                                                   NaN\n",
       "3549                                                   NaN\n",
       "3550     [def validation_step(self, batch, batch_idx):\\...\n",
       "3553     [Downloading https://ultralytics.com/assets/Ar...\n",
       "3554     [def forward(self, imgs,lead_time):\\r\\n    \"\"\"...\n",
       "3555     [xmin = xmax, ymin = ymax, xmax, ymax, boxes.a...\n",
       "3556     [pip install torch-summary\\r\\n\\r\\nsummary(mode...\n",
       "3557     [padding, output_padding, input = torch.randn(...\n",
       "3558     [Dataset, class JointImageDataset(torch.utils....\n",
       "3559                                                   NaN\n",
       "3560     [auto tensor = torch::zeros({80,434}, options)...\n",
       "3561                        [0, 1, 1, nn.CrossEntropyLoss]\n",
       "3563     [torch.no_grad, with torch.no_grad():\\r\\n    m...\n",
       "3564                                                   NaN\n",
       "3565     [torch.gather, torch.Tensor.argmin, torch.Tens...\n",
       "3566     [nn.DataParallel, \"model\", nn.Module,  model =...\n",
       "3567     [import torch\\r\\ntorch.manual_seed(1)\\r\\n\\r\\nb...\n",
       "3568     [attrbute_val = feature[:,:,3:4]\\r\\nprint(attr...\n",
       "3570     [height x width x n_channels, n_channels, matp...\n",
       "3571     [self.log(\"train_loss\", loss, prog_bar=True, o...\n",
       "3573     [forward, Encoder, for layer in self.layers:\\r...\n",
       "3574     [torch.cuda.Tensor, t3.device, t2.device, prin...\n",
       "3575                                                   NaN\n",
       "3576                                                   NaN\n",
       "3577                                                   NaN\n",
       "3578     [def Exec_ShowImgGrid(ObjTensor, ch=1, size=(2...\n",
       "3579     [returns = torch.tensor(returns)\\r\\nreturns = ...\n",
       "3581     [no_grad mode, grad mode enabled, a1, a, a = a...\n",
       "3582     [model_ft = models.resnet50(True)\\r\\nmodel_ft....\n",
       "3583                                                   NaN\n",
       "3584                                                   NaN\n",
       "3585                                                   NaN\n",
       "3586                                                   NaN\n",
       "3587     [requirements.txt, pip, https://download.pytor...\n",
       "3588     [pip install torch==1.8.1+cpu torchvision==0.9...\n",
       "3589     [torch==1.11.0+cpu\\r\\ntorchvision==0.12.0+cpu\\...\n",
       "3590     [--find-links https://download.pytorch.org/whl...\n",
       "3591                                                   NaN\n",
       "3592     [clone, def get_activation(name):\\r\\n    def h...\n",
       "3593     [pip install openvino-dev[pytorch,onnx]\\r\\n, d...\n",
       "3594                                                   NaN\n",
       "3595     [torch.Tensor.expand,  x = torch.rand(3)\\r\\n t...\n",
       "3596                                                   NaN\n",
       "3597     [import torch\\r\\nimport torchvision.models as ...\n",
       "3599                                                   NaN\n",
       "3600                                                   NaN\n",
       "3601                                                   NaN\n",
       "3602                                                   NaN\n",
       "3603                                                   NaN\n",
       "3604     [npx torchlive-cli doctor, Android SDK Manager...\n",
       "3606     [data = {'n': n, 'n': p, 'epoch': epoch} # etc...\n",
       "3607     [trainloader, for t in tqdm(range(10)):\\r\\n  f...\n",
       "3609     [    def forward(self, x):\\r\\n    x = self.hid...\n",
       "3610                                                   NaN\n",
       "3611     [__next__(), __dir__, cd, CustomDataset, __len...\n",
       "3612     [find -name \"lightning\", python -c \"import sys...\n",
       "3613                          [%conda, !conda, %pip, !pip]\n",
       "3614     [torch.isclose, correct_values = torch.isclose...\n",
       "3615     [padding='same', MaxPooling3D, MaxPool3d, MaxP...\n",
       "3616                                                   NaN\n",
       "3617                                                   NaN\n",
       "3618                                                [3000]\n",
       "3619                         [require_grad, requires_grad]\n",
       "3620     [a = torch.randn([32,100,50])\\r\\nb = torch.ran...\n",
       "3621     [import torch\\r\\n\\r\\nnet_params = torch.rand(5...\n",
       "3622     [pip==22.0.{0,1,2,3}, pip, pip3 --version, pip...\n",
       "3623                                                   NaN\n",
       "3624     [This means that some examples, such as the Po...\n",
       "3625     [p, imshow, dtype=torch.uint8, temp, # cell 1\\...\n",
       "3626     [out_features = 5  # Arbitrary for the example...\n",
       "3627     [m/(1-beta_m**i), m, m_hat, v, v_hat, m, v, fo...\n",
       "3628     [pip install split-folders\\r\\n\\r\\nimport split...\n",
       "3630                                                   NaN\n",
       "3631     [from typing import overload, Union\\r\\n\\r\\ncla...\n",
       "3632     [Union, from typing import Union\\r\\n\\r\\nclass ...\n",
       "3633                                                   NaN\n",
       "3634                                                   NaN\n",
       "3635                                                   NaN\n",
       "3636     [function, deepcopy, (), state_dict, import co...\n",
       "3637     [x.py, # from y import RoBerta_CLS\\r\\nfrom y i...\n",
       "3638     [import neuralnet\\r\\n, from neuralnet import m...\n",
       "3639                                                   NaN\n",
       "3640     [dim=1, (temp[0,i], temp[1,i]), i, dim, torch....\n",
       "3641     [struct TestNet2 : torch::nn::Module {\\r\\n\\r\\n...\n",
       "3642     [a = torch.rand(M, N)\\r\\nm, n = a.shape\\r\\nxx,...\n",
       "3643     [    numpy_indices = torch.tensor([[0, 1, 2, 7...\n",
       "3645                                                   NaN\n",
       "3646     [ImageFolder, DatasetFolder, find_classes, Dat...\n",
       "3647     [def test(encoded_seq, y_label, model_path, mo...\n",
       "3648     [long, seqs[prev_word_inds].long()\\r\\n, seqs[p...\n",
       "3649     [def tokenize_function(examples):\\r\\n    retur...\n",
       "3650     [tqdm, for epoch in range(start_epoch,\\r\\n    ...\n",
       "3651     [loss=0, loss.backward()\\r\\noptimizer.step()\\r...\n",
       "3652     [model=simple_net, params=linear_model.paramet...\n",
       "3653     [nvcc --version, conda install pytorch torchvi...\n",
       "3654     [cpu-only, torchvision torchaudio, conda insta...\n",
       "3655     [bcik,bckj-&gt;bc, matmul, nqhd,nkhd-&gt;nhqk,...\n",
       "3656                                                   NaN\n",
       "3657                                                   NaN\n",
       "3658                                                   NaN\n",
       "3659     [/usr/local/lib/python3.7/dist-packages/seqeva...\n",
       "3660                                                   NaN\n",
       "3661     [item, one-element tensor, sum(), item(), x = ...\n",
       "3662                                                   NaN\n",
       "3663                                                   NaN\n",
       "3664     [from typing import Union, Iterable\\r\\nimport ...\n",
       "3665     [#Set Parameters for a small LSTM network\\r\\ni...\n",
       "3666     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "3667                                                   NaN\n",
       "3668     [torch.fft.fftshift, torch.fft.ifftshift, impo...\n",
       "3669     [   target =  [[1,0,0],[0,1,0],[0,0,1],...]\\r\\...\n",
       "3670     [features = [1., 2., 5., 6.]\\r\\nprint(\"mean {}...\n",
       "3671     [inputs, labels = data[0], data[1]\\r\\n, inputs...\n",
       "3672                                                   NaN\n",
       "3673                     [Variable(), tkinter, Variable()]\n",
       "3674                                                   NaN\n",
       "3675     [x = torch.permute(0, 3, 1, 2), import torch\\r...\n",
       "3676     [gather_nd, gather, indices = tf.transpose(tf....\n",
       "3677     [multiclass=False, average=\"binary\", from skle...\n",
       "3678                                                   NaN\n",
       "3679     [# if not isinstance(param_groups[0], dict):\\r...\n",
       "3680     [def configure_optimizers(self):\\r\\n        pa...\n",
       "3681     [w, sp_mat, t, w = torch.sparse_coo_tensor(\\r\\...\n",
       "3682                                                   NaN\n",
       "3683     [view, .view(-1,...)\\r\\n, [0, 1, 2], [1] * 3\\r...\n",
       "3684                                   [SGD, model, model]\n",
       "3685                                                   NaN\n",
       "3686                                                   NaN\n",
       "3687     [.numel(), numel(), defined(), numel(), torch:...\n",
       "3689                                         [grid_sample]\n",
       "3690     [diag_embed, temp = torch.diag_embed(scale)\\r\\...\n",
       "3691                                                   NaN\n",
       "3692     [torch.distributions.Normal, normal, In [89]: ...\n",
       "3693                                                   NaN\n",
       "3694                                                   NaN\n",
       "3695     [x, x, y = ... # get one image from MNIST\\r\\nx...\n",
       "3696                     [pip install numpy --upgrade\\r\\n]\n",
       "3698                                                   NaN\n",
       "3699                [model= torchvision.models.resnet50()]\n",
       "3700     [class AlexNet(nn.Module):\\r\\n    def __init__...\n",
       "3701                                                   NaN\n",
       "3702     [train_label_weight, torch.float64, torch.floa...\n",
       "3704                                                   NaN\n",
       "3706                                                   NaN\n",
       "3707     [MNIST, import torch\\r\\nfrom torch import nn\\r...\n",
       "3708     [RandomNoise, transform, class RandomNoise(obj...\n",
       "3709     [return, noisy_data, mnist_trainset = datasets...\n",
       "3710                                                   NaN\n",
       "3711           [--cbase=16384\\r\\n, python \"train.py\" ... ]\n",
       "3712     [[], {}, float row[] = { 0.190625, 0.957468297...\n",
       "3714     [from onnx import optimizer\\r\\n, import onnxop...\n",
       "3715     [cmake .. -DTORCH_PATH=/home/andrei/miniconda3...\n",
       "3716                                                   NaN\n",
       "3717                                                   NaN\n",
       "3718                                                   NaN\n",
       "3719                                                   NaN\n",
       "3720     [tf.data.Dataset, # Following is the pre-proce...\n",
       "3721     [num_classes = 2\\r\\n# Step 1.\\r\\nmodel = torch...\n",
       "3722                                                   NaN\n",
       "3723     [0, import torch\\r\\n\\r\\nt = torch.tensor(\\r\\n ...\n",
       "3725     [y_est, y, y_est, y, y_est, import torch\\r\\nba...\n",
       "3726                                                   NaN\n",
       "3727                                                   NaN\n",
       "3728     [double, double, float, float64, float, torch....\n",
       "3730                   [list(net.module.parameters())\\r\\n]\n",
       "3732     [def perturb_patch(img, patch_idx, patch_size,...\n",
       "3733             [x = torch.tensor(d, requires_grad=True)]\n",
       "3734             [MemReader, std::strstreambuf, get(char)]\n",
       "3735     [blocks, nn.Sequential, nn.Sequential, blocks[...\n",
       "3736                                                   NaN\n",
       "3737     [std::vector, torch::Tensor, int a = 10;\\r\\nin...\n",
       "3738                                                   NaN\n",
       "3739     [feature_extractor, self.feature_extractor = n...\n",
       "3740                                                   NaN\n",
       "3741     [from azureml.core.model import Model, model.r...\n",
       "3742                                                   NaN\n",
       "3743                                                   NaN\n",
       "3744     [noise = torch.randn(1, nz, 1, 1, device=devic...\n",
       "3745     [dataloader, BatchSampler, Sampler, DataLoader...\n",
       "3746                                                   NaN\n",
       "3747                                                   NaN\n",
       "3748     [ x -= a, x = x - a, x, with torch.no_grad():\\...\n",
       "3749                                                   NaN\n",
       "3750                                                   NaN\n",
       "3751                                                   NaN\n",
       "3752                                                   NaN\n",
       "3753                                                   NaN\n",
       "3754                        [torch.Size([10, 10, 3, 256])]\n",
       "3756                                                   NaN\n",
       "3757                                                   NaN\n",
       "3759                                                   NaN\n",
       "3760     [def toDigit(l):\\r\\n    z = 1\\r\\n    s = 0\\r\\n...\n",
       "3761     [nn.BCEWithLogitsLoss, F.binary_cross_entropy_...\n",
       "3762     [device = torch.device('cuda')\\r\\n\\r\\n# transf...\n",
       "3763     [torch.repeat_interleave, import torch\\r\\n\\r\\n...\n",
       "3764     [__getitem__, class D(Dataset):\\r\\n    def __i...\n",
       "3765                                           [data.size]\n",
       "3766                                                   NaN\n",
       "3767                                                   NaN\n",
       "3769                                                   NaN\n",
       "3770                                                   NaN\n",
       "3771     [loss = criterion(outputs, torch.max(labels,1)...\n",
       "3772                                                   NaN\n",
       "3773     [nn.Linear(1, 13), nn.Linear(3, 13), unsqueeze...\n",
       "3774     [torch.nn.Module, LightningModule, trainer.fit...\n",
       "3775                                                   NaN\n",
       "3776     [tokenizer.add_tokens([f\"_{n}\" for n in range(...\n",
       "3777                                                   NaN\n",
       "3778                                                   NaN\n",
       "3780     [mp.spawn, torch.multiprocessing.spawn, fn(i, ...\n",
       "3781                                                   NaN\n",
       "3782     [torch.gather, tf.gather_nd, import tensorflow...\n",
       "3783     [import random\\r\\nimport numpy as np\\r\\nimport...\n",
       "3785                                                   NaN\n",
       "3786                                                   NaN\n",
       "3787     [RandLike, RandReferenced, import torch\\r\\nfro...\n",
       "3788     [nn.Parameter, nn.Module, nn.init.xavier_normal_]\n",
       "3789                                                   NaN\n",
       "3790                                                   NaN\n",
       "3791     [requires_grad, L, S, S, L, S.grad, L = torch....\n",
       "3792     [model, OrderedDict, nn.Module, eff_net = Effi...\n",
       "3793     [a[vector_norm(a,dim=1) &lt; thr] = 0, thr, im...\n",
       "3794                                                   NaN\n",
       "3795     [classifier(), cross_entropy(), X, final_hidde...\n",
       "3797                                                   NaN\n",
       "3798                                                   NaN\n",
       "3800     [transform, FashionMNIST, train_dataset = torc...\n",
       "3801                                                   NaN\n",
       "3802     [Module, cuda, Module, Parameter, Loss, cuda, ...\n",
       "3803     [scatter_add, In [54]: value = torch.zeros(3)\\...\n",
       "3804                                                   NaN\n",
       "3805                                                   NaN\n",
       "3806                                                   NaN\n",
       "3807     [nn.CrossEntropyLoss, #C, y_pred, y_pred, q_i,...\n",
       "3808     [from torch.hub import load_state_dict_from_ur...\n",
       "3809                       [60, total_timesteps, 1e5, 1e6]\n",
       "3810     [A, A, ind1, ind2, ind3,  ind = torch.stack((i...\n",
       "3811       [h, h = h.detach()\\r\\ndata = data.detach()\\r\\n]\n",
       "3812                                                   NaN\n",
       "3813     [self.gru.forward, hx, None, self.hidden, init...\n",
       "3814     [config.yaml, reload.py, base_config_cs, confi...\n",
       "3815                                                   NaN\n",
       "3817     [pip3 install --pre torch -f https://download....\n",
       "3818     [ f = nn.Tanh()\\r\\n output = f(x)\\r\\n, nn.Tanh...\n",
       "3819                [def f(x):\\r\\n  return nn.Tanh(x)\\r\\n]\n",
       "3820                                                   NaN\n",
       "3821     [conda install pytorch==1.5.0 torchvision==0.6...\n",
       "3822                           [&gt;= 1.17, 1.10.2, torch]\n",
       "3823     [nn.Module, torch.Tensor, cloned_model = copy....\n",
       "3825     [import torch\\r\\nimport torch.multiprocessing ...\n",
       "3826     [grouped_entities=True, self.nlp = pipeline(\"n...\n",
       "3827                                                   NaN\n",
       "3828     [ torch.rand(1,3,64,64).numel()\\r\\n12288\\r\\n 1...\n",
       "3829     [t2 = torch.nn.AvgPool2d(1, stride=1)(t)\\r\\n, ...\n",
       "3830                                                   NaN\n",
       "3833                                                   NaN\n",
       "3834                                                   NaN\n",
       "3836                                                   NaN\n",
       "3837                                                   NaN\n",
       "3838     [.size, .shape, if, elif, else, transpose(), i...\n",
       "3839     [    for class_path in file_list:\\r\\n        c...\n",
       "3840     [E, y, E, E + 100, X, indexes = np.hstack([np....\n",
       "3841     [N, BS, S = 10000, 1000, 100\\r\\nX = np.random....\n",
       "3843                                                   NaN\n",
       "3844                                                   NaN\n",
       "3845                                                   NaN\n",
       "3846     [.from_pretrained(), from transformers import ...\n",
       "3847                                                   NaN\n",
       "3850                                                   NaN\n",
       "3851                                                   NaN\n",
       "3852     [zero_(), w.grad.requires_grad == False, w.gra...\n",
       "3853     [np.load, X, ToTensor(), ByteTensor, __getitem...\n",
       "3854                                                   NaN\n",
       "3855     [accuracy_mult, predict(), def predict_labels(...\n",
       "3856     [linux-aarch64, linux-aarch64, beautifulsoup4,...\n",
       "3857                                                   NaN\n",
       "3858     [torch.matmul, bik,bkj-&gt;bij\\r\\n, k, ijp ? k...\n",
       "3859                           [self.data.iloc[index, 30]]\n",
       "3860     [.astype(np.float32), self.data = pd.read_csv(...\n",
       "3861                                                   NaN\n",
       "3862     [torch::Tensor CVtoTensor(cv::Mat img,int unsq...\n",
       "3863                                                   NaN\n",
       "3864                                                   NaN\n",
       "3865                                                   NaN\n",
       "3866     [hl.build_graph(model, t.zeros([10, 1])).build...\n",
       "3867                                                   NaN\n",
       "3868                                                   NaN\n",
       "3869     [index, 1, 2, input, torch.gather, input,  x =...\n",
       "3870     [self.fc1 = nn.Linear(73034, 120)\\r\\n, [(heigh...\n",
       "3871     [torch.flatten, x = torch.flatten(x,1)\\r\\nprin...\n",
       "3872         [ corr4d = model(batch.cuda())\\r\\n, 'cuda:0']\n",
       "3873     [conv2, (1, 64, 5, 5), (1, 64, 21, 21), fc1, 2...\n",
       "3874     [unfold, 768 == 3 * 16 * 16, img.reshape(1, 3,...\n",
       "3875                                                   NaN\n",
       "3876        [y = self._y[index, :], y = self._y[index], :]\n",
       "3878                                                   NaN\n",
       "3879     [Dataset, class MyDataSet(torch.utils.data.Dat...\n",
       "3880     [GLuint w_pbo[2];\\r\\n\\r\\n // Create pbo object...\n",
       "3882                                                   NaN\n",
       "3884                                                   NaN\n",
       "3885                                                   NaN\n",
       "3887       [y, y_hat = round(pred), __getitem__, __iter__]\n",
       "3888                                                   NaN\n",
       "3889                                                   NaN\n",
       "3890     [__init__, for i in range(len(self.data) - 1, ...\n",
       "3891     [__getitem__, class SkipBadItems(Dataset):\\r\\n...\n",
       "3892                                                   NaN\n",
       "3893     [nvcc -V, C:\\Users\\User&gt;nvcc -V\\r\\nnvcc: NV...\n",
       "3896                                                   NaN\n",
       "3897     [numpy, torch.from_numpy, torch.from_numpy, np...\n",
       "3898     [Tensor, numpy.array(), list(), np.mean(train_...\n",
       "3899                                                   NaN\n",
       "3900     [nn.Module, forward(), ConvNeuralNet, class Co...\n",
       "3903     [from torch import tensor, eye, sqrt, zeros, l...\n",
       "3904     [transform, self.transform, None, __getitem__,...\n",
       "3905     [transform = transforms.Compose([\\r\\n    trans...\n",
       "3906     [x, (64, 768, 2, 2), 3072, fc1, 64, fc1, fc2, ...\n",
       "3907     [Normalize, output = (input - mean) / std, Nor...\n",
       "3908     [torch.cartesian_prod(*tensors), /opt/conda/li...\n",
       "3909                                                   NaN\n",
       "3910                                                   NaN\n",
       "3911     [step0, step1, # Memory intensive part\\r\\nstep...\n",
       "3912                                   [ReduceLROnPlatuea]\n",
       "3913     [optimizer_kwargs, lr_scheduler_cls, from dart...\n",
       "3914     [gen_loss, gen_optimizer.step(), zero_grad, # ...\n",
       "3915        [with torch.no_grad():\\r\\n    /*my code*/\\r\\n]\n",
       "3916                                                   NaN\n",
       "3917                                                   NaN\n",
       "3918                                                   NaN\n",
       "3919     [from tensorflow.keras.models import Sequentia...\n",
       "3921     [torch.nn.functional.conv2d(input, weight), un...\n",
       "3922     [pycrypto, pycrypto, pip install -U steem\\r\\n,...\n",
       "3923     [pip install, setuptools, pip install, pip ins...\n",
       "3924                  [pip install python_package.whl\\r\\n]\n",
       "3925     [conda install libpython m2w64-toolchain -c ms...\n",
       "3926     [3e0de8af516c15547602977db939d8c2e44fcc0b  vis...\n",
       "3927                            [pip install pycryptodome]\n",
       "3928                               [vc_redist, pip, wheel]\n",
       "3929     [py -m pip install pipwin\\r\\npy -m pipwin inst...\n",
       "3930               [pip install &lt;your_lib_name&gt;\\r\\n]\n",
       "3931     [nodejs, install chocolatey and other necessar...\n",
       "3932                                                   NaN\n",
       "3933     [import random \\r\\nimport torch\\r\\nlist_number...\n",
       "3934     [{0, 1}, [0, 1], [10, 100], x -&gt; (b-a)x + a...\n",
       "3935     [inputs = torch.randn(1, 1, 4, 4)\\r\\nfc = torc...\n",
       "3936     [OrderedDict, Linear, hidden_layer, nn.Tanh, i...\n",
       "3937     [class Trainer():\\r\\n     def __init__(self,pa...\n",
       "3939     [[N,C,H,W], N, C, H, W, Conv2d, N, C, in_chann...\n",
       "3940     [import numpy as np\\r\\n# a list of lists\\r\\na ...\n",
       "3941     [model.load_state_dict(model_params,strict=Fal...\n",
       "3942                                                   NaN\n",
       "3943     [fold, unfold, # divide the batch of images in...\n",
       "3944     [DataLoader2, torch.utils.data.DataLoader2, to...\n",
       "3945                                                   NaN\n",
       "3946     [torch.utils.data.Sampler, batch_sampler, Data...\n",
       "3947     [torch.utils.data.sampler.Sampler, BucketSampl...\n",
       "3949     [download=True, root, augmented_data[0], matpl...\n",
       "3950                                                   NaN\n",
       "3951     [getattr(models, 'resnet152'), models.resent15...\n",
       "3952                                                   NaN\n",
       "3953     [sample[cat_indices].reshape(cat_indices.shape...\n",
       "3954     [import torch\\r\\nfrom models.deit import deit_...\n",
       "3955     [In [7]: x = torch.arange(12).view(4,3).float(...\n",
       "3956     [nvidia-smi\\r\\n, Sat Apr  4 15:31:57 2020     ...\n",
       "3961     [reload(), importlib.reload(sys.modules.get(Fe...\n",
       "3962         [datasets.MNIST, adjusted_df, datasets.MNIST]\n",
       "3963     [x --- | state_mapper | --&gt; y --- | ur5 | -...\n",
       "3964     [DATALOADER:\\r\\n    SAMPLER_TRAIN: \"RandomSubs...\n",
       "3965                                                   NaN\n",
       "3966                                                   NaN\n",
       "3967                                                   NaN\n",
       "3968                                                   NaN\n",
       "3970                                                   NaN\n",
       "3971     [python3,  from torch import linalg as LA\\r\\n ...\n",
       "3972     [Tensor.index_put, import torch\\r\\ndata = torc...\n",
       "3974                                 [x = x.view(1, 1479)]\n",
       "3975     [torch.jit.script, traced_NN = torch.jit.scrip...\n",
       "3976                                                   NaN\n",
       "3977                                                   NaN\n",
       "3979     [[512, 14, 14], [3, 224, 224], [3, 244, 244], ...\n",
       "3980     [image = torch.zeros((1,3,244,244)).cuda()\\r\\n...\n",
       "3982     [model.start = nn.Sequential(\\r\\n             ...\n",
       "3983     [conda-forge/cudatoolkit-dev, $ wget https://d...\n",
       "3984            [out, self.classifier, print, out, in_dim]\n",
       "3985     [GroupConv1D, self.conv_list, nn, nn.Module, ....\n",
       "3986     [torch.cat,     def forward(self, x):\\r\\n     ...\n",
       "3987     [import torch, torchvision as tv\\r\\nmodel = tv...\n",
       "3988     [__matmul__, torch.bmm, v, None, v[..., None],...\n",
       "3989     [(batch_size, channel_size, length),  train = ...\n",
       "3990     [def sync_initial_weights(model, rank, world_s...\n",
       "3992                                                   NaN\n",
       "3993                                                   NaN\n",
       "3995     [class Images_Dataset_folder(Dataset):\\r\\n    ...\n",
       "3996                                                   NaN\n",
       "3997                                                   NaN\n",
       "3998     [std::max_element, #include &lt;algorithm&gt;\\...\n",
       "4000     [unique_dim repo:pytorch/pytorch,  17: _builti...\n",
       "4001     [\\r\\n&gt; import os os.environ[\"CUDA_VISIBLE_D...\n",
       "4002     [self.beams_buf_float.type(torch.LongTensor), ...\n",
       "4003                                                   NaN\n",
       "4004                                                   NaN\n",
       "4005                                                   NaN\n",
       "4006                                                   NaN\n",
       "4007     [B, L, C, H, W = inp_seq.shape\\r\\nref_seq = to...\n",
       "4008                                                   NaN\n",
       "4009     [conda install pytorch torchvision torchaudio ...\n",
       "4011                                                   NaN\n",
       "4012                                                   NaN\n",
       "4013     [outputs, \"val_loss\", \"val_acc\", # This path, ...\n",
       "4014     [pytorch_lightning, validation_epoch_end(), va...\n",
       "4015     [tf.math.top_k, k, import tensorflow as tf\\r\\n...\n",
       "4016                                                   NaN\n",
       "4017     [Step 0: Train a Model in Keras. ...\\r\\nStep 1...\n",
       "4018                                                   NaN\n",
       "4019     [torch.unique, torch.nonzero, T1 = ...\\r\\nvalu...\n",
       "4020                                                   NaN\n",
       "4022     [inputs, labels = next(iter(test_loader))\\r\\n,...\n",
       "4023     [torch.onnx.export, from onnxruntime.transform...\n",
       "4024                                                   NaN\n",
       "4025     [from apex.parallel import DistributedDataPara...\n",
       "4026                                                   NaN\n",
       "4027                                [requires_grad = True]\n",
       "4029     [num_ftrs = self.axial.model.classifier[0].in_...\n",
       "4030                                                   NaN\n",
       "4032     [torch.roll,  x = torch.arange(1, 16).reshape(...\n",
       "4033               [torch.stack(), X = torch.stack(X)\\r\\n]\n",
       "4037                                                   NaN\n",
       "4039     [import numpy as np, outputs_x_select = torch....\n",
       "4042                                                   NaN\n",
       "4043                                                   NaN\n",
       "4044     [class PyTorchKnowledgeDistillationLoss(Knowle...\n",
       "4045                                                   NaN\n",
       "4047     [tensor.scatter_(), x = torch.zeros(3,4)\\r\\nn_...\n",
       "4048     [train_hidden_states, train_hidden_states.appe...\n",
       "4049                         [embbeding.detach(), outputs]\n",
       "4051     [backward, pred.max(1).indices, pred.argmax(1)...\n",
       "4052                                                   NaN\n",
       "4053     [indices = scores.argmax(dim=1)\\r\\nselection =...\n",
       "4054     [actor, SomeDistribution, detach, x, requires_...\n",
       "4056                                                   NaN\n",
       "4058                                                   NaN\n",
       "4059                              [torch.save, state_dict]\n",
       "4060     [Sequential,     def forward(self, input):\\r\\n...\n",
       "4061     [Module, add5 = Add(5), Add, add5, 5, Add, __i...\n",
       "4062                                                   NaN\n",
       "4063                                                   NaN\n",
       "4065                                                   NaN\n",
       "4066     [pytorch, from torchvision.transforms import R...\n",
       "4068     [test_epoch_end, def test_step(self, test_batc...\n",
       "4069      [self.i2h, self.i2o, self.i2h, hidden, self.i2h]\n",
       "4070              [model.cuda()\\r\\nmodel.parameters()\\r\\n]\n",
       "4071                                                   NaN\n",
       "4072     [pyg_graph, torch_geometric.data.Data, Data, _...\n",
       "4074     [self.vector = nn.Parameter(self.vector / torc...\n",
       "4075                                                   NaN\n",
       "4076     [resnet.eval(), import torch\\r\\nfrom torchvisi...\n",
       "4077     [io-binding, onnxruntime-gpu, CUDA EP, Tensort...\n",
       "4079                                                   NaN\n",
       "4080     ['word2vec.kv', 'word2vec.kv', .save(), 'word2...\n",
       "4081                                                   NaN\n",
       "4082     [next(model.parameters()).is_cuda, False, devi...\n",
       "4085                                                   NaN\n",
       "4086                                                   NaN\n",
       "4087     [DistributedSampler, import torch\\r\\nfrom torc...\n",
       "4088                                                   NaN\n",
       "4089     [python export.py --weights yolov5s.pt --inclu...\n",
       "4092     [# !pip install onnx onnxruntime-gpu \\r\\nimpor...\n",
       "4093                                [model.mar, model.mar]\n",
       "4094     [model.eval()\\r\\nFX      = []\\r\\nprint('\\nGene...\n",
       "4096                                                   NaN\n",
       "4097     [ elbo = torch.tensor(0, dtype=torch.float), e...\n",
       "4098     [fe, fc, loss2, fc, loss1, fc, fe, fc, loss1, ...\n",
       "4099                                                   NaN\n",
       "4100                                                  [-1]\n",
       "4101     [zy = 2 * xy[target_mask]\\r\\nxy[target_mask] =...\n",
       "4103     [Linear, # out = layer2(layer1(x))\\r\\n# given ...\n",
       "4104     [tensor = torch.Tensor([[[1, 0, 0, 7], [0, 1, ...\n",
       "4105     [pip install torch==1.9.0+cu111 torchvision==0...\n",
       "4106                                                   NaN\n",
       "4107     [model(x), model = torch.hub..., 1 x 384, line...\n",
       "4108                                                   NaN\n",
       "4109                                                   NaN\n",
       "4111                                                   NaN\n",
       "4112     [def foo(x, y, mode: bool = 0):\\r\\n    lib = t...\n",
       "4113                                                   NaN\n",
       "4114                                                   NaN\n",
       "4115                                        [Tensor, list]\n",
       "4116     [Error getting real path: 2, myscript.py, SIGA...\n",
       "4117                                                   NaN\n",
       "4118                                                   NaN\n",
       "4120     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "4121     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "4122                                                   NaN\n",
       "4124     [Conv1D, [1,x,x**2], Linear, n=3,  self.poly =...\n",
       "4125     [pkl, pt, pt, dict, ['g', 'g_ema', 'd', 'laten...\n",
       "4126                                                   NaN\n",
       "4127                                                   NaN\n",
       "4128     [...\\r\\nfrom torch.utils.data import Subset, D...\n",
       "4129     [class_weights=torch.tensor([0.21, ...], requi...\n",
       "4131     [tensors = [t1, t2, t3, ...]\\r\\nresult = torch...\n",
       "4132     [lin, gc1 = GCNConv(18, 16)\\r\\nspectral_norm(g...\n",
       "4133     [grad_list.append(target_model.fc1.weight.grad...\n",
       "4134                                                   NaN\n",
       "4135     ['TITLE', 'group_0', 'group_0', .visit(), .vis...\n",
       "4136     [__getitem__, y, X, idx, batch_y = np.array(ra...\n",
       "4137     [# install torchreid (don't need to re-build i...\n",
       "4138     [Y.grad, dL/dY, dL_over_dy, Z = X @ Y, @, matm...\n",
       "4139      [target, dict, \"boxes\", target, string, Dataset]\n",
       "4140                                                   NaN\n",
       "4141                                                   NaN\n",
       "4142                    [Dataparallel, tgt_mask, tgt_mask]\n",
       "4143                                                   NaN\n",
       "4144     [auto&amp; state = static_cast&lt;torch::optim...\n",
       "4145     [import torch\\r\\n\\r\\nt = torch.Tensor([12, 6, ...\n",
       "4146     [return_inverse, unique, import torch\\r\\n\\r\\nx...\n",
       "4147     [__init__, __getitem__, [], __len__, len, Data...\n",
       "4148     [__getitem__, __getitem__, list, tuple, class ...\n",
       "4149     [.clone(),  import sys\\r\\n import torch\\r\\n te...\n",
       "4150     [loss.backward(), autograd.grad(), backward(),...\n",
       "4151                                                   NaN\n",
       "4152     [ValueError: Unsupported ONNX opset version N,...\n",
       "4153     [try, var = 0\\r\\nif random.uniform(0, 1) &lt; ...\n",
       "4154     [n, c, ncuv,nctv-&gt;nctu, import torch\\r\\nx =...\n",
       "4155     [.pth, state_dict, class liteBDRAR(pl.Lightnin...\n",
       "4156     [path = './ckpt/BDRAR/3000.pth'\\r\\nbdrar = lit...\n",
       "4157     [class BDRAR(nn.Module), model, liteBDRAR(), s...\n",
       "4159     [import numpy as np\\r\\n\\r\\ndic = {\\r\\n  \"A\": [...\n",
       "4160     [for key in dic:\\r\\n    dic[key + \"1\"] = dic[k...\n",
       "4161     [ dic[\"A1\"]=dic[\"A\"][:8]\\r\\n dic[\"A2\"]=dic[\"A\"...\n",
       "4162     [from collections import ChainMap\\r\\n\\r\\nd = {...\n",
       "4165     [x.shape == [bs, 1, h, w], bs, x, [bs, h*w], [...\n",
       "4166     [import torch\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\...\n",
       "4167                                                   NaN\n",
       "4168                                                   NaN\n",
       "4169                                                   NaN\n",
       "4170                                                   NaN\n",
       "4171     [def manual_addition(xq1_int, scale1, zp1, xq2...\n",
       "4172     [torch.cat, x.T, temp, temp_vec = temp * torch...\n",
       "4173             [loss.backward()\\r\\noptimizer.step()\\r\\n]\n",
       "4174     [torch.backends.cudnn.enabled, import torch\\r\\...\n",
       "4175     [inputs = inputs.to(device)  \\r\\n, torch.nn.Mo...\n",
       "4176     [tokenizer.encode(article, return_tensors='pt'...\n",
       "4177                                                   NaN\n",
       "4178                                                   NaN\n",
       "4180                                                   NaN\n",
       "4181     [# Bert layers\\r\\ntext_input = tf.keras.layers...\n",
       "4182                                                   NaN\n",
       "4183                                                   NaN\n",
       "4184                                                   NaN\n",
       "4186                                                   NaN\n",
       "4188                                                   NaN\n",
       "4191                                                   NaN\n",
       "4192                                                   NaN\n",
       "4194     [y_pred, y_true,  torch.sub(y_true, y_pred[......\n",
       "4195                                                   NaN\n",
       "4196     [class LeNet(nn.Module):\\r\\n     def forward:\\...\n",
       "4198     [x = torch.round(x), x = torch.round(x), BCELo...\n",
       "4199                                                   NaN\n",
       "4201     [copy=True, nx.relabel_nodes, copy=False, nx.r...\n",
       "4202     [train_loss += loss, train_loss /= len(train_d...\n",
       "4203                                                   NaN\n",
       "4204                                                   NaN\n",
       "4205                                     [train_encodings]\n",
       "4206                                                   NaN\n",
       "4207     [class AutoEncoderNew(nn.Module):\\r\\n    def _...\n",
       "4208     [ignore_mismatched_sizes=True, model = tr.Robe...\n",
       "4209                                                   NaN\n",
       "4210                                                   NaN\n",
       "4211     [return nn.MSELoss()(state_action_values.float...\n",
       "4212                                                   NaN\n",
       "4213                                                   NaN\n",
       "4214     [ size_gb = 53760*224*32*32/1e9 #layer 1, 2, f...\n",
       "4216     [start, end, def function_maker(start, end):\\r...\n",
       "4217                                                   NaN\n",
       "4218     [sudo apt install nvidia-cuda-toolkit, nvcc --...\n",
       "4219     [cat /usr/local/cuda/version.txt, -f pip insta...\n",
       "4220     [DistillGPT2, N, 512/768, 768, DataLoader(), 3...\n",
       "4221     [MetadataCatalog.remove(\"coco_2017_train_panop...\n",
       "4222     [def collate_fn(batch):\\r\\n    data = batch[0]...\n",
       "4224     [training_step, def training_step(self, batch,...\n",
       "4225     [# L2 regularizers for layers\\r\\nmodel = keras...\n",
       "4226     [        # Forward propagate LSTM\\r\\n        o...\n",
       "4227                                                   NaN\n",
       "4228     [torch.tensor(), def training_step(self, train...\n",
       "4230     [(1 + tf.math.exp(10000 * outputs * labels))\\r...\n",
       "4231                                                   NaN\n",
       "4232                                                   NaN\n",
       "4233     [x_t, t=t0...tN, N, N x D, N, B, B x N x D, B,...\n",
       "4234     [def custom_loss(output, target):\\r\\n    prod ...\n",
       "4235                                                   NaN\n",
       "4237                                           [vis_utils]\n",
       "4238                                                   NaN\n",
       "4239                                 [device, (10,), (10)]\n",
       "4240                                                   NaN\n",
       "4242     [\"targets\": torch.tensor(self.target[item], dt...\n",
       "4243                                                   NaN\n",
       "4244                                          [run_clm.py]\n",
       "4245     [train_dataset, eval_dataset, torch.utils.data...\n",
       "4246     [...\\r\\nfrom torch.nn import ModuleList\\r\\n......\n",
       "4247     [inference.py, import os \\r\\nos.execute(\"pip i...\n",
       "4248                                                   NaN\n",
       "4249                                                   NaN\n",
       "4250                                                   NaN\n",
       "4251     [ x = torch.rand(1)\\r\\n y = torch.rand(1)\\r\\n ...\n",
       "4252                                                   NaN\n",
       "4253                                                   NaN\n",
       "4255                                                   NaN\n",
       "4256                                                   NaN\n",
       "4257     [act, def act(self, some_input, state):\\r\\n   ...\n",
       "4258                                                   NaN\n",
       "4259     [torchsummary.summary, torchsummary.summary, f...\n",
       "4260      [max_seq_length, max_seq_length, max_seq_length]\n",
       "4261     [test_dataset = datasets.MNIST(root='./mnist_d...\n",
       "4262           [Trainer, check_val_every_n_epoch, Trainer]\n",
       "4263                                                   NaN\n",
       "4264     [x.min(dim=-1), x.min(dim=-1).values, axis = -...\n",
       "4265                                         [True, False]\n",
       "4266     [spawn, fork, import multiprocessing as mp\\r\\n...\n",
       "4267     [matrix E, 1-E, E = torch.eye(adjacentMatrix.s...\n",
       "4268     [for local_batch, local_labels in train_loader...\n",
       "4269     [self.len = nb_samples / self.chunksize\\r\\n, /...\n",
       "4270               [seq_length, batch.shape[1], LSTM Cell]\n",
       "4271     [binary_cross_entropy_with_logits, binary_cros...\n",
       "4272                                                   NaN\n",
       "4273                                                   NaN\n",
       "4274     [[PAD], add_special_tokens, tokenizer = AutoTo...\n",
       "4275     [tokenizer = AutoTokenizer.from_pretrained(pre...\n",
       "4276                                                   NaN\n",
       "4277                                                   NaN\n",
       "4278     [MnistModel, self, nn.Module, __call__, MnistM...\n",
       "4281                                    [CrossEntropyLoss]\n",
       "4282     [if 0 in results.pandas().xyxy[0]['class']:\\r\\...\n",
       "4283                                                   NaN\n",
       "4284                 [head -n 1 /etc/nv_tegra_release\\r\\n]\n",
       "4285                                                   NaN\n",
       "4286                                                   NaN\n",
       "4287     [def transform(img_path):\\r\\n   img = self.loa...\n",
       "4288     [results.save(), results.save()\\r\\nimport cv2\\...\n",
       "4289     [  def drawRectangles(image, dfResults):\\r\\n  ...\n",
       "4290     [import cv2\\r\\n\\r\\nimg = cv2.imread(\"image_pat...\n",
       "4291     [fit, # Compute and print loss\\r\\nloss = self....\n",
       "4292                                                   NaN\n",
       "4293               [sudo apt install libpython3.9-dev\\r\\n]\n",
       "4294     [__getitem__, __setitem__, __delitem__, class ...\n",
       "4295     [gc.collect(), torch.cuda.empty_cache(), impor...\n",
       "4296     [CUDA error, from torch import cuda\\r\\n\\r\\n\\r\\...\n",
       "4297       [a[[i for i in range(len(a)) if i not in idx]]]\n",
       "4298                                                   NaN\n",
       "4299                     [.pth, filename.pt, filename.pth]\n",
       "4300     [tf.math.top_k, x = tf.constant([\\r\\n  [8, -2,...\n",
       "4301     [AutoModelForMaskedLM.from_pretrained, AutoMod...\n",
       "4302                                                   NaN\n",
       "4303     [torch.Tensor.scatter_, b = torch.zeros_like(a...\n",
       "4304                                                   NaN\n",
       "4305                                            [torch.py]\n",
       "4306                                                   NaN\n",
       "4307     [torch.mean, dim, dim, int, int, T.mean(dim=0)...\n",
       "4308     [resume, True, def train(resume: bool=False):\\...\n",
       "4309                                   [_get_ade20k_pairs]\n",
       "4310                 [b = torch.index_select(a, 0, c)\\r\\n]\n",
       "4311     [a, b, c, step = 2\\r\\nb = a.view(-1,step,a.siz...\n",
       "4312     [step = 2\\r\\nidx = torch.arange(0,a.size(0),st...\n",
       "4313     [OrderedDict([('out', tensor([[[[-1.7589, -1.7...\n",
       "4316                                                   NaN\n",
       "4317     [                chosen_cats = torch.Tensor([a...\n",
       "4318     [model = transformers.BertForSequenceClassific...\n",
       "4319     [from sklearn.preprocessing import OneHotEncod...\n",
       "4320     [df['column_name'] = df['column_name'].astype(...\n",
       "4321                                                   NaN\n",
       "4322     [(batch_size, height, width, num_of_channels),...\n",
       "4323                                                   NaN\n",
       "4324                                                   NaN\n",
       "4325                                                   NaN\n",
       "4326     [torch.cat, dim,  concat = torch.cat([layer_1,...\n",
       "4327                                                   NaN\n",
       "4328                                                   NaN\n",
       "4329                                                   NaN\n",
       "4330                                                   NaN\n",
       "4331     [loss_function = torch.nn.CrossEntropyLoss(red...\n",
       "4332                                                   NaN\n",
       "4335                                                   NaN\n",
       "4336                                                   NaN\n",
       "4337                                                   NaN\n",
       "4338                                                   NaN\n",
       "4339     [..., def masktensor(X, array_of_indices):\\r\\n...\n",
       "4340                                                   NaN\n",
       "4341     [import librosa\\r\\nimport pathlib\\r\\nimport te...\n",
       "4343                                                   NaN\n",
       "4344                                                   NaN\n",
       "4345     [torch.save(), torch.save(tensor, 'path/to/fil...\n",
       "4347     [Subset, torch, from torch.utils.data import S...\n",
       "4348     [import transformers\\r\\nfrom datasets import l...\n",
       "4349                                                   NaN\n",
       "4350     [arr, ntimes = 10000\\r\\nnplayers = 10\\r\\nhdf5f...\n",
       "4351     [#create array for index values\\r\\nidx_arr = n...\n",
       "4353     [yield, def generator(filelist, masklist):\\r\\n...\n",
       "4354     [fill_data, __iter__, import pandas as pd\\r\\ni...\n",
       "4355     [masked_lm_labels, labels, 103, tokenizer.mask...\n",
       "4356     [CondBatchNorm, class FedCondBatchNorm2d:\\r\\n ...\n",
       "4357                                [self.alpha = alpha()]\n",
       "4358     [gradient_accumulation_steps, mean, mean, sum,...\n",
       "4359     [[np.arange(0, self.batch_size), action], acti...\n",
       "4360     [class MyExtractor:\\r\\n    def __init__(self, ...\n",
       "4361     [min_freq, Counter, counter = Counter()\\r\\nfor...\n",
       "4362     [dist.all_gather, import torch\\r\\nimport torch...\n",
       "4364                                                   NaN\n",
       "4366     [output.logits, torch.argmax(output.logits, di...\n",
       "4367     [x, y, PyTorch Geometric introduction, import ...\n",
       "4368     [retinanet.load_state_dict(torch.load('filenam...\n",
       "4369                                                   NaN\n",
       "4370                                                   NaN\n",
       "4371     [ignore_mismatched_sizes=True, model = AutoMod...\n",
       "4372     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4373                                                   NaN\n",
       "4374     [int64, batch_X = batch_X.to(device=device, dt...\n",
       "4375                                                   NaN\n",
       "4377     [tensor, list, __get_item__, torch.stack(patch...\n",
       "4378                                                   NaN\n",
       "4379     [#include &lt;iostream&gt;\\r\\n#include &lt;mpi...\n",
       "4380                                                   NaN\n",
       "4381                                                   NaN\n",
       "4383                                                   NaN\n",
       "4384                                                   NaN\n",
       "4385                                                   NaN\n",
       "4386     [import tensorflow as tf\\r\\nimport torch\\r\\nim...\n",
       "4387                                                   NaN\n",
       "4388                                       [out, out, out]\n",
       "4389                  [BCELoss, BCEWithLogitsLoss, target]\n",
       "4390     [class model(nn.Module):\\r\\n    def __init__(s...\n",
       "4391     [def __init__(self,num_classes=6):\\r\\n    supe...\n",
       "4392     [    _, yhat = torch.max(z.data, 1)\\r\\n    cor...\n",
       "4393                       [BCELoss(), CrossEntropyLoss()]\n",
       "4394     [logger, self.log(), pytorch_lightning.callbac...\n",
       "4396     [detach, predictions, def transform_torch(pred...\n",
       "4397                           [  grad = output.grad \\r\\n]\n",
       "4398                                                   NaN\n",
       "4399                                                   NaN\n",
       "4400     [tf.keras.Model, class NBeatsBlock(tf.keras.Mo...\n",
       "4401                                                   NaN\n",
       "4402     [b, a, torch.cat, 1, torch.cat((a, b.reshape(1...\n",
       "4403     [#Sample annotation output \\r\\njson_annotation...\n",
       "4404                                                   NaN\n",
       "4405     [import os.path\\r\\nfrom os import path\\r\\na= p...\n",
       "4406     [cwd, cwd, import os\\r\\nprint(os.getcwd())\\r\\n...\n",
       "4407     [import random\\r\\nimport torch\\r\\nfrom torch i...\n",
       "4408     [class regression(nn.Module):\\r\\n    def __ini...\n",
       "4409                                                   NaN\n",
       "4411                                                   NaN\n",
       "4412     [ conv = nn.Conv1d(in_channels=56 , out_channe...\n",
       "4413                                                   NaN\n",
       "4414     [Batch x Features, Batch x Classes, self.fc = ...\n",
       "4415     [model = models.resnet50(pretrained = True)\\r\\...\n",
       "4417     [torch.Tensor.gather, x = torch.tensor([[[0, 1...\n",
       "4418                                                   NaN\n",
       "4419     [loss.backward(), optimizer.step(), model.eval...\n",
       "4420                                                   NaN\n",
       "4421                                                   NaN\n",
       "4422     [torchtext.data.TabularDataset.splits, fields,...\n",
       "4423     [checkpoint_callbacks = [\\r\\n    EarlyStopping...\n",
       "4424     [return, forward(), def forward(self,x):\\r\\n  ...\n",
       "4425     [model = models.resnet50(pretrained = True)\\r\\...\n",
       "4426     [import copy\\r\\nimport torch\\r\\n\\r\\nsource_t =...\n",
       "4427     [import torch\\r\\n\\r\\nt = torch.tensor([[101,20...\n",
       "4428     [def plot_results(pil_img, prob, boxes):\\r\\n  ...\n",
       "4429                                                   NaN\n",
       "4430     [plt.specgram, spectrum, torch.from_numpy, spe...\n",
       "4431     [import torch\\r\\nsample_tensor = torch.tensor(...\n",
       "4432                                                   NaN\n",
       "4433                                                   NaN\n",
       "4435                                                   NaN\n",
       "4436                                                   NaN\n",
       "4438                                                   NaN\n",
       "4439     [model = ResNet50(...)\\r\\nmodel = DDP(model,.....\n",
       "4440                      [(-1, 7*7*64), [-1, 246016], -1]\n",
       "4441                                                   NaN\n",
       "4442     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4443                                                   NaN\n",
       "4444     [(s, a, r, s', done), def learn(self, episodes...\n",
       "4445                                                   NaN\n",
       "4446     [nn.ModuleList, __init__, class Model(nn.Modul...\n",
       "4447     [torch.diag,  x = torch.tensor([[1, 2, 3, 4],\\...\n",
       "4448     [torch.diagonal, import torch \\r\\nimport tenso...\n",
       "4449                                                   NaN\n",
       "4450     [bids, 'nan', bids == 'nan',  bids = torch.ara...\n",
       "4451     [import tensorflow as tf\\r\\nfrom PIL import Im...\n",
       "4452     [import tensorflow as tf\\r\\nfrom PIL import Im...\n",
       "4453     [(10, 3, 32, 32), import torch\\r\\nfrom sklearn...\n",
       "4454     [torch.matmul, class Matmul(nn.Module):\\r\\n   ...\n",
       "4455                                       [tt.RandomCrop]\n",
       "4458                                                   NaN\n",
       "4459                                                   NaN\n",
       "4460                                                   NaN\n",
       "4461     [y = torch.tensor([main_loss, ac1_loss, ac2_lo...\n",
       "4462                                                   NaN\n",
       "4463     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4465     [squeeze, squeeze, [320,3], [32,3], self.Embed...\n",
       "4466                                                   NaN\n",
       "4467                                                   NaN\n",
       "4469     [Torch Geometric don't use torch=1.11.0 at the...\n",
       "4470     [tensor_b = torch.tensor([[[4, 20], [1, -1]], ...\n",
       "4471     [mu_n +- ci, n&gt;=30, torch_compute_confidenc...\n",
       "4472     [INPUT_DIM = len(TEXT.vocab) #~5,000 tokens\\r\\...\n",
       "4473     [import torch.nn as nn\\r\\n\\r\\nclass MultiClass...\n",
       "4474     [tf.data.Dataset, convert = tf.data.TextLineDa...\n",
       "4475                                                   NaN\n",
       "4476     [dls = DataLoaders.from_dsets(\\r\\n    defects_...\n",
       "4477     [add_noise(), data /= (data_sum + 1e-16), add_...\n",
       "4478     [criterion = nn.CrossEntropyLoss(weight=torch....\n",
       "4479                                                   NaN\n",
       "4480     [trained_model = train(start_epoch, 6, valid_l...\n",
       "4481     [torch.view, torch.flatten, torch.nn.Flatten, ...\n",
       "4482     [y = w*x + b, dy/dx = w\\r\\ndy/dw = x\\r\\ndy/db ...\n",
       "4483     [nn.utils.prune.l1_unstructured,  m = nn.Linea...\n",
       "4485                                                   NaN\n",
       "4486     [ torch.stack(tuple(torch.prod(torch.combinati...\n",
       "4487     [a = [[4, 2, 1, 6],[1, 2, 3, 8], [92, 4, 23, 5...\n",
       "4488     [nvcc --version, pip install torch==1.7.1+cu11...\n",
       "4489                                                   NaN\n",
       "4490                                                   NaN\n",
       "4491                                                   NaN\n",
       "4492     [att., \\r\\nstate_dict = torch.load('path\\to\\ch...\n",
       "4493     [import torch\\r\\nfrom collections import Order...\n",
       "4494                                                   NaN\n",
       "4495     [InvertibleLeakyReLU.negative_slope, self.nega...\n",
       "4497     [class bert_model(nn.Module):\\r\\n  def __init_...\n",
       "4498     [model = my_model()\\r\\n# train ...\\r\\ntorch.sa...\n",
       "4499     [cudatoolkit, conda create -n foo -c pytorch -...\n",
       "4500                                                   NaN\n",
       "4501                                                   NaN\n",
       "4502     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "4504     [def images_to_tensor(images):\\r\\n    #images ...\n",
       "4505     [import torch\\r\\n\\r\\nx= torch.rand(6000, 30, 3...\n",
       "4509     [nn.Upsample(), size, scale_factor, mode, alig...\n",
       "4510                                                   NaN\n",
       "4512                        [with autocast, with autocast]\n",
       "4513                                                   NaN\n",
       "4514     [img = Image.fromarray((255*imgs[0]).numpy().a...\n",
       "4515     [ln -s /home/envs/segmentation_base/bin/x86_64...\n",
       "4516     [conda, gcc, gcc, # system gcc\\r\\nwhich gcc &a...\n",
       "4517     [train_loader = DataLoader(mnist_train, batch_...\n",
       "4518     [self.linear_layer, self.mask, class ScalingNe...\n",
       "4519     [None, torch.Tensor, NaN, torch.full,  torch.f...\n",
       "4520                                                   NaN\n",
       "4522                                                   NaN\n",
       "4524                                                   NaN\n",
       "4525                                                   NaN\n",
       "4527     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "4528     [batch_size, spk_rec, mem_rec = net(data.view(...\n",
       "4529                                                   NaN\n",
       "4530                                                   NaN\n",
       "4531     [last_hidden_state[mask_index], softmax, probs...\n",
       "4532                                                   NaN\n",
       "4534     [_, idx = output.sum(dim = 0).max(1), (targets...\n",
       "4535     [A[3, 3], [[a, b, c],\\r\\n [d, e, f],\\r\\n [g, h...\n",
       "4536     [ x = torch.rand(1, 1, 12, 3)\\r\\n\\r\\n x\\r\\nten...\n",
       "4537                                                   NaN\n",
       "4538                                                   NaN\n",
       "4539                                                   NaN\n",
       "4540     [    features_train_tensor = torch.tensor(inpu...\n",
       "4541                                                   NaN\n",
       "4542            [__init__, self.transform = transform\\r\\n]\n",
       "4543     [trainer = pyli.Trainer(gpus=1, max_epochs=epo...\n",
       "4544     [sample_img.requires_grad_(), sample_img.requi...\n",
       "4545                                                   NaN\n",
       "4546                   [loss.backward(), optimizer.step()]\n",
       "4548     [GPU, CPU, GPU, class Sample(nn.Module):\\r\\n  ...\n",
       "4549                                                   NaN\n",
       "4550                                         [a, x = a[0]]\n",
       "4551     [pip install --ignore-installed --upgrade tens...\n",
       "4552                                                   NaN\n",
       "4553                                                   NaN\n",
       "4554               [loss=error(outputs,labels.long())\\r\\n]\n",
       "4555     [targetsTrain=torch.from_numpy(targets_train)\\...\n",
       "4556     [model_name = \"emilyalsentzer/Bio_ClinicalBERT...\n",
       "4557     [numel(), model.parameters(), from torchinfo i...\n",
       "4558     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "4559     [tensor = np.random.RandomState(42).uniform(si...\n",
       "4560                                                   NaN\n",
       "4561            [pin_memory=True, non_blocking=True, to()]\n",
       "4562     [random_split, # Created using indices from 0 ...\n",
       "4564     [def d(l):\\r\\n    return math.sqrt(sum([x**2 f...\n",
       "4565     [torch.utils.data, DataLoader(\\r\\n    dataset,...\n",
       "4566                                                   NaN\n",
       "4567     [class Module(nn.Module):\\r\\n  def __init__(se...\n",
       "4568     [conda, pip, ps -elf | grep python\\r\\n, kill -...\n",
       "4569     [torch.FloatTensor, l = [torch.tensor(3.)] * 3...\n",
       "4570     [Pytorch, Sys.getenv(), RETICULATE_PYTHON, Sys...\n",
       "4571                   [self.model, self.model.to(\"cuda\")]\n",
       "4572     [self.h = torch.tensor([torch.tanh(self.xW1[0]...\n",
       "4573     [conda search cudatoolkit\\r\\n, conda install c...\n",
       "4574                                                   NaN\n",
       "4575                                                   NaN\n",
       "4576     [@contextlib.contextmanager\\r\\ndef _disable_tr...\n",
       "4577     [(64, 100, 257),  x, y = torch.rand(64, 100), ...\n",
       "4580     [g, g = g.view(2,3,2,3)\\r\\nres = g[range(2),:,...\n",
       "4581     [optimizer = torch.optim.Adam(clfr.parameters(...\n",
       "4582       [layer.requires_grad=False, False, True, False]\n",
       "4583                                                   NaN\n",
       "4584     [x = x.view(x.size(0), -1)\\r\\n, self.fc1 = nn....\n",
       "4585                                                   NaN\n",
       "4586     [torch, .retain_grad(), learning_rate = 0.01\\r...\n",
       "4587                                                   NaN\n",
       "4588                                                   NaN\n",
       "4589                                                   NaN\n",
       "4590     [a_list = [i*2 for i in range(100)]\\r\\n, b_lis...\n",
       "4591     [torch.gather,  b = 2; d = 3; h = 2; w = 1\\r\\n...\n",
       "4592     [#Define Hook: \\r\\ndef get_features(name):\\r\\n...\n",
       "4593     [x_hat, [batch_size, 2048], x_hat, class class...\n",
       "4594                                                   NaN\n",
       "4595     [torch.no_grad, .backward(), A, model_X, model...\n",
       "4597     [...\\r\\nmodel = BinaryClassifier()\\r\\noptimize...\n",
       "4598                                                   NaN\n",
       "4599                                                [f, f]\n",
       "4600                                                   NaN\n",
       "4601                                                   NaN\n",
       "4602                                                   NaN\n",
       "4603     [pip3 install --upgrade torch\\r\\npip3 install ...\n",
       "4604     [AddChannel, EnsureChannelFirstd, AsChannelFir...\n",
       "4605     [X = torch.einsum(\"rij, sij\", A, A)\\r\\nY = tor...\n",
       "4606     [features_x, # create a loader for the data\\r\\...\n",
       "4607                                                   NaN\n",
       "4608     [class FE(nn.Module):\\r\\n  def __init__(self,m...\n",
       "4610                                                   NaN\n",
       "4611                                                   NaN\n",
       "4612     [pytorch 1.10, isin, def isin(ar1, ar2):\\r\\n  ...\n",
       "4613     [namestodistance = [('Alice', .1), ('Bob', .3)...\n",
       "4614     [[(W−K+2P)/S]+1, [], zero, [(68-9+2*0)/4]+1 -&...\n",
       "4615     [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "4617     [!cd /content/drive/MyDrive/Colab_Notebooks/ce...\n",
       "4618                                                   NaN\n",
       "4619     [torch.stack(tensors, dim=0, *, out=None) → Te...\n",
       "4620                                                   NaN\n",
       "4621                                                   NaN\n",
       "4622     [trainloader, batch= iter(trainloader)\\r\\nimag...\n",
       "4623                                                   NaN\n",
       "4624                                                   NaN\n",
       "4626                                                   NaN\n",
       "4627     [BCEWithLogitsLoss, float, long, t, dtype=torc...\n",
       "4628     [self.conv, \\r\\nX = torch.randn(1, 1, 224, 224...\n",
       "4629     [      wrapped_model.to(device=device)\\r\\n    ...\n",
       "4631                                                   NaN\n",
       "4632                                                   NaN\n",
       "4634     [i1 = tr.tensor(0.0, requires_grad=True)\\r\\ni2...\n",
       "4636                                                   NaN\n",
       "4637     [-100, n_batch, nn.CrossEntropyLoss, class Cro...\n",
       "4638                                                   NaN\n",
       "4639     [BERT, BERT, from transformers import BertToke...\n",
       "4640     [pipenv install torch torchvision torchaudio, ...\n",
       "4641                                                   NaN\n",
       "4642                                                   NaN\n",
       "4643                                                   NaN\n",
       "4644                                                   NaN\n",
       "4645     [y1 = gene1.fc1.weight\\r\\ny2 = gene2.fc1.weigh...\n",
       "4647     [   TORCH_MAJOR = int(torch.__version__.split(...\n",
       "4649     [loss_r = -torch.min(ratio*delta_batch, clippe...\n",
       "4650     [class Generator(object):\\r\\n\\r\\ndef __init__(...\n",
       "4651     [data_gen(), __next__, next(), data_gen, def d...\n",
       "4652     [epoch, from pytorch_lightning import loggers\\...\n",
       "4653     [cfg.MODEL.TENSOR_MASK.SCORE_THRESH_TEST = 0.5...\n",
       "4654                                                   NaN\n",
       "4655     [loss = loss_fn(outputs, labels), outputs, _ ,...\n",
       "4657     [delimiter=\"\\t\", usecols=range(0,7), delimiter...\n",
       "4658                                           [PIL.Image]\n",
       "4659     [png_image = Image.open(png_file), PIL.PngImag...\n",
       "4660                                                   NaN\n",
       "4661     [A, A, # you can keep 'A' unconstrained\\r\\nA =...\n",
       "4662                                                   NaN\n",
       "4663                                                   NaN\n",
       "4664     [random_split, from torch.utils.data import ra...\n",
       "4665                                                   NaN\n",
       "4666                                                   NaN\n",
       "4667     [When multiple candidate versions match a vers...\n",
       "4668     [model.parameters(), model.parameters(), get_p...\n",
       "4669                                                   NaN\n",
       "4670     [eta, iter, total_loss, loss_cls, loss_box_reg...\n",
       "4671     [# create dummy indices to index the correct r...\n",
       "4672     [model = torch.hub.load('ultralytics/yolov5', ...\n",
       "4673     [/weights/last.py, import os  \\r\\nimport torch...\n",
       "4674                                                   NaN\n",
       "4675     [    x_mask= torch.zeros(H,W,device=x.device, ...\n",
       "4676     [z, x, y, z = x + j y, z, r, phi, z = r exp(j ...\n",
       "4677     [mu, std = out_RL[0]\\r\\ndist = Normal(mu, std)...\n",
       "4678                                 [sample(), rsample()]\n",
       "4679                                                   NaN\n",
       "4680                                                   NaN\n",
       "4682     [self.flatten = nn.Flatten()\\r\\nself.linear_re...\n",
       "4683                             [torch.int64, torch.long]\n",
       "4684     [def _initialize_weights(self):\\r\\n    for m i...\n",
       "4685                                                   NaN\n",
       "4686     [torch.bincount, max(input)+1, max(input), max...\n",
       "4687                                                   NaN\n",
       "4688             [pip,  Python 3.8.10\\r\\n, pip 21.3.1\\r\\n]\n",
       "4689                                                   NaN\n",
       "4690     [data, Planetoid, x, edge_index, y, train_mask...\n",
       "4691     [for, if, def zzz():\\r\\n  asdf=[]\\r\\n  for i i...\n",
       "4693     [lengths, mask, mask, a.size(1), cumsum(), mas...\n",
       "4694     [/usr/lib/wsl/lib/libcuda.so.1, libcuda.so, /u...\n",
       "4695     [sudo ldconfig, libcuda.so, libcuda.so.1, libc...\n",
       "4696     [pip install torch==1.10.1+cu111 torchvision==...\n",
       "4697     [baseline = (1 - baseline_lr) * baseline + bas...\n",
       "4698                                                   NaN\n",
       "4699                                                   NaN\n",
       "4700     [.to(), nn.Module, torch.tensor, torch.tensor,...\n",
       "4701     [return positive_img, return torch.tensor(posi...\n",
       "4702     [torch.no_grad, torch.no_grad, Tensor.backward()]\n",
       "4703                                                   NaN\n",
       "4704     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "4705                                                   NaN\n",
       "4706                                                   NaN\n",
       "4707                                                   NaN\n",
       "4708     [custom_imports = dict(\\r\\n    imports=['mmdet...\n",
       "4709                                                   NaN\n",
       "4710                                                   NaN\n",
       "4711     [ X = torch.randn(30,1,2)\\r\\n t = torch.zeros(...\n",
       "4712     [b, loss = criterion_mse(imgs_pred[:, :, b:-b,...\n",
       "4713                                                   NaN\n",
       "4714                      [how, Why, When, Best Practices]\n",
       "4715                                                   NaN\n",
       "4716     [def accuracy_mse(output, target):\\r\\n   \\r\\n ...\n",
       "4717     [loss.backward(), fit(), fit(), model.compile(...\n",
       "4718                                                   NaN\n",
       "4719     [class MyDataset(Dataset):\\r\\n\\r\\n    def __in...\n",
       "4720     [transform(np.array([[-1,-1,1,-1],[-1,1,-1,-1]...\n",
       "4722     [.parameters(), .named_parameters(), for name,...\n",
       "4723     [retain_graph=True, loss.backward(), loss, ret...\n",
       "4725                                                   NaN\n",
       "4726     [loss = criterion_mse(imgs_pred[:, :, 6:70, 6:...\n",
       "4727     [exp,  import torch\\r\\n import torch.nn.functi...\n",
       "4728                                                   NaN\n",
       "4729     [__getitem__, __len__, dataset[i], __len__, le...\n",
       "4730     [from torch.utils.data import Dataset, DataLoa...\n",
       "4731                                                   NaN\n",
       "4732     [model = AutoModelForSequenceClassification.fr...\n",
       "4733     [def __getitem__(self, index):\\r\\n    path = ....\n",
       "4734     [nn.Identity(), import torch \\r\\nimport torch....\n",
       "4735     [loss_fn(output, target)\\r\\n, loss_fn(output, ...\n",
       "4736     [labels = labels.astype(np.float32).tolist()\\r\\n]\n",
       "4738                                                   NaN\n",
       "4739     [get_optimizer, torch.optim.&lt;optimizer&gt;,...\n",
       "4741     [dim=1, dim=-1, src, In [31]: arr = torch.zero...\n",
       "4742     [subset = [X_train[i_] for i_ in train_index]\\...\n",
       "4743     [intent_hs = torch.tile(intent_hs[:, None, :],...\n",
       "4744      [$! pip install --upgrade torch torchvision\\r\\n]\n",
       "4745                    [device, model.to(device), device]\n",
       "4746                                                   NaN\n",
       "4747                                                   NaN\n",
       "4749     [environment.yaml, pytorch, pytorch, environme...\n",
       "4750                                                   NaN\n",
       "4751                                                   NaN\n",
       "4752                                                   NaN\n",
       "4753     [import torch\\r\\n\\r\\nimport torch.nn as nn\\r\\n...\n",
       "4754     [image= np.stack((img,)*3, axis=-1), A.Normali...\n",
       "4755                                                   NaN\n",
       "4756     [pydicom.pixel_data_handlers.util.apply_modali...\n",
       "4757                                                   NaN\n",
       "4759     [fnames, h5fr.copy(), h5fr.copy(h5fr[ds],h5fw,...\n",
       "4760                                                   NaN\n",
       "4761     [import torch\\r\\np = torch.tensor([\\r\\n    [0....\n",
       "4762                                                   NaN\n",
       "4763                                                   NaN\n",
       "4764                                                   NaN\n",
       "4765     [n, m, c, (n, m, c), M(m, c), M(n, m, c), M(m,...\n",
       "4767                                                   NaN\n",
       "4768     [import torch\\r\\n\\r\\ndef custom_activ(input):\\...\n",
       "4770                                                   NaN\n",
       "4771     [Python 3.8.10 (default, Sep 28 2021, 16:10:42...\n",
       "4773                                                   NaN\n",
       "4775     [ll = [[3, 5, 10, 11], [1, 5, 10]]\\r\\nn = len(...\n",
       "4776                                                   NaN\n",
       "4777     [processed_file_names, len(self.processed_file...\n",
       "4778     [dist, dim, torch.index_select, import torch\\r...\n",
       "4779     [import torch.nn as nn\\r\\n\\r\\nnum_inputs = 10\\...\n",
       "4780     [(batch_size, seq_size, embedding_dim), torch....\n",
       "4781     [torch.roll, import numpy as np\\r\\n\\r\\nX = np....\n",
       "4783     [import pandas as pd\\r\\nimport numpy as pd\\r\\n...\n",
       "4784                                                   NaN\n",
       "4785     [# convert to float\\r\\npredictions = predictio...\n",
       "4786                [y_ = (y_&gt;0.5).float()\\r\\n, y_, y_]\n",
       "4787                        [y_ = (y_&gt;0.5).float()\\r\\n]\n",
       "4790     [Tensordot, x1, x2, ([1], [1]), dims, x1, x2, ...\n",
       "4791     [weight, Conv2d,  c = torch.nn.Conv2d(in_chann...\n",
       "4793                                                   NaN\n",
       "4794     [stride=(1,128), 4, (4,4), 291, A.unsqueeze(1)...\n",
       "4795     [from numba import cuda\\r\\ncuda.select_device(...\n",
       "4796                          [h += poolX., h = h + poolX]\n",
       "4797     [def forward(self, x):\\r\\n    h = x\\r\\n    h =...\n",
       "4798                                                   NaN\n",
       "4799                                                   NaN\n",
       "4800     [DataLoader, test_set = MyDataset(...) # your ...\n",
       "4801                    [X.to(device), x=x.to(device)\\r\\n]\n",
       "4802     [x = torch.tensor([2])\\r\\ny = torch.tensor([3]...\n",
       "4803     [torch.gather, &gt;&gt; torch.gather(x, -1, y)...\n",
       "4804                                                   NaN\n",
       "4805                                                   NaN\n",
       "4806               [BCELoss, [0, 1], z, [128,], y, [128,]]\n",
       "4808                                                   NaN\n",
       "4809                               [result.numpy()[0]\\r\\n]\n",
       "4810     [PyTorch, .data_ptr(), &gt;&gt; net.fc2.weight...\n",
       "4811     [requires_grad = True, new_tensor, new_tensor ...\n",
       "4812                                                   NaN\n",
       "4813                 [torchtext.legacy.___, torchtext.___]\n",
       "4814                                                   NaN\n",
       "4815                                                   NaN\n",
       "4817     [.requires_grad, False, for p in first_model.p...\n",
       "4818     [requires_grad_, # Freezing network Sequential...\n",
       "4819     [predictor.predict(input)\\r\\n, predictor.predi...\n",
       "4820                                                   NaN\n",
       "4821     [hparams, from tbparse import SummaryReader\\r\\...\n",
       "4822     [from tensorboard.backend.event_processing imp...\n",
       "4823     [CrossEntropyLoss, BCELoss, [0, 1], &gt; 0.5, ...\n",
       "4824     [model.classifier   = nn.Sequential(\\r\\n    nn...\n",
       "4825     [apply, df_test.value[0], print(df_test.value[...\n",
       "4827                                                   NaN\n",
       "4828                                                   NaN\n",
       "4829                                                   NaN\n",
       "4830     [batch_size = 4\\r\\ntrain_dataset = tf.data.Dat...\n",
       "4831                                                   NaN\n",
       "4832                                                   NaN\n",
       "4833                                                   NaN\n",
       "4834                                                   NaN\n",
       "4838                                                   NaN\n",
       "4839     [six 1.15.0, pip install -r requirements.txt\\r...\n",
       "4840                                                   NaN\n",
       "4841     [unsqueeze, my_old_tensor, my_new_tensor = (to...\n",
       "4842                                                   NaN\n",
       "4843     [pip install torch-scatter==2.0.8 -f https://d...\n",
       "4844                                             [pytorch]\n",
       "4845     [for step in range(num_steps):\\r\\n    cur1 = s...\n",
       "4846     [optimizer = SGD(model.parameters(), lr=learni...\n",
       "4847                                                   NaN\n",
       "4848     [return inverse, test_tensor = torch.tensor([1...\n",
       "4849     [  x = torch.tensor([1, 1, 2, 3, 3, 3])\\r\\n  v...\n",
       "4850                                                   NaN\n",
       "4851                                                   NaN\n",
       "4852     [train, valid, test = Multi30k.splits(exts=('....\n",
       "4853     [# I assume that you named your input image as...\n",
       "4854                                                   NaN\n",
       "4855     [# Convert outputs from 0-1 to 0, 255\\r\\nimg_i...\n",
       "4856     [import numpy as np\\r\\nimport cv2\\r\\nimg = np....\n",
       "4858                                                   NaN\n",
       "4859                                                   NaN\n",
       "4860                                                   NaN\n",
       "4861     [ t.reshape(3,2,-1).transpose(0,1).reshape(2,-...\n",
       "4862     [Nx8, (cx, cy, w, h, a), def DOTA_2_OBB(boxes)...\n",
       "4863                                                   NaN\n",
       "4864                                                   NaN\n",
       "4865     [if tensordata.shape == torch.Size([0]): \\r\\n ...\n",
       "4866     [inp1 = inp + a  # create a separate variable ...\n",
       "4867     [torch.load, # create model\\r\\nmodel = SomeMod...\n",
       "4869                                                   NaN\n",
       "4870     [(1, 60000, 28, 28), (60000, 1, 28, 28),  x.tr...\n",
       "4871     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "4872     [if item_vector.shape == torch.Size([0]): \\r\\n...\n",
       "4873     [import pandas as pd\\r\\nimport torch\\r\\nimport...\n",
       "4874     [train_target = torch.tensor(train['Target'].v...\n",
       "4875     [import pandas as pd\\r\\nimport torch\\r\\n\\r\\n# ...\n",
       "4876     [df.values, import torch.utils.data as data_ut...\n",
       "4877     [pandas dataframe -&gt; numpy array -&gt; pyto...\n",
       "4878     [#This works for me\\r\\n\\r\\ntarget = torch.tens...\n",
       "4879     [tensor_ = torch.from_numpy(df.to_numpy().asty...\n",
       "4880     [nan, base_lr, loss_weight, base_lr, 'inf', 'n...\n",
       "4882     [nan, class checkFiniteLayer(caffe.Layer):\\r\\n...\n",
       "4883     [count, attack(), count = 1, attack(), global ...\n",
       "4884     [b,l,h,i,d, C[b,l,h,d] += A[b,l,d] * B[h,i,d]\\...\n",
       "4885     [c = np.einsum('bld,hid-&gt;blhd', a,b)\\r\\n, e...\n",
       "4886                                                   NaN\n",
       "4887     [torch, torchvision, cuda, pip install torch==...\n",
       "4888     [import cv2,glob\\r\\nimport numpy as np\\r\\nfrom...\n",
       "4889     [cross_entropy_loss(models, target)\\r\\n, cross...\n",
       "4890     [numpy, tensor, numpy, crossentropyloss, targe...\n",
       "4891     [top_idx = torch.topk(A, 2, dim=1).indices\\r\\n...\n",
       "4892                                        [LSTM_regr, x]\n",
       "4893     [class formDataset(Dataset):\\r\\n\\r\\n    def __...\n",
       "4894                          [im = torch.stack(x, 0)\\r\\n]\n",
       "4895     [nn.CrossEntropyLoss, import torch\\r\\nclass ML...\n",
       "4898     [ torch.stack((A.T, B.T), 1)\\r\\ntensor([[[1, 1...\n",
       "4899                                                   NaN\n",
       "4900                                                   NaN\n",
       "4901                                                   NaN\n",
       "4902                                                   NaN\n",
       "4903                                                   NaN\n",
       "4904     [summary, .forward(), (input, weight, output),...\n",
       "4905     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "4906     [mlflow.set_tracking_uri(uri=f'file://{hydra.u...\n",
       "4907                           [instance_type='local_gpu']\n",
       "4909                                                   NaN\n",
       "4910     [import torch\\r\\nmodel = ...\\r\\nstate_dict = t...\n",
       "4911     [jacobian, J = jacobian(lambda x: f(theta, x),...\n",
       "4912     [x  = np.arange(4)   # shape (4,)\\r\\nxx = x.re...\n",
       "4913                                                   NaN\n",
       "4914     [(914, 19), in_features, in_features, linear1,...\n",
       "4915     [torch.gather, I, N, i, n, I = [0, 1, 2, 3]\\r\\...\n",
       "4916     [import torch\\r\\n\\r\\ndata = torch.tensor([[[[0...\n",
       "4918                                                   NaN\n",
       "4919                                                   NaN\n",
       "4921                   [torch.Tensor.clone, a, b, grad_fn]\n",
       "4922                                                   NaN\n",
       "4923     [x, torchvision.utils.make_grid, x, import tor...\n",
       "4924                                                   NaN\n",
       "4926     [device, model.device,  next(model.parameters(...\n",
       "4927                                                   NaN\n",
       "4928     [y, w, x, y_i = sum_j w_ij x_j, i, w_ij, i, W,...\n",
       "4929                                                   NaN\n",
       "4931     [nvidia-smi, +--------------------------------...\n",
       "4932                                                   NaN\n",
       "4933                                                   NaN\n",
       "4934     [output_padding, pixelshuffle, interpolate, Re...\n",
       "4935     [# Create some dummy data: we establish a line...\n",
       "4936                                                   NaN\n",
       "4937                                                   NaN\n",
       "4938                                            [LinearLR]\n",
       "4939     [nn.ReLU(inplace=True), nn.ReLU(iplace=True), ...\n",
       "4941                                                   NaN\n",
       "4942     [conda create -n myenv\\r\\nconda activate myenv...\n",
       "4944                                                   NaN\n",
       "4945     [1.3, TrainingArguments, accuracy, accuracy, e...\n",
       "4946                                                   NaN\n",
       "4947     [from rest_framework.decorators import api_vie...\n",
       "4948     [t1 = torch.zeros([1,5]) # tensor([[0., 0., 0....\n",
       "4949                                                   NaN\n",
       "4950                                                   NaN\n",
       "4951     [nn.Sequential,  network = nn.Sequential(model...\n",
       "4952     [class myNN(nn.Module):\\r\\n    def __init__(se...\n",
       "4953                                                   NaN\n",
       "4954                                                   NaN\n",
       "4955                                                   NaN\n",
       "4956     [Tensor, Tensor.data, Tensor, Tensor.data, Ten...\n",
       "4957                                           [SimpleMLP]\n",
       "4958     [lr(step=0)=0.1, lr(step=10)=0, lr(step) = -0....\n",
       "4959     [from torch.utils.tensorboard import SummaryWr...\n",
       "4961                                                   NaN\n",
       "4962     [a1, a2, numpy.ndarray, a1.detach().cpu().nump...\n",
       "4963                                                   NaN\n",
       "4964     [def forward(self, t0, t1, i):\\r\\n    ...\\r\\n,...\n",
       "4965     [torch.Tensor.any, torch.Tensor.nonzero,  x.an...\n",
       "4966                                                   NaN\n",
       "4967                                                   NaN\n",
       "4968     [transformer, transformers, AllenNLP, from tra...\n",
       "4970            [X = X.index_add(0, indices, Y)\\r\\n, X, Y]\n",
       "4971     [for (int i = 0; i &lt; 3 * width * height; i+...\n",
       "4972                                                   NaN\n",
       "4973     [def forward(self, x):\\r\\n    a1 = self.relu(s...\n",
       "4974     [Block, nn.Module, reverse, conv1_network(x, r...\n",
       "4976     [Bert, gradient_checkpointing, gradient_checkp...\n",
       "4977                                                   NaN\n",
       "4979     [nn.Sequential(*reversed([layer for layer in o...\n",
       "4981     [proj_size, num_layers, dropout, class Encoder...\n",
       "4982                                                   NaN\n",
       "4983     [state, float, long, state = state.float()\\r\\n...\n",
       "4984     [stats=np.array([1,2,3,4,5,6])\\r\\nprint(type(s...\n",
       "4985                                                   NaN\n",
       "4986     [PIL.Image.open, torch.Tensor, np.ndarray, A.T...\n",
       "4987                                                   NaN\n",
       "4988                                                   NaN\n",
       "4989                                                   NaN\n",
       "4990                                                   NaN\n",
       "4991                                                   NaN\n",
       "4992                                                   NaN\n",
       "4993                                                   NaN\n",
       "4994                                                   NaN\n",
       "4995     [mdl.train(), mdl.eval(), mdl.train(), mdl.tra...\n",
       "4996     [torch.gather, # A.shape = (NB, N, 2, 2)\\r\\nB ...\n",
       "4997                                                   NaN\n",
       "4998     [view, .contiguous(), torch.tensor.diagflat(),...\n",
       "5000       [torch7, .pt, .pth, .t7, onnx, readNetFromONNX]\n",
       "5001                                                   NaN\n",
       "5002     [import cupy as cp\\r\\nfrom cupyx.scipy.ndimage...\n",
       "5003                                                   NaN\n",
       "5004                                                   NaN\n",
       "5005                                                   NaN\n",
       "5006     [nn.ModuleList,         self.convolutions1 = n...\n",
       "5007     [labels, loss, loss = loss_function(out, label...\n",
       "5008                                                   NaN\n",
       "5009     [seed, pos_layout = nx.spring_layout(g, seed=1...\n",
       "5011                                                   NaN\n",
       "5012     [# the loss function \\r\\ndef mse(Y, target):\\r...\n",
       "5013                                                   NaN\n",
       "5014                                                   NaN\n",
       "5015     [q, q, with torch.no_grad():\\r\\n    q = q - et...\n",
       "5017     [embeddings = self.embedding_layer(input_featu...\n",
       "5018                                                   NaN\n",
       "5019     [virtualenv -p  /opt/homebrew/Caskroom/minifor...\n",
       "5020             [torch.index_select, torch.Tensor.select]\n",
       "5021                                                   NaN\n",
       "5022     [nx.draw_networkx_edge_labels(), #!/usr/bin/py...\n",
       "5026     [model = ...\\r\\ntokenizer = ...\\r\\n    \\r\\ndef...\n",
       "5027     [TypeError: torch.max received an invalid comb...\n",
       "5028                                                   NaN\n",
       "5029     [d = torch.abs(a.view(-1, 1, 2) - a.view(1, -1...\n",
       "5031     [nn.Module, nn.Module.register_full_backward_h...\n",
       "5032     [r = a[:, None] - b[None, :]\\r\\nk = torch.exp(...\n",
       "5033     [k = torch.exp(- (a.reshape(-1,1)*b.reshape(1,...\n",
       "5035                                                   NaN\n",
       "5036                                                   NaN\n",
       "5037     [$ pip install mypackage/ --no-cache-dir --no-...\n",
       "5038     [def toeplitz(c, r):\\r\\n    vals = torch.cat((...\n",
       "5040                                                   NaN\n",
       "5042                                                   NaN\n",
       "5044                                                   NaN\n",
       "5045                                                   NaN\n",
       "5046     [nn.Module, 0, nn.Module.register_full_backwar...\n",
       "5048                                                   NaN\n",
       "5050     [None, n[:, None], dim=1, n.unsqueeze(dim=1), ...\n",
       "5051     [transforms.Resize(), transformed = torchvisio...\n",
       "5052                                                   NaN\n",
       "5054     [ConcatDataset, torch.utils.data, import torch...\n",
       "5055     [ENV, ENV, ~/.bashrc, PATH, /root/.bashrc, exp...\n",
       "5056     [__eq__, False, model_load == model_cpu, model...\n",
       "5058     [nn.ConvTranspose2d, nn.Conv2d, ConvTranspose2...\n",
       "5059                                                   NaN\n",
       "5060     [word2vec.wv.index2word, pretrained_embedding ...\n",
       "5061                                                   NaN\n",
       "5062     [nn.ConvTranspose2d, out = (x - 1)s - 2p + d(k...\n",
       "5063     [stride-1, padding, -2p, dilation, output_padd...\n",
       "5064                                                   NaN\n",
       "5065                                                   NaN\n",
       "5066                                                   NaN\n",
       "5067                                                   NaN\n",
       "5068     [output = output / output.amax(dim=(1,2,3), ke...\n",
       "5069     [ import torch\\r\\n import torch.nn.functional ...\n",
       "5070     [class CustomIterableDatasetv1(IterableDataset...\n",
       "5071     [Dataset, __iter__, torch.utils.data.get_worke...\n",
       "5072     [32x119072 and 800x300, nn.Linear(800, 300), 8...\n",
       "5073                                                   NaN\n",
       "5074                               [optimizer.zero_grad()]\n",
       "5075                                                   NaN\n",
       "5076     [nn.ModuleDict, nn.Sequential, parameters, nn....\n",
       "5077     [torch.nn.Sequential, base, classifier, class ...\n",
       "5078                                                   NaN\n",
       "5079     [predict, model(...), __call__, forward, model...\n",
       "5081     [y = x1*x2, a, b, y = a*x1 + b*x2, x1, x2 -&gt...\n",
       "5082                                                   NaN\n",
       "5083                                                   NaN\n",
       "5084     [nn.Module.modules, _modules, m = wn(m), m, nn...\n",
       "5085                                [rnn_jax.apply(), for]\n",
       "5086     [from torchtext.legacy.data import Field, Tabu...\n",
       "5087                                                   NaN\n",
       "5090              [model(test_X_torch.float().cuda())\\r\\n]\n",
       "5091                                                   NaN\n",
       "5092     [torchvision/models/vgg.py, __all__, __all__ =...\n",
       "5093                                                   NaN\n",
       "5094                                      [eval(), eval()]\n",
       "5095                                                   NaN\n",
       "5096     [torch_img, [0,1], numpy_img, numpy_img_float,...\n",
       "5097     [out_bboxes1[:min(out_bboxes.shape[0], self.cf...\n",
       "5098     [img_align_celeba.zip, CelebA, download=True, ...\n",
       "5099                                       [download=True]\n",
       "5100     [data/celeba/img_align_celeba/000001.jpg, data...\n",
       "5101     [ x1, y1, x2, y2 = torch.randint(0, 9, (4,))\\r...\n",
       "5102                                                   NaN\n",
       "5103     [prob_fake, prob_fake, D(fake_pair), loss_G, l...\n",
       "5104     [C, select = 337  # which segment to select\\r\\...\n",
       "5105     [torchvision.transforms.Normalize, mean, \"shif...\n",
       "5106                                                   NaN\n",
       "5107     [torch.LongTensor, for inputs, targets in data...\n",
       "5108     [for epoch in range(num_epochs):\\r\\n    for (w...\n",
       "5109                  [model, float, outputs, float,  int]\n",
       "5110     [with torch.autocast('cuda'):\\r\\n    loss = se...\n",
       "5111                                         [output_size]\n",
       "5112                                                   NaN\n",
       "5113     [nn.BCEWithLogitsLoss, outputs, targets, label...\n",
       "5114     [(x) -----&gt; netG ----&gt; (fake) -&gt; netD...\n",
       "5115     [backwards, (2) Update G network, Generator, (...\n",
       "5116                                                   NaN\n",
       "5118                                 [py3.9_cpu_0, 1.10.0]\n",
       "5119                                                   NaN\n",
       "5120     [import torch\\r\\nfrom sklearn.model_selection ...\n",
       "5121     [nll_loss, log_softmax, log_softmax,   def for...\n",
       "5122                                                   NaN\n",
       "5123     [numpy.concatenate((a.cpu(), b.cpu()), torch.c...\n",
       "5124     [np.concatenate(), torch.cat(), tf.concat(), ....\n",
       "5125                                         [torch.cat()]\n",
       "5127     [torch.no_grad, def first_layer_update(weight)...\n",
       "5128     [with torch.no_grad():\\r\\n  for param in layer...\n",
       "5129                                                   NaN\n",
       "5130     [image   -)  shape: torch.Size([3, 850, 600]),...\n",
       "5131                                                   NaN\n",
       "5133     [scipy.linalg.circulant(), scipy.linalg.circul...\n",
       "5134     [torch.gather, mtx_row, dim=1, (3, 3), tensor(...\n",
       "5135                                                   NaN\n",
       "5136                                                   NaN\n",
       "5138                                                   NaN\n",
       "5139     [max_prediction_length, group_ids, max_predict...\n",
       "5141     [torch.Tensor, int, torch.Tensor(0), torch.Ten...\n",
       "5142     [XForSequenceClassification, X, EncoderDecoder...\n",
       "5143     [torch.bmm,  torch.bmm(A[..., None, :], B[...,...\n",
       "5144     [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndef...\n",
       "5146     [X_train, X_test, Y_train, Y_test = train_test...\n",
       "5147     [import splitfolders \\r\\n\\r\\n#### input datase...\n",
       "5148                                                   NaN\n",
       "5149     [test, train, train, data = data.to(device)\\r\\...\n",
       "5150     [model, Variable, requires_grad, torch.no_grad...\n",
       "5151                                          [nvidia-smi]\n",
       "5152     [--shm-size=10g, --ulimit memlock=-1, export N...\n",
       "5153     [torchrun, python -m torch.distributed.launch,...\n",
       "5154     [torch.distributed.init_process_group(backend,...\n",
       "5155                                                   NaN\n",
       "5156                                                   NaN\n",
       "5157     [nn.Modules, forward, def forward(self, x: Ten...\n",
       "5158     [(10, 16, 4, 4), 16*4*4, fc1, nn.Flatten, clas...\n",
       "5159     [encoder_state_dict , decoder_state_dict , tor...\n",
       "5160                                                   NaN\n",
       "5161     [Resnet50, Linear, model.fc = nn.Sequential(\\r...\n",
       "5162                                                  [fc]\n",
       "5163                           [pip install torchtext\\r\\n]\n",
       "5164     [nn.Module, nn.DataParallel, module,  p_model ...\n",
       "5165     [KL(P || Q) = – sum x in X P(x) * log(Q(x) / P...\n",
       "5166                                                   NaN\n",
       "5167     [pred_vals, pred_inds = torch.max(outputs.data...\n",
       "5168     [correct_train += float((predicted == label))....\n",
       "5169                                                   NaN\n",
       "5170     [RandomSampler,  ds = MyDataset(N)\\r\\n sampler...\n",
       "5171     [torch.nn.utils.parameters_to_vector,  net(tor...\n",
       "5172                                                   NaN\n",
       "5174                                                   NaN\n",
       "5175                                                   NaN\n",
       "5176                                                   NaN\n",
       "5178                                                   NaN\n",
       "5179     [requires_grad = True, loss = 1 - torch.mean(t...\n",
       "5180                                                   NaN\n",
       "5181                                                   NaN\n",
       "5182     [load_dataset, torch.utils.data.DataLoader, ba...\n",
       "5183                                                   NaN\n",
       "5184     [import torch\\r\\nmodel = torch.nn.Sequential(t...\n",
       "5185     [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "5186     [log, class MyModule(LightningModule):\\r\\n\\r\\n...\n",
       "5187     [import torch.nn.functional as F\\r\\n\\r\\nx = F....\n",
       "5189     [RandomRotation, Grayscale, class Combination(...\n",
       "5190     [dropout, relu, import torch.nn as nn\\r\\nimpor...\n",
       "5192     [scores = model(x)\\r\\npredictions = scores.arg...\n",
       "5193     [nn.NLLLoss, y_hat, y, nn.NLLLoss,  -y_hat[tor...\n",
       "5195     [1, out = [(2p + x - k)/s + 1]\\r\\n, p, k, s, [...\n",
       "5196     [(batch_size, 33856), (batch_size, 640000), fc...\n",
       "5197                                                   NaN\n",
       "5198                                                   NaN\n",
       "5199                                                   NaN\n",
       "5200                                                   NaN\n",
       "5202     [Sim, Sim = torch.rand((5, 5))\\r\\nsamples_idx ...\n",
       "5203     [samples_idx,  Sim = torch.rand(5, 5)\\r\\ntenso...\n",
       "5204     [ Sim = torch.rand((5, 5))\\r\\ntensor([[0.8128,...\n",
       "5205                                                   NaN\n",
       "5206                       [CNN, inception.fc, RandomCrop]\n",
       "5207                 [model.eval(), with torch.no_grad():]\n",
       "5208                                                   NaN\n",
       "5209     [label2id, id2label, import shap\\r\\nfrom trans...\n",
       "5210     [label2id, ModelForSequenceClassification, ent...\n",
       "5211     [--img 640\\r\\n, --cache\\r\\n, !python train.py ...\n",
       "5212     [def discrimination_step(net, optimizer, crite...\n",
       "5213     [def discrimination_step(net, optimizer, crite...\n",
       "5214                                                   NaN\n",
       "5215     [MyModel, _modules, for module_key in model._m...\n",
       "5216     [nn.Module, _parameters, _buffers, _modules, _...\n",
       "5217     [(batch_size, 1), (batch_size,), y_val,  loss ...\n",
       "5218     [Y_tr, one_hot_label = torch.nn.functional.one...\n",
       "5219     [summary(), device=.., cuda:0, summary(model, ...\n",
       "5220     [grad_fn, grad_fn, data, net.linear_layer.weig...\n",
       "5221     [SubsetRandomSampler, train_subsampler, val_su...\n",
       "5222        [inputs.view(inputs.size(0), -1) &gt; 0.5\\r\\n]\n",
       "5223     [optim.step(), weight_decay, optim = torch.opt...\n",
       "5224                                                   NaN\n",
       "5225     [self.h5_file = h5py.File(save_path, 'w'), __i...\n",
       "5226     [a, b, torch.Tensor.repeat, b,  b + a.repeat(1...\n",
       "5227     [import torch\\r\\nimport numpy as np\\r\\n\\r\\n# c...\n",
       "5228                                                   NaN\n",
       "5229     [pip install pytorch-nlp\\r\\n, from torchnlp.en...\n",
       "5230     [Collections.Counter, torchtext, vocab, from t...\n",
       "5231     [from torchtext.vocab import vocab\\r\\nfrom col...\n",
       "5232     [std = torch.exp(log_std)  # Define the transf...\n",
       "5233                                                   NaN\n",
       "5234     [embeds = sum(self.embeds(inputs).view(1,-1))\\...\n",
       "5235     [nn.Parameter, torch.Tensor,  self.p1 = nn.Par...\n",
       "5236     [Parameter, Parameter, self.initial_value, [se...\n",
       "5237     [for i, (trains, labels) in enumerate(train_it...\n",
       "5238                                             [dropout]\n",
       "5239     [W, b, W = W.cuda()\\r\\nb = b.cuda()\\r\\n, W = t...\n",
       "5240                  [Q, a, Q.sum(), a, Q, a, Q.sum(), a]\n",
       "5241                                                   NaN\n",
       "5242                                                   NaN\n",
       "5243     [[B,N,L], [B,N], input = input[:,None,:]\\r\\n, ...\n",
       "5244     [for i in range(epochs):\\r\\n    model.train()\\...\n",
       "5245     [params[k].data, params[k],  loss(f(w[i], x)),...\n",
       "5246                                                   NaN\n",
       "5247                                                   NaN\n",
       "5248                                                   NaN\n",
       "5250                                                   NaN\n",
       "5251     [model(test_set)\\r\\n, wandb, wandb.log({\"MSE t...\n",
       "5252                                                   NaN\n",
       "5253     [optimizer = torch.optim.Adam(model.parameters...\n",
       "5254        [resnext50_32x4d = resnext50_32x4d.cuda()\\r\\n]\n",
       "5255     [def __init__(self, in_channels,\\r\\n          ...\n",
       "5256     [nn.Module.parameters, torch.nn.utils.paramete...\n",
       "5257     [float(double_variable)\\r\\n,                  ...\n",
       "5261                                                   NaN\n",
       "5263                                                   NaN\n",
       "5264     [torch.cuda.nccl.is_available, True,     In [1...\n",
       "5265     [loss, loss.backward()\\r\\n, loss2, overall_los...\n",
       "5266                                                   NaN\n",
       "5268                                                   NaN\n",
       "5269     [nn.GRU, output, h_n, nn.Sequential, class Fea...\n",
       "5270     [.to(device), .to(cuda), \\r\\n    for e in rang...\n",
       "5273     [import soundfile as sf\\r\\nsf.available_format...\n",
       "5274     [datset=np.array(dataset).reshape(-1, 50, 15),...\n",
       "5275                                                   NaN\n",
       "5276                   [y, scores[torch.arange(5), y]\\r\\n]\n",
       "5277     [torch.gather,  torch.gather(scores, 1, y[:,No...\n",
       "5278       [Conv2d, Linear, Conv2d, nn.Linear, Flattening]\n",
       "5279     [torch.device(), .to(device), .cpu().detach(),...\n",
       "5280     [Net, encoder, decode, forward, nn.Module, nn....\n",
       "5281     [class A(object):\\r\\n    def __init__(self):\\r...\n",
       "5282     [__init__, self, this, class Point:\\r\\n    def...\n",
       "5285     [class MyClass:\\r\\n    \"\"\"A simple example cla...\n",
       "5287     [#! /usr/bin/python2\\r\\n\\r\\nclass Person:\\r\\n\\...\n",
       "5288     [__init__, __init__, def __init__(self, arg1, ...\n",
       "5292     [class foo:\\r\\n    def bar(self):\\r\\n         ...\n",
       "5293     [class MyClass:\\r\\n\\r\\n    def __init__(self):...\n",
       "5294     [class Cat:\\r\\n    def __init__(self, name):\\r...\n",
       "5295     [# Source: Class and Instance Variables\\r\\n# h...\n",
       "5297     [__init__, self, self, __init__, class SomeObj...\n",
       "5298     [device = torch.device('cuda') if torch.cuda.i...\n",
       "5300     [ weight = torch.rand(1, 1, 5, 5)\\r\\n, padding...\n",
       "5302     [(10, 250, 150), # x is of shape (10, 250, 150...\n",
       "5303                                                   NaN\n",
       "5304     [with torch.no_grad():\\r\\n    gt_vgg_features ...\n",
       "5305     [encoded = torch.tensor([10,  4, 17, 19, 16, 2...\n",
       "5306     [torch.Tensor.to, device,  mask = torch.tril(t...\n",
       "5307                                                   NaN\n",
       "5308                                                   NaN\n",
       "5310     [from keras import backend as K\\r\\n\\r\\ndef mas...\n",
       "5311     [torch.load, state_dict = torch.load('model_fi...\n",
       "5312           [min_prediction_length, min_encoder_length]\n",
       "5313                                                   NaN\n",
       "5314     [filter_vals, 10, conv1,  conv1.weight.data = ...\n",
       "5315     [conv, conv1 = nn.Conv2d(1, 6, 3)\\r\\nconv2 = n...\n",
       "5316                       [nn.Module, pl.LightningModule]\n",
       "5317                                                   NaN\n",
       "5319     [pretrained=True, pretrained=False, checkpoint...\n",
       "5320     [detection.fasterrcnn_resnet50_fpn(pretrained=...\n",
       "5321                                                   NaN\n",
       "5322     [.to(), all_preds_int = all_preds.to(torch.int...\n",
       "5323     [topk, def remove_weaklings(x, percentage, axi...\n",
       "5324                                                   NaN\n",
       "5325     [args.epoch_iters, loader_train, StopIteration...\n",
       "5326     [class NormalAutoEncoder(nn.Module):\\r\\n    de...\n",
       "5327     [.load_state_dict(), model.load_state_dict(che...\n",
       "5328     [original_array = torch.rand(1, 512, 37, 59)\\r...\n",
       "5330                                                   NaN\n",
       "5331                                                   NaN\n",
       "5332     [with torch.no_grad():\\r\\n     model.eval()\\r\\...\n",
       "5333                            [dtype='float32', float()]\n",
       "5334                         [hn, (D*num_layers, N, Hout)]\n",
       "5335     [batch_size=64, 4, dataloader, 4, one[3].shape...\n",
       "5336                                                   NaN\n",
       "5337                                                   NaN\n",
       "5338     [torch.save(model.state_dict(), PATH), torch.s...\n",
       "5339     [batch_size, batch_size, trainloader, DataLoad...\n",
       "5340     [parameters = set()\\r\\nfor net in nets:\\r\\n   ...\n",
       "5341                                                   NaN\n",
       "5342     [ pad = lambda v: F.pad(v, [0, len(m)-len(v)],...\n",
       "5343     [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "5345     [streaming =True,  dataset = load_dataset (\"/....\n",
       "5346     [torch.autograd.Function, nn.Module, torch.aut...\n",
       "5348     [for index, data in enumerate(zip(d[0],d[1],d[...\n",
       "5349     [torch.version.cuda, 10.2, 11.4, conda install...\n",
       "5350     [0, nn.NLLLoss,  logits = torch.randn(5, 3, re...\n",
       "5351                                                   NaN\n",
       "5353     [state_dict, state_dict, GatherModel(), state_...\n",
       "5354                                                   NaN\n",
       "5355                                                   NaN\n",
       "5356     [__getitem__, idx, class SinusDataset(Dataset)...\n",
       "5357     [torch.nn.Module.forward, self, self, data,   ...\n",
       "5359     [float[] NO_NORM_STD = {1.0f, 1.0f, 1.0f};\\r\\n...\n",
       "5360     [arr, mask.reshape((2, 1, 3, 3)) * arr\\r\\n, ma...\n",
       "5361     [res, .requires_grad, torch.cat, torch.FloatTe...\n",
       "5362     [emb, torch.Tensor, res, requires_grad, res, e...\n",
       "5363     [pyro, A, B, C, p(D|A,B,C), def cond_mean(a, b...\n",
       "5364                                                   NaN\n",
       "5365     [vec, length, torch.tensor, def variable_from_...\n",
       "5367     [torch.optim.SGD, 'momentum_buffer',  m = nn.L...\n",
       "5368     [collate_fn, def collate_fn(list_items):\\r\\n  ...\n",
       "5369     [r1[0, 0], r2[80, 0], r1[0, 0] - r2[80, 0], 0....\n",
       "5370                                                   NaN\n",
       "5371                                                   NaN\n",
       "5373     [cuda, autocast, import torch\\r\\nfrom torch im...\n",
       "5374     [jax.lax.pad, torch.nn.functional.pad, from ja...\n",
       "5375                                       [@, __matmul__]\n",
       "5376                                                   NaN\n",
       "5377     [torch.autograd.grad, torch.autograd.grad, bac...\n",
       "5378     [ModelClass:\\r\\n    def__init__(self):\\r\\n\\r\\n...\n",
       "5379     [z, y, z, y,  y = x.pow(2).sum()\\r\\n torch.aut...\n",
       "5380     [B, C, torch.transpose,  A = torch.rand(1, 4, ...\n",
       "5381     [reshape, view, shape, transpose, permute, B=1...\n",
       "5382     [def IoU(predict: torch.Tensor, target: torch....\n",
       "5383     [model = nn.Sequential(nn.LSTM(40, 256, 3, bat...\n",
       "5384     [_, tup = self.bilstm(inp)\\r\\n, out = tup[0].s...\n",
       "5385     [0, 'person', self.all_calibration_params[pers...\n",
       "5386     [man sbatch, --signal=USR1@30, USR1, #SBATCH -...\n",
       "5387     [ weights= np.array([0.00000001, 1/112, 1/116,...\n",
       "5391     [x = torch.tensor([[[1, 2, 3],\\r\\n            ...\n",
       "5392                                                   NaN\n",
       "5394                                                   NaN\n",
       "5395                                                   NaN\n",
       "5396                               [ResNet.pt, state_dict]\n",
       "5397     [torch.nn.functional.one_hot, torch.nn.functio...\n",
       "5400     [data, target, cuda, cuda(), cuda(), to.device...\n",
       "5401     [target, .cuda(), forward(), def forward(self,...\n",
       "5402     [nn.Sequential, Res_Block, __init__, self.l1, ...\n",
       "5403                             [Res_Block, Res_Block[0]]\n",
       "5404     [torch.utils.data.RandomSampler, class DS(Data...\n",
       "5405     [if sys.platform != 'win32':\\r\\n    register_r...\n",
       "5406     [m_numpy, (1,1,6,6), Conv2d, kernel, import nu...\n",
       "5407     [(batch_size, n_channels, height, width), 6x6,...\n",
       "5408                                                   NaN\n",
       "5409     [torch.cat, col1 = torch.cat([t[0] for t in sa...\n",
       "5410     [torch.stack, (rows, cols), (cols, rows),  c1,...\n",
       "5411     [.stack(), .cat(), pyro, [pyro.sample('samples...\n",
       "5412                                                   NaN\n",
       "5413                      [[3, 1024, 1024], [3, 600, 600]]\n",
       "5414                                                   NaN\n",
       "5415     [import torch\\r\\n\\r\\ndef my_softmax(x):\\r\\n\\r\\...\n",
       "5416                                                   NaN\n",
       "5417     [torch.einsum,  torch.einsum('ijkl,i,j,k,l-&gt...\n",
       "5418     [(c * x[:, None, None, None] * x[None, :, None...\n",
       "5419                                                   NaN\n",
       "5421     [Longformer, Bigbird, Reformer, 16k, 4096, 64k...\n",
       "5423                                                   NaN\n",
       "5424     [    #Import the library:\\r\\n    import intel_...\n",
       "5425     [import intel_extension_for_pytorch as ipex\\r\\...\n",
       "5426     [intel_extension_for_pytorch, import intel_ext...\n",
       "5427     [python run_qa.py\\r\\n    --model_name_or_path ...\n",
       "5428     [x, y, torchvision.utils.draw_bounding_boxes, ...\n",
       "5429                                                   NaN\n",
       "5431                                                   NaN\n",
       "5432     [bfloat16, float32, nan/inf, 0, 0, float32, bf...\n",
       "5433     [torch.FloatTensor(map(lambda r: map(lambda x:...\n",
       "5434     [torch.*Tensor,  torch.FloatTensor([recs for r...\n",
       "5435     [requires_grad_,  model_conv.classifier.requir...\n",
       "5436                                       [CustomDataset]\n",
       "5437     [history = xmp.spawn(fit, args=(epochs, lr), n...\n",
       "5438     [t6, t7, generatorG,         # ...\\r\\n        ...\n",
       "5439     [pip install pytorch-ignite, MeanAbsoluteRelat...\n",
       "5440     [torch.distributed.distributed_c10d._get_globa...\n",
       "5441                                          [n, BCELoss]\n",
       "5443     [nn.Module.modules, nn.Module.children, for ch...\n",
       "5444                                                   NaN\n",
       "5445                                                   NaN\n",
       "5446     [H, A, W, A@W, W.sum(), w_mean = A@W / W.sum()...\n",
       "5447     [model.train, with torch.no_grad(), was_traini...\n",
       "5448                                                   NaN\n",
       "5449     [==, torch.isclose(grads[-1], grads_02[-1] * 5...\n",
       "5450                                [f.backward(), x.grad]\n",
       "5451     [requires_grad=True, q = x + y \\r\\nf = q * z\\r...\n",
       "5452     [x = torch.tensor(1., requires_grad = True)\\r\\...\n",
       "5454                                                   NaN\n",
       "5456                                                   NaN\n",
       "5458     [import copy, population = [best_model for _ i...\n",
       "5459     [sm_35, pip install torch==1.3.1+cu92 -f https...\n",
       "5460     [out = self.relu(self.linear5(out))\\r\\n, self....\n",
       "5461     [class Discriminator(nn.Module):\\r\\n    def __...\n",
       "5462        [del tokenizer_ctrl, torch.cuda.empty_cache()]\n",
       "5463     [torch.cat(),  a = torch.rand([16,1])\\r\\n b = ...\n",
       "5464     [# or not only local_rank 0\\r\\nif local_rank =...\n",
       "5465     [list(model.children())[:7], nn.Sequential(), ...\n",
       "5466     [out = self.fc(out[:, -1, :]), batch_size x se...\n",
       "5467                                                   NaN\n",
       "5468                                                   NaN\n",
       "5469     [a = torch.randn(2,3) # input1\\r\\nb = torch.ra...\n",
       "5470     [diff = sample - last_mean\\r\\nsample_covmat = ...\n",
       "5471     [nn.Linear, population[0].weight = nn.Paramete...\n",
       "5472     [x, [x]*n, x, [nn.Linear(1,1) for _ in range(p...\n",
       "5473     [fairseq, master, main, main, bart = torch.hub...\n",
       "5474                                                   NaN\n",
       "5475     [ignore_index, None, nn.NLLLoss, nll_loss, tor...\n",
       "5477     [Tensor.grad, vector_list, torch.randn(), back...\n",
       "5478     [_get_conv1_out, _get_conv2_out, conv1, conv2,...\n",
       "5479                                                   NaN\n",
       "5481                                                   NaN\n",
       "5482            [Python: Select Interpreter, Ctrl+Shift+p]\n",
       "5483     [nn.CrossEntropyLoss, nn.CrossEntropyLoss, cri...\n",
       "5484     [class CycleGan:\\r\\n    ...\\r\\n\\r\\nc_gan = Cyc...\n",
       "5486                       [loss_value += float(loss)\\r\\n]\n",
       "5487     [!pip install torch==1.8.1+cu102 -f https://do...\n",
       "5488     [a, b, b = b - 1, b, a,  a = torch.tensor([[1,...\n",
       "5489     [distribution = pyd.Bernoulli(probs=train_vars...\n",
       "5491     [loss_blue, loss_blue, loss_red, loss_red, net...\n",
       "5492     [y, Long, data[i, :, :], y[i, :], nn.Module, d...\n",
       "5493     [weight[train_labels],  sample_weights = np.ar...\n",
       "5494     [type(module).__name__, nn.Module,  model = So...\n",
       "5495     [nn.Module, out = self.conc([out1, out2])\\r\\n,...\n",
       "5496     [F.nll_loss, F.cross_entropy, pred,  -torch.su...\n",
       "5497     [IterableDataset, __next__, __iter__, getData,...\n",
       "5498                                                   NaN\n",
       "5499     [sudo apt-get install pkg-config\\r\\npip3 insta...\n",
       "5500     [git clone https://github.com/huggingface/tran...\n",
       "5501     [brew install sentencepiece\\r\\npip3 install se...\n",
       "5502     [set_weights, with torch.no_grad():\\r\\n    mod...\n",
       "5503     [*=, mask = text != self.pad_token\\r\\ndenom = ...\n",
       "5505     [torch.nn.utils.prune, torch.nn.utils.prune.re...\n",
       "5506     [weight, torch.nn.functional.conv2d, class Net...\n",
       "5507     [G, x, G = (1 + torch.matmul(x, x.T)).pow(2)\\r\\n]\n",
       "5508     [import dgl.data\\r\\nimport matplotlib.pyplot a...\n",
       "5509                 [y, x, y = batch\\r\\ny = y.long()\\r\\n]\n",
       "5511     [self.transform, blob, image, blob, torch.allc...\n",
       "5512     [D, D, G, D, E_x[log(D(x))] + E_z[log(1-D(G(z)...\n",
       "5513     [(synthesis) miranda9~/automl-meta-learning $ ...\n",
       "5514                                      [--no-cache-dir]\n",
       "5515     [detach, with torch.no_grad():\\r\\n    doc = se...\n",
       "5516     [nn.Module, layers, nn.ModuleList,   self.laye...\n",
       "5517     [nn.Conv2d(in_channels = 1, out_channels = 18,...\n",
       "5520     [float64, float32, float16, float32, float64, ...\n",
       "5521     [h_t = torch.zeros((batch_size,1))\\r\\nc_t = to...\n",
       "5522     [fit(), training=True, gamma * (batch - mean(b...\n",
       "5523     [import torch\\r\\n\\r\\n\\r\\n# Use torch.nn.Module...\n",
       "5524     [nn.Sequential(), import torch\\r\\nencoded_dim ...\n",
       "5525     [yhat, yhat, [0, 1], BCELoss, nn.BCEWithLogits...\n",
       "5526     [dataset.imgs, In [ ]: print(dataset.imgs[0])\\...\n",
       "5527                                                   NaN\n",
       "5528     [out = F.adaptive_avg_pool3d(input=out, output...\n",
       "5530     [H_n^0, (B, L, D), packed_output, h_c, _, (h_t...\n",
       "5531     [logger, class MetricTracker(Callback):\\r\\n\\r\\...\n",
       "5532     [from pytorch_lightning.utilities import rank_...\n",
       "5533     [torch.nn.MaxPool1d, N, [1, 2, 3, 4, 5, 6, 7, ...\n",
       "5534     [torch.max, axis=1,  maxpool = torch_tensor.ma...\n",
       "5535     [[CLS], tokens = tokens[1:]\\r\\ntags = tags[1:]...\n",
       "5536     [import numpy as np\\r\\nimport numba as nb\\r\\n\\...\n",
       "5537     [C_ij = max_k ( W_ik M_kj)\\r\\n, M = W * W - N ...\n",
       "5538     [normalize, a, numpy.ndarray, normalize, b, to...\n",
       "5540                        [func(*torch.tensor[2,3])\\r\\n]\n",
       "5541                                                   NaN\n",
       "5542     [img, (B, C, H, W), B, C, H, W, img[0, 1, 2, 3...\n",
       "5543     [torch-sparse, pip install --upgrade git+https...\n",
       "5544     [ arr.shape\\r\\n(1,2,3)\\r\\n arr.ndim\\r\\n3\\r\\n, ...\n",
       "5545                                                   NaN\n",
       "5546                      [pip install tensorflow-gpu\\r\\n]\n",
       "5547     [idx, [data,label], [data], idx, dataloader, i...\n",
       "5548                   [shuffle=False, DistributedSampler]\n",
       "5549     [requires_grad, False, layer.requires_grad_(Fa...\n",
       "5552                                                   NaN\n",
       "5553                                                   NaN\n",
       "5554     [d = torch.distributions.Uniform(5, 80)\\r\\n\\r\\...\n",
       "5555     [(inputs batch, labels batch), for idx, data i...\n",
       "5557                                                   NaN\n",
       "5558     [from random import randint\\r\\n\\r\\nclass C:\\r\\...\n",
       "5559     [id(), class a:\\r\\n    pass\\r\\n\\r\\nmy_a = a()\\...\n",
       "5560     [import torchtext.legacy, !pip install torchte...\n",
       "5561     [# old \\r\\nfrom torchtext.legacy import data, ...\n",
       "5562                                                   NaN\n",
       "5563                                                   NaN\n",
       "5564     [BertForQuestionAnswering, QuestionAnsweringMo...\n",
       "5565     [from transformers import pipeline\\r\\n\\r\\nnlp ...\n",
       "5566     [dmat, torch.logical_and, mask = torch.logical...\n",
       "5567     [def __init__(self):\\r\\n    ...\\r\\n    self.ls...\n",
       "5568     [[None] * len(labeled_trainloader), None, labe...\n",
       "5569     [torch.nn.CrossEntropyLoss, {l_1, ... l_j, ......\n",
       "5570                                                   NaN\n",
       "5571     [model.param, optim = torch.optim.Adam(model.p...\n",
       "5572                                      [drop_last=True]\n",
       "5573     [state, state = torch.zeros((shape[0], shape[1...\n",
       "5574     [A, loss, my_loss, A,     state = torch.reshap...\n",
       "5577     [conda, pip3, conda, conda-forge, conda instal...\n",
       "5578     [pip3 install torch==1.9.1+cu111 torchvision==...\n",
       "5579     [0.10.1, pip3 install torch==1.9.1+cu111 torch...\n",
       "5580     [module load cuda-toolkit/11.1, 1.9.0-py3.9_cu...\n",
       "5581     [conda install -y torchtext -c pytorch\\r\\n, co...\n",
       "5582     [undefined symbol: _ZTVN5torch3jit6MethodE, ma...\n",
       "5583                                                   NaN\n",
       "5584     [( 8, 1, 2294, 1914, 3), ( 5, 1, 2294, 1914, 3...\n",
       "5585       [transforms.Grayscale(), transform.Compose([])]\n",
       "5586     [int64, sorted_lookup_table, indexes = torch.s...\n",
       "5587     [searchsorted, lookup_table, sorted_lookup_tab...\n",
       "5588     [_colors, indexed_image,  indexed_image = torc...\n",
       "5589     [tensor = tensor.mul(0.5).add(0.5).mul(255.0);...\n",
       "5590     [200k+1, i, 0, if i % 2000 == 1:    # print ev...\n",
       "5591     [axis=0, axis=1, dim, 1,  x = torch.arange(1, ...\n",
       "5592     [n, n, n,  x_1d = list(torch.empty(3, 2))     ...\n",
       "5593     [t1 = torch.tensor([1,2,3])\\r\\nt2 = torch.tens...\n",
       "5594     [optim = torch.optim.Adam(\\r\\n            [\\r\\...\n",
       "5595     [(synthesis) miranda9~/ultimate-utils/ultimate...\n",
       "5597     [state, def forward(x, state):\\r\\n    x, s0 = ...\n",
       "5598     [@Berriel, pip uninstall torch torchvision tor...\n",
       "5599     [import torch\\r\\nimport numpy as np\\r\\nimport ...\n",
       "5601     [--img, --conf, python train.py --img 672 1216...\n",
       "5602     [{\\r\\n  let a = [],\\r\\n      b = [];\\r\\n  func...\n",
       "5603     [TEXT, LABEL, use_vocab=False, LabelField, tor...\n",
       "5604                                [src_key_padding_mask]\n",
       "5605     [conda, conda install pytorch torchvision cuda...\n",
       "5608     [model_ipex=model, model_ipex.to(ipex.DEVICE),...\n",
       "5609                                 [final_model.to(...)]\n",
       "5610     [transforms.Normalize(mean, std), train_datase...\n",
       "5611                                                   NaN\n",
       "5613     [from transformers import AutoTokenizer, AutoM...\n",
       "5614                                                   NaN\n",
       "5615     [model = BertForSequenceClassification.from_pr...\n",
       "5616     [fc1, fc2, p=0.2, input_dim, fc1, fc2,     def...\n",
       "5617                                                   NaN\n",
       "5618     [W_ih, (4*hidden_size, num_directions * proj_s...\n",
       "5619                                                   NaN\n",
       "5620     [...\\r\\nsmall_reshaped = small.transpose(2, 0,...\n",
       "5621     [def chunker(seq, batch_size=16):\\r\\n    retur...\n",
       "5622     [torch.Tensor, list,  P1 = torch.rand(60)\\r\\n ...\n",
       "5623     [float64, float32, tensor(1.2).item()\\r\\ntenso...\n",
       "5624                                   [test_loader, 1225]\n",
       "5625                            [__getitem__(self, index)]\n",
       "5626                                                   NaN\n",
       "5627     [(batch_size,),   model = CNN()\\r\\n  criterion...\n",
       "5628            [pip3 uninstall torch, pip3 install torch]\n",
       "5629     [grad,  p = nn.Linear(10, 1, bias=False)\\r\\n p...\n",
       "5630     [forward, torch.cat((x, y), 1), class AlexNet(...\n",
       "5631     [cudnnConvolutionBackwardFilter, CUDNN_CONVOLU...\n",
       "5632     [from PIL import Image\\r\\nfrom PIL import Imag...\n",
       "5633     [cudatoolkit, pytorch, environment.yml, name: ...\n",
       "5634     [conda, 4.10.3, 4.11.0, conda --version, conda...\n",
       "5635                           [torch.cuda.is_available()]\n",
       "5636     [transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0....\n",
       "5637     [# Calculate the mean, std of the complete dat...\n",
       "5638     [Dropout, import torch\\r\\nfrom torch.nn.functi...\n",
       "5639     [droppath, x = x + droppath(block(x))\\r\\n, blo...\n",
       "5640     [@, __matmul__, x, (N, *, in_feature), w, (out...\n",
       "5641     [def test_dataloader(self):\\r\\n    mnist_test ...\n",
       "5642     [test_dataloader, return, def test_dataloader(...\n",
       "5643     [return, test_dataloader(), Dataset, DataLoade...\n",
       "5644     [CUDA 11.1, ~/.bashrc, ~/.bashrc, export CUDA_...\n",
       "5645     [Compiling cuda extensions with\\r\\nnvcc: NVIDI...\n",
       "5646                             [int_classes = int, _six]\n",
       "5647                                                   NaN\n",
       "5648                                        [nn.MaxPool2d]\n",
       "5649                                                   NaN\n",
       "5650     [checkpoint_callback, pl.Trainer, checkpoint_c...\n",
       "5651     [16*4*4, 256, 16*5*5, self.fc1 = nn.Linear(256...\n",
       "5652     [if dis_loss is not None:\\r\\n    dis_loss.back...\n",
       "5653     [def backward(self, gen_loss=None, dis_loss=No...\n",
       "5654                                                   NaN\n",
       "5655     [nn.Conv1d, nn.Conv2d, nn.Conv3d, _ConvNd, res...\n",
       "5656     [class Autoencoder(nn.Module):\\r\\n  def __init...\n",
       "5657     [.cuda(), .to(device), with profile(activities...\n",
       "5658     [th2, waitKey(1), threading.Event, waitKey(30)...\n",
       "5659     [time.sleep(0.03), waitKey(), import time\\r\\nd...\n",
       "5661     [output, output, probs = torch.nn.functional.s...\n",
       "5662     [f: x, y -&gt; (x - y)², mse_loss, reduction, ...\n",
       "5663     [conda install pytorch torchvision torchaudio ...\n",
       "5664     [ToTensorV2, trainset = datasets.ImageFolder(t...\n",
       "5665     [import numpy as np\\r\\nfrom typing import Any,...\n",
       "5666     [nn.MaxPool1d, kernel_size, stride,  m = nn.Ma...\n",
       "5667     [m = nn.MaxPool1d((4,), 4)\\r\\n, torch.nn.MaxPo...\n",
       "5668                             [A_tensor.reshape(768,1)]\n",
       "5669                                                   NaN\n",
       "5670     [nn.Module, tf.keras.layers.Layer, call, forwa...\n",
       "5671     [nn.Conv3d(in_c, out_c, conv_kernel_size, padd...\n",
       "5672     [Byte, Float, np.uint8, np.float32, __getitem_...\n",
       "5673     [wandb, wandb.log({'val_loss': val_loss, 'trai...\n",
       "5674     [v, x, forward, Net2, class Net(nn.Module):\\r\\...\n",
       "5675                                                   NaN\n",
       "5676                                                   NaN\n",
       "5677        [torch.use_deterministic_algorithms(True)\\r\\n]\n",
       "5678     [__init__(...), class GNN(nn.Module):\\r\\n  def...\n",
       "5679     [%pip install cloud-tpu-client==0.10 https://s...\n",
       "5680     [import torch\\r\\nx = torch.randn(size=(4,3,2))...\n",
       "5681     [import torch\\r\\n\\r\\ntorch.manual_seed(2021)\\r...\n",
       "5682     [def delete_row_tensor(a, del_row, device):\\r\\...\n",
       "5683     [x*y, import torch\\r\\n\\r\\ntorch.manual_seed(20...\n",
       "5684                                                   NaN\n",
       "5685     [...\\r\\nfor Images, Poses in dataiter:\\r\\n    ...\n",
       "5686                    [.cpu(), .cpu(), .cpu(), PoseLoss]\n",
       "5687                                                   NaN\n",
       "5688                                                   NaN\n",
       "5690     [aten::copy_, cudaHostAlloc, cudaLaunchKernel,...\n",
       "5691     [nn.Module, class NN(nn.Module):\\r\\n    def __...\n",
       "5692     [f: x -&gt; x², df/dx = 2x, df/dx, x, torch.no...\n",
       "5693                                                   NaN\n",
       "5694        [loss = loss_fun(y_pred, y_train.float())\\r\\n]\n",
       "5695     [global_output, local_output = gen(noise.to(de...\n",
       "5696     [state_dict, load_state_dict,  model_ce.load_s...\n",
       "5697     [model = nn.Sequential(\\r\\n    nn.Linear(3072,...\n",
       "5698     [import torch\\r\\nimport torch.nn as nn\\r\\nmode...\n",
       "5699     [item&lt;T&gt;(), int main() {\\r\\n    auto con...\n",
       "5700     [DataLoader, batch_sampler, sampler, Dataset, ...\n",
       "5701     [local mode, privileged, 2.80.0, local mode, s...\n",
       "5702     [nn.Conv2d(3, 49, 4, bias=True), nn.Conv2d(3, ...\n",
       "5703     [(1, 3, 128, 128),  my_list = [torch.rand(1, 3...\n",
       "5704     [ vgg16 = torchvision.models.vgg(pretrained=Tr...\n",
       "5706     [RUN git clone https://github.com/CVMI-Lab/ST3...\n",
       "5707     [__getitem__, train_set,  non_augmented = CIFA...\n",
       "5708     [class MyRandomResizedCrop(object):\\r\\n    def...\n",
       "5709     [RandomResizedCrop, scale, scale, RandomResize...\n",
       "5710     [| Trial name                    | status   | ...\n",
       "5711     [dim=?, torch.max, (values, indices), torch.ti...\n",
       "5712     [torch.histc, collections.Counter, torch.histc...\n",
       "5713     [batch_size=2, input_dim, model = Simple_NN(in...\n",
       "5714     [PReLU (LeakyReLU), PReLU (LeakyReLU), docker ...\n",
       "5715     [.view(-1), loss = criterion(output, target.vi...\n",
       "5718                                                   NaN\n",
       "5720     [torch.save, f, torch.save, os.PathLike, write...\n",
       "5721                                                   NaN\n",
       "5722     [torch.scatter_, value, Tensor.scatter_(dim, i...\n",
       "5723                                                   NaN\n",
       "5724     [criterion = nn.BCEWithLogitsLoss(reduction='n...\n",
       "5725     [for g_iter in range(generator_iters), d_progr...\n",
       "5726     [\\r\\n    from torch.utils.data import Dataset,...\n",
       "5727     [from torch.utils.data import DataLoader\\r\\n\\r...\n",
       "5728     [transforms, transforms.ToPILImage(), # [...]\\...\n",
       "5729     [ravel_multi_index, output = input[idx[0, :], ...\n",
       "5730     [loss,     loss += criterion(output, target_cl...\n",
       "5732     [torch_geometric.utils.convert.from_scipy_spar...\n",
       "5733                                                   NaN\n",
       "5734                                                   NaN\n",
       "5735                                                   NaN\n",
       "5736     [batch_size, model.fit, steps_per_epoch, model...\n",
       "5737     [sequence_output = encoder_outputs[0]\\r\\nseque...\n",
       "5738     [x, y, torch.nn.Module.register_forward_hook, ...\n",
       "5739     [NUM_EPOCHS = 100\\r\\ntrain_data, val_data = .....\n",
       "5740     [ layer = nn.Linear(4, 1, bias=False)\\r\\n laye...\n",
       "5741     [y_pred, (batch_size, n_classes), (3, 4), y_tr...\n",
       "5742                                                   NaN\n",
       "5743     [import torch\\r\\n\\r\\nx = torch.tensor([\\r\\n   ...\n",
       "5744                                                   NaN\n",
       "5745     [keepdim=True, torch.max(), torch.take_along_d...\n",
       "5746     [ Ordinal_Pooling_NN(torch.tensor([[1.9, 0.4, ...\n",
       "5747     [loss_class = F.cross_entropy(out_class, y_cla...\n",
       "5748     [loc = torch.load('/content/gdrive/MyDrive/Dat...\n",
       "5749     [Xs, (n, 2), x, (2,), (n, 2), Xs, x, (1, 2), T...\n",
       "5750                                                   NaN\n",
       "5751     [Data(edge_index=[2, 4], x=[3, 1]), edge_index...\n",
       "5752     [torch.sum(), torch.sqrt(torch.sum(torch.squar...\n",
       "5753     [torch.cdist, torch.cdist(train.unsqueeze(0), ...\n",
       "5754     [pytorch, cudatoolkit=11.2, cudatoolkit=11.2, ...\n",
       "5755     [forward, for name, module in res.named_module...\n",
       "5756     [from .transform import GeneralizedRCNNTransfo...\n",
       "5757     [loss_func, # Pick a random input to the netwo...\n",
       "5761     [padding=True, truncation=True, max_length = 1...\n",
       "5762     [outputs.last_hidden_state[:, 0. :], outputs.l...\n",
       "5763     [torch.autograd.grad(x, W, grad_outputs=torch....\n",
       "5764     [f, θ_ag, θ_bg, f(x; θ_ag, θ_bg), ag, bg, L = ...\n",
       "5765                                                   NaN\n",
       "5766     [import torch\\r\\n\\r\\nx = torch.Tensor(\\r\\n   [...\n",
       "5767     [axis=1, 3, axis=-1, torch.permute, torch.swap...\n",
       "5768                                                   NaN\n",
       "5769     [multiprocessing, request.session, requests.se...\n",
       "5770     [torch.einsum, torch.matmul,  torch.einsum('ij...\n",
       "5772     [.__class__(), ann1.load_state_dict(ann1.state...\n",
       "5773     [torch.load(), # Model class must be defined s...\n",
       "5774                                                   NaN\n",
       "5776     [S,T, mask, S, T, ST,  ST = torch.stack((S, T)...\n",
       "5777     [torch.stack(\\r\\ntorch.meshgrid(x, y)\\r\\n).T.r...\n",
       "5778     [TypeError: cannot pickle 'generator' object, ...\n",
       "5780     [nn.Modules, nn.Sequential, import torch.nn as...\n",
       "5781     [denseblock1.denselayer2.conv1, model.densenet...\n",
       "5783     [torch.Tensor,  print('{:.2f}'.format(torch.ra...\n",
       "5784     [def doc_pairs_with_n_docs_per_shingle(X, nps=...\n",
       "5785     [F.normalize, dim=1, if self.l2_norm:\\r\\n    m...\n",
       "5786     [Pytorch Geometric, train_mask, A&lt;-&gt;B\\r\\...\n",
       "5787     [out = model(data[data.train_mask]), Data, tra...\n",
       "5788          [np.random.choice(list(candidate_sets))\\r\\n]\n",
       "5789     [polyvore_outfits.py,         [...]\\r\\n       ...\n",
       "5790     [Vocab, torch.nn.Module, __call__, forward(), ...\n",
       "5791     [torch.profiler, profiler, # other profilers a...\n",
       "5792     [kwargs, 'args', *args, 'kwargs', **kwargs, Co...\n",
       "5794     [nn.Conv3d, model.conv1.conv_1.conv3d = nn.Con...\n",
       "5795     [torch.Tensor, torch.Tensor, axis=0, axis=-2, ...\n",
       "5796     [from abc import ABC\\r\\n\\r\\nimport torch\\r\\nim...\n",
       "5797     [NotImplementedError, __len__, self.data_image...\n",
       "5798     [layers[0], 64, layer1, self.layer_attend1 =  ...\n",
       "5799                       [load_state_dict, strict=False]\n",
       "5800     [np.unique, unq, ind = np.unique(np.stack((x, ...\n",
       "5801     [x = torch.tensor([0, 0, 0, 1, 1, 2, 2, 2, 2])...\n",
       "5802     [c.shape = (40, 6), c = a * b.unsqueeze(1)\\r\\n...\n",
       "5803     [model = ConvNet()\\r\\n\\r\\n# get data from some...\n",
       "5804                                                   NaN\n",
       "5805     [class Net(nn.Module):   \\r\\n\\r\\n\\r\\n   def __...\n",
       "5806     [output, (batch_size, n_logits), (batch_size, ...\n",
       "5807     [DeepLabV3, OrderedDict[Tensor], OrderedDict, ...\n",
       "5808     [from torch.autograd.functional import jvp\\r\\n...\n",
       "5809     [input.shape[0] x input.shape[1],  x_f = x.fla...\n",
       "5810     [torch.cuda.empty_cache()\\r\\n, import datetime...\n",
       "5811     [torch.cuda.empty_cache(), torch.cuda.empty_ca...\n",
       "5812     [__name__ == '__main__', True, dataloader, mod...\n",
       "5814     [data, torch.utils.data.random_split, from tor...\n",
       "5815     [(fc): Linear(in_features=512, out_features=10...\n",
       "5816                                                   NaN\n",
       "5817     [axis=1,  x = x.unsqueeze(1)\\r\\n, __getitem__,...\n",
       "5818     [data,  model.weight.data[0, 2] = 0\\r\\n, torch...\n",
       "5819     [torch.Tensor.scatter_, value, src,  value.sca...\n",
       "5820     [dm.train_dataloader(), dm.train_loader, for b...\n",
       "5821     [#images=#batches, (3, 1, 28, 28), (3, 3, 28, ...\n",
       "5822     [input_batch.size = torch.Size([1, 3, 519, 103...\n",
       "5823     [import torch\\r\\nimport torchvision\\r\\nfrom de...\n",
       "5824     [__getitem__, def __getitem__(self, index):\\r\\...\n",
       "5825     [hidden, torch.manual_seed(1)\\r\\nlstm = nn.LST...\n",
       "5826                                                   NaN\n",
       "5828     [onnx2pytorch, onnx_model = onnx.load(path_to_...\n",
       "5829     [from transformers import BertTokenizerFast\\r\\...\n",
       "5830     [import numpy as np                           ...\n",
       "5831                                         [batch_first]\n",
       "5832     [self.image_list[idx][2:], self.image_list['pa...\n",
       "5833     [class Attention_module(torch.nn.Module):\\r\\n ...\n",
       "5835     [position_ids, position_ids, position_ids = to...\n",
       "5836                                                   NaN\n",
       "5837                                                   NaN\n",
       "5838                                                   NaN\n",
       "5839     [torch.distributed.Reducer, DistributedDataPar...\n",
       "5840                             [gradient_as_bucket_view]\n",
       "5841     [forward, def forward(self, x):\\r\\n    ...\\r\\n...\n",
       "5842     [ f = lambda x, y: (x**3 + y**3).mean()\\r\\n H ...\n",
       "5843     [VSCode, ipynb, remote-ssh, VSCode, VPN, impor...\n",
       "5844     [for i in model.parameters():\\r\\n    x = i.dat...\n",
       "5845                                                   NaN\n",
       "5846     [torch.unique, return_counts,  x = torch.randi...\n",
       "5847     [input dim, kernel_size, input_size, #An examp...\n",
       "5848     [loss_fn, classes, self.df.Finding.unique(), l...\n",
       "5849     [torch.roll,  rolled = x.roll(shifts=1, dims=1...\n",
       "5850     [torch.no_grad(), train,         with torch.no...\n",
       "5851                                                   NaN\n",
       "5852     [    n_input, n_output = 5, 3\\r\\n    x = torch...\n",
       "5853     [5, z = x@w + b, bce = -[y_true*log(σ(y_pred))...\n",
       "5854         [[], ., model.dl.backbone.layer4[2]conv3\\r\\n]\n",
       "5855                                                   NaN\n",
       "5856                          [x &gt;= 0, x[x &lt; 0] = 0]\n",
       "5857     [conda activate &lt;name&gt;, conda install nu...\n",
       "5858     [torch.nn.utils.prune, Conv2D, import torch\\r\\...\n",
       "5859     [tf.matmul, for i in range(10000):\\r\\n  C = A ...\n",
       "5860                                                   NaN\n",
       "5861                                     [clip_grad_norm_]\n",
       "5862                                                   NaN\n",
       "5863     [num_workers, 0, num_workers, 0, num_workers=0...\n",
       "5864     [train_iterator = BucketIterator.splits(\\r\\n  ...\n",
       "5865     [torchtext, TranslationDataset, TabularDataset...\n",
       "5866     [selective_mask, def selective_mask(image_src,...\n",
       "5867     [best_loss = 0, if val_loss &gt; best_loss:\\r\\...\n",
       "5868                                        [ReLU, Linear]\n",
       "5869     [num_labels=9, hf_model = AutoModelForSequence...\n",
       "5871     [Traceback (most recent call last):\\r\\n  File ...\n",
       "5872                                                   NaN\n",
       "5873     [def init_mlp(layer_sizes, std=.01, bias_init=...\n",
       "5874                                                   NaN\n",
       "5875     [nn.Sequential, nn.Module, class Square(nn.Mod...\n",
       "5876     [x / x.mean(0), BatchNorm2d, GroupNorm, BatchN...\n",
       "5877     [float32, float16, torch.cuda.amp, float32, fl...\n",
       "5879     [huggingface-transformers, AutoModel.from_pret...\n",
       "5880     [ x = torch.ones(2,3,4).transpose(0,1)\\r\\n x_p...\n",
       "5881                                                   NaN\n",
       "5882     [LazyLinear, torch.nn.Linear, in_features, for...\n",
       "5883     [cnn = nn.Sequential(\\r\\n    nn.Conv2d(3, 32, ...\n",
       "5884     [b, import torch\\r\\nx = [1,2,3,4,5,6,7,8,9,10,...\n",
       "5885     [x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\\r\\nx =...\n",
       "5886     [errG.backward()\\r\\ntorch.nn.utils.clip_grad_n...\n",
       "5887     [def my_Conv2dRelu_b2(input_q, conv_layer, out...\n",
       "5888                                                   NaN\n",
       "5889     [...\\r\\nfrom torch.utils.tensorboard import Su...\n",
       "5890                                                   NaN\n",
       "5891                                                   NaN\n",
       "5892     [!pip uninstall torch\\r\\n, Proceed (y/n)?, y, ...\n",
       "5893     [torch.hub._validate_not_a_forked_repo=lambda ...\n",
       "5894     [labels = labels.long(), labels = torch.hstack...\n",
       "5895     [self.make_gen_block, self, __init__, self, se...\n",
       "5896                                                   NaN\n",
       "5897     [as_strided, torch.as_strided, as_strided, lin...\n",
       "5898     [self.down_blocks = nn.ModuleList = ([\\r\\n...\\...\n",
       "5899     [ImageFolder, torch.utils.data.random_split,  ...\n",
       "5900     [train_data = train_data.__getitem__([i for i ...\n",
       "5901     [[tool.poetry.dependencies]\\r\\npython = \"^3.8\"...\n",
       "5902     [torch.gather, torch.gather(prob,1, y)\\r\\n, ga...\n",
       "5903     [dset.ImageFolder, loader, pil_loader, def pil...\n",
       "5904     [import torch\\r\\n\\r\\ndef my_func(device: str, ...\n",
       "5905     [encoding = tokenizer.encode_plus(question, to...\n",
       "5906                                                   NaN\n",
       "5907     [torch.permute, x, torch.rand(3, 3, 512, 256),...\n",
       "5908                                           [unsqueeze]\n",
       "5909     [CSVDataset, torch.utils.data.ConcatDataset, C...\n",
       "5911     [forward, torchvision.models.resnet152, layer4...\n",
       "5912        [import torch\\r\\nprint(torch.__version__)\\r\\n]\n",
       "5913     [import torch\\r\\nA = torch.tensor([range(1,11)...\n",
       "5914     [torchvision,  vgg = torchvision.models.vgg16(...\n",
       "5915     [x, 100, 16, 100, 16x16, 100*16*16, y, 100, 10...\n",
       "5916     [torchvision.transforms.Normalize, torchvision...\n",
       "5917     [train_transform = transforms.Compose([\\r\\n   ...\n",
       "5918     [__getitem__,     def __getitem__(self, index)...\n",
       "5919                                                   NaN\n",
       "5920     [nn.GRU, torch.nn.GRU,  gru = nn.GRU(input_siz...\n",
       "5921                                                   NaN\n",
       "5922     [norm, masked_embedding, [256, 66, 64], norm, ...\n",
       "5923     [ torch.load('model.pt', encoding='ascii')  # ...\n",
       "5925     [pip3, python, python3, python3.6, python3.8, ...\n",
       "5926     [torch.nn.BCELoss, torch.nn.BCELoss(), x = tor...\n",
       "5927     [__call__(), def, def my_func(m,n):\\r\\n    ret...\n",
       "5928     [axis=1, t,   t\\r\\ntensor([[[11., 12.],\\r\\n   ...\n",
       "5929     [uploaded = files.upload(), best_test.pth, sta...\n",
       "5930     [.upload(), state_dict = torch.load(next(iter(...\n",
       "5931     [Image.fromarray, Image.fromarray(img[...,::-1...\n",
       "5933                                                   NaN\n",
       "5934                                                   NaN\n",
       "5935     [torch.gather, x, x.shape = (4, 8, 6), tensor(...\n",
       "5936                                                   NaN\n",
       "5937                                                   NaN\n",
       "5938     [transforms.Scale(imageSize), ....\\r\\ntransfor...\n",
       "5939     [[myhost ~]$ screen\\r\\n, [myhost ~]$ screen -r...\n",
       "5940                                      [[0, 1], (h, w)]\n",
       "5941                                                   NaN\n",
       "5942     [activation = {}\\r\\ndef get_activation(name):\\...\n",
       "5944     [model.eval(), # ...\\r\\n\\r\\nmodel.to(device)\\r...\n",
       "5945     [_bn, torchvision, batch_size=2, batch_size=12...\n",
       "5946     [input, text, def forward(self, input, text, i...\n",
       "5947     [model, out = model(x)\\r\\n, __init__, model, Y...\n",
       "5948              [Accelerator, None, Google Colaboratory]\n",
       "5949                               [pip list | grep torch]\n",
       "5950                 [!pip uninstall cloud-tpu-client\\r\\n]\n",
       "5951     [RUN pip3 install torch==1.9.0+cpu torchvision...\n",
       "5952                                                   NaN\n",
       "5953     [nn.Conv1d, (batch_size, n_channels, sequence_...\n",
       "5954                                                   NaN\n",
       "5955     [groups, kernel.weight.grad = conv.weight.grad...\n",
       "5956     [kernel.weight.data = conv.weight.data.mean(0)...\n",
       "5957     [-9223372036854775808, NaN, NaN, y_true_2 = to...\n",
       "5958                                                   NaN\n",
       "5959     [0, from torch.distributions.multivariate_norm...\n",
       "5960     [.to('cuda'), shape_p = shape.to('cuda'), shap...\n",
       "5962     [os.urandom(), import  functools\\r\\nimport  os...\n",
       "5963     [pytorch_geometric, from_networkx, from_networ...\n",
       "5964                                                   NaN\n",
       "5965     [nn.AdaptativeAveragePool2d, (10, 256, 6, 6), ...\n",
       "5966     [conda install pytorch -c pytorch-nightly --fo...\n",
       "5967     [conda, pip, pip3 install --pre torch torchvis...\n",
       "5968                                                   NaN\n",
       "5969     [hidden_size, (1, out_features), batch_size=1,...\n",
       "5970     [import torch\\r\\n\\r\\n# creating a dummy model\\...\n",
       "5971     [vgg.pth, import torchvision\\r\\nvgg = models.v...\n",
       "5972     [import numpy as np\\r\\n\\r\\nA = np.array([[1,0,...\n",
       "5973     [outputs = network(imgs), loss = loss_fn(outpu...\n",
       "5974     [double outputs_data[batch];\\r\\nstd::memcpy(ou...\n",
       "5975     [conda install pytorch-geometric -c rusty1s -c...\n",
       "5976          [y_train = y_train.values.reshape(-1,1)\\r\\n]\n",
       "5977     [1, 2, 0, 1, labels, 0, 1, tensor([1, 1, 1, 1,...\n",
       "5978     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "5980     [log_metrics, save_metrics, # rest of the trai...\n",
       "5981                                                   NaN\n",
       "5983     [num_workers=0, criterion(outputs_t.float(), t...\n",
       "5984                                                   NaN\n",
       "5985     [AutoModelForSequenceClassification, softmax, ...\n",
       "5986                                                   NaN\n",
       "5987     [import os\\r\\n\\r\\nfrom torchvision.datasets.fo...\n",
       "5988     [torch.einsum,  feature_matrix_new = torch.ein...\n",
       "5989     [perm, Transpose_52, onnxruntime/core/provider...\n",
       "5990                                                   NaN\n",
       "5991     [auto output1_t = output.toTuple()-&gt;element...\n",
       "5992     [To draw bounding boxes you can try the follow...\n",
       "5993                                                   NaN\n",
       "5994                                                   NaN\n",
       "5995     [pix_w = int(bb[2]*img_w)\\r\\npix_h = int(bb[3]...\n",
       "5996                                                   NaN\n",
       "5997     [torch.diag,  new_probs.diag()\\r\\ntensor([-1.1...\n",
       "5998     [v_min, v_max, new_min, new_max,  v_min, v_max...\n",
       "6000                    [--ntasks-per-node, 1, --nodes, 1]\n",
       "6001                                                   NaN\n",
       "6002                                                   NaN\n",
       "6003     [collate_fn, class DS(Dataset):\\r\\n    def __i...\n",
       "6004      [KeyError, self.side_map[side]), KeyError: None]\n",
       "6005            [padding='max_length', tokenizer.encode()]\n",
       "6006     [f, x, (n,), y = f(x), (n, n), [x_i]_i for i ∈...\n",
       "6007     [torch.utils.data.ConcatDataset([test_set_a, t...\n",
       "6008                                   [aws configure\\r\\n]\n",
       "6009     [(bs, c, w), (4, 1, 4), 4, 4, (bs, 4, 1), (4,)...\n",
       "6010                                                   NaN\n",
       "6011     [transforms.Resize(), InterpolationMode.BILINE...\n",
       "6012                                                   NaN\n",
       "6013     [def forward(self, x):\\r\\n   x = F.relu(self.c...\n",
       "6015     [nan/Inf, forward, TrainingArguments, args = T...\n",
       "6017                                         [num_workers]\n",
       "6018     [...\\r\\n...\\r\\n\\r\\ntrain_set = IndexedDataset(...\n",
       "6019                                                   NaN\n",
       "6020                                                   NaN\n",
       "6021     [def __contains__(self, element):\\r\\n    r\"\"\"C...\n",
       "6022     [to.device('name_device'), torch.Tensor, name_...\n",
       "6023        [torch.use_deterministic_algorithms(True)\\r\\n]\n",
       "6024                                                   NaN\n",
       "6025     [google/reformer-enwik8, LMHead, google/reform...\n",
       "6026     [config.axial_pos_embds_dim, (d1,d2), config.a...\n",
       "6027     [z = torch.zeros(2, 3)\\r\\noutput=  (z,z.clone(...\n",
       "6028                           [h, c = output, output\\r\\n]\n",
       "6029     [# put model in train mode\\r\\nmodel.train()\\r\\...\n",
       "6030     [SelfAttention, import torch\\r\\nimport torch.n...\n",
       "6032     ['''\\r\\nfirst import the following, here Paral...\n",
       "6033     [(-1,), -1, value.shape[2:], value.shape, valu...\n",
       "6034                                                   NaN\n",
       "6035     [model.resize_token_embeddings(len(tokenizer))...\n",
       "6038     [import dgl\\r\\nimport numpy as np\\r\\nimport pi...\n",
       "6039                                                   NaN\n",
       "6040     [mask = output[0]['scores'] &gt; 0.3\\r\\nfor ke...\n",
       "6041     [result = []\\r\\nfor d in output:\\r\\n  boxes, l...\n",
       "6042     [transformers.GPT2LMHeadModel, transformers.GP...\n",
       "6043                                                   NaN\n",
       "6044     [wt.sum(), wt=one_hot*weight,  wt = one_hot*we...\n",
       "6045     [1e-4, 1e-4, scheduler, torch.optim.lr_schedul...\n",
       "6046                                                   NaN\n",
       "6047     [weight, self.layer1, self.layer2, nn.Conv2d, ...\n",
       "6048                                                   NaN\n",
       "6049                                                   NaN\n",
       "6050                                                   NaN\n",
       "6051     [# First I create some dummy data\\r\\nlabel = n...\n",
       "6052     [# define a separator token\\r\\nsep_idx = 70\\r\\...\n",
       "6053     [torch.gather, torch.gather(t.expand(4, -1), 1...\n",
       "6054                                                   NaN\n",
       "6057     [label_ids, label, label, int, float, torch.Te...\n",
       "6058                                                   NaN\n",
       "6059     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "6060     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "6061     [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "6064     [/opt/myglibc, LD_LIBRARY_PATH=/opt/myglibc py...\n",
       "6065                                                   NaN\n",
       "6066                [torch.backends.cudnn.enabled = False]\n",
       "6067                                                   NaN\n",
       "6069     [# First you can use model.children() method t...\n",
       "6070            [pip install --upgrade pandas==1.2.5 \\r\\n]\n",
       "6071     [def train(epoch, loader, loss_fn, optimizer, ...\n",
       "6073     [input = input.view(input.size(0), 3, 70, 320)...\n",
       "6074                                                   NaN\n",
       "6076                           [import dill as pickle\\r\\n]\n",
       "6078                                                   NaN\n",
       "6079     [i, True, i, True,  y[mask] = x[mask]\\r\\n y\\r\\...\n",
       "6080          [(x.unsqueeze(1) + x_cent.unsqueeze(0))\\r\\n]\n",
       "6081     [validation_set = torchvision.datasets.MNIST('...\n",
       "6082     [cuda:2, cuda:0, map_location=device_id, torch...\n",
       "6083                                                   NaN\n",
       "6084     [project = partial(\\r\\n        pyproj.transfor...\n",
       "6085                                       [model.train()]\n",
       "6087     [O(n), input = input.to(torch.bool)\\r\\nfor i, ...\n",
       "6089                                                   NaN\n",
       "6091                                                   NaN\n",
       "6092                                                   NaN\n",
       "6093     [def train(nets, loaders, optimizer, criterion...\n",
       "6094                                                   NaN\n",
       "6095     [from transformers import AutoModel\\r\\nmodel =...\n",
       "6096     [from transformers import AutoTokenizer, AutoM...\n",
       "6097     [ test_torch = torch.from_numpy(test)\\r\\n test...\n",
       "6098     [np.eye(2, self.LABELS[label])\\r\\n, np.eye(2)[...\n",
       "6099     [torch.cuda.__init__, import torch\\r\\nfrom tor...\n",
       "6101     [.data, Torch.*Tensor,  x = torch.rand(4, requ...\n",
       "6104     [nn.parallel.DistributedDataParallel, torch.au...\n",
       "6105                                                   [m]\n",
       "6106                                                   NaN\n",
       "6107     [SM_HPS='{\"batch-size\": \"256\", \"learning-rate\"...\n",
       "6108     [__init__, __call__, my_model, my_model_instan...\n",
       "6109     [class My_model(nn.Module):\\r\\n    def __init_...\n",
       "6110     [nn.Module, class Model(nn.Module)\\r\\n    pass...\n",
       "6112     [# suppose we have a tensor/batch of probabili...\n",
       "6113                                                   NaN\n",
       "6116     [best_model_state, best_model_state = deepcopy...\n",
       "6117     [CHW, HWC, CHW, HWC, H, W, CHW, HWC, CHW, torc...\n",
       "6118     [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "6119                                                   NaN\n",
       "6120     [import os\\r\\nfrom PIL import Image\\r\\nimport ...\n",
       "6121     [def load_checkpoint(checkpoint, model, optimi...\n",
       "6122                           [y = &lt;w, x&gt;, w, x, x]\n",
       "6124                         [__init__, forward, __init__]\n",
       "6125     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "6127                                       [trainer.fit()]\n",
       "6129     [DataParallel, DistributedDataParallel, model ...\n",
       "6130     [MSE, MSE(y, y_hat) = (y_hat-y)², MSE, dMSE/dy...\n",
       "6133     [import os\\r\\nimport inspect\\r\\nimport torch\\r...\n",
       "6134     [torch.sort, False, True, stable=True, torch.s...\n",
       "6135     [torchvision.transforms, Normalize, mean, (mea...\n",
       "6137     [import torch\\r\\nfrom torchvision import trans...\n",
       "6138     [class GaussianNoise(nn.Module):\\r\\n\"\"\"Gaussia...\n",
       "6140     [for idx, tensor in enumerate(dataloader0):\\r\\...\n",
       "6141      [buffered_arange, buffered_arange, torch.arange]\n",
       "6142                                                   NaN\n",
       "6143                                                   NaN\n",
       "6144                [torch.no_grad(), max(1)[1], max, dim]\n",
       "6146     [F.binary_cross_entropy_with_logits, nn.BCEWit...\n",
       "6147                                                   NaN\n",
       "6148     [def test_data(mdl):\\r\\n    #Input new data\\r\\...\n",
       "6149     [from torch import tensor, cat\\r\\nx = tensor([...\n",
       "6150     [BCELoss, p, q, y = tf.convert_to_tensor([0.2,...\n",
       "6151     [criterion = torch.nn.CrossEntropyLoss()\\r\\nlo...\n",
       "6152                           [torch.nn.CrossEntropyLoss]\n",
       "6153     [for epoch in range(2):  # loop over the datas...\n",
       "6154     [torch/datasets/FashionMNIST/raw/, gzip -d *.g...\n",
       "6155     [optimizer = optim.RMSprop(net.parameters(), l...\n",
       "6156     [nn.CrossEntropyLoss, (batch_size,), [0, num_c...\n",
       "6157     [outputs1, In [11]: import torch\\r\\n\\r\\nIn [12...\n",
       "6158     [nn.Module, nn.Sequential, nn.Module, nn.Seque...\n",
       "6159                              [ git lfs install. \\r\\n]\n",
       "6160     [from_tf=True, from transformers import AutoTo...\n",
       "6161     [9.76 GiB reserved in total by PyTorch, torch....\n",
       "6162     [import cv2\\r\\nimport torch\\r\\n\\r\\nimg = cv2.i...\n",
       "6163                  [img, img.float(), reflection_pad2d]\n",
       "6164     [class DescriptorDataset(torch.utils.data.Data...\n",
       "6165     [__getitem__, ix, __getitem__, class Descripto...\n",
       "6167     [+=, weights = weights - weights.grad * lr, we...\n",
       "6168     [batch_action, torch.gather, def learn(...):\\r...\n",
       "6169                                                   NaN\n",
       "6170     [# ufunc docstring\\r\\n# op.identiy is 0\\r\\nr =...\n",
       "6171     [t.storage().size(), torch.Tensor, Tensor.stor...\n",
       "6172     [batch_size=4, 1, 3, nn.MSELoss, reduction='no...\n",
       "6173     [x=x+4, x, x, x=x+4, import torch\\r\\nx = torch...\n",
       "6174                                                   NaN\n",
       "6175     [!wget https://raw.githubusercontent.com/Micro...\n",
       "6176     [torch.unique,  input.unique().topk(k=2).value...\n",
       "6177     [\\r\\nimport sysconfig\\r\\nfrom setuptools impor...\n",
       "6178                                                   NaN\n",
       "6179     [summary(model, input_size=(16, 512), dtypes=[...\n",
       "6181     [model(inputs.float())\\r\\n, outputs_dict = mod...\n",
       "6182     [ result\\r\\ntensor([...], requires_grad=True)\\...\n",
       "6183                                                   NaN\n",
       "6184     [x = torch.ones((64, 3, 32, 32))\\r\\nx = x[:, 0...\n",
       "6185     [torch.mean, keepdim,  x = torch.rand(64, 3, 3...\n",
       "6186                                     [torch.no_grad()]\n",
       "6187                                                   NaN\n",
       "6188     [load_from_checkpoint, trained_model = NCF.loa...\n",
       "6189     [self.save_hyperparameters(logger=False)\\r\\n, ...\n",
       "6190     [torchinfo, torchinfo.py, dtypes, None, torch....\n",
       "6191     [import onnx\\r\\nimport torch\\r\\n\\r\\nmodel = ge...\n",
       "6192     [model = torch.load('your_model.py')\\r\\nkeras_...\n",
       "6193                                                   NaN\n",
       "6194                                                   NaN\n",
       "6196                      [[200, 10, 30], [180, 180, 180]]\n",
       "6197     [# Create the dataset\\r\\ndataset = dset.ImageF...\n",
       "6198     [alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'  # th...\n",
       "6199     [Tensor.item(),  import torch\\r\\n t = torch.te...\n",
       "6200      [x.shape == [a, b], nn.Linear(c, c, bias=False)]\n",
       "6201                                                   NaN\n",
       "6203                                                   NaN\n",
       "6204                                                   NaN\n",
       "6205                   [_convolution_mode, padding='same']\n",
       "6206     [...\\r\\ndef calc_same_padding(kernel_size, str...\n",
       "6207                                                   NaN\n",
       "6208     [from itertools import cycle\\r\\n\\r\\nclass Data...\n",
       "6209                                                   NaN\n",
       "6210     [==, py -m pip install torch==1.9.0+cu111 torc...\n",
       "6211     [.devcontainer/devcontainer.json, \"runArgs\": [...\n",
       "6212                                                   NaN\n",
       "6213     [create_adj, a, torch.tensor, def create_adj(x...\n",
       "6214     [b, b, b, requires_grad = True, loss, requires...\n",
       "6216     [from torch_scatter import scatter_max\\r\\n\\r\\n...\n",
       "6217                                                   NaN\n",
       "6218     [value, 705, hypothesis, hypothesis, ignored_c...\n",
       "6219                                                   NaN\n",
       "6220     [writer.add_embedding(data.values,\\r\\n        ...\n",
       "6221     [sys.argv, from sys import argv\\r\\nargv.append...\n",
       "6222     [16*16*3, 16*16, x.view(-1, 16*16), (24, 16*16...\n",
       "6223     [stack = [[seq[i],label[i]] for i in range(seq...\n",
       "6224                                                   NaN\n",
       "6225     [torch.nn.DataParallel(), .to(torch.device('cp...\n",
       "6226                                                   NaN\n",
       "6227     [ x = torch.arange(1, 91, dtype=float).reshape...\n",
       "6228     [class BCNN(nn.Module):\\r\\n    def __init__(se...\n",
       "6229     [y ----------------------------&gt;|\\r\\nb ----...\n",
       "6230     [w_i, W = nn.Parameter(torch.rand(3))\\r\\n, w0,...\n",
       "6231                                                   NaN\n",
       "6232     [nn.Linear(i, o), (b, i), b, import torch\\r\\ni...\n",
       "6233     [# labels is a numpy array of shape n,1 contai...\n",
       "6234     [axis=0, axis=1, X.view(-1, 28*28), (batch_siz...\n",
       "6235                                                   NaN\n",
       "6236                         [model._conv_stem, model._fc]\n",
       "6238     [x, x_i, i, [0,n], y = x**2, L = sum(y_i), dL/...\n",
       "6239     [batch_size=15\\r\\n, 16488 / 15 * 0.7 = 769.44 ...\n",
       "6240                                                   NaN\n",
       "6241                                                   NaN\n",
       "6242     [pytorch.positive, numpy, positive, +1, negati...\n",
       "6243                                        [@tf.function]\n",
       "6244     [bs, IOU, bs=15, 4, IOU, IOU(output, y, bs=bs)...\n",
       "6245     [class TextClassificationModel(nn.Module):\\r\\n...\n",
       "6249                           [def __init__, def __int__]\n",
       "6250                               [def forward(self, x):]\n",
       "6251     [&lt;module 'torchvision' from '/usr/local/lib...\n",
       "6252                                                   NaN\n",
       "6253     [def sum_rows(x): \\r\\n   y = x[None] + x[:, No...\n",
       "6254     [from torch.optim import lr_scheduler\\r\\n\\r\\nc...\n",
       "6255     [to, nn.Module, model, to, Tensor, nn.Module.t...\n",
       "6256                                                   NaN\n",
       "6257     [CUDA_VISIBLE_DEVICES, torch.cuda.device_count...\n",
       "6258     [self.embedding_word, word_indices, word_ind_t...\n",
       "6259                                                   NaN\n",
       "6260                                                   NaN\n",
       "6262     [train_states = {}\\r\\nfor epoch in range(max_e...\n",
       "6263                                                   NaN\n",
       "6264     [nn.Conv2d, m, m2, m.weight, m2.weigth, m.bias...\n",
       "6265     [int, tuple, m, m2,  m\\r\\nConv2d(3, 3, kernel_...\n",
       "6266     [(x.size(0), x.size(1)-idxs.size(1)), (3, 7), ...\n",
       "6267     [i, cell_number[???] += 1,  p = torch.from_num...\n",
       "6268     [h_out, ula, def sliding_windows(data, seq_len...\n",
       "6269     [f, def f(x):\\r\\n    x = torch.sin(torch.exp(x...\n",
       "6270     [loss = torch.zeros(1)\\r\\nfor i in range(10):\\...\n",
       "6271                                                   NaN\n",
       "6272                                                   NaN\n",
       "6273     [out, model = model.to(device)\\r\\nfor batch, _...\n",
       "6274                                                   NaN\n",
       "6275     [def rand_argmax(tens):\\r\\n    max_inds, = tor...\n",
       "6276     [import numpy as np\\r\\nimport torch\\r\\n\\r\\nyou...\n",
       "6278                                                   NaN\n",
       "6279                                                   NaN\n",
       "6280                                                   NaN\n",
       "6281     [$ nvidia-smi | grep CUDA\\r\\n| NVIDIA-SMI 470....\n",
       "6282     [conda install -c conda-forge cudatoolkit-dev\\...\n",
       "6283                                                   NaN\n",
       "6284     [base_model, __init__, class SDataset(torch.nn...\n",
       "6285     [np.split(value.numpy(), np.unique(row.numpy()...\n",
       "6286               [self.critic_optimizer.zero_grad()\\r\\n]\n",
       "6287     [strict, hvp(), strict=True, RuntimeError: The...\n",
       "6288     [scheduler = get_constant_schedule_with_warmup...\n",
       "6289     [import torch\\r\\n\\r\\ninitial_lr = 2e-6\\r\\n\\r\\n...\n",
       "6290                                                   NaN\n",
       "6291     [torch.linalg.norm, ord, 0, 1, 2, Tensor.norm,...\n",
       "6293                                                   NaN\n",
       "6294     [zero_gradients(), zero_grad(), def zero_gradi...\n",
       "6295                                                   NaN\n",
       "6296     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "6297     [BatchNorm2d, class MyBatchNorm2d(nn.BatchNorm...\n",
       "6298     [cr = nn.CrossEntropyLoss(weight=torch.tensor(...\n",
       "6299     [a, class PositionalEncodingLayer(nn.Module):\\...\n",
       "6300                                                   NaN\n",
       "6301                                                   NaN\n",
       "6302                                                   NaN\n",
       "6303                                                   NaN\n",
       "6304     [{'Name': 'Average training loss', 'Regex': 'A...\n",
       "6305                                                   NaN\n",
       "6306                                                   NaN\n",
       "6307     [register_backward_hook(hook), hook, nn.Module...\n",
       "6308                                                   NaN\n",
       "6309     [rnn = nn.LSTM(10, 20, 2), nn.Module, nn.LSTM,...\n",
       "6310                                                   NaN\n",
       "6312     [torch.unsqueeze, torch.unsqueeze(x, 0)\\r\\n, N...\n",
       "6313     [# initialize with custom configuration of Tou...\n",
       "6314     [DataParallel, transformers, SciBERT, transfor...\n",
       "6315     [len(contour) &gt; contour_threshold, _compute...\n",
       "6316     [tmp = -1 + 2 * torch.randint(low=0, high=2, s...\n",
       "6317     [self.dec_conv3 = nn.Sequential(\\r\\n    nn.Con...\n",
       "6318     [import torch\\r\\nx = torch.randn(3000000, 2).c...\n",
       "6320                                                   NaN\n",
       "6321     [(100, 1), (100,), unsqueeze(-1), x.float(), s...\n",
       "6322                                                   NaN\n",
       "6323                                     [torch-geometric]\n",
       "6325     [@=, @, *, *, A @ B, A * B, A @= B, A *= B, A ...\n",
       "6327                                                   NaN\n",
       "6328            [self.optimizer.param_groups[0][\"lr\"]\\r\\n]\n",
       "6329     [target, (b, 1, h, w), ind, (b, 1, N, 2), 1, N...\n",
       "6330     [# assuming ind is a list of tuples of (dim2 i...\n",
       "6331     [src/crowd_counting.py, import network, import...\n",
       "6332     [F.conv1d, F, torch.nn.functional, F.conv1d(x,...\n",
       "6333     [class Generator(object):\\r\\n    def __init__(...\n",
       "6334                                                   NaN\n",
       "6335                                                   NaN\n",
       "6336                                                   NaN\n",
       "6337                                                   NaN\n",
       "6338                           [DataLoader, shuffle, True]\n",
       "6339     [if, (outputs.detach()-fin_val.detach())*(targ...\n",
       "6340                                                   NaN\n",
       "6341     [a = d_params[0]\\r\\nc = W*a+b\\r\\n-------------...\n",
       "6342                                                   NaN\n",
       "6344     [(channels, height, width)\\r\\n, (height, width...\n",
       "6346     [model2, model = resnet()\\r\\n, model.load_stat...\n",
       "6347     [transform, fast.ai, img = open_image('any_ima...\n",
       "6348     [[3, 336, 500] vs [3, 500, 336],  x = x.permut...\n",
       "6349     [nn.Parameter, nn.Module, .parameters(), requi...\n",
       "6350     [from pytorchvideo.models.slowfast import crea...\n",
       "6352                                                 [img]\n",
       "6353     [torch.gather, numpy.take, torch.gather, Y, X,...\n",
       "6354     [Z, X, Y, i, B, M, N = 13, 7, 19\\r\\n\\r\\nX = np...\n",
       "6355     [state_dim = 10\\r\\narchitecture = (256, 256)  ...\n",
       "6356     [flow_from_dataframe, import pandas as pd     ...\n",
       "6357     [height = floor((input_height + padding_top + ...\n",
       "6358                                         [masked_fill]\n",
       "6359     [import torch\\r\\nimport torch.optim as optim\\r...\n",
       "6360                                             [QThread]\n",
       "6361     [class CustomDataset(Dataset):\\r\\n\\r\\ndef __in...\n",
       "6362                                                   NaN\n",
       "6363     [torch.Size([64, 3, 28, 28]), nn.Linear(), # N...\n",
       "6364     [in_features, in_features = 3*28*28\\r\\n\\r\\ncla...\n",
       "6365     [int((w + 2*p - d*(k - 1) - 1)/s + 1)\\r\\n, nn....\n",
       "6366     [import spacy\\r\\nfrom torchtext.data.utils imp...\n",
       "6367     [lr_find(), lrs = learn.lr_find(suggest_funcs=...\n",
       "6368                                                   NaN\n",
       "6369                                                   NaN\n",
       "6370     [fast-trees, tree-sitter, 0.2.0, tree-sitter, ...\n",
       "6371     [fast_trees, tree_sitter, tree_sitter, fast_tr...\n",
       "6373     [train.fr, $ !ls -al .data/multi30k\\r\\ntotal 5...\n",
       "6374     [writer.add_scalar('accuracy/train',  torch.su...\n",
       "6375     [x = x.view( -1, x.size( 1 ))\\r\\n, self.encode...\n",
       "6376     [repeats, list, tuple, ints, list, tuple, repe...\n",
       "6377     [module., torch.save(model.module.state_dict()...\n",
       "6378     [# normalize the vectors\\r\\nnVs = Vs / torch.n...\n",
       "6379     [nn.Linear(768, 512), somewhere defined in __i...\n",
       "6381                                                   NaN\n",
       "6383                       [.cuda, torch.cuda.empty_cache]\n",
       "6384                                                   NaN\n",
       "6385     [DataLoader, Dataset, mnist_train_dl = torch.u...\n",
       "6386     [pip install utils, &gt;&gt; import utils\\r\\n&...\n",
       "6387                                                   [x]\n",
       "6388     [net.fc2, zero_grad, net.fc2.weight.grad = Non...\n",
       "6389     [seg, (b, 3, h, w), colors = torch.FloatTensor...\n",
       "6390                                            [view(-1)]\n",
       "6391                                                   NaN\n",
       "6392     [torch.nn.Sequential, forward(), Sequential,  ...\n",
       "6393     [model = torch.load('a.pth', encoding='latin')...\n",
       "6394     [torch.nn.L1Loss(), torch.nn.MSELoss(), [[0.13...\n",
       "6395     [model.requires_grad_(False)\\r\\n, model.fc1 = ...\n",
       "6396     [import torch\\r\\na = torch.arange(0,4).view(1,...\n",
       "6397                                                   NaN\n",
       "6398     [# Example tensor\\r\\na = torch.tensor([1, 2, 3...\n",
       "6399                                                   NaN\n",
       "6400                                                   NaN\n",
       "6401     [np.array, Enhanced, torch.from_numpy, import ...\n",
       "6402                                                   NaN\n",
       "6403     [intra-op, matmul, inter-op, inter-op, op1, op...\n",
       "6404     [pretrained=True, 4 channel, x=torch.randn((5,...\n",
       "6405     [pretrained=True, def inception_v3(pretrained:...\n",
       "6407     [pytorch, torch, &gt; pip install torch\\r\\n,  ...\n",
       "6408     [0, batch_size, length, modulo, 0, __getitem__...\n",
       "6409                                                   NaN\n",
       "6410     [pl.metrics.Accuracy(compute_on_step=False)\\r\\...\n",
       "6412                                                   NaN\n",
       "6413     [multiprocess_num = 8\\r\\nbatch_size = int(len(...\n",
       "6414                    [distributed.worker.daemon, False]\n",
       "6415     [float32, $ cat t73.py\\r\\nfrom numba import cu...\n",
       "6416     [reset_running_stats(), BatchNorm, def drop_to...\n",
       "6417     [BinaryCrossEntropyWithLogits,         return ...\n",
       "6418     [RuntimeError: all elements of input should be...\n",
       "6419                                                   NaN\n",
       "6420     [x, 'cuda:0', x = torch.randn(8,10)  \\r\\nmodel...\n",
       "6421     [    while str(received_data)[-2] != '.':\\r\\n,...\n",
       "6422     [file_name, test_data = [{'file_name': '.../im...\n",
       "6423     [# What you have\\r\\nmodel = models.resnet18()\\...\n",
       "6424     [f(x) = a*x, df/dx = a,  x = torch.rand(10, re...\n",
       "6425                                                   NaN\n",
       "6426     [length_sorted_idx = np.argsort([-embedder._te...\n",
       "6427          [Attention, Attention, Multi-head Attention]\n",
       "6428                                             [720x720]\n",
       "6429                                                   NaN\n",
       "6430                                                   NaN\n",
       "6432                                                   NaN\n",
       "6433     [torch.nn.Identity, (6): ResNetBasicHead(\\r\\n ...\n",
       "6434     [model = torch.hub.load('facebookresearch/pyto...\n",
       "6435                                                   NaN\n",
       "6436         [image=np.asarray(image), torch.from_numpy()]\n",
       "6437                                                   NaN\n",
       "6438     [model = AutoModelForSequenceClassification.fr...\n",
       "6440     [[0, 1]x[0, 1], [[0, 0], [1, 1], [1, 0], [0, 1...\n",
       "6441                                        [0, 1, 0.5423]\n",
       "6442     [[bos], w1, w2, [eos], [bos] w_1  w_2  w_3\\r\\n...\n",
       "6443     [from sklearn.metrics import accuracy_score\\r\\...\n",
       "6444                                                   NaN\n",
       "6445                                                   NaN\n",
       "6446     [t = tensor([[1,3,2,6]])\\r\\n\\r\\nrows = t.shape...\n",
       "6447                  [fill, fill, Tensor, fill, ToTensor]\n",
       "6448     [item(), float, json_errors = {k: v.item() for...\n",
       "6449                                                   NaN\n",
       "6450                                                   NaN\n",
       "6451     [urllib.parse.urlparse, D:/PhD/..., gopen_sche...\n",
       "6452     [from itertools import islice\\r\\nimport webdat...\n",
       "6453     [a[torch.arange(n)[:, None], b]\\r\\n,  n, m, k ...\n",
       "6455                                                   NaN\n",
       "6456     [evaluate(), train_one_epoch(), train, train_o...\n",
       "6458     [self(obs_t.unsqueeze(0)), nn.Linear(64, 2), m...\n",
       "6459     [q_values = self(obs_t.unsqueeze(0)) , q_value...\n",
       "6460     [self.actor, nn.Module, class Actor(nn.Module)...\n",
       "6461     [preds = model(i), output = []\\r\\nwith torch.n...\n",
       "6462                                                   NaN\n",
       "6463     [(batch_size, hidden_size), GroupNorm, GroupNo...\n",
       "6464     [xmin = []\\r\\nxmax = []\\r\\ny = []\\r\\nprint(np....\n",
       "6465            [horizontal_translation.cpu().numpy()\\r\\n]\n",
       "6466                                                   NaN\n",
       "6467     [torch.tensor, torch.save(train_loss_set, os.p...\n",
       "6468     [net = Net()\\r\\nmodel = torch.nn.DataParallel(...\n",
       "6469                                                   NaN\n",
       "6470     [ModuleList, ModuleDict, eval, setattr, weight...\n",
       "6471                                                   NaN\n",
       "6472        [os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\\r\\n]\n",
       "6473     [criterion=nn.BCEWithLogitsLoss()\\r\\n, criteri...\n",
       "6474                                                   NaN\n",
       "6475     [return_inverse, torch.unique, i, indices, ind...\n",
       "6476              [.data, v0.4.0, .data, x.data, autograd]\n",
       "6477                                  [mobilenet_v3_small]\n",
       "6478     [import torch._utils_internal\\r\\n...\\r\\npath =...\n",
       "6479     [a = torch.tensor([[0, 1, 0, 0],\\r\\n          ...\n",
       "6480                                                   NaN\n",
       "6481                            [torch.tensor([imgs])\\r\\n]\n",
       "6483                                                   NaN\n",
       "6484     [oc, s, block_size, [i + oc * j for i in range...\n",
       "6485     [self.enc1 = nn.Linear(in_features=28, out_fea...\n",
       "6486                                                   NaN\n",
       "6487                                          [nvidia-smi]\n",
       "6488     [poetry run &lt;package&gt; --version, Install...\n",
       "6489     [class Network(nn.Module):\\r\\n  def __init__(s...\n",
       "6492     [import matplotlib.pyplot as plt\\r\\nimport cv2...\n",
       "6493     [import torch\\r\\n\\r\\n# create tensors to repre...\n",
       "6495                                                   NaN\n",
       "6497     [import torch.nn as nn\\r\\nloss = nn.CrossEntro...\n",
       "6498     [torch.split(), torch.cat(), output_tensor = t...\n",
       "6499     [unfolding, import torch\\r\\nimport torch.nn.fu...\n",
       "6501     [in_channels, 1, 42, # Add a dimension at inde...\n",
       "6502                                       [in_channels=1]\n",
       "6503     [cuda, pip install torch==1.7.0+cu110 -f https...\n",
       "6504                                                   NaN\n",
       "6505     [loss = criterion(outputs, labels), outputs, l...\n",
       "6506     [UserWarning: The .grad attribute of a Tensor ...\n",
       "6507     [from torchvision import transforms\\r\\ntensor_...\n",
       "6508     [import numpy as np\\r\\n\\r\\nimg = np.array(Imag...\n",
       "6509     [# Create boxes list\\r\\nboxes = [\\r\\n    [anno...\n",
       "6510     [git clone https://github.com/pytorch/pytorch\\...\n",
       "6512     [torch.unbind, import torch\\r\\n\\r\\na = torch.t...\n",
       "6513     [nn.Conv2d(32, 64, kernel_size=3, stride=1, pa...\n",
       "6514                                                   NaN\n",
       "6515     [f(y) = x**2, f'(y) = 2*x, x = torch.arange(3)...\n",
       "6516                                                   NaN\n",
       "6517     [#Your code\\r\\noutputs = model(images) # Reall...\n",
       "6518                                              [pip -V]\n",
       "6520                                                   NaN\n",
       "6522     [datamodule, trainer.fit(model, datamodule=Fru...\n",
       "6523                                                   NaN\n",
       "6524     [train_df = pd.DataFrame(columns=[\"img_name\",\"...\n",
       "6525     [import os\\r\\nimport pandas as pd\\r\\nfrom torc...\n",
       "6526                                                   NaN\n",
       "6527             [dataset_path, ls -a, .ipynb_checkpoints]\n",
       "6528     [root/dog/xxx.png\\r\\nroot/dog/xxy.png\\r\\nroot/...\n",
       "6529     [!rm -R test/train/.ipynb_checkpoints\\r\\n!ls t...\n",
       "6530     [Module, .data, .to(...), for p in net.paramet...\n",
       "6531                                                   NaN\n",
       "6532                                                   NaN\n",
       "6533     [(4, 200, 300), (x, y), [0, x1, y1], [1, x2, y...\n",
       "6534     [_, preds = torch.max(outputs, dim=1), argmax,...\n",
       "6535     [model.eval(), sigmoid, tanh, softmax, relu, s...\n",
       "6536     [def get_transformations():\\r\\n    return tran...\n",
       "6539     [dist = (tensor1 - tensor2).pow(2).sum(3).sqrt...\n",
       "6540     [#Linear Layer\\r\\n##hidden_feature_size = 1 in...\n",
       "6542                                              [/audio]\n",
       "6543     [0, 1, import torch\\r\\n\\r\\nsamples, features =...\n",
       "6545     [torch==1.9.0\\r\\ntorchvision==0.10.0\\r\\n, torc...\n",
       "6546                       [pip install pillow==8.2.0\\r\\n]\n",
       "6547     [torch==1.9.0+cu111\\r\\ntorchvision==0.10.0+cu1...\n",
       "6550     [nn.CrossEntropyLoss, (batch_size, n_class), (...\n",
       "6551     [,, ., __getitem__, PennFudanDataset,         ...\n",
       "6552                                                   NaN\n",
       "6553     [import torch\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\...\n",
       "6554     [import torch\\r\\nimport torch.nn.functional as...\n",
       "6555     [import torch\\r\\nimport torch.nn.functional as...\n",
       "6556                                                   NaN\n",
       "6557     [class GCN(torch.nn.Module):\\r\\n    def __init...\n",
       "6558                   [sudo apt install cmake\\r\\n, cmake]\n",
       "6559     [torch.utils.data.Dataset, import dask.datafra...\n",
       "6560                     [torch.Size([]), torch.tensor(5)]\n",
       "6561     [output = [torch.Tensor([*a, *b]) for a, b in ...\n",
       "6562     [import torch\\r\\nx = torch.randn(n, d)\\r\\nJ = ...\n",
       "6563                  [type(input)\\r\\n, !python --version]\n",
       "6566     [[0.60, 0.07, 0.12], 60% chance that element 1...\n",
       "6567                                                   NaN\n",
       "6568                  [\\r\\noutput_vector = mtx[[x,y]]\\r\\n]\n",
       "6569                                                   NaN\n",
       "6570     [torch.from_numpy(arr), import numpy as np\\r\\n...\n",
       "6571                                                   NaN\n",
       "6572                                                [curl]\n",
       "6573     [tf.Variable, trainable=False, w, b, tf.Variab...\n",
       "6574     [class HRFAE(nn.Module):\\r\\n    def __init__(s...\n",
       "6575                                                   NaN\n",
       "6576     [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "6577     [loss = (d_mtx[y] * y_pred).sum()\\r\\n, y, torc...\n",
       "6579                                                   NaN\n",
       "6580     [set_weights, get_weights, assign, input_shape...\n",
       "6581                              [v = v.unsqueeze(0)\\r\\n]\n",
       "6582     [array_sum += float(array[i, j])\\r\\n,  .1+.1+....\n",
       "6583     [float(array[i][j]), array[i][j], ~0, loop-bas...\n",
       "6584     [numpy, import numpy as np\\r\\n\\r\\nval_v_small ...\n",
       "6585     [import torch\\r\\nfrom ignite.metrics import Me...\n",
       "6586     [(14000, 2), (64, 2), comp = (composition_matr...\n",
       "6587     [import torch\\r\\n\\r\\ntorch.manual_seed(0)\\r\\nb...\n",
       "6588     [import torch\\r\\nnClass    = 3\\r\\nrepeat    = ...\n",
       "6589     [EdgeSplitter, train_test_split, dataset = sg....\n",
       "6590     [import random\\r\\nlabels = list()\\r\\nfor i in ...\n",
       "6591     [astype, rng = np.random.default_rng() # set s...\n",
       "6592     [float64, float32, float32, IMG_Rando = np.ran...\n",
       "6593     [MultivariateLinearRegressionModel, nn.Module,...\n",
       "6594     [model_path =  os.path.join(model_dir, 'macro_...\n",
       "6595     [FileNotFoundError: [Errno 2] No such file or ...\n",
       "6596     [torch.nn.functional.unfold, torch.nn.function...\n",
       "6597     [def get_dim_blocks(dim_in, kernel_size, paddi...\n",
       "6598     [torch.quantile(), import torch\\r\\n# Generate ...\n",
       "6599     [def predict(tensor, model):\\r\\n    yhat = mod...\n",
       "6600     [[tensor], tensor, tensor, model(tensor), tensor]\n",
       "6601     [c = (A[:, None, :] == B[None, ...]).all(dim=2...\n",
       "6602                                             [MSELoss]\n",
       "6603                                                   NaN\n",
       "6605                                                   NaN\n",
       "6606                                                   NaN\n",
       "6607                                                   NaN\n",
       "6608     [model = torch.hub.load('ultralytics/yolov5', ...\n",
       "6609     [test_data = datasets.ImageFolder('test/', tra...\n",
       "6610     [bias, bias, import torch\\r\\nfrom torch import...\n",
       "6611     [224x224, 179776, 4x44944, Resize, transform, ...\n",
       "6612     [resize, transforms, transform = transforms.Co...\n",
       "6613                           [export LC_ALL=C.UTF-8\\r\\n]\n",
       "6614                                                   NaN\n",
       "6615     [Module, .to(...), Tensor, s = s.to(device)\\r\\...\n",
       "6616     [import torch\\r\\nfrom torch.nn import function...\n",
       "6617                                                   NaN\n",
       "6618     [results = torch.empty((0,2048))\\r\\nresults.to...\n",
       "6619     [tf.scatter_nd, @tf.function\\r\\ndef csr_to_den...\n",
       "6620     [print([values[indptr[i]:indptr[i+1]] for i in...\n",
       "6621                               [x, x = torch.rand(10)]\n",
       "6622                                                   NaN\n",
       "6623                                                   NaN\n",
       "6624                                                   NaN\n",
       "6625                                                   NaN\n",
       "6626     [RNN, def init_hidden(self):\\r\\n        return...\n",
       "6627                                                   NaN\n",
       "6628     [# this method can be defined outside your mod...\n",
       "6629               [self.weights, self.register_parameter]\n",
       "6630     [x,  sig(Linear(x)) &gt; 0.5, sig(Linear(x)) &...\n",
       "6632     [tokenizer = AutoTokenizer.from_pretrained(pre...\n",
       "6633     [# ls -ld /dev/nvidia*\\r\\ndrwxr-x--- 2 root ro...\n",
       "6634     [ImageFolder, Dataset, self.samples, __getitem__]\n",
       "6635     [_getitem_, _getitem_, def __getitem__(self, i...\n",
       "6636                                                   NaN\n",
       "6637                                                   NaN\n",
       "6639       [torch.cuda.empty_cache(), for i in range(11):]\n",
       "6640     [RuntimeError: CUDA out of memory. Tried to al...\n",
       "6641     [import torch\\r\\ntorch.__version__ #1.7\\r\\nwei...\n",
       "6642                                  [CrossEntropyLoss()]\n",
       "6643      [[batch], argmax, labels=b_labels.argmax(dim=1)]\n",
       "6645                                                   NaN\n",
       "6646                                                   NaN\n",
       "6647                  [f(z), g(input)=L, ∂L/∂z*, z, ∂L/∂z]\n",
       "6649                                                   NaN\n",
       "6650     [pytesseract.pytesseract.tesseract_cmd = r'pat...\n",
       "6651     [config.yaml, mask_rcnn_X_101_32x8d_FPN_3x, Pu...\n",
       "6652                                                   NaN\n",
       "6653                                                   NaN\n",
       "6654     [CUDA out of memory, batch_size, import objsiz...\n",
       "6655                                                   NaN\n",
       "6656     [import torch\\r\\ntensor = torch.ones((1, 25200...\n",
       "6657     [\\r\\n  T1= torch.narrow(YourTensor, 1,0 , 80*8...\n",
       "6658     [PadSequence, collate_fn, cuda, class PadSeque...\n",
       "6659     [lengths = torch.LongTensor([len(x) for x in s...\n",
       "6660                                                   NaN\n",
       "6661          [pip uninstall tqdm\\r\\npip install tqdm\\r\\n]\n",
       "6662                                                   NaN\n",
       "6663     [# instantiate the configuration for your mode...\n",
       "6664     [_seed = 2021\\r\\ntrain_dataset, test_dataset =...\n",
       "6665     [x, size of final range, size of original rang...\n",
       "6667                                                   NaN\n",
       "6668     [for batch in range(batches):\\r\\n    data = []...\n",
       "6669     [np.mean([x[:,None,:],y[None,...]], axis=0)\\r\\...\n",
       "6670                                                   NaN\n",
       "6671     [import torchvision\\r\\nmodel = torchvision.mod...\n",
       "6672                  [model.encoders[0].basic_module\\r\\n]\n",
       "6673     [.weight, import copy\\r\\nimport torch\\r\\n\\r\\nd...\n",
       "6674     [numpy.ndarray.__array_interface__, torch.Tens...\n",
       "6675                                                   NaN\n",
       "6677                                                   NaN\n",
       "6678     [relu, o1, detach, o2, # This diff is 0 when o...\n",
       "6679     [the net_input, size=(1,3,256,256), (1,3,4144,...\n",
       "6680     [loss.backward()\\r\\nfor p in model.parameters(...\n",
       "6681     [torch.gradient, diff = torch.gradient(inputs)...\n",
       "6682     [model = Cifar10CnnModel()\\r\\n, model.network[...\n",
       "6684     [pip install opencv-python\\r\\n, cv2.resize(src...\n",
       "6685                                                   NaN\n",
       "6686                                                   NaN\n",
       "6687     [def collate_batch(batch):\\r\\n    batch.sort(k...\n",
       "6691     [torchtext.data.functional.to_map_style_datase...\n",
       "6692     [from torchvision import transforms\\r\\nfrom PI...\n",
       "6693     [classifier, in_features=model.classifier.in_f...\n",
       "6694     [import torchvision\\r\\n\\r\\nmodel = torchvision...\n",
       "6695                                                   NaN\n",
       "6696     [# Learn with Label Propagation\\r\\nlabel_propa...\n",
       "6697     [pred = torch.argmax(output, dim=1), pred, if ...\n",
       "6699     [data = torch.rand(10,1)\\r\\ndataset = torch.ut...\n",
       "6701     [moveaxis, movedim, swapaxes, swapdims, permut...\n",
       "6702                                                   NaN\n",
       "6703     [def forward(self,x):        \\r\\n   out = self...\n",
       "6704                                                   NaN\n",
       "6705                                                   NaN\n",
       "6706                                                   NaN\n",
       "6707     [indices = np.indices(input.shape)\\r\\nindices[...\n",
       "6708     [nn.Linear(512, 258), shape=(128,256), shape=(...\n",
       "6710     [~93%, LABEL, LABEL = data.LabelField(preproce...\n",
       "6711                                                   NaN\n",
       "6712                         [pip install torch --upgrade]\n",
       "6713     [vals, vals, N = 5 # your choice goes here\\r\\n...\n",
       "6714     [torch.nn.Sequential, torch.nn.Sequential, tra...\n",
       "6715     [(fc): Linear(in_features=2048, out_features=1...\n",
       "6716                                                   NaN\n",
       "6717                                                   NaN\n",
       "6718     [# reshapes X to (T, R, n, m, d)\\r\\nX_rs = X.v...\n",
       "6719                                                   NaN\n",
       "6720                                                   NaN\n",
       "6721                                                   NaN\n",
       "6724     [\\r\\nclass MGenDenseNet(nn.Module):\\r\\n  def _...\n",
       "6725     [conda install -y pytorch torchvision torchaud...\n",
       "6727     [from detectron2.utils.visualizer import Color...\n",
       "6728                                                   NaN\n",
       "6729     [mmdownload -f keras -n resnet50 -o ./, mmconv...\n",
       "6730     [einsum, einsum, ARD_kernel, einsum, @, einsum...\n",
       "6731     [M = U'*U\\r\\n, y[p] = U*x[p] p=1..\\r\\n, (x[p]-...\n",
       "6732     [output_padding, import torch.nn.functional as...\n",
       "6733     [T = torch.randn(1,3,128,256)\\r\\nprint(T.shape...\n",
       "6734     [RuntimeError: Expected to mark a variable rea...\n",
       "6735     [roi_heads.box_predictor.xxx, find_unused_para...\n",
       "6736                                                   NaN\n",
       "6737                                                   NaN\n",
       "6738                                                   NaN\n",
       "6739                                                   NaN\n",
       "6740                                                   NaN\n",
       "6741                                                   NaN\n",
       "6742                                                   NaN\n",
       "6744                                                   NaN\n",
       "6745     [torch.isnan(tensor).any()\\r\\n, inf, NaN, torc...\n",
       "6746     [from_pretrained, flaubert, info = FlaubertMod...\n",
       "6747                                                   NaN\n",
       "6748                                                   NaN\n",
       "6749                  [predicted = y_pred.ge(.5).view(-1)]\n",
       "6750     [MinMaxScaler, torch.nn.L1Loss, torch.nn.MSELo...\n",
       "6751                                                   NaN\n",
       "6752     [x = F.softmax(x,dim=1) # or whatever dimensio...\n",
       "6753                                                   NaN\n",
       "6754     [import torch\\r\\n\\r\\ndef compute_distance_matr...\n",
       "6756     [def backward_batchnorm2d(input, output, grad_...\n",
       "6757     [nix-shell, torch-1.8.0, torch-geometric-1.7.0...\n",
       "6758     [nix-shell, torch-1.9.0, torch-geometric-1.7.2...\n",
       "6760     [forward,  def forward(self, x):\\r\\n        fe...\n",
       "6761     [...\\r\\n# statistics\\r\\n    running_loss += lo...\n",
       "6762     [from sklearn.metrics import f1_score\\r\\n\\r\\nX...\n",
       "6763     [Unable to cast from non-held to held instance...\n",
       "6764     [from tokenizers import BertWordPieceTokenizer...\n",
       "6766     [import torch \\r\\nimport torchvision.transform...\n",
       "6767     [import numpy as np\\r\\nimport pandas as pd\\r\\n...\n",
       "6768                                                   NaN\n",
       "6769     [__getitem__, class CachedVolumeDataset(Datase...\n",
       "6770     [class JigsawDataset:\\r\\n    def __init__(self...\n",
       "6771     [ids = dataset[\"ids\"]    \\r\\nmask = dataset[\"m...\n",
       "6772     [p = mp.Process(target=model.simulate(N = 10, ...\n",
       "6773                                                   NaN\n",
       "6775                                                   NaN\n",
       "6776     [torch.nn.Module, class SentimentModel_t(torch...\n",
       "6777     [pip install germansentiment\\r\\n, from germans...\n",
       "6778     [\\r\\nconv = nn.Conv2d(1, 1, 1, bias=False)\\r\\n...\n",
       "6779                                                   NaN\n",
       "6780             [t3=torch.kron(t1,t2).reshape(a,b,c)\\r\\n]\n",
       "6781     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "6782     [Dataset, csvs, ❯ cat csvs/1.csv\\r\\n1,2,3\\r\\n2...\n",
       "6783     [tf.Variable, torch.tensor, torch.tensor, output]\n",
       "6784                                  [kubectl get events]\n",
       "6785                                                   NaN\n",
       "6786                                                   NaN\n",
       "6787     [import torch\\r\\nx = torch.tensor([[1, 2, 3]])...\n",
       "6788     [m = nn.Sigmoid(), This loss combines a Sigmoi...\n",
       "6789     [forward(x), 5, def unet_function(x, in_channe...\n",
       "6790                                                   NaN\n",
       "6791                                 [model.eval()\\r\\n, p]\n",
       "6792     [map_location, model.load_state_dict(torch.loa...\n",
       "6793                                   [nn.Linear(512, 1)]\n",
       "6794     [n_classes=4, (batch, 4, width, height), 4, to...\n",
       "6796     [torchtext, 0.11.0,  pip install torchtext --u...\n",
       "6797                                [kernel_size, strides]\n",
       "6798                                                   NaN\n",
       "6799              [torch.BCELoss(), CrossEntropyLoss, BCE]\n",
       "6800                                                   NaN\n",
       "6801     [state_dict, \\r\\nnew_params = OrderedDict()\\r\\...\n",
       "6802     [torch.roll, expand, torch.gather, t = tensor(...\n",
       "6804     [def compose_single(lhs, rhs, length):\\r\\n    ...\n",
       "6805     [self.A = new_tensor\\r\\n, self.A = new_tensor....\n",
       "6806     [NewResNet18.conv1=nn.Conv2d(in_channels=1,out...\n",
       "6807     [return F.log_softmax(x, dim=1), torch.Size([3...\n",
       "6808     [y = torch.ones((1000,10)).type(torch.complex6...\n",
       "6809     [import numpy as np\\r\\nimport torch\\r\\n\\r\\ny =...\n",
       "6810     [import numpy as np\\r\\n\\r\\nx = np.array([[1,0,...\n",
       "6812                                                   NaN\n",
       "6814     [probs, 1, for label, p in enumerate(probs[0])...\n",
       "6818                                                   NaN\n",
       "6819     [forward, x.view(-1), nn.Linear, x,   ...\\r\\n ...\n",
       "6820                                                   NaN\n",
       "6821                                                   NaN\n",
       "6823                           [True, model.eval(), False]\n",
       "6824     [t[i, j, k] = i*10 + j + k, t = torch.tensor(n...\n",
       "6825     [n = np.array([np.arange(10), np.arange(10, 20...\n",
       "6826     [A = np.array([[0,0,1,1,2,3],[5,6,7,8,9,3]])\\r...\n",
       "6827     [class PairedValGather():\\r\\n    def __call__(...\n",
       "6828                                                   NaN\n",
       "6829                                                   NaN\n",
       "6833     [nn.Linear, __call__, self.fc2(x), __call__, _...\n",
       "6834     [use_multiprocessing, False, model_args.use_mu...\n",
       "6835     [RuntimeError: unable to mmap 280 bytes from f...\n",
       "6836                                                   NaN\n",
       "6837                         [ model.to(torch.double)\\r\\n]\n",
       "6838     [Net, image, Net, features, import torch\\r\\nim...\n",
       "6839     [net1 = Net1()\\r\\nnet2 = Net2()\\r\\nbce = torch...\n",
       "6840     [b, n x 1, # original implementation\\r\\nb1 = b...\n",
       "6841     [gpu_info = !nvidia-smi\\r\\ngpu_info = '\\n'.joi...\n",
       "6842     [def forward(self, x):\\r\\n        x = self.mod...\n",
       "6843     [import numpy as np\\r\\nA = np.array([[3, 1], [...\n",
       "6844     [(A == B[..., None]).any(axis=1).astype(bool)\\...\n",
       "6845                                                   NaN\n",
       "6846         [next(iter(train_data)), dataset, Dataloader]\n",
       "6847                                                   NaN\n",
       "6848     [[ first, second\\r\\n  third, forth  ]\\r\\n, [ f...\n",
       "6849     [numpy, In [559]: x = np.array([\\r\\n     ...: ...\n",
       "6850     [x, x, y, y, x, x, 1, 2, 3, 4, reshape, what_i...\n",
       "6851                                                   NaN\n",
       "6852                                        [numpy.argmax]\n",
       "6853                                                   NaN\n",
       "6854                                                   NaN\n",
       "6856     [use_cuda = torch.cuda.is_available()\\r\\ndevic...\n",
       "6857     [act, nn.BatchNorm2d, ResNet, net = ResNet(inp...\n",
       "6858                                                   NaN\n",
       "6860     [train_dataset, validation_dataset= train_data...\n",
       "6861     [from datasets.dataset_dict import DatasetDict...\n",
       "6862     [from datasets import load_dataset\\r\\ndataset ...\n",
       "6864                                                   NaN\n",
       "6865     [logits, softmax, 0 - 1, pred = output.cpu().d...\n",
       "6866                                                   NaN\n",
       "6868     [def compute_loss(y_hat, y):\\r\\n    return nn....\n",
       "6869          [nn.Linear(317520, 1), nn.Linear(317520, 2)]\n",
       "6870       [loss = compute_loss(y_hat, torch.tensor([0]))]\n",
       "6871                                                   NaN\n",
       "6872     [['a', 'b', 'c', 'd', 'e'], scene.keys(), outp...\n",
       "6874     [t = torch.tensor([[2., 2., 2., 2.],\\r\\n      ...\n",
       "6875                                                   NaN\n",
       "6876     [relu, class NeuralNetwork(nn.Module):\\r\\n    ...\n",
       "6877     [input_size, output_size, num_classes, # two l...\n",
       "6878                                    [pretrained=False]\n",
       "6879                                        [gc.collect()]\n",
       "6880                                                   NaN\n",
       "6881     [loss.backward(), with torch.no_grad():\\r\\n   ...\n",
       "6882     [LOADED = False \\r\\n\\r\\ndef handler():\\r\\n    ...\n",
       "6883                                                   NaN\n",
       "6884                                                   NaN\n",
       "6886     [topk, import torch \\r\\nmatrix = torch.tensor(...\n",
       "6888     [resnet50.conv1, import torchvision.models as ...\n",
       "6889     [def OH3(x,end=2,len=3):\\r\\n    vector = torch...\n",
       "6890     [def HO3(x,end=2,len=3):\\r\\n start=[0]*3\\r\\n e...\n",
       "6891     [from torch.nn.utils.rnn import pad_sequence\\r...\n",
       "6892     [loss_train, train, nvidia-smi -l 1, train, re...\n",
       "6893                                                   NaN\n",
       "6894     [model.load_state_dict(torch.load(PATH, map_lo...\n",
       "6895     [4 img= plt.imread(img_path)\\r\\n5 k = np.zeros...\n",
       "6896     ['...\\ground_truth\\GT_IMG_1.mat', '...\\IMG_1.j...\n",
       "6897     [for i, (batch, targets) in enumerate(val_load...\n",
       "6898     [forward, Model, foward, class Model(nn.Module...\n",
       "6899     [torch.cat, torch.stack, final, (N, M, 512), f...\n",
       "6900                                                   NaN\n",
       "6901     [import torch\\r\\n\\r\\nEVENT_TYPES = 20\\r\\ncount...\n",
       "6904                                                   NaN\n",
       "6905     [learn = cnn_learner(data, \\r\\n               ...\n",
       "6906                                                   NaN\n",
       "6907       [retain_graph = True, retain_graph, backward()]\n",
       "6908     [GCN, Graphconvlayer, Graphconvlayer, forward,...\n",
       "6911     [WeightedRandomSampler, def make_weights_for_b...\n",
       "6912                                       [torch.inverse]\n",
       "6913     [idx, Dataset, pd.DataFrame, df.iloc[idx], [id...\n",
       "6916     [torch.Size([128]), torch.Size([256]), torch.S...\n",
       "6917     [class SNet(nn.Module):\\r\\n  def __init__(self...\n",
       "6918     [loss.backward(),     # Training\\r\\n    lr = 0...\n",
       "6919                                                   NaN\n",
       "6920     ['data', 'label', __getitem__, dataset_normali...\n",
       "6921     [a = torch.rand(32, 128, 1)\\r\\na = a.permute(1...\n",
       "6922     [import torch \\r\\n\\r\\ntensor = torch.zeros(5, ...\n",
       "6923                                                   NaN\n",
       "6924     [av_reward /= float(cum_done+1)\\r\\n, av_reward...\n",
       "6925     [topk, x = tensor([0.9998, 0.9997, 0.9991, 0.9...\n",
       "6926     [DataSet, class MyDataSet(torch.utils.data.Dat...\n",
       "6927     [M, R, T, [0,0,0,1], (R | T \\\\ 0 | 1), Y_1 = M...\n",
       "6928     [torch.multiply, torch.mm(), relative_pose = t...\n",
       "6929     [torch.abs(x**2 - torch.abs(x)), WolframAlpha,...\n",
       "6931     [ import tensorrt as trt\\r\\nimport pycuda.auto...\n",
       "6932     [import numpy as np\\r\\nimport tensorrt as trt\\...\n",
       "6933     [class MultipleFC(nn.Module):\\r\\n  def __init_...\n",
       "6934                                                   NaN\n",
       "6935                                                   NaN\n",
       "6936     [import torch\\r\\n\\r\\nmask = torch.rand(5, 10) ...\n",
       "6937     [class StochasticDepth(torch.nn.Module):\\r\\n  ...\n",
       "6940     [batch_size, 60000/128=468.75, 60000 - 468*128...\n",
       "6941     [state, with open('/content/checkpoint.t7', 'w...\n",
       "6942     [LRPNet, nn.AvgPool2d, keep_features,         ...\n",
       "6943     [0, 1D, (batch, num_features), batch = 64\\r\\nf...\n",
       "6944                                                   NaN\n",
       "6945     [torch.topk,  a = torch.randn(5,4)\\r\\n a\\r\\nte...\n",
       "6946     [.reshape(shape), .contiguous().view(shape), x...\n",
       "6948     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "6949                                      [Tensor, tensor]\n",
       "6950     [example_tensor = torch.Tensor(\\r\\n    [\\r\\n  ...\n",
       "6951     [min_lr, float, list, 0, scheduler = torch.opt...\n",
       "6954     [setattr, getattr,         self.lin_cat = nn.M...\n",
       "6957     [def f1(tensor):\\r\\n    tensor = tensor.permut...\n",
       "6958                                                   NaN\n",
       "6959                                                   NaN\n",
       "6960                                                   NaN\n",
       "6961     [tensor, list, tensor, dtype, float32, 3D, 0, ...\n",
       "6962     [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "6963     [nn.Linear(a, b), torch.Size([N, a]), x, x.res...\n",
       "6964     [1, CHW, HWC, my_model = CNN(...)\\r\\nrandom_im...\n",
       "6965                                                   NaN\n",
       "6966     [reduction=none, loss = torch.nn.BCELoss(reduc...\n",
       "6967     [def BCELoss_class_weighted(weights):\\r\\n\\r\\n ...\n",
       "6968     [from torch import nn\\r\\nweights = torch.Float...\n",
       "6969          [CE_loss = CrossEntropyLoss(weight=[…])\\r\\n]\n",
       "6970     [y_train_mean = y_train.mean()\\r\\n            ...\n",
       "6971     [SEED = 1234\\r\\n\\r\\nrandom.seed(SEED)\\r\\nnp.ra...\n",
       "6972     [sigmoid(10),  1 / (1 + torch.exp(-torch.tenso...\n",
       "6973     [vectors = self.embeddings_user.weight\\r\\n, im...\n",
       "6974     [torch.set_default_tensor_type('torch.cuda.Flo...\n",
       "6975     [epochs = tqdm(range(epochs_num), desc=\"Epochs...\n",
       "6976     [model, Sequential(\\r\\n  (0): Linear(in_featur...\n",
       "6977                                                   NaN\n",
       "6978                                                   NaN\n",
       "6979     [pos_weight ( Tensor , optional ) – a weight o...\n",
       "6980     [n = len(list_text)\\r\\nA = torch.empty(n,n)\\r\\...\n",
       "6981     [out = np.concatenate(list(map(lambda x: x[1]....\n",
       "6982     [data = np.stack([np.stack([d for d in d_]) fo...\n",
       "6983                           [keras.model.fit, epochs=1]\n",
       "6984                                                   NaN\n",
       "6985     [dlc_practical_monologue.py, if args.seed &gt;...\n",
       "6986     [if args.seed &gt;= 0:\\r\\n    torch.manual_see...\n",
       "6987                                                   NaN\n",
       "6988                                                   NaN\n",
       "6990     [initial_reps_list = []\\r\\nfor i, sample_outpu...\n",
       "6991     [B = 3\\r\\nnum_nodes0 = 4\\r\\nnum_nodes = 3\\r\\nn...\n",
       "6992     [ import torch\\r\\n hidden_states = torch.arang...\n",
       "6993              [a[:, tr_indices][..., val_indices]\\r\\n]\n",
       "6994     [torch.save(model, model.state_dict(), models,...\n",
       "6995     [Model, torch.nn.Module, class Model(torch.nn....\n",
       "6996     [from smart_open import open as smart_open\\r\\n...\n",
       "6997     [optimizer.step(),         output = net2(input...\n",
       "6998     [CLS, pooler_output, [batch_size, seq_length, ...\n",
       "6999     [TabularDataset, Run in Console's namespace in...\n",
       "7000                                                   NaN\n",
       "7001     [bias=None, norm, if type(norm_layer) == funct...\n",
       "7002                                                   NaN\n",
       "7003     [torch.empty_like, torch.empty, torch.empty((2...\n",
       "7004                                                   NaN\n",
       "7005     [import torch\\r\\n    torch.cuda.empty_cache()\\...\n",
       "7006                                                   NaN\n",
       "7007     [@tf.function\\r\\ndef get_variation_uncertainty...\n",
       "7008     [def get_variation_uncertainty(prediction_scor...\n",
       "7009     [ImageFolder, import pandas as pd\\r\\nfrom path...\n",
       "7010                                                   NaN\n",
       "7011                                                   NaN\n",
       "7012     [ParameterDict, ModuleDict, nn.module, class N...\n",
       "7013     [self.weights = nn.ParameterList([nn.Parameter...\n",
       "7014     [def bilinear_interpolate_torch(im, y, x):\\r\\n...\n",
       "7015     [torch.nn.CosineSimilarity, def feat_prototype...\n",
       "7016                                [Loss(a,b), Loss(b,a)]\n",
       "7017     [nn.modules.module.Module, __init__.py, file1....\n",
       "7018     [v = torch.rand(3).unsqueeze(0)\\r\\nm = torch.r...\n",
       "7019     [import torch\\r\\nimg = torch.rand((3,1080,1080...\n",
       "7020     [torch.einsum, import torch\\r\\nimg = torch.ran...\n",
       "7021                                                   NaN\n",
       "7022          [state_dict, .grad, backward(), zero_grad()]\n",
       "7023     [[6,3], [3, 6], nn.BCELoss, nn.CrossEntropyLos...\n",
       "7024     [to, device = torch.device(\"cuda\")\\r\\nb_input_...\n",
       "7025     [requirements=[\"torch==1.8.1+cpu\", \"-f\", \"http...\n",
       "7026     [def forward(self, input, hidden):\\r\\n    emb ...\n",
       "7027     [torch.randperm, t, t[:,torch.randperm(t.shape...\n",
       "7028     [ a\\r\\ntensor([[[1, 1],\\r\\n         [2, 2],\\r\\...\n",
       "7029                                                   NaN\n",
       "7030                                                   NaN\n",
       "7031                                                   NaN\n",
       "7033                                                   NaN\n",
       "7034                           [ pip install mmseg==1.3.0]\n",
       "7035     [pip install openmim\\r\\nmim install mmsegmenta...\n",
       "7036     [shift, copy as path, .jpeg, .jpg, aBc.TXT, ab...\n",
       "7037                                                   NaN\n",
       "7039             [pred = model(img, augment=False)[0]\\r\\n]\n",
       "7041     [self.transform, ToTensor, x_jpg = self.transf...\n",
       "7042     [torch.nn.functional.one_hot, label, n, torch....\n",
       "7043         [.pth, import, class, class, torch.nn.Module]\n",
       "7044     [w0 = model.linear1.weight[0, :]\\r\\nw0_hat = w...\n",
       "7045     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "7046     [A = [0.8, 0.9], B = [1.0, 0.0], A = np.array(...\n",
       "7049                                                   NaN\n",
       "7050     [import torch\\r\\ntest_tensor=torch.tensor([[1,...\n",
       "7051     [y, n, __init__, Dataset, self.label_names = [...\n",
       "7052     [__getitem__, data, label, __getitem__, collat...\n",
       "7053     [class RMSLELoss(nn.Module):\\r\\n    def __init...\n",
       "7054                                                   NaN\n",
       "7055     [pip3 install torch==1.7.1 torchvision==0.8.2 ...\n",
       "7056     [demo.py, model = BiSeNet(args.num_classes, ar...\n",
       "7058     [    ...\\r\\n    #main function\\r\\n\\r\\n    #tra...\n",
       "7059     [result, X, W_ih, torch.where(outputs &gt; 0, ...\n",
       "7060     [conda install pytorch==1.7.1 torchvision==0.8...\n",
       "7061     [t, torch.cat(t.split(128, dim=1))\\r\\n, torch....\n",
       "7062     [np.vstack(np.hsplit(arr, 4))\\r\\n, np.hstack(n...\n",
       "7063     [!python models/export.py --weights ./runs/tra...\n",
       "7064     [relu, sigmoid, sigmoid, def forward(self, x):...\n",
       "7065     [nn.ModuleList, self.list_1 = nn.ModuleList(se...\n",
       "7067     [1, ..., #classes, P, Image.putpalette, import...\n",
       "7069     [weights, import torch\\r\\n\\r\\ntest_act = torch...\n",
       "7070     [%%timeit\\r\\nfor _ in range(10**4): tokenizer(...\n",
       "7071     [return_dict=False, o1, _ = self.bert(\\r\\n    ...\n",
       "7072                                                   NaN\n",
       "7073     [conv2d, conv1d, conv3d, allclose, 1e-8, def t...\n",
       "7074     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7075                                                   NaN\n",
       "7076     [from io import BytesIO\\r\\n\\r\\nimg = Image.ope...\n",
       "7077     [self.losses.append(loss) \\r\\n, self.losses.ap...\n",
       "7078     [i, v, def dense_from_coo(i, v):\\r\\n    rows =...\n",
       "7080     [M1, M2, p1, p2, p3, p1 = 0.5 # for example\\r\\...\n",
       "7081                                         [PYTORCH_JIT]\n",
       "7082     [import numpy as np\\r\\nimport torch\\r\\n\\r\\n\\r\\...\n",
       "7083     [w, .to_event(1), sigma, (), sigma, def model_...\n",
       "7086                                                   NaN\n",
       "7087     [[64, 1], [64], import torch\\r\\na = torch.rand...\n",
       "7088                                                   NaN\n",
       "7089     [sudo apt-get remove --purge nvidia*\\r\\n, wget...\n",
       "7090     [center, normalize = lambda vect: vect/vect.no...\n",
       "7093     [def discrete_curl(self, pred):\\r\\n        new...\n",
       "7094                                                   NaN\n",
       "7095     [int64, int32, DataLoader, import torch\\r\\nimp...\n",
       "7096                                                   NaN\n",
       "7097     [import torch\\r\\ntorch.manual_seed(0)\\r\\ndevic...\n",
       "7098     [index.unsqueeze(len(index.shape)).expand(*ind...\n",
       "7099                                                   NaN\n",
       "7101     [0, 1, x = F.relu(x)\\r\\nreturn (x)\\r\\n, torch....\n",
       "7103                                                   NaN\n",
       "7104     [T* at::Tensor::data&lt;T&gt; const, T = long ...\n",
       "7106     [signals = np.stack([src.signal for src in pst...\n",
       "7107                                       [x = F.relu(x)]\n",
       "7108     [for i in range(B.shape[0]):\\r\\n    rv = B[i]\\...\n",
       "7110                                                   NaN\n",
       "7114     [sum, class Model(nn.Module):\\r\\n    def __ini...\n",
       "7115     [grad, torch.autograd,  import torch\\r\\n from ...\n",
       "7116     [import torchvision\\r\\nmodel = torchvision.mod...\n",
       "7117                        [__init__, model.parameters()]\n",
       "7118     [model.load_state_dict(checkpoint['model_state...\n",
       "7119     [\\r\\nmodel = create_model()\\r\\nmodel.load_stat...\n",
       "7120                            [pip upgrade transformers]\n",
       "7121     [{\\r\\n\"runtimes\": {\\r\\n    \"nvidia\": {\\r\\n    ...\n",
       "7122     [ARG PYTORCH=\"1.3\"\\r\\nARG CUDA=\"10.1\"\\r\\nARG C...\n",
       "7123     [conda create -n dlearn python=3.7 pytorch tor...\n",
       "7124     [r'yourString'\\r\\n, self.HR =r'C:/Users/My_com...\n",
       "7125     [topk(), W @ X, topk(Wx), In [1]: import torch...\n",
       "7126     [def sparse_(tensor, sparsity, std=0.01):\\r\\n ...\n",
       "7127                                                   NaN\n",
       "7128     [from transformers import BertTokenizer\\r\\nTOK...\n",
       "7129     [torch_model.load_state_dict(torch.load(path))...\n",
       "7130                                                   NaN\n",
       "7131     [import numpy as np\\r\\na = np.array([0.0557094...\n",
       "7132     [int, carry, carry, def roundall(scores, decim...\n",
       "7133                                                   NaN\n",
       "7134     [cls, offset = self.model([proposal, fm], stag...\n",
       "7135                                                   NaN\n",
       "7136     [BCEWithLogitsLoss, WithLogits, BCELoss, BCELo...\n",
       "7137                                                   NaN\n",
       "7139     [self._to_linear, __init__, self._to_linear = ...\n",
       "7140     [myimage.reshape(-1,3,32,32)\\r\\nprint(myimage....\n",
       "7141                                                   NaN\n",
       "7142     [from transformers import logging\\r\\nlogging.s...\n",
       "7143     [from transformers import logging\\r\\n\\r\\nloggi...\n",
       "7144                                                   NaN\n",
       "7145                                                   NaN\n",
       "7147     [discriminator_loss = discriminator_loss + dis...\n",
       "7148     [conv1, layer2, handle = model.layer2[0].conv1...\n",
       "7149                                                   NaN\n",
       "7150     [self.weightx = torch.nn.Parameter(your_inital...\n",
       "7151     [torch.chunk, cat, unsqueeze(1), A = torch.ran...\n",
       "7152     [split, reshape,  a = torch.arange(10).reshape...\n",
       "7153     [torch.unbind, import torch\\r\\n\\r\\ntensor = to...\n",
       "7154     [model = ResNet(Bottleneck, [3, 4, 6, 3], **kw...\n",
       "7155                                                   NaN\n",
       "7156     [from knn_cuda import KNN\\r\\n, knn = KNN(k=7)\\...\n",
       "7157     [batch_sampler, DataLoader, IMG_EXTENSIONS = [...\n",
       "7158     [dataloader, class ImageFolderLoader(Dataset):...\n",
       "7159                                 [pkill -9 python\\r\\n]\n",
       "7160                                                   NaN\n",
       "7161                                                   NaN\n",
       "7162     [utils.py, def collate_fn(batch):\\r\\n    retur...\n",
       "7163     [transforms, transforms, data_transforms['trai...\n",
       "7164     [class experimental_dataset(Dataset):\\r\\n\\r\\n ...\n",
       "7165     [increased_dataset = torch.utils.data.ConcatDa...\n",
       "7166     [data.transforms, import torch\\r\\nfrom torchvi...\n",
       "7167     [FiveCrop, TenCrop,  transform = Compose([\\r\\n...\n",
       "7168                                                   NaN\n",
       "7170                                                   NaN\n",
       "7171                                                   NaN\n",
       "7172                                                   NaN\n",
       "7173     [bert_tokenizer = BertTokenizer.from_pretraine...\n",
       "7174     [A = torch.tensor([[1.0, 100, 100], [1, 2, 3],...\n",
       "7175                                                   NaN\n",
       "7176     [torch.no_grad, def forward(self, x):\\r\\n     ...\n",
       "7177     [a, b, class Net(nn.Module):\\r\\n    def __init...\n",
       "7179     [trainset = cows_train\\r\\n, trainset, folder_p...\n",
       "7180     [alexnet, sharp_image, convnet, ConvTranspose2...\n",
       "7181     [\"module\": \"torch.distributed.launch\", -m, arg...\n",
       "7182     [forward, ,, self.fc = nn.Linear(1024,200, bia...\n",
       "7183     [class GoogleNet(nn.Module):\\r\\n    def __init...\n",
       "7184     [class GoogleNet(nn.Module):\\r\\n    def __init...\n",
       "7185     [forward, ResNet, forward, class AttentionResN...\n",
       "7186     [layer = torch.nn.Linear(n_in_features, n_out_...\n",
       "7187     [fill_mask(\"Auto Car &lt;mask&gt;.\")\\r\\n, MASK...\n",
       "7188     [from transformers import BertTokenizer\\r\\ntok...\n",
       "7189     [torch.manual_seed(), torch.use_deterministic_...\n",
       "7191     [mode, t = torch.tensor([P1,P2,P3])\\r\\nt.mode(...\n",
       "7192     [scipy.mode, import numpy as np\\r\\nfrom scipy....\n",
       "7193                                                   NaN\n",
       "7194     [text_pipeline, tokens_list = hparams[\"tokeniz...\n",
       "7195     [info = torchaudio.info(wav)\\r\\nsig = sb.datai...\n",
       "7196                                                   NaN\n",
       "7197     [M.unsqueeze(0) * V.unsqueeze(1)\\r\\n, (1, d1, ...\n",
       "7198             [torch.einsum('ij,bj-&gt;bij', M, V)\\r\\n]\n",
       "7199     [alpha, id(alpha), id(alpha_optimizer.param_gr...\n",
       "7200     [LabelEncoder, from sklearn import preprocessi...\n",
       "7201     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7202                             [nn.Sequential.modules()]\n",
       "7204                                                   NaN\n",
       "7205     [model.device\\r\\n, fill_mask = pipeline(\\r\\n  ...\n",
       "7206     [a, a = torch.Tensor([[1, 2, 3, 4]])\\r\\nb_abbr...\n",
       "7207     [require_grad, requires_grad, for param in mod...\n",
       "7208     [require_grad, requires_grad, # To freeze the ...\n",
       "7209     [ #layer3\\r\\n            torch.nn.Conv2d(in_ch...\n",
       "7210     [@MobeusZoom, Normal, # normal.py\\r\\nclass Nor...\n",
       "7211     [torch.nn.Dropout, inplace, False, outplace_dr...\n",
       "7212     ['dataset/var/UCF-101\\\\train\\\\ApplyEyeMakeup',...\n",
       "7213     [[num_nodes, num_node_features], [2058, 1], Ou...\n",
       "7214     [for...loop, generator, tf.data, from PIL impo...\n",
       "7215                     [self.dropout = Dropout(dropout)]\n",
       "7216     [Dropout, self.dropout = Dropout(dropout), for...\n",
       "7217     [pytorch.nn, with torch.no_grad(), embeddings,...\n",
       "7218                                              [:, ...]\n",
       "7219                                                   NaN\n",
       "7220     [h0 = torch.zeros((1, 16, 32)).to(device)\\r\\n,...\n",
       "7222                                                   NaN\n",
       "7223     [# Method 1: Use the jacobian function\\r\\nCPU ...\n",
       "7224     [torch.autograd.functional.jacobian(vectorize=...\n",
       "7225     [def dilate(t, k):\\r\\n  x = t.squeeze()\\r\\n  x...\n",
       "7226     [A, A.squeeze(), func(), import torch\\r\\nimpor...\n",
       "7227     [import torch\\r\\nfrom torch import Tensor\\r\\nf...\n",
       "7228                                                   NaN\n",
       "7229     [batch_size*node_num, attribute_num, batch_siz...\n",
       "7230                                                   NaN\n",
       "7231     [pred = net(input1,input2) #input1 ---&gt; mni...\n",
       "7232     [[batch_size, 10], self.dense = nn.Linear(128,...\n",
       "7233                                                   NaN\n",
       "7235     [from_numpy, clone, copy, b = torch.from_numpy...\n",
       "7236                                                   NaN\n",
       "7237                                                   NaN\n",
       "7238     [torch.set_printoption(),  th = torch.tensor((...\n",
       "7239     [scheduler = ... # initialize some LR schedule...\n",
       "7240     [torch.flatten, torch.nn.Flatten, start_dim, e...\n",
       "7241                                                   NaN\n",
       "7242                                                   NaN\n",
       "7244     [import torch\\r\\nx = torch.randn([3, 136, 64, ...\n",
       "7245     [# nn architecture\\r\\nclass Net(nn.Module):\\r\\...\n",
       "7246     [print(out.dtype)\\r\\nprint(y.dtype)\\r\\n, \"torc...\n",
       "7247                                                   NaN\n",
       "7248     [from torch_geometric.datasets import TUDatase...\n",
       "7250     [model_str = 'resnet50'\\r\\nmodel = torch.hub.l...\n",
       "7251     [import torch\\r\\ntensor = torch.randn(50, 512,...\n",
       "7252     [nn.BCEWithLogitsLoss(), nn.CrossEntropyLoss, ...\n",
       "7253     [[batch, num_classes, H, W], [batch, H, W], H,...\n",
       "7254                         [model.train(), model.eval()]\n",
       "7255     [for param in model.parameters():\\r\\n     para...\n",
       "7256     [def prepare_data(self):\\r\\n, def setup(self,s...\n",
       "7257     [state= torch.load(\"/content/model_WandB_12.pt...\n",
       "7258     [x = a[0]*(b&lt;4) + a[1]*((4&lt;=b)&amp;(b&lt...\n",
       "7259                                                   NaN\n",
       "7260     [accuracy = correct / 512\\r\\n, accuracy = corr...\n",
       "7261     [self.training_dataset, DataModuleClass, prepa...\n",
       "7262     [DataSet, Sample, (Sample, None), (Sample, Lab...\n",
       "7263     [class MyDataSet(T.utils.data.Dataset):\\r\\n  #...\n",
       "7264     [ignore_index, class CDiscountDataset:\\r\\n    ...\n",
       "7265     [total = 0.0\\r\\ntotalsq = 0.0\\r\\ncount = 0\\r\\n...\n",
       "7266     [0, x, -100, y, nn.CrossEntropyLoss(), ignore_...\n",
       "7269     [torch.autograd, nn.Module, F, class UnknownF(...\n",
       "7270     [def prepare_data(self):\\r\\n    a = np.random....\n",
       "7271     [setup(), prepare(), dm = DataModuleClass()\\r\\...\n",
       "7272     [lin_4, lin_5, class MlpNN(nn.Module):\\r\\n\\r\\n...\n",
       "7273                                                   NaN\n",
       "7274                                                   NaN\n",
       "7275     [torch._C._cuda_init(), CUDA arch flags, pytor...\n",
       "7276                                                   NaN\n",
       "7277                                                   NaN\n",
       "7278                                                   NaN\n",
       "7280                                                   NaN\n",
       "7281                                                   NaN\n",
       "7282                                                   NaN\n",
       "7284                      [xla, !pip install -U numpy\\r\\n]\n",
       "7286     [encoder = ...\\r\\ndecoder = ...\\r\\nautoencoder...\n",
       "7287     [torch.script, torch.jit, import torch\\r\\n\\r\\n...\n",
       "7288     [log_dir, tensorboard, 9, from torch.utils.ten...\n",
       "7289                     [torch.solve, torch.linalg.solve]\n",
       "7291     [self.BigLSTM = BigLSTM(...), self.lstm1 = nn....\n",
       "7292                                                   NaN\n",
       "7293     [ImageFolder, torch.nn.Dataset, import torch\\r...\n",
       "7294     [loss.backward(), .grad, t.grad, t, torch.auto...\n",
       "7295     [I = [1,2,3]\\r\\ndont = [4,5,6]\\r\\neat = [7,8,9...\n",
       "7296                                                   NaN\n",
       "7298                                                   NaN\n",
       "7299     [t = torch.rand(2, 3, 4)\\r\\nt = t.argmax(dim=2...\n",
       "7300                        [res = x.argmax(axis = 2)\\r\\n]\n",
       "7301     [x=[[[0, 1, 0, 0],\\r\\n[1, 0, 0, 0],\\r\\n[0, 0, ...\n",
       "7302     [--region, gcloud create model --region, gclou...\n",
       "7304     [print(next(model.parameters()).device)\\r\\n, p...\n",
       "7305     [import torch\\r\\nimport torch.nn.functional as...\n",
       "7306     [cumsum(), 1, # mark the consecutive blocks\\r\\...\n",
       "7307     [weighted = (net_output * att_scores[..., None...\n",
       "7308                                                   NaN\n",
       "7310     [box_a = np.random.randn(1,4)\\r\\nbox_b = np.ra...\n",
       "7311                                                   NaN\n",
       "7313     [flag=True, getSequentialVersion(), Flatten, i...\n",
       "7314     [BatchNormalization, scale, offset, accumulate...\n",
       "7315     [TensorFlow, TensorFlow, tf.function, tf.funct...\n",
       "7316                                                   NaN\n",
       "7317                                                   NaN\n",
       "7318     [SimpleDataLoader, MultiProcessDataLoader, max...\n",
       "7319     [org_dataset.data, (N, 32, 32, 3), (N, 3, 32, ...\n",
       "7320     [input= torch.Size([1, 100, 12])\\r\\n1st Conv= ...\n",
       "7321     [def torch_cos_sim(v,cos_theta,n_vectors = 1,E...\n",
       "7323     [# done in two steps to avoid averaging across...\n",
       "7324                                                   NaN\n",
       "7325                                    [conv3x3, conv1x1]\n",
       "7327     [device = torch.device(\"cuda:0,1\" if torch.cud...\n",
       "7328                                                   NaN\n",
       "7329     [class FC(nn.Module):\\r\\n  def __init__(self, ...\n",
       "7330     [def _constant_scale(initial: int, factor: int...\n",
       "7331     [class EmbeddingNet(nn.Module):\\r\\n  def __ini...\n",
       "7332     [label_vec = torch.zeros(100).float()\\r\\nlabel...\n",
       "7333                                                   NaN\n",
       "7334     [def forward(self, input):\\r\\n    for module i...\n",
       "7335      [net1, F.relu(self.fc1(out)), net2, self.out(x)]\n",
       "7336                                                   NaN\n",
       "7337     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "7338     [conda install pytorch torchvision torchaudio ...\n",
       "7339     [loss.backward(), retain_graph, backward(), re...\n",
       "7341                                                   NaN\n",
       "7343                                                   NaN\n",
       "7344                                                   NaN\n",
       "7346     [F.nll_loss, 0.1 ,0.2 etc, 0,1,2 .., import os...\n",
       "7347                              [F.nll_loss, F.mse_loss]\n",
       "7348     [tfds.as_numpy(dataset), torch.as_tensor(data,...\n",
       "7349     [record_path, meta, df = pd.json_normalize(dat...\n",
       "7350                                                   NaN\n",
       "7351                        [on_end, log_metrics_to_wandb]\n",
       "7352     [from allennlp.training.callbacks.callback imp...\n",
       "7353     [  def act(self,obs):\\r\\n    #state=T.tensor(o...\n",
       "7354     [optimizer = torch.optim.Adam(RONANetv1.parame...\n",
       "7355     [# this\\r\\noptimizer = torch.optim.Adam(RONANe...\n",
       "7356                                                   NaN\n",
       "7358     [num_correct += torch.sum(torch.eq(top_class.s...\n",
       "7360     [def trades():\\r\\n    model.eval()\\r\\n    crit...\n",
       "7361     [torch.stack,  object_ids = [tensor([2., 3.]),...\n",
       "7362     [import torch\\r\\n\\r\\nf = torch.nn.Linear(10, 5...\n",
       "7363     [t, t.reshape((-1,)+t.shape[2:])\\r\\n, -1, t.sh...\n",
       "7364     [import torch\\r\\n\\r\\ntests = [\\r\\n    torch.ra...\n",
       "7365                      [pip install alennlp==0.9.0\\r\\n]\n",
       "7366                            [requires_grad = True\\r\\n]\n",
       "7367     [(N, C, d1, d2), (N, d1, d2), (N, 1, d1, d2), ...\n",
       "7369     [import torch\\r\\nfrom torch.autograd import gr...\n",
       "7370                                                   NaN\n",
       "7371     [forward, Policy.act, for step in range(STEPS)...\n",
       "7372     [import torch\\r\\na = torch.randn(1, 3, 256, 25...\n",
       "7373     [softmax = nn.Softmax(dim=1)\\r\\n, nn.Softmax, ...\n",
       "7374           [os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"]\n",
       "7375     [python, CUDA_VISIBLE_DEVICES=\"\" python ...\\r\\...\n",
       "7376             [os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"]\n",
       "7377     [[144] yaw, pitch, roll = model(img)\\r\\n, [146...\n",
       "7378     [f, x, y, f(x,y) = g(h(x,y)), df/dy = dg/dh * ...\n",
       "7379                                                   NaN\n",
       "7380                                                   NaN\n",
       "7381                                                   NaN\n",
       "7382                                                   NaN\n",
       "7383     [from_archive, model.tar.gz, model, from_archi...\n",
       "7384     [Sequential(), model = tf.keras.Sequential([fi...\n",
       "7385     [ # To export\\r\\n model = torch.hub.load('pyto...\n",
       "7387     [numpy.einsum, C = np.einsum('ijk,ikl-&gt;il',...\n",
       "7388     [DataParallel, DataParallel, model, device = t...\n",
       "7389                                                   NaN\n",
       "7390                                                   [N]\n",
       "7391     [torch.nn.Adaptive{Avg, Max}Pool{1, 2, 3}d, to...\n",
       "7392                                                   NaN\n",
       "7393     [from gensim.models import Word2Vec\\r\\nfrom mu...\n",
       "7394     [embedding_dimensions =  number_of_categories*...\n",
       "7395     [Dataset, __len__(), __getitem__(), train_load...\n",
       "7396     [model.eval(), with torch.no_grad():, for e in...\n",
       "7397                                                   NaN\n",
       "7398                                      [data_ptr(), id]\n",
       "7399     [sigmoid, forward(), def check_accuracy(loader...\n",
       "7400                             [torch.long, torch.int64]\n",
       "7401     [dropout, import torch.nn.functional as F\\r\\n\\...\n",
       "7402     [m, n = mytensor.weight.numel()\\r\\nm = int(rou...\n",
       "7403                                      [cacheddata.pth]\n",
       "7404     [model.conf = 0.25  # confidence threshold (0-...\n",
       "7405     [import torch\\r\\nmodel = torch.hub.load('ultra...\n",
       "7406     [def return_indices(dataset_class):\\r\\n    \\r\\...\n",
       "7407     [ArgumentParser.parse_args(args=None, namespac...\n",
       "7408     [!pip install segmentation-models-pytorch==0.0.3]\n",
       "7409                                                   NaN\n",
       "7412     [seq_model = nn.Sequential(OrderedDict([\\r\\n('...\n",
       "7413                                                   NaN\n",
       "7414     [import torch \\r\\nfrom torch import nn\\r\\n\\r\\n...\n",
       "7415     [img, tf.browser.toPixels(img), OpenCV, matplo...\n",
       "7416     [t = torch.tensor([[[1., 3.],\\r\\n         [2.,...\n",
       "7417                                                   NaN\n",
       "7419     [.sum, .sum(), dpred/dinput, pred = sum(loss) ...\n",
       "7420                                                   NaN\n",
       "7421                   [torch.stack(list), CUDA OOM error]\n",
       "7422                                                   NaN\n",
       "7423     [class VGG16SUM(nn.Module):\\r\\n    \\r\\n    def...\n",
       "7424     [.data, Parameter, for param1, param2 in zip(m...\n",
       "7425                                                   NaN\n",
       "7426     [jshtml, from matplotlib import rc\\r\\nrc('anim...\n",
       "7427     [num_workers &gt; 0, train/test(), if __name__...\n",
       "7428                                       [images.cuda()]\n",
       "7429     [loss_func, def loss_func(output, target): ret...\n",
       "7430     [import os \\r\\nos.environ['LD_LIBRARY_PATH']='...\n",
       "7431     [RuntimeError: Expected 4-dimensional input fo...\n",
       "7433     [s[i:j:k], x = i + n*k, 0 &lt;= n &lt; (j-i)/k...\n",
       "7434                               [Final, pytorch-nighly]\n",
       "7435                                                   NaN\n",
       "7436     [.to(device),     count0,count1,count2 = torch...\n",
       "7437     [SubsetRandomSampler, train_indices, val_indic...\n",
       "7438                                                   NaN\n",
       "7439     [optimizer.zero_grad()\\r\\nloss.backward() # yo...\n",
       "7440     [x[:1], x[0],  torch.vstack((f(x[:1]), g(x[1:]...\n",
       "7442     [detect.py, model, 'yolov5s', import torch\\r\\n...\n",
       "7443     [import torch.nn.utils.prune as prune\\r\\nprune...\n",
       "7444     [valid_size = 0.2\\r\\nnum_train = len(train_dat...\n",
       "7445     [inputs = batch[\"image\"].type(torch.cuda.Float...\n",
       "7446           [model = model.type(torch.cuda.LongTensor)]\n",
       "7447                                [watch -n1 nvidia-smi]\n",
       "7448                                                   NaN\n",
       "7450     [take, B = A.take([0,1,2], axis=2)\\r\\n, tf.sli...\n",
       "7451     [NN, gradH, HH.grad_fn, gradH.grad_fn, pred, N...\n",
       "7452                                                   NaN\n",
       "7453     [loss = CrossEntropyLossFlat \\r\\nlearn3 = Lear...\n",
       "7454     [import torch\\r\\nfrom time import time\\r\\ndef ...\n",
       "7455     [class, index_select, import torch\\r\\nfrom tim...\n",
       "7456     [max_length, max_length, model.config.max_length]\n",
       "7457     [enumerate, for i, batch in enumerate(loaders[...\n",
       "7458                                                   NaN\n",
       "7459                                                   NaN\n",
       "7460     [RuntimeError: Given groups=1, weight of size ...\n",
       "7461                                                   NaN\n",
       "7462     [import numpy as np\\r\\n\\r\\na = np.zeros((20,3,...\n",
       "7463     [    train_trans = transforms.Compose([\\r\\n   ...\n",
       "7464     [ print(optimizer.__class__.__name__)\\r\\n\\r\\nA...\n",
       "7466                                                   NaN\n",
       "7467     [Dataset, Dataset, DataLoader, Dataset, __geti...\n",
       "7469     [xxx = torch.tensor([[1], [2], [3]])\\r\\nxxx = ...\n",
       "7470     [__len__, __length__, torch.utils.data.Dataset...\n",
       "7471                                                   NaN\n",
       "7472     [return_sequences, False, LSTM, ....\\r\\n....\\r...\n",
       "7473                                                   NaN\n",
       "7476                                                   NaN\n",
       "7477     [INCIDENT_NUMBER, sample_concatenated_embeddin...\n",
       "7478     [__init__, [(\"img1\", p1), (\"img1\", p2), ..., (...\n",
       "7479     [pred_y = torch.max(test_outputs, 1)[1].data.n...\n",
       "7480     [def load(self):\\r\\n      try:\\r\\n        chec...\n",
       "7482     [torch.exp, torch.autograd.set_detect_anomaly(...\n",
       "7483                        [inf, df(a.x)/dx = a.df(x)/dx]\n",
       "7484     [wandb.log(), import matplotlib.pyplot as plt\\...\n",
       "7485     [    def cos_sim(A, B, dim, eps=1e-08):\\r\\n   ...\n",
       "7486     [repeated_image = image.repeat_interleave(128,...\n",
       "7487                                                   NaN\n",
       "7489                                                   NaN\n",
       "7490     [ARG PYTORCH=1.3\\r\\nARG CUDA=10.1\\r\\nARG CUDNN...\n",
       "7491     [a, (?, d), b, (d,), cmp = a.eq(b).all(dim=1)....\n",
       "7492     [import torch\\r\\na = torch.tensor([[1, 0], [0,...\n",
       "7493     [import random\\r\\nimport numpy as np\\r\\nimport...\n",
       "7494     [seed + worker_id, random, import torch\\r\\nfro...\n",
       "7495     [dic.append( {\\r\\n    'hidden_states': outputs...\n",
       "7496     [class DataframeDataset(torch.utils.data.Datas...\n",
       "7497     [self.feedbak_weight = nn.Parameter(self.sign_...\n",
       "7498     [np.random.shuffle(), import numpy as np\\r\\nfr...\n",
       "7499     [import torch\\r\\n# A is your tensor\\r\\nB = tor...\n",
       "7500     [[0], [actions], [actions.item()], self.Q.forw...\n",
       "7501     [requires_grad, import torch.nn.functional as ...\n",
       "7502     [import torchvision.transforms as T\\r\\nimport ...\n",
       "7503     [test = torch.tensor([100])\\r\\ntest_copy = tes...\n",
       "7505            [validation_epoch_end, on_event_start/end]\n",
       "7506                                                   NaN\n",
       "7507     [b_opt, clone, tanh, model_net.b_opt.is_leaf, ...\n",
       "7508     [dataloader = DataLoader(dataset, batch_size=1...\n",
       "7509           [worker_init_fn, torch.seed(my_fav_number)]\n",
       "7510                             [x = np.delete(x, 1)\\r\\n]\n",
       "7511     [nn.CosineSimilarity, import torch\\r\\nimport t...\n",
       "7512     [feedforwardnet, feedforwardnet(20, 'trainlm')...\n",
       "7513                                                   NaN\n",
       "7514     [resnet.zero_grad(), logit = resnet(data), # C...\n",
       "7515                                                   NaN\n",
       "7516     [for, labels, classes, # ...\\r\\nfor inputs, la...\n",
       "7517     [x = torch.rand(15, 3, 4,6)\\r\\ny1 = torch.rot9...\n",
       "7519     [torch.triu_indices, t = tensor([[1.9392, -1.9...\n",
       "7520                                             [os.path]\n",
       "7521                                                   NaN\n",
       "7522     [OrderedDict, from collections import OrderedD...\n",
       "7523     [In [1]: import tensorflow as tf\\r\\nIn [2]: da...\n",
       "7524     [kernel_size, (3,3), Conv1d, CausalConv1d(in_c...\n",
       "7525                                  [--batch-size 3\\r\\n]\n",
       "7526     [# ...\\r\\n\\r\\n# from [batch_size, 1, 28, 28] &...\n",
       "7527     [data_transforms[x], transforms[x], torchvisio...\n",
       "7528     [#This is the section that loads your model\\r\\...\n",
       "7529     [def complement_idx(idx, dim):\\r\\n    \"\"\"\\r\\n ...\n",
       "7531     [.to(device), learn = cnn_learner(dls, resnet3...\n",
       "7532     [Variable, Variable, requires_grad, True, Vari...\n",
       "7535                                                   NaN\n",
       "7536     [with torch.no_grad():\\r\\n  params[0][0][0][0]...\n",
       "7538     [DoppelDiscriminator,     nn.Linear(25, 1),\\r\\...\n",
       "7539     [get_transform, transforms.append(T.Resize((22...\n",
       "7540                                                   NaN\n",
       "7541      [x_train = x_train.reshape(-1, 1), (N,1), (N,2)]\n",
       "7542                                                   NaN\n",
       "7543                                                   NaN\n",
       "7545     [import tensorflow as tf\\r\\nfrom tensorflow im...\n",
       "7546                                                   NaN\n",
       "7548                                                   NaN\n",
       "7549     [t, f(x1) = y1, f(x2) = y2, loss = mse(y1,y2) ...\n",
       "7550                                                   NaN\n",
       "7551     [nn.Module, import torch\\r\\nfrom torch import ...\n",
       "7552     [import signal\\r\\n\\r\\nclass TimeoutException(E...\n",
       "7553     [import time\\r\\nimport signal\\r\\n\\r\\nclass Tim...\n",
       "7554     [subprocess, subprocess.check_call([sys.execut...\n",
       "7555     [import time\\r\\n\\r\\nfor x in range(0,3):\\r\\n  ...\n",
       "7556     [import signal\\r\\n\\r\\ndef signal_handler(signu...\n",
       "7557     [pip install torch==1.8.0+cu101 torchvision==0...\n",
       "7558     [random_split, dataset = TensorDataset(x_tenso...\n",
       "7559     [dataset = CustomDataset(x_tensor_flat, y_tens...\n",
       "7561     [torch.arange, import torch\\r\\nfrom torch impo...\n",
       "7562     [from torchvision import transforms\\r\\n\\r\\ndef...\n",
       "7563     [data, X_train, Y_train = data, d = {'a': [1,2...\n",
       "7564     [state_dict(), scheduler, torch.save(), import...\n",
       "7565     [def create_dataset(img_folder):\\r\\n   \\r\\n   ...\n",
       "7566     [starflut package, Pytorch_mobile, String pred...\n",
       "7567                [1.8.1, 11.1, 0.4, torch 1.8.0, 1.8.1]\n",
       "7568     [pip install torch==1.8.0+cu111 torchvision==0...\n",
       "7569     [/home/mona/research/code/frankmocap/detectors...\n",
       "7570     [xpermuted = x3.permute(0, 2, 3, 1)\\r\\nxreshap...\n",
       "7571     [def loss_loglik(y_mean, y_logvar, x):\\r\\n    ...\n",
       "7572                                                   NaN\n",
       "7573     [t = torch.tensor(arr)\\r\\nmask = torch.arange(...\n",
       "7574     [pod install, sudo gem install ethon, gem, eth...\n",
       "7575                        [arch -x86_64 pod install\\r\\n]\n",
       "7576     [df = pd.DataFrame({\"Col1\":[1,2,3,4], \"Col2\":[...\n",
       "7577     [for batch_idx, (data, target) in enumerate(tr...\n",
       "7578                                                   NaN\n",
       "7579                                                   NaN\n",
       "7580              [permute, unfold, unfold, permute, view]\n",
       "7581     [x = torch.tensor([[1, 2, 3, 4, 5],\\r\\n       ...\n",
       "7582     [forward pass, dataX, float, outputs = model(d...\n",
       "7583     [data.type()\\r\\n, data.float()\\r\\ndata.double(...\n",
       "7584                                                   NaN\n",
       "7585     [layers = [nn.Conv2d(number_f, number_f, 3, 1,...\n",
       "7586                                                   NaN\n",
       "7587     [embedding = TransformerWordEmbeddings('emilya...\n",
       "7588     [import keras\\r\\nfrom keras.layers import Acti...\n",
       "7589     [torch.topk, k = 2\\r\\noutput = torch.randn(5)\\...\n",
       "7591             [pip install torch-cluster --upgrade\\r\\n]\n",
       "7592     [import torch\\r\\n\\r\\nconv_inp1 = torch.rand(1,...\n",
       "7593                                                   NaN\n",
       "7594     [conv1d, [B, C, L], B, C, L, conv1d, nn.Conv1d...\n",
       "7595                                                   NaN\n",
       "7597     [nnet = get_nnet_model(...)\\r\\n, get_nnet_mode...\n",
       "7598                                                   NaN\n",
       "7599     [json, json.loads(), import json\\r\\n\\r\\nwith o...\n",
       "7600     [inspect, grep, find, torch.nn, inspect, torch...\n",
       "7601                                  [CrossEntropyLoss()]\n",
       "7603     [self.start_index=step*batch, __getitem__, (se...\n",
       "7604     [[cross_entropy_loss(output_1, target_1), cros...\n",
       "7605     [--preload, printenv,   GUNICORN_CMD_ARGS: '--...\n",
       "7606     [torch.nn.AvgPool2d(kernel_size=3, stride=1)\\r...\n",
       "7608     [Is it a right way to train a model? In many a...\n",
       "7609     [pipeline.add(CenterCrop(224, 224))\\r\\n       ...\n",
       "7610     [x = x.reshape(x.size(0), -1)\\r\\nprint(x.shape...\n",
       "7611                                                   NaN\n",
       "7612                    [RandomNodeSplit, RandomNodeSplit]\n",
       "7614                                                   NaN\n",
       "7615     [force_download, force_reload, torch.load.hub,...\n",
       "7616                                                   NaN\n",
       "7619     [retain_graph=True, retain_graph=True, for i i...\n",
       "7620     [backward(), retain_graph=True, loss.sum().bac...\n",
       "7621     [Pandas Series, train_image_paths = 'data/trai...\n",
       "7622     [Series.apply, def func(x):\\r\\n    train_image...\n",
       "7623                                                   NaN\n",
       "7624     [torch.eig, torch.linalg.eig, torch.linalg.eig...\n",
       "7625     [from glob import glob\\r\\nclass VimeoDataset(D...\n",
       "7626     [class ReduceConv(torch.nn.Module):\\r\\n  def _...\n",
       "7627                                                   NaN\n",
       "7628     [class KAAM(torch.nn.Module):\\r\\n   def __init...\n",
       "7630                                                   NaN\n",
       "7631     [INITIAL_LEARNING_RATE = 0.01\\r\\nyour_min_lr =...\n",
       "7632     [  def forward(self, x_c, y_c):\\r\\n    return ...\n",
       "7633                                                   NaN\n",
       "7635     [np.swapaxes(A, 0, 2).transpose(0,2,1), A, swa...\n",
       "7636     [print((torch.rand(64)).shape)  # torch.Size([...\n",
       "7637     [CnnPolicy, MlpPolicy, BaseFeatureExtraction, ...\n",
       "7638     [pip install openvino-dev[onnx]\\r\\n, mo --inpu...\n",
       "7639                                                   NaN\n",
       "7640                                  [model.freeze()\\r\\n]\n",
       "7641                                                   NaN\n",
       "7642     [res = cv2.resize(img, dsize=(50, 50), interpo...\n",
       "7643     [.next(), train_loader, next(), iter(), Python...\n",
       "7644     [1.0.0, torch&gt;=1.0.0,!=1.8.0\\r\\n, torch&gt;...\n",
       "7645                                                   NaN\n",
       "7646     [on_save_checkpoint(), on_load_checkpoint(), d...\n",
       "7647     [nn.Module.state_dict(), self.some_data = torc...\n",
       "7648     [numpy, import numpy as np\\r\\narr = np.array([...\n",
       "7649     [offset, diagonal, x = torch.arange(1,10).view...\n",
       "7650     [np.indices, arr = np.array([[1,2,3],[4,5,6],[...\n",
       "7651     [import numpy as np\\r\\na = np.ones((3,3))\\r\\np...\n",
       "7652     [shape (3,4,3,3), import torch\\r\\nimport torch...\n",
       "7653     [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "7654     [train_inds, test_inds = next(GroupShuffleSpli...\n",
       "7655     [x = y = torch.tensor([0,1,2])\\r\\n\\r\\npairs = ...\n",
       "7656     [layer.load_state_dict({'weight': torch.tensor...\n",
       "7657     [class FancyNetwork(nn.Module):\\r\\n    [...]\\r...\n",
       "7659     [sorted, indices = torch.sort(out,descending=T...\n",
       "7660     [nn, requires_grad=True, import torch.nn as nn...\n",
       "7661     [__call__, torch.nn.Module, LinearRegression, ...\n",
       "7662     [in_features, out_features, N_batch, in_featur...\n",
       "7663     [CrossEntropyLoss, output, (n), label, [batch,...\n",
       "7664     [tf.image.extract_patches(), torch.nn.Unfold, ...\n",
       "7665     [testimage = np.rollaxis(image,1,4)\\r\\nz = tf....\n",
       "7666     [OneHotEncoder, dtype=float64, X, forward(), c...\n",
       "7667     [RNN, double, torch.set_default_tensor_type(t)...\n",
       "7668     [plt.savefig(), import uuid, def display_detec...\n",
       "7669     [ignore_index = 3\\r\\nmetric = ConfusionMatrix(...\n",
       "7670     [torch.save({\\r\\n        'epoch': epoch,\\r\\n  ...\n",
       "7671                                    [model.children()]\n",
       "7672                                                   NaN\n",
       "7673     [res = [x[indices == i_] for i_ in indices.uni...\n",
       "7674     [numpy, openblas, libopenblas-base:arm64, libo...\n",
       "7675     [xHat, xHat, xHat, data, train_loader, valid_l...\n",
       "7676     [pip install torch==1.8.1+cu111 torchvision==0...\n",
       "7677                                                   NaN\n",
       "7678     [torch.cat, x1 = torch.randn(13,2)\\r\\nx2 = tor...\n",
       "7679     [(n,1), (n,), nn.Conv1d(in_channels, out_chann...\n",
       "7681                                                   NaN\n",
       "7682     [pip3 install torch==1.9.0+cu111 torchvision==...\n",
       "7683     [conda install pytorch torchvision torchaudio ...\n",
       "7684     [conda update conda\\r\\npip install --upgrade p...\n",
       "7685     [&lt;your virtualenv path&gt;/bin/python -m to...\n",
       "7686     [conda create -n pya100 python=3.9, nvcc --ver...\n",
       "7687                                                   NaN\n",
       "7688     [grid, [-1, 1], x = -1, y = -1, x = 1, y = 1, ...\n",
       "7689     [weight_orig, weight_mask, torch.nn.utils.prun...\n",
       "7690     [expected object of backend CUDA but got CPU, ...\n",
       "7691     [# 080521 debug RuntimeError: CUDA error: an i...\n",
       "7692                                                   NaN\n",
       "7693                     [torch.nn.functional.affine_grid]\n",
       "7694                                              [{0, 1}]\n",
       "7695     [torch.utils.data.Subset, ImageFolder, from to...\n",
       "7697     [self.convs = nn.ModuleList([\\r\\n             ...\n",
       "7698                                                   NaN\n",
       "7699     [conda install pytorch==1.4.0 torchvision==0.5...\n",
       "7700     [r, requires_grad, nx = net_x()\\r\\nr = torch.t...\n",
       "7701                     [iteration_ += 1, iteration_ =+1]\n",
       "7702                                                   NaN\n",
       "7703     [labeled_data = [*zip(dataset, labels)]\\r\\ndat...\n",
       "7704                                                   NaN\n",
       "7705     [Dataset, B, C, H, W, 16x1x64x64, 16x64x64, # ...\n",
       "7707     [cpp_extension.py, \"/usr/local/conda3/lib/pyth...\n",
       "7708                                                   NaN\n",
       "7709     [&lt;, a + b, add(a, b), a - b, sub(a, b), a *...\n",
       "7711     [torchtext.data.Field, torchtext.data.BucketIt...\n",
       "7712     [RuntimeError: Trying to backward through the ...\n",
       "7713     [self.h = self.h.detach(),     def forward(sel...\n",
       "7715     [unfold, fold, import torch\\r\\nimport torch.nn...\n",
       "7716                                                   NaN\n",
       "7717     [ConvNN_model = models.Sequential()\\r\\nConvNN_...\n",
       "7718     [def predict(self, test_images):\\r\\n    self.e...\n",
       "7720     [dataloader, .view(), 4D, def test(model, devi...\n",
       "7721                                [6.9077, -log(1/1000)]\n",
       "7722     [forward, def forward(self, tokens, masks=None...\n",
       "7723                                           [forward()]\n",
       "7724                                                   NaN\n",
       "7725     [torchtext.legacy.data.field\\r\\ntorchtext.lega...\n",
       "7726     [self.logger.log_hyperparams, self.log, metric...\n",
       "7727     [u_intents, # dummy values for demonstration\\r...\n",
       "7728     [def myBlur( t):\\r\\n    sigm = ( random.unifor...\n",
       "7729                                                   NaN\n",
       "7730     [MNIST, /home/psando/CustomMNISTDataset, /home...\n",
       "7731     [outputs, _ = self.lstm(embeddings)\\r\\n# shape...\n",
       "7732                                            [n_epochs]\n",
       "7735                                                   NaN\n",
       "7736                                                   NaN\n",
       "7737                                                [z, z]\n",
       "7739                                                   NaN\n",
       "7740                                                   NaN\n",
       "7741     [traced = torch.trace(model.forward)(xample_in...\n",
       "7742     [max_vals, _ = a.max(axis=1, keepdim=True)\\r\\n...\n",
       "7743                                                   NaN\n",
       "7744     [storage, a = torch.tensor([3,2,3,4])\\r\\nprint...\n",
       "7745                                     [b.cumsum(0)\\r\\n]\n",
       "7746     [.train(), .eval(), .training, True, False, Dr...\n",
       "7748     [torch.empty, cpu, class CPC(nn.Module):\\r\\n  ...\n",
       "7749     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "7750                                    [.cuda(), .cuda()]\n",
       "7751     [model = Policy().cuda(), model = Policy(), mo...\n",
       "7752     [nn.BCEWithLogitsLoss, pred, torch.sigmoid(pre...\n",
       "7754     [val, ind = inp[:, :, 2].squeeze().topk(k=4, d...\n",
       "7755     [x, (3, 4, 3), k,  import torch\\r\\n x = torch....\n",
       "7756                                                   NaN\n",
       "7757     [while not done:\\r\\n    action = model.act(sta...\n",
       "7758                                                   NaN\n",
       "7759     [import numpy as np\\r\\n\\r\\narr = np.array([[[0...\n",
       "7760                                                   NaN\n",
       "7761     [_, detach(), def on_after_backward(self) -&gt...\n",
       "7762     [import torch\\r\\n\\r\\n# shape [2, 3, 4]\\r\\nblah...\n",
       "7763     [a, M x B x C,  M = 3\\r\\n B = 5\\r\\n C = 4\\r\\n ...\n",
       "7765                                                   NaN\n",
       "7766                                                   NaN\n",
       "7767     [state = env.reset(), action = model.act(state...\n",
       "7768     [torch.save(), torch.save({\\r\\n            'ep...\n",
       "7769     [w1 = w1 - w1.grad*0.001\\r\\n, w1, w1, w1, .gra...\n",
       "7770     [torch.Tensor([256, channels]), (256, channels...\n",
       "7771     [1 channel, datasets, 3 channels, import torch...\n",
       "7772     [n, enumerate, n = 50000\\r\\n\\r\\nfor i,epoch in...\n",
       "7773     [idx, source, (B,N), (B, K, p), p=2, idx, 0, K...\n",
       "7774     [gather,  new_idx = idx.unsqueeze(-1).expand_a...\n",
       "7775     [nn.Embedding(vocab_size, embed_size), {'hello...\n",
       "7778     [add_idx, temp = add_ids(data_utils.dataset.Te...\n",
       "7779     [from torch import tensor\\r\\n\\r\\nindex = tenso...\n",
       "7780     [# Just for my version of system and cuda, you...\n",
       "7781     [import torchvision  \\r\\nprint(torchvision.__v...\n",
       "7782     [x, N, x, [1, 0, 0, ...], [0, 1, 0, 0, ...], y...\n",
       "7783     [hessian, import torch\\r\\n\\r\\ntorch.autograd.f...\n",
       "7784     [NumPy, from autograd import elementwise_grad ...\n",
       "7785                                                   NaN\n",
       "7786     [import numpy as np\\r\\narr = np.random.rand(3,...\n",
       "7787     [experience = copy.deepcopy((current_state, ac...\n",
       "7790                                                   NaN\n",
       "7791                                                   NaN\n",
       "7792                                                   NaN\n",
       "7794     [def compare_state_dict(dict1, dict2):\\r\\n    ...\n",
       "7798     [def demo_basic(rank, world_size):\\r\\n    prin...\n",
       "7799     [pip uninstall uninstall torch torchaudio torc...\n",
       "7800     [&gt; sudo rmmod nvidia_uvm\\r\\n&gt; sudo modpr...\n",
       "7802                                                   NaN\n",
       "7803     [backward, 1000, validation_epoch_end, # Done ...\n",
       "7804     [nn.Module.train(), self.training = mode\\r\\nfo...\n",
       "7805            [64, 81, 64, 22, Xavier, 2015, ReLU, 1000]\n",
       "7806     [plt.imshow(), 3, 4, (28,28,1), imshow(), plt....\n",
       "7807     [image, [1,28,28], image.permute(1,2,0), [28, ...\n",
       "7808     [torch.cat, import torch\\r\\n\\r\\narr1 = torch.t...\n",
       "7809                                                   NaN\n",
       "7810     [filter_size - 1, Conv2d(padding=...), (h, w) ...\n",
       "7812     [import torch.nn.functional as F\\r\\n\\r\\nn = se...\n",
       "7813                                                   NaN\n",
       "7814     [range(n), out, out, i, avail, j, avail, out[j...\n",
       "7815     [type(param), parameter, named_parameters(), n...\n",
       "7816     [_, cls_hs = self.bert(sent_id, attention_mask...\n",
       "7817     [einops, \\r\\nimport einops\\r\\ninput_tensor = e...\n",
       "7818                                                   NaN\n",
       "7820     [FiveCrop(), Lambda, transform = transforms.Co...\n",
       "7821     [dl = learn.dls.test_dl(test_df)\\r\\nlearn.get_...\n",
       "7822                                                   NaN\n",
       "7823                [pip install transformers==2.11.0\\r\\n]\n",
       "7825     [ import torch\\r\\n torch.__version__\\r\\n'1.7.1...\n",
       "7826     [self.embed(labels)...\\r\\n, 10 -&gt; 784, self...\n",
       "7827     [{'state_dict': {'model.conv1.weight': tensor(...\n",
       "7828     [#load digits using the module load_digits()\\r...\n",
       "7829              ['../data', '/Users/***/Downloads/data']\n",
       "7830                                                   NaN\n",
       "7831                                                   NaN\n",
       "7832     [pad_token_id, ByteLevelBPETokenizer, from tra...\n",
       "7834     [import torch\\r\\n\\r\\nx = torch.tensor([\\r\\n   ...\n",
       "7835     [mnist_train.data\\r\\n, data, mnist_train, __in...\n",
       "7836                                                   NaN\n",
       "7837     [if self.training:\\r\\n    #call _ScaleGradient...\n",
       "7838     [VAE, __init__, integrated, forward, model(x),...\n",
       "7839     [y[i]=1, y = torch.tensor(y)\\r\\n\\r\\ndef concur...\n",
       "7840     [for batch in train_data_loader:\\r\\n    inputs...\n",
       "7841     [import gc\\r\\n\\r\\n# add this after computing o...\n",
       "7842                                                   NaN\n",
       "7843     [repeat, expand, new = P.unsqueeze(1).expand(-...\n",
       "7844     [class GradReverse(Function):\\r\\n    @staticme...\n",
       "7845                                                   NaN\n",
       "7847                                                   NaN\n",
       "7848     [loss.backward(), step(), class test_net_1(nn....\n",
       "7849     [self.relu = nn.functional.relu(torch.FloatTen...\n",
       "7850           [.backward(), .backward(torch.tensor(1.0))]\n",
       "7851     [for batch_idx, (input, target) in enumerate(t...\n",
       "7852                                          [nvidia-smi]\n",
       "7854     [python -c \"import torch;print(torch.version.c...\n",
       "7855     [conda install -y pytorch==1.7.1 torchvision t...\n",
       "7856     [unhandled cuda error, NCCL version ..., NCCL_...\n",
       "7859     [import torch\\r\\n\\r\\ndevice = torch.device('cu...\n",
       "7860     [torch.Variable, 8, gc.collect(), torch.cuda.e...\n",
       "7861     [import threading\\r\\n\\r\\n\\r\\ndef preload_model...\n",
       "7862     [app.run(host=\"0.0.0.0\", port=int(os.environ.g...\n",
       "7863     [class ImageTransformer(nn.Module):\\r\\n    def...\n",
       "7864     [forward, ..., class MyModel(torch.nn.Module):...\n",
       "7865     [Linear,     P = 20\\r\\n    self.features = nn....\n",
       "7866     [forward, x = self.fc5(x), x = F.&lt;function&...\n",
       "7867     [torch.Tensor.storage(), torch.Storage, a.stor...\n",
       "7868     [*x, def block, *block(...), nn.Sequential, de...\n",
       "7875     [# take only the final time step\\r\\nout1 = out...\n",
       "7876     [ones = 1 * torch.ones(2,4)\\r\\ntwos = 2 * torc...\n",
       "7877     [ from einops import rearrange\\r\\n\\r\\n x.shape...\n",
       "7878     [x, y = tile_x_dim, tile_y_dim   # for readabi...\n",
       "7879     [block(), import torch\\r\\nimport numpy as np\\r...\n",
       "7880     [import torch\\r\\nX = torch.cat([torch.ones((2,...\n",
       "7881     [c = a[b]\\r\\n,  c\\r\\ntensor([[1, 2],\\r\\n      ...\n",
       "7882                                            [download]\n",
       "7883     [eval, from torch import tensor\\r\\n\\r\\nmy_tens...\n",
       "7884     [# across dim0\\r\\nfor i in range(data.size(0))...\n",
       "7885                           [truth.device, pred.device]\n",
       "7886                                        [transformers]\n",
       "7888     [import torch\\r\\ntorch.tensor([[1,2,3],[4,5,6]...\n",
       "7889                                                   NaN\n",
       "7890     [mask = A.diagonal() == 0\\r\\nA += torch.diag(m...\n",
       "7891     [N=10\\r\\na = torch.randint(0,N,[N,N])\\r\\n\\r\\n#...\n",
       "7892     [optimizer_step(), def optimizer_step(self, ep...\n",
       "7893     [len(l) - 1, a= torch.randperm(len(l)-1) #wher...\n",
       "7894     [Conv2d, padding, stride=1, padding = kernel_s...\n",
       "7895     [batch_size, ImageDataLoaders.from_name_func, ...\n",
       "7896                                                   NaN\n",
       "7897     [#test_images = G_net(z_)\\r\\ntest_images = G_n...\n",
       "7898     [tokenizer.batch_encode_plus, batch_size, def ...\n",
       "7899     [optimizer, criterion, def train_during_valida...\n",
       "7900     [source.gather(2,index.unsqueeze(2)).squeeze(2...\n",
       "7901                                        [torch == 1.6]\n",
       "7902     [torch.jit.trace, import torch\\r\\n\\r\\n\\r\\nclas...\n",
       "7903                 [weights, weights.permute([2,3,1,0])]\n",
       "7905     [pip install torch===1.5.0 torchvision===0.6.0...\n",
       "7906     [RUN pip install -r requirements.txt\\r\\n, torc...\n",
       "7908                                                   NaN\n",
       "7910     [self.classifier = nn.Sequential(nn.MaxPool2d(...\n",
       "7912     [argsort, def mask_split(tensor, indices):\\r\\n...\n",
       "7914     [t = torch.tensor([1,2,3,4])\\r\\nprint(t[[0,1,3...\n",
       "7915     [real_cpu.size(0), len(real_cpu), len(data[0])...\n",
       "7916     [...\\r\\nall_preds = []\\r\\n\\r\\nfor data_v, targ...\n",
       "7917     [precision, floatmode, 'fixed', numpy.set_prin...\n",
       "7918      [min, torch.min([]), dist[i][mask[i] == 0], min]\n",
       "7919         [.grad, None, .backward(), model.zero_grad()]\n",
       "7920     [loss.item(), loss, .item(), trainingloss += c...\n",
       "7921     [criterion.backward(), optimizer.step(), train...\n",
       "7922     [from coremltools.converters.mil import regist...\n",
       "7923     [grid_sample, grid, grid_sample, grid, in_sz  ...\n",
       "7924     [10 epochs , lr = 0.0001, 10 epochs, optimizer...\n",
       "7925     [for param in mask_model.parameters():\\r\\n    ...\n",
       "7926     [fill_(), import torch\\r\\nimport torch.nn as n...\n",
       "7927            [torch.set_printoptions(precision=10)\\r\\n]\n",
       "7928     [t1 = torch.tensor([[1, 2, 3], [4, 5, 6], [1, ...\n",
       "7929                                                   NaN\n",
       "7930     [Decoder, torch.nn.Upsample, torch.nn.Conv2d, ...\n",
       "7931     [torch.dot, torch.dot(input, other, *, out=Non...\n",
       "7932     [torch.matmul(input, other, *, out=None) → Ten...\n",
       "7933     [CrossEntropy, NLLLoss, data_y = torch.LongTen...\n",
       "7934                                                   NaN\n",
       "7935     [train_loader.dataset, validation_loader.dataset]\n",
       "7936     [pip install -U pt2keras\\r\\n, resnet18, import...\n",
       "7938     [model = torch.nn.DataParallel(model), torch.s...\n",
       "7939     [conda uninstall pytorch, conda uninstall cpuo...\n",
       "7940     [pytorch                   1.5.1              ...\n",
       "7941     [ scheduler = torch.optim.lr_scheduler.CosineA...\n",
       "7943     [import torch\\r\\n\\r\\nx = torch.randn(100, requ...\n",
       "7944     [Predictions = torch.argmax(Pred)\\r\\n, Predict...\n",
       "7945     [BertModel.from_pretrained(), save_pretrained(...\n",
       "7946                                                   NaN\n",
       "7947     [pip install torch==1.8.0+cu111 torchvision==0...\n",
       "7948                                                   NaN\n",
       "7950     [w = w + (w.grad * l_rate), w, w, with torch.n...\n",
       "7951     [# Define this at line 426:\\r\\nint_seq_length ...\n",
       "7952     [return _VF.stft(input, n_fft, hop_length, win...\n",
       "7953               [out = img[idx[...,0], idx[...,1]]\\r\\n]\n",
       "7954               [out[idx[...,0], idx[...,1]] = img\\r\\n]\n",
       "7955     [dim=0, Softmax, long tensor, float, double,  ...\n",
       "7956     [torch.save(models[0].state_dict(), \"test0.pth...\n",
       "7957     [old, mask, new, # torch.where\\r\\nresult = old...\n",
       "7958                                                   NaN\n",
       "7959                                                   NaN\n",
       "7960         [arr[[0,1,2,3], [0,2,1,2]]\\r\\n, np.arange(4)]\n",
       "7961     [ import torch\\r\\n import numpy as np\\r\\n s = ...\n",
       "7962     [import numpy as np\\r\\nx = [[ 0,  1,  2],\\r\\n ...\n",
       "7963     [torch.nn.CrossEntropyLoss, torch.softmax, nn....\n",
       "7964     [list, list_tensors = [torch.tensor([1,2]), to...\n",
       "7965     [device, import torch\\r\\n...\\r\\nmodel = torchr...\n",
       "7966                                    [import torch\\r\\n]\n",
       "7967                   [512 * 768, num_words * dim, [CLS]]\n",
       "7969     [loss_actor, loss_critic, state, state -&gt; q...\n",
       "7970                                                   NaN\n",
       "7974     [from torch import utils.data as data_utils\\r\\...\n",
       "7975     [ import torch\\r\\n import torchvision as tv\\r\\...\n",
       "7976     [batch_size = 16\\r\\n\\r\\ntransform = transforms...\n",
       "7978     [(batch_size, 6, 30, 30), INPUT: 1 x 32 x 32\\r...\n",
       "7979     [B = batch_size\\r\\nT = sequence_length (padded...\n",
       "7980                           [track_running_stats=False]\n",
       "7982     [nn.Conv1d, import torch\\r\\nfrom torch import ...\n",
       "7983     [def get_train_dataset_pos_weights(self):\\r\\n ...\n",
       "7984                                                   NaN\n",
       "7985                                                   NaN\n",
       "7986     [empty = [0,0,0,0,0,0,0,0,0]\\r\\n\\r\\ntokens = [...\n",
       "7987     [sequence_output = outputs.last_hidden_state\\r...\n",
       "7988                                       [onnx, forward]\n",
       "7989     [forward, Sequential, class Model(nn.Module):\\...\n",
       "7990        [torch.jit, torch.jit.trace, torch.jit.script]\n",
       "7991     [torch.meshgrid, u, v, torch.einsum, Kinverse,...\n",
       "7992     [!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\\r\\n...\n",
       "7993     [from torchvision import datasets\\r\\nnew_mirro...\n",
       "7994     [torchvision==0.9.1, from torchvision import d...\n",
       "7995     [from sklearn.datasets import fetch_openml\\r\\n...\n",
       "7996     [new_mirror = 'https://ossci-datasets.s3.amazo...\n",
       "7997     [import tensorflow as tf\\r\\nmnist = tf.keras.d...\n",
       "7998     [import torch\\r\\nimport torchvision\\r\\nfrom to...\n",
       "7999                                                   NaN\n",
       "8000                             [python -m visdom.server]\n",
       "8001                                                   NaN\n",
       "8003     [AdaptiveAvgPool2d, 1x1, 256, self.fc_1 = nn.L...\n",
       "8004     [NLLLoss, target = [0, 0, 1, 0]\\r\\n, 1, [0, 0,...\n",
       "8005     [targets, tensor([[0],\\r\\n        [0],\\r\\n    ...\n",
       "8006                                                   NaN\n",
       "8007                                                   NaN\n",
       "8008                                                   NaN\n",
       "8009     [-100, output_mask = mask[:, 1:], :-1, labels ...\n",
       "8010     [#shift things \\r\\noutput_logits = logits[:,:-...\n",
       "8011                                                   NaN\n",
       "8012     [torch.gather(logits, -1, idx.unsqueeze(-1)), ...\n",
       "8013     [X_train = X_train / 255 #normalization of pix...\n",
       "8014     [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "8015                                                   NaN\n",
       "8016     [torch.jit.script, torch.jit.trace, torch.onnx...\n",
       "8018     [A, X, def vso(seq_out, valid_mask):\\r\\n    X ...\n",
       "8021                                                   NaN\n",
       "8022                                                   NaN\n",
       "8023                                                   NaN\n",
       "8024     [__init__, class Generator(nn.Module):\\r\\n  de...\n",
       "8025                                                   NaN\n",
       "8026                                                   NaN\n",
       "8027                                                   NaN\n",
       "8028     [  torch.nn.parameter.Parameter\\r\\n        A k...\n",
       "8029                                                   NaN\n",
       "8030     [w := w - eta1 (E[l] +- std[l]/sqr{B})\\r\\n, w ...\n",
       "8031     [enumerate, ...\\r\\nfor j, row_x in enumerate(x...\n",
       "8032                                                   NaN\n",
       "8033     [ import torch\\r\\n A = torch.tensor([[[ 1.,  2...\n",
       "8035                                                   NaN\n",
       "8036     [from tqdm import trange\\r\\nclass ROCKET():\\r\\...\n",
       "8037     [(ex. input.shape = (a, b) and nn.Linear(c, c,...\n",
       "8038                            [Conv2d, Linear, gpu, cpu]\n",
       "8039     [resnet = models.resnet50(pretrained=True)\\r\\n...\n",
       "8040     [torch.gather, from numpy.lib.stride_tricks im...\n",
       "8041     [import torch\\r\\n\\r\\nmat = torch.Tensor(\\r\\n[[...\n",
       "8042     [model = models.resnet18(pretrained=True, prog...\n",
       "8043     [Module.forward, __call__, .forward, Module.fo...\n",
       "8044     [pip install torch==1.8.0+cu111 torchvision==0...\n",
       "8045     [def force_cudnn_initialization():\\r\\n    s = ...\n",
       "8046     [output = torch.nn.Sigmoid()(output)\\r\\nloss =...\n",
       "8048                                        [transformers]\n",
       "8049     [x = ((X-lower_bound).clamp(min=0)+lower_bound...\n",
       "8050     [conv = nn.Conv2d(1, 1, kernel_size=2)\\r\\nwith...\n",
       "8052     [output_size=(H, W), (H, W), scale_factor=4, (...\n",
       "8054                                                   NaN\n",
       "8055     [#inputs are changed in order from the above q...\n",
       "8056                                                   NaN\n",
       "8057                                                   NaN\n",
       "8058                                                   NaN\n",
       "8059     [import torch\\r\\n\\r\\nz = torch.rand((1,6))\\r\\n...\n",
       "8060     [z, z+rand(), rand(), z, loss = criteria(z, to...\n",
       "8061     [torch.no_grad, import torch\\r\\n\\r\\nz = torch....\n",
       "8062     [bert_classifier = BertClassifier(freeze_bert=...\n",
       "8064     [for (input_t, target_t) in dataloader:\\r\\n   ...\n",
       "8065                                                   NaN\n",
       "8066     [f(x) = (x + 1)², df/dx = 2(x + 1), x_ij, y_mn...\n",
       "8067                                                   NaN\n",
       "8068     [python test.py --weights_path weights/yolov3....\n",
       "8069                                                   NaN\n",
       "8070     [torch==1.7.1\\r\\ntorchvision==0.8.2\\r\\n, pip, ...\n",
       "8072     [unfold, import torch\\r\\nimport torch.nn.funct...\n",
       "8073     [torch, torch 1.7.1, torch 1.4.1, virtualenv, ...\n",
       "8075                                                   NaN\n",
       "8076     [docker run torchserve:local ...., CMD, torchs...\n",
       "8077     [self.scheduler.step(avg_loss)\\r\\n, self.step(...\n",
       "8078            [long, F.one_hot, F.one_hot(t.long())\\r\\n]\n",
       "8080     [import os\\r\\nos.environ['WANDB_MODE'] = 'offl...\n",
       "8081     [BCELoss, CrossEntropyLoss, Sigmoid(), BCEWith...\n",
       "8082     [!pip install git+https://github.com/PyTorchLi...\n",
       "8083     [!pip install torchtext==0.8.0 torch==1.7.1 py...\n",
       "8084        [!pip install --upgrade pytorch-lightning\\r\\n]\n",
       "8085     [!pip install git+https://github.com/PyTorchLi...\n",
       "8086     [1.3.0dev, !pip install https://github.com/PyT...\n",
       "8087     [pip install pytorch-lightning==1.4.4\\r\\n\\r\\np...\n",
       "8088     [num_classes, mask_head, num_classes, num_clas...\n",
       "8089     [torch.nn.ConstantPad?d, from torch import nn\\...\n",
       "8092                                                   NaN\n",
       "8093     [labels, torch.tensor(labels, dtype=torch.long...\n",
       "8094     [train_loader = torch.utils.data.DataLoader(da...\n",
       "8095     [np.argmax, axis, (target==np.argmax(output, a...\n",
       "8096                                                   NaN\n",
       "8098     [# Use load state dict\\r\\nmodel_source = Model...\n",
       "8099     [answer:\\r\\ntest_t[0, 0, 0, :] = torch.tensor(...\n",
       "8100                                                   NaN\n",
       "8101     [import torch\\r\\n\\r\\na = torch.arange(5, dtype...\n",
       "8102     [LightningModule, result.log('train_loss', los...\n",
       "8103     [enter code heretrain_dataset = torchvision.da...\n",
       "8104     [0.9.0, torchtext.data.Field, torchtext.legacy...\n",
       "8105     [torchtext.data.Pipeline -&gt; torchtext.legac...\n",
       "8106                                                   NaN\n",
       "8107                                                   NaN\n",
       "8110                                                   NaN\n",
       "8111                                                   NaN\n",
       "8112              [*iterable, resnet_block, nn.Sequential]\n",
       "8113     [nprocs=world_size, mp.spawn(), import torch\\r...\n",
       "8114     [weights = torch.randn(2,3,requires_grad=True)...\n",
       "8115     [from threading import Thread\\r\\n\\r\\ndef _trai...\n",
       "8116     [ --model-file ./xxx/aaa/full_model.py, --extr...\n",
       "8117     [    all_ordered_idx_pairs = torch.cartesian_p...\n",
       "8118     [torch.arange(), :, x = torch.tensor([\\r\\n    ...\n",
       "8119     [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "8120     [import tensorboard as tb\\r\\ntf.io.gfile = tb....\n",
       "8121     [x1 = x[:, 0]\\r\\nx2 = x[:, 1]\\r\\n# x1: (tensor...\n",
       "8122     [ModelCheckpoint, filepath, dirpath, filepath,...\n",
       "8123     [CLASS pytorch_lightning.callbacks.model_check...\n",
       "8124     [print(model), class NetWidth(nn.Module):\\r\\n ...\n",
       "8126     [class CustomNet(nn.Module):\\r\\n    def __init...\n",
       "8127     [(torch.unsqueeze(a, 2)*b).sum(axis=0)\\r\\n ten...\n",
       "8130                                                   NaN\n",
       "8131     [tokenizer = BertTokenizer.from_pretrained(\"be...\n",
       "8132     [pip, conda, conda, iNLTK, pip, conda, pip ins...\n",
       "8133                              [torch.cuda.synchronize]\n",
       "8134                                                   NaN\n",
       "8135                                                   NaN\n",
       "8136     [model.eval(), model.load_state_dict(torch.loa...\n",
       "8137     [pl.metrics.Accuracy(), dtype=torch.long, self...\n",
       "8138     [# define a cross validation function\\r\\ndef c...\n",
       "8139                                                   NaN\n",
       "8141     [timestamps = [np.datetime64(\"2014-09-10T22:10...\n",
       "8143     [MNIST, download, wget, sudo apt install wget\\...\n",
       "8144                                                   NaN\n",
       "8145                                   [x, S, xxSxxx?\\r\\n]\n",
       "8146     [from six.moves import urllib\\r\\nopener = urll...\n",
       "8147                                                   NaN\n",
       "8148     [data, requests.post, Content-Type: applicatio...\n",
       "8149                                                   NaN\n",
       "8151                                                   NaN\n",
       "8152     [mask = tensor &lt; 255\\r\\nresult = tensor * m...\n",
       "8153                                                   NaN\n",
       "8154     [input_val, torch.clamp(),     out = out.clamp...\n",
       "8155                                                   NaN\n",
       "8156     [optimizer = optim.SGD(model.parameters(), lr=...\n",
       "8157     [def collate_fn(data):\\r\\n    imgs, lengths = ...\n",
       "8158     [shape, db, import numpy as np\\r\\n\\r\\ndb = np....\n",
       "8159                                                   NaN\n",
       "8160     [for n in range(0,9):\\r\\n    cluster_ = data2[...\n",
       "8161     [images, torch.Size([32, 3, 244, 244])\\r\\n, to...\n",
       "8163                                                   NaN\n",
       "8164     [      for images , labels in trainloader:\\r\\n...\n",
       "8165     [pip install torch==1.5.1\\r\\npip install trans...\n",
       "8166                                                   NaN\n",
       "8168     [map(), lambda(), round(x * 2) / 2, a = [0.1, ...\n",
       "8169     [root (string), MNIST/processed/training.pt, M...\n",
       "8170     [.data, import os\\r\\nCURR_DIR = os.getcwd()\\r\\...\n",
       "8171     [torch.repeat(), target_tensor, torch.Size([2,...\n",
       "8172     [pytorch, np.block, import numpy as np\\r\\nitem...\n",
       "8173     [ a=tf.Variable([[1,2],[3,4]])\\r\\n a.assign([[...\n",
       "8174     [from keras.utils.np_utils import to_categoric...\n",
       "8175     [state({\\r\\n       'epoch': epoch + 1,\\r\\n    ...\n",
       "8176                                                   NaN\n",
       "8177     [if args.gpu:\\r\\n    torch.cuda.set_device(arg...\n",
       "8178     [torch.cuda.set_device(args.gpu)\\r\\n, int(args...\n",
       "8179     [torch, _lazy_import_torch, def _lazy_import_t...\n",
       "8180     [sys.modules, torch, sys.modules['torch'], sys...\n",
       "8181     [torch.stack, value = 1.37\\r\\na = torch.normal...\n",
       "8182     [a.shape\\r\\ntorch.Size([10, 5])\\r\\n\\r\\na.unsqu...\n",
       "8183     [image = np.array([[1, 2], [3, 4]], dtype='int...\n",
       "8184     [ConvertImageDtype, F.convert_image_dtype, F_t...\n",
       "8186     [(1, 2), 1, 2, torch.randn(*size, *, out=None,...\n",
       "8187     [torch.save(the_model.state_dict(), PATH)\\r\\n,...\n",
       "8188     [torch.stack, predictions = torch.stack(predic...\n",
       "8189                                                   NaN\n",
       "8190     [t, t_1d, -1, intersection = (t_1d == t[0]) &a...\n",
       "8191                                                   NaN\n",
       "8192     [scale_factor, unsqueeze(0), interpolate, impo...\n",
       "8193     [to(), model = Node2Vec(data.edge_index, embed...\n",
       "8194                                                   NaN\n",
       "8197                                                   NaN\n",
       "8198     [model=models.resnet18(pretrained=True)\\r\\nmod...\n",
       "8200     [nn.LSTM, nn.LSTM, nn.LSTM, nn.LSTM, nn.LSTMCe...\n",
       "8201     [state_dict, import copy\\r\\n\\r\\n# check initia...\n",
       "8202                               [optimizer.zero_grad()]\n",
       "8204                         [torch.float64, torch.double]\n",
       "8205     [seq_len x emb_dim, 20 x 8, num_heads=2, emb_d...\n",
       "8207     [import numpy as np\\r\\nimport tensorflow as tf...\n",
       "8208     [  torch.nn.parameter.Parameter\\r\\n        A k...\n",
       "8209     [torch.gather,  a.gather(1, b.unsqueeze(1))\\r\\...\n",
       "8210     [while (randn_tensor_size &gt; 5)\\r\\n{\\r\\n    ...\n",
       "8211                [grad_fn, IndexBackward, nn.Embedding]\n",
       "8213     [RuntimeError: Providing a bool or integral fi...\n",
       "8214     [a = torch.tensor([[[1., 0., 0., 0.]],\\r\\n    ...\n",
       "8215                                                   NaN\n",
       "8218     [loss = criterion(outputs, classes), classes =...\n",
       "8219                                                   NaN\n",
       "8220                                                   NaN\n",
       "8221     [nvidia-smi, NVML: Driver/library version mism...\n",
       "8223     [batch_size=1, batch_size, n, __getitem__, n, ...\n",
       "8224                                                [iloc]\n",
       "8225     [Lambda, from torchvision.transforms.functiona...\n",
       "8226                                                   NaN\n",
       "8227     [import torch\\r\\n\\r\\nx = torch.randn(1000, req...\n",
       "8228     [import torch\\r\\n\\r\\nx = torch.randn(10, requi...\n",
       "8229                                                   NaN\n",
       "8230                                            [cProfile]\n",
       "8231     [pytorch_lightning, pip install --upgrade pyto...\n",
       "8232     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8233                                                   NaN\n",
       "8234     [pytorch, tensorflow, pytorch, ImageFolder, Da...\n",
       "8235     [(n,n,n), +, *, import numpy as np\\r\\n\\r\\n# De...\n",
       "8236     [import onnx\\r\\nfrom onnx2pytorch import Conve...\n",
       "8237     [29*29*16, net2 = nn.Sequential(\\r\\n\\r\\nnn.Con...\n",
       "8238                                     [a[:,:-1, :]\\r\\n]\n",
       "8239                                                   NaN\n",
       "8240                                                   NaN\n",
       "8241                                                   NaN\n",
       "8242     [chosen_transforms = {'train': transforms.Comp...\n",
       "8244     [transformer.load_state_dict(torch.load(checkp...\n",
       "8245     [\\r\\n    x = tensor([[3, 3, 5, 5, 5],\\r\\n     ...\n",
       "8246                                             [Dataset]\n",
       "8247     [for i, data in enumerate(train_loader, 0):\\r\\...\n",
       "8248     [sympy, import sympy as sym\\r\\n\\r\\nx = sym.Sym...\n",
       "8249                                                   NaN\n",
       "8250                                         [lsof, fuser]\n",
       "8251     [a = torch.zeros(10**9, dtype=torch.float)\\r\\n...\n",
       "8252                                                   NaN\n",
       "8253     [9, 1031, input_dim, 9, hidden_dim, train = Va...\n",
       "8255     [numpy.ufunc, np.add, np.ceil, +, -, torch.add...\n",
       "8256     [from sklearn.cluster import KMeans\\r\\nkm = KM...\n",
       "8257     [Dataset, __iter__, __getitem__, __getitem__, ...\n",
       "8258     [load_checkpoint, def load_checkpoint(checkpoi...\n",
       "8259                                                   NaN\n",
       "8260                                                   NaN\n",
       "8261     [my_data.dat, import io\\r\\n\\r\\nwith open('my_d...\n",
       "8262     [torch.jit.trace, import torch\\r\\nimport torch...\n",
       "8263     [    import torch\\r\\n    import torchvision\\r\\...\n",
       "8264                                        [fc5, forward]\n",
       "8266     [X1 = X1[:, None] # change the shape from 100 ...\n",
       "8268     [torch, float32, 0, float32, 0, long long, int...\n",
       "8272     [tf.keras.Sequential([\\r\\n    layers.ZeroPaddi...\n",
       "8273     [32SC3, int, kByte, unsigned char, auto tensor...\n",
       "8274     [setattr(net, \"head.fc\", torch.nn.Linear(1111,...\n",
       "8275                     [torch.var(a[0], unbiased=False)]\n",
       "8276     [unbiased=False, 5/4 = 1.25, N-1, N, result, s...\n",
       "8277     [nn.ConvTranspose2d, y = (x − 1)s - 2p + d(k-1...\n",
       "8278     [overfit_model, over_model.parameters(), optim...\n",
       "8279                                             [softmax]\n",
       "8280     [torchvision, RandomCrop, torchvision.transfor...\n",
       "8281     [torchvision.transformer, torchvision.transfor...\n",
       "8282     [import torch\\r\\nimport torchvision.transforms...\n",
       "8283                                                   NaN\n",
       "8284     [loss = loss_fn(out,torch.argmax(targets, dim=...\n",
       "8285     [from transformers import GPT2Tokenizer\\r\\n\\r\\...\n",
       "8286     [data = train_iterator.dataset.data \\r\\nshape ...\n",
       "8287                               [forward, model(input)]\n",
       "8288                                           [nn.Module]\n",
       "8289     [query.size(), tgt_len, bsz, embed_dim, query,...\n",
       "8290                                                   NaN\n",
       "8291                          [print(x[idx.tolist()])\\r\\n]\n",
       "8292     [torch::sizes(), IntArrayRef sizes()\\r\\n, torc...\n",
       "8293     [#include &lt;torch/script.h&gt;\\r\\nint main()...\n",
       "8294                     [torch::_shape_as_tensor(tensor)]\n",
       "8295     [import os\\r\\n\\r\\nimport torch\\r\\nimport torch...\n",
       "8296     [docker run -it \\\\r\\n    --shm-size=64g \\r\\n, ...\n",
       "8297                                                   NaN\n",
       "8298     [(64, 1, 28, 28), X, X = self.pool3(X), (64, 1...\n",
       "8299     [inference, # forward the main model\\r\\npred_s...\n",
       "8300     [max_norm, from torch import LongTensor, norm\\...\n",
       "8301     [for maskCounter in range(masks.shape[0]):\\r\\n...\n",
       "8303     [(indices == ytrue.reshape(-1,1)).any(1)\\r\\n, ...\n",
       "8304     [torch.nn.functional.one_hot(targets), torch.S...\n",
       "8305     [X_tensor = torch.tensor(X_before, dtype=torch...\n",
       "8306     [ellipsis, t = torch.randn(2, 3, 6, 5, 9, 3)\\r...\n",
       "8307     [einsum, torch.einsum, numpy.einsum, import nu...\n",
       "8308                                                   NaN\n",
       "8309     [#include &lt;memory&gt;\\r\\n\\r\\nint main()\\r\\n...\n",
       "8310                                                   NaN\n",
       "8311     [for images, labels in trainloader:\\r\\n       ...\n",
       "8313                                                   NaN\n",
       "8314                                                   NaN\n",
       "8315     [Gaussian mixtures, silhouette score criteria,...\n",
       "8316     [A = np.array([ 57, 58, 59, 60, 61, 78, 79, 80...\n",
       "8317     [PIL.Image, torch.Tensor, torchvision.transfor...\n",
       "8318                                                   NaN\n",
       "8319                                                   NaN\n",
       "8320     [conda search, $ conda search 'pytorch[channel...\n",
       "8321                                                   NaN\n",
       "8322                                                   NaN\n",
       "8325     [class CustomDataset(data.Dataset):\\r\\n    def...\n",
       "8326     [def __init__(self, src_file, m_rows=None):\\r\\...\n",
       "8327     [glob, import glob\\r\\n\\r\\nfolders = glob.glob(...\n",
       "8328     [pip install dicom2jpg, import dicom2jpg\\r\\n\\r...\n",
       "8331                                                   NaN\n",
       "8332                                                   NaN\n",
       "8333     [pip, pip install torch==1.7.1+cu110 torchvisi...\n",
       "8334     [nan, import torch\\r\\nx = torch.tensor([1, 2, ...\n",
       "8335                                                   NaN\n",
       "8336                                                   NaN\n",
       "8337     [nn.CrossEntropyLoss, nn.functional.cross_entr...\n",
       "8338     [channels:\\r\\n  - pytorch\\r\\n  - conda-forge\\r...\n",
       "8339                                                   NaN\n",
       "8340     [(batch, 3, 800, 600), conv_layer_b1, (batch, ...\n",
       "8341     [(512, 8), def __init__(self, M=1):\\r\\n    ......\n",
       "8342     [model.hidden_cell = (torch.zeros(1, 1, model....\n",
       "8344                                                   NaN\n",
       "8345     [x, y, y = ax + b, a, b, y, x_pred, x_pred, x,...\n",
       "8348                               [cxx11, libcall_ts_cpp]\n",
       "8349                                                   NaN\n",
       "8350     [model, model1, optimizer = torch.optim.Adam(m...\n",
       "8351                                                   NaN\n",
       "8352                                                   NaN\n",
       "8353                                                   NaN\n",
       "8354     [loss += -g * logprob, loss = loss + (-g * log...\n",
       "8356     [    #Serialize entire Model to the \\r\\n    to...\n",
       "8357     [torch.save(model.state_dict(), PATH), torch.s...\n",
       "8358     [# Serialize the model\\r\\nimport cloudpickle\\r...\n",
       "8359     [kernel_size=SZ, stride=2, SZ, x.size(1), out ...\n",
       "8360                                                   NaN\n",
       "8361                                                   NaN\n",
       "8362     [DistributedDataParallel, BatchNorm, Distribut...\n",
       "8363                                                   NaN\n",
       "8364     [conv2d, channels_last, conv2d, cuda, True, ts...\n",
       "8365     [import numpy as np\\r\\nfrom sklearn.metrics im...\n",
       "8367     [if __name__ == \"__main__\":\\r\\n    main()\\r\\n,...\n",
       "8368     [conv1.weights, conv1.bias, conv2.weight, conv...\n",
       "8369     [from Transformers import AutoModel, AutoModel...\n",
       "8370     [ignore_mismatched_sizes=True, model = AutoMod...\n",
       "8371     [from torchvision import transforms\\r\\nimport ...\n",
       "8373                                                   NaN\n",
       "8374     [self.upconv2 = self.expand_block(64, 32, 3, 1...\n",
       "8375     [x -&gt; ax² + bx + c, c, psi, w, b, psi, x, p...\n",
       "8376                                                   NaN\n",
       "8377                                                   NaN\n",
       "8378     [abgrabgrabgr...., aaaa....bbbb....gggg....rrr...\n",
       "8379     [nn.Module, nn.Parameter, nn.Module, class Hyp...\n",
       "8380     [nn.GRU, GRUNet, forward,     def forward(self...\n",
       "8381                                                   NaN\n",
       "8382     [(batch, seq_length, n_classes), 0, 1, 2, 3, (...\n",
       "8384     [__len__, return, def __len__(self):\\r\\n    re...\n",
       "8385     [O = floor(((W - K + 2P)/S) + 1)\\r\\n, (3, 3), ...\n",
       "8386     [ReduceLROnPlateau, i.e.,     if self.num_bad_...\n",
       "8387                                                   NaN\n",
       "8388     [y = q(x)\\r\\nz = y.detach()\\r\\nz.requires_grad...\n",
       "8389                       [portpicker.pick_unused_port()]\n",
       "8390                                                   NaN\n",
       "8392     [     import numpy as np\\r\\n     x = np.array(...\n",
       "8395                                                   NaN\n",
       "8396     [seq2seq, seq2seq, guide, seq2seq, seq2seq, _ ...\n",
       "8397     [virtualenv -p python3.8 torch17\\r\\nsource tor...\n",
       "8398     [for i in range(1000):\\r\\n    print(i)\\r\\n    ...\n",
       "8399                    [pytorch-gpu.1-6, pytorch-gpu.1-4]\n",
       "8400     [import torch\\r\\n\\r\\ni = torch.tensor([[2, 2, ...\n",
       "8402     [self.double(), self.type(dst_type), self.type...\n",
       "8403     [out1 = train_model(input1)\\r\\nout2 = freeze_m...\n",
       "8404     [Class Dataset, def __len__(self):, def __geti...\n",
       "8405     [art, adversarial-robustness-toolbox, pip inst...\n",
       "8406                                                   NaN\n",
       "8407     [allennlp&gt;=v2.0.0, lazy, DatasetReader, sup...\n",
       "8408     [def _read(self, file_path: str) -&gt; Iterato...\n",
       "8409                                    [.cuda(), .cuda()]\n",
       "8410                                         [.to(device)]\n",
       "8411     [# the extend_from_instances expands your voca...\n",
       "8412     [[[x1], [x2], [x3]], sum, x1 + x2 + x3, x, y =...\n",
       "8413     [forward:\\r\\n  out = input / torch.sum(input, ...\n",
       "8414     [kernel_size=3, groups=3, class Net(nn.Module)...\n",
       "8415     [nn.MaxPool3d, 2, (2,2,2), 2, (2,2,2), 2x2x2, ...\n",
       "8416     [ReLU, ReLU, class model_dnn_2(nn.Module):\\r\\n...\n",
       "8417     [cudatoolkit, cat /opt/miniconda3/conda-meta/c...\n",
       "8418     [    def forward(self, x):\\r\\n        x = x.vi...\n",
       "8419                                                   NaN\n",
       "8420      [Pillow 5.3.0, Torch 0.4.0, 1.7.0, Pillow 7.0.0]\n",
       "8421     [nn.MSELoss, (n,), MatrixFactorization, (n,), ...\n",
       "8422                                                   NaN\n",
       "8423     [nn.Linear(128, 10), self.fc1, self.fc1 = nn.L...\n",
       "8424     [float32, double, float64, float, def train_ne...\n",
       "8425     [answer_start = torch.argmax(start_scores) \\r\\...\n",
       "8426                         [nn.Linear(224 * 3 * 3, 896)]\n",
       "8427     [predictions = model.predict(x=xtest.astype(\"f...\n",
       "8428     [v[i], v_, v_ = [v[0]]\\r\\nfor i in range(1, N)...\n",
       "8429     [result: {'boxes': tensor(*[[  0.,   0., 286.,...\n",
       "8430     [acc = sum(logits == batch_y) * 1.0 / len(logi...\n",
       "8431     [if num_objs == 0:\\r\\n    boxes = torch.zeros(...\n",
       "8432     [torch.nn.functional.conv2d, resized_image4D =...\n",
       "8433     [numel, x, t, (3, 2), x = 9, t, (3, 3), (9, 2)...\n",
       "8434                                                   NaN\n",
       "8435     [(1, 10), (10, 1), nn.Linear, nn.BCEWithLogits...\n",
       "8436              [self.fc3, self.fc3, nn.Linear(100 , 1)]\n",
       "8437     [import torch\\r\\nimport torchvision\\r\\n\\r\\npre...\n",
       "8438     [n_steps, X, y, batch_size, n_features,     de...\n",
       "8439                                                   NaN\n",
       "8440     [    def forward(self,x):\\r\\n        e1 = F.re...\n",
       "8441     [activations = {}, forward, activations['enc1'...\n",
       "8442     [ImageFolder, class ImageSubFolder(torch.utils...\n",
       "8443     [checkpointer = DetectionCheckpointer(trainer....\n",
       "8444     [torch.save(trainer.model, \"MyCustom/path/mymo...\n",
       "8446     [result = []\\r\\nfor i in a:\\r\\n    try: # to a...\n",
       "8448     [tensor in tensor, True, torch.tensor([2,5]) i...\n",
       "8449     [text='my text to classify'\\r\\nmodel=BertForSe...\n",
       "8450     [import torch\\r\\nimport torch.nn.functional as...\n",
       "8451     [def collate_fn(batch):\\r\\n    data_list, labe...\n",
       "8452     [data_loader = torch.utils.data.DataLoader(dat...\n",
       "8453                                                   NaN\n",
       "8454                                                   NaN\n",
       "8455     [@pysnooper.snoop()\\r\\ndef greedy_search(input...\n",
       "8456     [PyObject * THPVariable_Wrap(at::Tensor t);\\r\\...\n",
       "8457     [import torch.nn as nn\\r\\n\\r\\nmodel = nn.Seque...\n",
       "8458     [net.eval() #测试模式 \\r\\nwith torch.no_grad():\\r\\...\n",
       "8459     [from scipy.io import savemat\\r\\n\\r\\nwith torc...\n",
       "8460     [def, async def, run_in_threadpool, loop.run_i...\n",
       "8461     [uvicorn app:webapp --port 3030 --reload\\r\\n, ...\n",
       "8462     [\"modules\", nn.Module, nn.Module.modules, clas...\n",
       "8463     [matmul, a @ b.T, torch.matmul, @, torch.diago...\n",
       "8464            [expected_result = (a * b).sum(dim=1)\\r\\n]\n",
       "8465     [model  = torch.load(\"defect_classifier.pt\")\\r...\n",
       "8466     [class summation: \\r\\n    def __init__(self, f...\n",
       "8467                                                   NaN\n",
       "8468     [net2 = Net2()\\r\\nnet2.load_state_dict(net1_st...\n",
       "8469                                                   NaN\n",
       "8470                                                   NaN\n",
       "8471     [torch.roll, def random_patch(a, size) -&gt; T...\n",
       "8472     [Steps : \\r\\n1 ] Go to C:// Users / UserName /...\n",
       "8473               [split, cat, md5sum, pytorch_model.bin]\n",
       "8474                                                   NaN\n",
       "8475     [torchvision, model_resnet18 = torchvision.mod...\n",
       "8476     [!pip3 install git+https://github.com/ourownst...\n",
       "8477     [LightningModule, forward, import torchvision....\n",
       "8478     [model, model.layer3, model.layer3, nn.Module,...\n",
       "8479                       [pretrained_model.freeze()\\r\\n]\n",
       "8480     [weight_decay, reduce_sum(abs(x)), reduce_sum(...\n",
       "8481                                                   NaN\n",
       "8482     [IndexError, # sample input tensors\\r\\nIn [210...\n",
       "8484     [torch.flatten(), nn.Flatten(), nn.Module, for...\n",
       "8485     [model = BertForSequenceClassification.from_pr...\n",
       "8486     [from torch.utils.mobile_optimizer import opti...\n",
       "8488     [import torch\\r\\nx = torch.rand(4,6)\\r\\nres = ...\n",
       "8489                                             [weights]\n",
       "8490     [[3, 7, 7], [1, 64, H, W], import torch\\r\\nimp...\n",
       "8491     [FBetaMeasure, FBetaMultiLabelMeasure, FBetaMu...\n",
       "8492     [classifier.0.convs.3.1, layers = ['classifier...\n",
       "8493     [self.G, c_fixed_list, torchvision.utils.save_...\n",
       "8495                                                   NaN\n",
       "8496     [torch.sigmoid(self.linear(x)), nn.BCELoss, nn...\n",
       "8497     [Conv2d, MaxPool2d, (H, W), (H/2, W/2), (batch...\n",
       "8498     [Linear, input_image : (28,28,1)\\r\\nafter_Conv...\n",
       "8499                   [projection, nn.MultiheadAttention]\n",
       "8500                                                   NaN\n",
       "8501     [pip, ## cu101\\r\\npip install torch==1.7.1+cu1...\n",
       "8502     [class MyLossLayer(nn.Module):\\r\\n  def __init...\n",
       "8503                        [train1.append(x.numpy())\\r\\n]\n",
       "8504     [np.array, list, .numpy(), train1 = torch.stac...\n",
       "8505     [PIL.Image, torch.Tensor, class ThresholdTrans...\n",
       "8506                                                   NaN\n",
       "8507                                             [bias, 1]\n",
       "8508                                                   NaN\n",
       "8509          [nn.CrossEntropyLoss, loss = -log(1/8) = ~2]\n",
       "8510                                                   NaN\n",
       "8511     [PIL.Image.fromarray, Image.open, torch.Tensor...\n",
       "8512     [__init__, nn.Sequential, class Net(nn.Module)...\n",
       "8513                                                   NaN\n",
       "8514                                                   NaN\n",
       "8515                              [28, 14, (1, 1, 28, 28)]\n",
       "8516                                                   NaN\n",
       "8517                                                   NaN\n",
       "8518     [X.shape, [1, 512, 1], [1, 512, 512], [1, 512,...\n",
       "8519     [MLModel\\data\\categories\\*.txt, data\\categorie...\n",
       "8520     [stat_batch, (64,), nn.CrossEntropyLoss, stat_...\n",
       "8521     [ pip install torchaudio -f https://download.p...\n",
       "8522                       [pip install torchaudio==0.4.0]\n",
       "8524     [from setuptools import setup\\r\\nfrom torch.ut...\n",
       "8526     [nn.CrossEntropyLoss, 0, 1, ECGNet, __getitem_...\n",
       "8527     [Variable, torch.Tensor, volatile, with torch....\n",
       "8528     [__init__, __init__(self), super(LR, self).__i...\n",
       "8529     [@staticmethod\\r\\ndef backward(ctx, grad_outpu...\n",
       "8530                                                   NaN\n",
       "8531     [x = self.layer2(x), x = self.fc1(x), torch.Si...\n",
       "8532     [a[:][:][0], __getitem__, a[:][:][0], b = a[:]...\n",
       "8534     [forward, state_dict, flattenNetwork, net, net...\n",
       "8537     [torch.vstack(), torch.stack(), # sample tenso...\n",
       "8539                                                   NaN\n",
       "8541     [ v, e = 10, 0\\r\\n v, e = torch.tensor([v]), t...\n",
       "8542     [torch.sqrt(), torch.rfft(), torch.sqrt(), ret...\n",
       "8543     [collate_fn, from torch.utils.data.dataloader ...\n",
       "8544     [pip install torch==1.7.1+cpu torchvision==0.8...\n",
       "8545     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8546                                                   NaN\n",
       "8547                                       [shm, ipc=host]\n",
       "8548     [def estimate_p(nt, vs, n_kw, n_k):\\r\\n    ret...\n",
       "8549                            [nb_epochs * len(dataset)]\n",
       "8551     [torch.argmax, torch.max,  outputs = torch.ran...\n",
       "8552     [model.to(device)\\r\\n, device = \"cuda\" if torc...\n",
       "8553     [input_dim, summary, torchsummary, class Logis...\n",
       "8554                                          [conda list]\n",
       "8555     [ModuleNotFoundError: No module named 'torch.n...\n",
       "8556     [x.lower().endswith('.JPG'), false, x.lower()....\n",
       "8557                                                   NaN\n",
       "8558     [ inputs_tokens = torch.tensor([[  1, 101,  18...\n",
       "8559     [sentence[0].to('cpu')\\r\\n, cpu_sentence = sen...\n",
       "8560     [nn.RNN, nn.Sequential, nn.LSTM, nn.Linear, rn...\n",
       "8561     [nn.LSTM, nn.Module, class GetLSTMOutput(nn.Mo...\n",
       "8562     [get_params, forward, get_params, RandomRotati...\n",
       "8563     [self.fc1 = nn.Sequential(\\r\\n    nn.Linear(20...\n",
       "8564     [datasets.MNIST, torch.Size([64, 1, 28, 28]), ...\n",
       "8565     [class MLP(nn.Module):\\r\\n    def forward(self...\n",
       "8566     [torch.expand,  x = torch.randn(200,1)\\r\\n y =...\n",
       "8568      [result = vp[vp_sa_s, 0]\\r\\n, vp, (10, 1), , 0]]\n",
       "8570                                                   NaN\n",
       "8571                                                   NaN\n",
       "8572     [torch.tensor.contiguous(), copy.deepcopy(),  ...\n",
       "8573     [i = torch.arange(bs).reshape(bs, 1, 1) # shap...\n",
       "8574     [t1 = t0[[[b] for b in range(bs)], labels]\\r\\n...\n",
       "8575                                                   NaN\n",
       "8576                                                   NaN\n",
       "8577                                                   NaN\n",
       "8578     [requires_grad, torch.ones, torch.diagflat,  t...\n",
       "8579     [BatchNorm1d, batch_size=1, BatchNorm, batch_s...\n",
       "8580                                        [model.eval()]\n",
       "8581     [from torch.utils.data import DataLoader\\r\\n.....\n",
       "8584     [import torchvision.utils as vutils\\r\\nimport ...\n",
       "8586                                                   NaN\n",
       "8587     [(batch_size, timesteps, number_of_features_at...\n",
       "8588                                              [params]\n",
       "8589     [MM, self.matrix2, MM(), MM.__call__(), forwar...\n",
       "8590     [class my_mul:\\r\\n        def __init__(self, h...\n",
       "8591                                                   NaN\n",
       "8592                                                   NaN\n",
       "8593                                                   NaN\n",
       "8594     [my_model, class MyModel(nn.Module):\\r\\n    de...\n",
       "8595                                                   NaN\n",
       "8597     [pytorch_cluster, true, pip uninstall, pip, co...\n",
       "8598     [pip uninstall torch \\r\\n, pip install torch==...\n",
       "8599     [mask = torch.zeros_like(mf_model.partner_emb....\n",
       "8601     [model = models.vgg16(pretrained=True).cuda()\\...\n",
       "8602     [hessian, import torch\\r\\n\\r\\n\\r\\ndef pow_redu...\n",
       "8603     [torch_geometric, 1.7.0, pip install --no-inde...\n",
       "8604     [torch.prod, [torch.prod((temp.T[i] == tesnor2...\n",
       "8605     [hidden = model.init_hidden()\\r\\noutputs, hidd...\n",
       "8606     [hidden, hidden, hidden, zeros, nn.Linear, cla...\n",
       "8607     [.cuda(), nn.Module, model.cuda(), img = img.c...\n",
       "8609     [contentImage, content_features, style_feature...\n",
       "8610                                                   NaN\n",
       "8611                                                   NaN\n",
       "8612                                                   NaN\n",
       "8613                                                   NaN\n",
       "8614     [tensor_a, tensor_b, tensor_c, torch.where, to...\n",
       "8615     [nn.Flatten,  m = nn.Sequential(\\r\\n...    nn....\n",
       "8616     [PATH, torch.load, torch.save, state_dict = to...\n",
       "8617                                                   NaN\n",
       "8618     [nn.Conv3d, (-1, 16, 45, 54, 45), 16*45*54*45=...\n",
       "8619     [ft_anchor_generator = AnchorGenerator(\\r\\n   ...\n",
       "8620                                                   NaN\n",
       "8621     [class Model(nn.Module):\\r\\n       def __init_...\n",
       "8622     [torch.optim.Optimizer, requires_grad, .backwa...\n",
       "8623                                                   NaN\n",
       "8624                                                   NaN\n",
       "8625     [[1, 32, 32], [3, 32, 32], np.concatenate((ima...\n",
       "8627     [DataLoader, drop_last, False, drop_last=False...\n",
       "8628     [_accumulated_batches_reached, _num_training_b...\n",
       "8629     [map_location, torch.load, state_dict = torch....\n",
       "8630     [torchvision.datasets.kinetics.Kinetics400, Vi...\n",
       "8631     [torch.gather,  grid.flatten(start_dim=0, end_...\n",
       "8632     [y_t = torch.linspace(-1., 1., 16, device='cpu...\n",
       "8633     [--no-cache-dir, pip install --no-cache-dir to...\n",
       "8634     [actor, critic, actor, critic, loss_actor = -s...\n",
       "8635     [import torch\\r\\n\\r\\nindices = torch.tensor([[...\n",
       "8636     [functional, torch.nn.functional.dropout, self...\n",
       "8637     [Dropout, def forward(self, x, p=0.5):\\r\\n    ...\n",
       "8638                  [loss = loss(outputs, labels), loss]\n",
       "8639     [m(input), __call__, __call__, forward, nn.Mod...\n",
       "8640                                                   NaN\n",
       "8641     [axis=1, k*c, (bn, k*c, 32, 32), nn.Conv2d, 2*...\n",
       "8642     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8643     [predict, class LitMNISTDreamer(LightningModul...\n",
       "8644     [trainer, model = Net(...), x, model(x), forwa...\n",
       "8645     [test_dataset = Dataset(test_tensor)\\r\\ntest_g...\n",
       "8646                                                [test]\n",
       "8647     [Myloss1, Myloss2, sqrt, y = torch.randn(2,3)\\...\n",
       "8648     [    BERTmodel = AutoModel.from_pretrained('be...\n",
       "8649     [import torchvision.models as models\\r\\nimport...\n",
       "8650     [torch.gather, import torch\\r\\ntest_tensor = t...\n",
       "8652     [torch&gt;1.7, a = torch.rand((10, 20, 4))\\r\\n...\n",
       "8653                                                   NaN\n",
       "8654     [torch.einsum, numpy.einsum, batch_size = 5\\r\\...\n",
       "8655                                                   NaN\n",
       "8656                                                   NaN\n",
       "8657     [REQUIRED_PACKAGES = [line.strip() for line in...\n",
       "8661     [L1loss, l1_loss = torch.nn.L1Loss(reduction='...\n",
       "8662     [def l1_loss(output, target):\\r\\n    loss = to...\n",
       "8666     [def __init__(self,...):\\r\\n  ...\\r\\n  self.mo...\n",
       "8667                                     [LightningModule]\n",
       "8668     [A = torch.FloatTensor([[1, 2], [3, 4]])\\r\\nB ...\n",
       "8669     [class Decoder(nn.Module):\\r\\n\\r\\n  def __init...\n",
       "8670                                                   NaN\n",
       "8671     [from distutils.core import setup, Extension\\r...\n",
       "8674                                                   NaN\n",
       "8676     [BertForSequenceClassification, BertModel, [CL...\n",
       "8679     [ data_lebel = data_lebel.reset_index()\\r\\n cl...\n",
       "8681     [                print(data.shape)\\r\\n        ...\n",
       "8682     [input_dim, torch.autograd.Variable, torch.ten...\n",
       "8683                           [avail_actions[:, 1:] == 0]\n",
       "8684     [avail_actions[:, 1:] == 0, for, for i in rang...\n",
       "8685     [.item(), loss, loss = self.criterion(output, ...\n",
       "8686     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "8687     [optimizer1.step(), loss2.backward(retain_grap...\n",
       "8688     [nn.LSTM, class Model(nn.Module):\\r\\n    def _...\n",
       "8689     [param, model.parameters(), param, model.param...\n",
       "8690     [extended_attention_mask = extended_attention_...\n",
       "8691     [import os\\r\\n\\r\\nprint(\"PYTHONPATH:\", os.envi...\n",
       "8692                                                   NaN\n",
       "8693                                                   NaN\n",
       "8694     [x.fill_diagonal_(0)\\r\\n, 1 - I, 1 - torch.eye...\n",
       "8695     [torch.eye, import torch\\r\\n\\r\\nx = torch.tens...\n",
       "8696     [grpc_inference_port=7000\\r\\ngrpc_management_p...\n",
       "8697     [dist = torch.distributions.uniform.Uniform(-1...\n",
       "8698     [np.reshape, transpose, new = original.transpo...\n",
       "8700     [pip install --pre torch torchvision -f https:...\n",
       "8701                                                   NaN\n",
       "8703     [output, [1, 10], 1, 1, 1, 10, loss = loss_fn(...\n",
       "8704     [import tensorflow as tf\\r\\ntf.debugging.set_l...\n",
       "8705     [pytorch-hessian-eigenthings/main.py, --, --se...\n",
       "8706     [forward, prediction = neuralNet.Forward(dataS...\n",
       "8707                                                   NaN\n",
       "8708     [num_classes, torch.utils.data.Subset, torch.u...\n",
       "8710     [ vector = torch.tensor([[1,5,3], [2,3,4]])\\r\\...\n",
       "8711                                                   NaN\n",
       "8712     [x = x.view(-1, 64*14*14), torch.Size([1, 1, 2...\n",
       "8713     [BatchNorm(), self.bn1 = nn.BatchNorm2d(16), c...\n",
       "8714     [loc, mu, scale, sigma, loc, scale, torch.dist...\n",
       "8715                                                   NaN\n",
       "8716     [tf.keras.layers.Conv1D, (batch_shape + (steps...\n",
       "8717     [class InceptionNet(nn.Module):\\r\\n    def __i...\n",
       "8718     [gd_loss = ((dx_real.abs() - dx_fake.abs())**2...\n",
       "8719     [dx_real = real[:, :, :, 1:, :] - real[:, :, :...\n",
       "8720     [key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')]\n",
       "8721     [1024, batch_size=128, torch.utils.data.Datase...\n",
       "8722     [tensordot, tensor4D, raw = tensor4D.view(nb_x...\n",
       "8723     [main(), if __name__ == \"__main__\":, import py...\n",
       "8724     [rocminfo, ROCk module is NOT loaded, possibly...\n",
       "8725     [pyopencl, PYOPENCL_CTX='0', ctx = cl.create_s...\n",
       "8726     [n_class, n_class, n_class, n_class, prob = f(...\n",
       "8727     [nn.Sigmoid, nn.Softmax, nn.Sigmoid, nn.BCELos...\n",
       "8728     [Hout​=(Hin​−1)×stride[0]−2×padding[0]+dilatio...\n",
       "8729             [random.py, import numpy.core.multiarray]\n",
       "8731     [y_train = torch.from_numpy(y_train).double()....\n",
       "8732     [Tensor.type(dtype), float32, float64, device ...\n",
       "8733                                                   NaN\n",
       "8734     [print, torch.cuda.is_available()\\r\\n, True, F...\n",
       "8735     [-10000, 10000, data = (data - data.min()) / (...\n",
       "8736     [torchvision.models.vgg*, model = torchvision....\n",
       "8737     [if, \\r\\ndef heatmap(tensor: torch.Tensor) -&g...\n",
       "8738     [pic_output = pic_output.view(-1, 45, 45, 3).c...\n",
       "8739     [nn.LSTM, self.lstm = nn.LSTM(self.input_size,...\n",
       "8740                                                 [n-1]\n",
       "8741     [nn.Sequential, .children(), forward, view(1, ...\n",
       "8742     [nn.Flatten, tail, \\r\\nimport torch\\r\\nimport ...\n",
       "8743     [ \"C:\\Users\\micha&gt;nvidia-smi --query-gpu=me...\n",
       "8744     [    fft_im = torch.rfft(img.clone(), signal_n...\n",
       "8745     [device = torch.device('cuda:0' if torch.cuda....\n",
       "8747     [torch.bincount, A, reverse_map, reverse_map, ...\n",
       "8748     [torchvision.transforms.Normalize, [0, 1], mea...\n",
       "8749     [mead=0, std=1, output=(output - 0) / 1, from ...\n",
       "8750     [ans, f, f, fns = [f.clone().to(device) for de...\n",
       "8751     [collate_fn, bAbi_Dataset, /dataloader.py, tor...\n",
       "8752     [class CustomDataset(InMemoryDataset):\\r\\n    ...\n",
       "8753     [torch_geometric.data.Data, __getitem__, def _...\n",
       "8755     ['/data/users2/oiler/github/imagenet-data/val/...\n",
       "8756                                                   NaN\n",
       "8757                                                   NaN\n",
       "8758                                                [nccl]\n",
       "8759     [.finfo(), .finfo().max, .iinfo(), finfo, iinf...\n",
       "8760     [(batch_size, 120, 1, 1), 120*1*1, 120, 120*2*...\n",
       "8762     [collate_fn, input_words, input_chars, syn_tre...\n",
       "8764     [class DGCNN(nn.Module):\\r\\n    def __init__(s...\n",
       "8765     [pred = model(img.to(device))[0]\\r\\n, x.to(dev...\n",
       "8766     [Input: Tensor = [#batch,#vertex,#feature]\\r\\n...\n",
       "8767     [epoch=1/2, epoch=1/2, len(trainset)//batch_si...\n",
       "8768     [batch_size=2,  t1 = torch.LongTensor([[3], [5...\n",
       "8770     [$ vi /home/mona/venv/smplifyx/lib/python3.6/s...\n",
       "8771     [mask_c0 = mask_d2 * mask_d0_d1\\r\\n# mask_c1 =...\n",
       "8772     [ x\\r\\ntensor([[[0, 0, 1, 1],\\r\\n         [0, ...\n",
       "8773     [PIL, cv2, import cv2\\r\\nimg = cv2.imread('fac...\n",
       "8774     [RUN mkdir ~/.cache\\r\\nRUN chmod -R 777 ~/.cac...\n",
       "8775     [RUN python3 -c 'from transformers import Auto...\n",
       "8776     [pip install torch===1.7.1 torchvision===0.8.2...\n",
       "8777     [torch.nn.CrossEntropyLoss, train_y = torch.te...\n",
       "8778                                 [.unsqueeze(1), x, y]\n",
       "8779     [utf-8,   converter =  tf.compat.v1.lite.TFLit...\n",
       "8780     [torch.nn.AvgPool1d, mean = nn.AvgPool1d(kerne...\n",
       "8781     [class NewModel(nn.Module):\\r\\n    def __init_...\n",
       "8782                                                   NaN\n",
       "8783     [model, input, output, m = models.resnet18(pre...\n",
       "8784     [nn.MaxPool, (32, 64, 16, 16), nn.Linear, (bat...\n",
       "8785     [nn.MaxPool2d, nn.Linear, x = x.view(x.size(0)...\n",
       "8786     [n x d, X, n, label, k x d, n, def vcentroids(...\n",
       "8787     [import torch\\r\\n\\r\\nB = 32\\r\\nN = 1000\\r\\ndim...\n",
       "8788     [itrs, def itr_merge(*itrs):\\r\\n    for itr in...\n",
       "8789     [ConcatDataset, DataLoader, import torch\\r\\nfr...\n",
       "8790     [DataLoader, trainval = [d for dl in [train_lo...\n",
       "8791     [add_module, class Net(nn.Module):\\r\\n    def ...\n",
       "8794                                                   NaN\n",
       "8795     [torchvision.transforms.Normalize(\\r\\n        ...\n",
       "8796     [torchvision.transforms.Normalize(), mean, std...\n",
       "8797     [import torch\\r\\nimport torchvision\\r\\n\\r\\nimp...\n",
       "8798     [cv2.normalize, [min(data), max(data)], [a, b]...\n",
       "8799     [img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\r\\...\n",
       "8800     [torchvision.utils.make_grid, if tensor.dim() ...\n",
       "8801                                                   NaN\n",
       "8802     [(b, c, h, w), b, c, h, w, nn.Conv2d(256, 80, ...\n",
       "8803     [from torch.utils.data import Dataset, DataLoa...\n",
       "8804     [expand, model = torchvision.models.video.mc3_...\n",
       "8805     [print, from io import StringIO  # Python3\\r\\n...\n",
       "8806     [targets = np.random.randint(0,10,(10,))\\r\\n\\r...\n",
       "8807     [np.logical_and, targets = np.array([-1,0,1,2,...\n",
       "8808     [del X_batch, y_pred = model(X_batch...), .bac...\n",
       "8809     [view(), torch.unsqueeze(), unsqueeze(dim=0), ...\n",
       "8810     [nn.KLDivLoss, kl = torch.mean(b * (torch.log(...\n",
       "8812     [&gt;python\\r\\n&gt;import platform\\r\\n&gt;plat...\n",
       "8813     [def setup(self, stage: Optional[str] = None) ...\n",
       "8814     [import torch\\r\\nimport torchvision.transforms...\n",
       "8815     [torch.Tensor, transform(data), transforms.ToT...\n",
       "8816                                                   NaN\n",
       "8817        [[0, 40], tanh, tanh, N(0, 1), tanh, nn.PReLU]\n",
       "8819     [BasicBlock, torchvision.models, import *, fro...\n",
       "8820     [c = torch.rand((3,4), requires_grad=True)  # ...\n",
       "8821     [class MyTransformerModel(nn.Module):\\r\\ndef _...\n",
       "8822                                                   NaN\n",
       "8823     [4_onnx_opencv_inf.py, blob = cv2.dnn.blobFrom...\n",
       "8825     [torch.Tensor.index_put_, accumulate, True,  w...\n",
       "8826                     [layoutlm, pytorch 1.4, layoutlm]\n",
       "8828     [@register_torch_op\\r\\ndef maximum(context, no...\n",
       "8829                [!pip install -U torchtext==0.8.0\\r\\n]\n",
       "8830     [!pip install -U torchtext==0.10.0\\r\\n, torcht...\n",
       "8831                 [pip install -U torchtext==0.6.0\\r\\n]\n",
       "8832         [conda install -c pytorch torchtext==0.8\\r\\n]\n",
       "8833     [L1, self.linear, torch.norm, nn.L1Loss, param...\n",
       "8834                     [SummaryWriter, log_dir, log_dir]\n",
       "8835     [logger.add_scalar('%s Epoch Loss' % experimen...\n",
       "8836                                                   NaN\n",
       "8837     [topk, bottleneck.argpartition, import bottlen...\n",
       "8838     [permute, permute, reshape, permute, reshape, ...\n",
       "8839     [permute, nn.LSTM, nn.Linear, nn.LSTM, output,...\n",
       "8840     [torch.index_add, torch.scatter,  indx \\r\\nten...\n",
       "8841     [require_grad=True, one, one = torch.tensor([1...\n",
       "8842                        [.backward(), len(dataloader)]\n",
       "8843     [indices[0], 0, indices[1], 2, x, dim=0, torch...\n",
       "8844     [B, B,  map = {x.item(): i for i, x in enumera...\n",
       "8845     [B, A, In [*]: for x in B:\\r\\n    ...:     pri...\n",
       "8846     [perfplot, import torch\\r\\n\\r\\n\\r\\ndef apply(a...\n",
       "8847     [[-1, 1], visualization = torchvision.utils.ma...\n",
       "8848     [torchvision.transform.Normalize, mean(data)=0...\n",
       "8849                                                   NaN\n",
       "8850                                                   NaN\n",
       "8851     [x = self.fc3(x) \\r\\nx = F.softmax(self.fc3(x)...\n",
       "8852     [relu, relu, def __init__(self, input_dim2, hi...\n",
       "8853     [256x256x32, (c, h, w), (h, w, c), c, h, w, c,...\n",
       "8854     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8855     [None, .grad, is_leaf,  x = torch.FloatTensor(...\n",
       "8856     [def grid_torch(x_coords, y_coords, grid_size=...\n",
       "8858     [torch, torch.manual_seed(seed), net_x/y/z, ne...\n",
       "8859                                                   NaN\n",
       "8860     [    class DataLoader:\\r\\n        stats = ((0....\n",
       "8861                                                   NaN\n",
       "8862     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "8863     [return F.embedding(\\r\\n    input, self.weight...\n",
       "8864     [t1, torch.gather,  index = torch.tensor([[(i+...\n",
       "8865     [hidden, forward, Torch.Tensor, r_output, hidd...\n",
       "8866     [def forward(self, nn_input, hidden):\\r\\n    '...\n",
       "8867     [conda install -c conda-forge pytorch cudatool...\n",
       "8868     [nn.Linear, nn.Linear, weight, 2048, model.avg...\n",
       "8869     [Windows Environment Variables, CUDA_CACHE_MAX...\n",
       "8870     [.pt, torch.save(model.state_dict(), \"your/pat...\n",
       "8871                                                   NaN\n",
       "8872     [.pth, .pt/-h, \\r\\n# your model\\r\\nclass YourM...\n",
       "8873     [torch.load(), utils, from utils import some_f...\n",
       "8874     [batch_size=1000, (1000, 1), (1000), torch.uns...\n",
       "8875     [labels = torch.nn.functional.one_hot(labels)\\...\n",
       "8876                                                   NaN\n",
       "8877                                                   NaN\n",
       "8878     [grad, None, grad, .grad, Tensor, Tensor, .gra...\n",
       "8879     [z = torch.from_numpy(np.array([1., 1.])).floa...\n",
       "8880                      [torchvision.datasets.PhotoTour]\n",
       "8881     [(batch_size, seq_len, input_size), sample_x.u...\n",
       "8882     [ (#batch,#number_of_timesteps,#number_of_feat...\n",
       "8883     [h0 = torch.zeros(self.num_layers, x.size(0), ...\n",
       "8885     [--model_name_or_path, gpt2, !python3 run_clm....\n",
       "8886     [model_name_or_path, --overwrite_output_dir, -...\n",
       "8887     [examples = {i: [] for i in range(len(classes)...\n",
       "8888     [import os\\r\\nimport zipfile \\r\\nimport gdown\\...\n",
       "8889     [from torchvision.datasets import ImageFolder\\...\n",
       "8890        [from aif360.datasets import AdultDataset\\r\\n]\n",
       "8891                                                   NaN\n",
       "8892     [def uniform_data_set(minimum=80, maximum=120,...\n",
       "8893                                                   NaN\n",
       "8894                                                   NaN\n",
       "8895     [nn.CosineSimilarity, n, x, (n, d), d, n=3, d=...\n",
       "8896     [if torch.cuda.is_available():\\r\\n    weight =...\n",
       "8897     [torch.scatter_, A.scatter_(dim=2, index=P, sr...\n",
       "8898     [nn.Linear, input_shape, in_features, out_feat...\n",
       "8899     [target, model = nn.Linear(5, 1)  # from 5-dim...\n",
       "8900                                                  [32]\n",
       "8901     [combined = torch.cat((ListA.view(-1), ListB.v...\n",
       "8902                                                   NaN\n",
       "8903              [model.eval(), model.train(), BatchNorm]\n",
       "8904     [(c, h, w), c, nn.Conv2d, BatchNorm2d, torch.r...\n",
       "8905     [k, x, k_expanded = k.expand_as(x)\\r\\n, 1, k_e...\n",
       "8906                                                   NaN\n",
       "8907     [nn.GRU, (seq_len, batch, input_size), (batch,...\n",
       "8908                                                   NaN\n",
       "8909       [x = torch.flatten(x, start_dim=1, end_dim=-1)]\n",
       "8910     [(1, 512, 14, 14), torch.einsum, torch.einsum(...\n",
       "8911     [torch.no_grad(), grads = torch.autograd.grad(...\n",
       "8912     [(h_n, c_n), &lt; t, nn.LSTM, num_layers, rnn ...\n",
       "8913     [cp36-cp36m, torch-1.3.1%2Bcpu-cp36-cp36m-linu...\n",
       "8914     [!conda uninstall pytorch torchvision\\r\\n, !co...\n",
       "8915     [k = nn.Conv1d(1,64,kernel_size=5)\\r\\ninput = ...\n",
       "8916     [(b, c, w), b, c, w, kernel_size, w, nn.Linear...\n",
       "8917     [smp.utils.losses.DiceLoss(), mask = mask[0, :...\n",
       "8918                                                   NaN\n",
       "8919     [dim=0, x.permute(1, 0, 2, 3).flatten(start_di...\n",
       "8920                                                   NaN\n",
       "8921                                                   NaN\n",
       "8923     [torch.unsqueeze(),  a = torch.zeros(4, 5, 6)\\...\n",
       "8925     [torch.transpose, batch_size = 128\\r\\nsequence...\n",
       "8926     [[0, 1], mean, std, x in [x_min, x_max] -&gt; ...\n",
       "8927     [ToTensor, pillow, ToPilImage, from PIL import...\n",
       "8928     [import torch\\r\\nx = torch.rand(3, 4, 3, 2, 6)...\n",
       "8929     [torch.reshape, b, n, c, h, w = X.shape\\r\\nX =...\n",
       "8930     [[10], [N,1] =&gt; [10,1], torch.zeros(N).to(d...\n",
       "8931     [&gt; idx = torch.arange(x.shape[1], 0, -1)\\r\\...\n",
       "8932     [x = torch.tensor([[[ 0,  0,  2,  3,  4,  5,  ...\n",
       "8933     [permute, import torch\\r\\nx = torch.rand(10, 5...\n",
       "8934                                                   NaN\n",
       "8936                                                   NaN\n",
       "8937                                                   NaN\n",
       "8938     [[a x b] = [batch size x in_channels]\\r\\n[c x ...\n",
       "8939     [tf.nn.softmax_cross_entropy_with_logits, F.cr...\n",
       "8940     [tf.nn.softmax_cross_entropy_with_logits,  imp...\n",
       "8941     [bce_loss, bce_loss, torch.nn.BCELoss, inputs,...\n",
       "8942     [nn.Linear, nn.Embedding, trg_emb = nn.Embeddi...\n",
       "8943     [MNISTDataset, self.transforms, None, __getite...\n",
       "8944                                                   NaN\n",
       "8945     [batch, channels, (6, 3, 300, 300), 300x300, (...\n",
       "8946     [add_images, add_figure, from torch.utils.tens...\n",
       "8947     [nn.Linear, wX+b, sigmoid(WX+b), model = nn.Se...\n",
       "8948                      [Linear, Linear, Linear, Linear]\n",
       "8951     [def build_index_map(model):\\r\\n  ind_to_ind =...\n",
       "8952     [default_hp_metric, TensorBoardLogger(save_dir...\n",
       "8953     [hp_metric, TensorBoardLogger(save_dir='tb_log...\n",
       "8954     [data, mask, data[mask]\\r\\ntensor([[1066.3000,...\n",
       "8955     [RandomChoice, class RandomChoice(RandomTransf...\n",
       "8956     [torchvision, import albumentations as A\\r\\n\\r...\n",
       "8957     [import random\\r\\nimport numpy as np\\r\\nimport...\n",
       "8958     [if, vflip, import random\\r\\nimport torchvisio...\n",
       "8959     [t = transforms.RandomRotation(degrees=360)\\r\\...\n",
       "8960     [in_channels, out_channels, out_channels, (in_...\n",
       "8962     [0, 1, x, (batch, x1, x2), x1, trade_quantity,...\n",
       "8963     [torch.nn.Embedding, torch.Tensor, import torc...\n",
       "8964                                                   NaN\n",
       "8965     [import tensorflow as tf\\r\\nfrom tensorflow im...\n",
       "8966     [1 - cos(A), cos(A), X^2 + 4, -(X^2 + 4), loss...\n",
       "8967     [in_channels, conv, out_channels, in_channels,...\n",
       "8968     [                RGBMean = [123.68,116.779,103...\n",
       "8972                                                   NaN\n",
       "8974                                                   NaN\n",
       "8975     [from fairseq.models.roberta import RobertaMod...\n",
       "8976     [roberta = torch.hub.load('pytorch/fairseq:mai...\n",
       "8977     [features, avgpool, classifier, features, nn.M...\n",
       "8978     [t.repeat_interleave(2, dim=1)\\r\\n, ensor([[[1...\n",
       "8979     [torch, nn.Sequential, library(torch)\\r\\n\\r\\nm...\n",
       "8980                                                   NaN\n",
       "8981     [x, (seq-len x batch-size x emb-dim), (batch-s...\n",
       "8982     [pred[0], pred, pred = torch.tensor([[212.3856...\n",
       "8983     [import tensorflow as tf\\r\\n\\r\\ninputs = tf.on...\n",
       "8984     [-1, In [58]: arr = np.array([[ 1, 2, 3, 4, 5]...\n",
       "8985                                                   NaN\n",
       "8986     [print('\\n 1. Probability of HeartDisease give...\n",
       "8987     [24 q=HeartDisease_infer.query(variables=['hea...\n",
       "8989     [x[:, :, -1].view(-1)\\r\\n, torch.cat, pred, to...\n",
       "8990     [tp1 = torch.DoubleTensor([[123., 43, 4], [-23...\n",
       "8991     [view, # Using your notations\\r\\nn, k, m = fea...\n",
       "8992     [grad, 1, ones, grad = torch.autograd.grad(out...\n",
       "8993                                                   NaN\n",
       "8994     [criterion = nn.NLLLoss()\\r\\n...\\r\\nx = model(...\n",
       "8995     [cpu(), view, image_unflat = image_tensor.deta...\n",
       "8996                [from xxx.yyy import zzz, import ipdb]\n",
       "8998     [all_out = torch.cat([o_[:, None] for o_ in ou...\n",
       "8999     [def MSELoss2(outputs, labels, weights):\\r\\n  ...\n",
       "9000     [for epoch in range(n_epochs):\\r\\n    model.tr...\n",
       "9001                                                   NaN\n",
       "9002                                                   NaN\n",
       "9003                                                   NaN\n",
       "9005     [elif not done:\\r\\n     target = reward + self...\n",
       "9006                                                   NaN\n",
       "9007                                                   NaN\n",
       "9008     [outputs = model(input_ids, mask, label=label)...\n",
       "9009                                                   NaN\n",
       "9010     [!pip install 'git+https://github.com/facebook...\n",
       "9011     [import sys\\r\\nimport torch\\r\\npyt_version_str...\n",
       "9012     [a[0, indices[0]], a[1, indices[1]], a[0, indi...\n",
       "9014     [axis=1, outputs = (P_u * Q_i).sum(axis=1) + b...\n",
       "9015     [batch_size, seq_len, input_size, num_features...\n",
       "9016     [midrow = b[0, 0, b.shape[3]//2, :]\\r\\npad = (...\n",
       "9017     [t.is_cuda, t.cuda(), t.cpu(), t = torch.randn...\n",
       "9018     [nn.ModuleList, self.hidden_layers = nn.Module...\n",
       "9019     [indices, a[torch.arange(len(a)),indices.view(...\n",
       "9020     [def gather_righthand(src, index, check=True):...\n",
       "9021     [arange, def squeeze_index(x, dim, index):\\r\\n...\n",
       "9022                                                   NaN\n",
       "9023                                                   NaN\n",
       "9024                                                   NaN\n",
       "9026                                                   NaN\n",
       "9027     [bins = [np.sum(a[np.argwhere(bins_indices == ...\n",
       "9028     [ bins = torch.unique(bins_indices)\\r\\n vfunc ...\n",
       "9029     [import torch\\r\\n\\r\\nn = 3\\r\\na = torch.tensor...\n",
       "9030                                                   NaN\n",
       "9032                                                   NaN\n",
       "9034     [maskrcnn_resnet50_fpn, model = torchvision.mo...\n",
       "9035     [result = model(cv2.cvtColor(scr, cv2.COLOR_BG...\n",
       "9036     [True, import cv2\\r\\nimport numpy as np\\r\\n\\r\\...\n",
       "9037                                                   NaN\n",
       "9038     [Tensor, Numpy, # sims is a Tensor &lt;tf.Tens...\n",
       "9039     [x = torch.arange(4).reshape(4, 1, 1).repeat(1...\n",
       "9040     [def side_by_side_reshape(x):\\r\\n    n_pairs =...\n",
       "9041     [self.fc, out.view(out.size(0), -1), out.size(...\n",
       "9043     [in, p = torch.arange(1, 5).reshape((2,2))\\r\\n...\n",
       "9046                      [True, False, True, False, True]\n",
       "9047               [M-&gt;N, 8, N by M, M-&gt;8N, 8N by M]\n",
       "9048                                                   NaN\n",
       "9049     [pip install wheel, pip install https://downlo...\n",
       "9050     [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "9051                                                   NaN\n",
       "9052                                                   NaN\n",
       "9053     [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "9054     [1, 0, def get_disc_loss(gen,disc,criterion,re...\n",
       "9055                          [model.half(), model.half()]\n",
       "9056     [X, Y, import torch\\r\\nX = X.reshape(batch_siz...\n",
       "9057     [fc.bias, Addmm(bias, x, T(weight), T, Addmm, ...\n",
       "9058     [t.unfold(i, n, s), n &gt;= s, n + s &lt;= t.s...\n",
       "9059     [63840, 160, flatten, inp_unfolded[:, ::2, :]....\n",
       "9060     [train_dataset.train_data.to(CTX)  #train_data...\n",
       "9061     [def preprocess(x, y):\\r\\n    return x.view(-1...\n",
       "9062                     [torch::kInt16, torch::KInt16, k]\n",
       "9063     [(-1, 2), tensor_input = np.array([[[1,2],[1,3...\n",
       "9064                                                   NaN\n",
       "9065                                                   NaN\n",
       "9066                                                   NaN\n",
       "9067     [weight, \\r\\nloss_w = labels  # ignore labels ...\n",
       "9068     [encoder = nn.DataParallel(network.EncoderCell...\n",
       "9069                                                   NaN\n",
       "9070     [def focal_loss(y_real, y_pred, eps = 1e-8, ga...\n",
       "9071     [EPS = 1e-9\\r\\ndef focal_loss(y_real, y_pred, ...\n",
       "9072     [train_loader = torch.utils.data.DataLoader(\\r...\n",
       "9073     [fasterrcnn_resnet50_fpn, FrozenBatchNorm2d, B...\n",
       "9074                                        [GaussianBlur]\n",
       "9075                                  [conda update --all]\n",
       "9076     [b = torch.rand(10, requires_grad=True) # crea...\n",
       "9077     [pyproject.toml, [tool.poetry.dependencies]\\r\\...\n",
       "9078     [nn.Sequential, __init__, return, __init__, in...\n",
       "9079     [        # data = np.array(Image.open(img_path...\n",
       "9080     [conv3d, nn.Conv3d, self.conv_5, ([2, 64, 99, ...\n",
       "9081     [optimizer_cp = deepcopy(optimizer), optimizer...\n",
       "9084                                                   NaN\n",
       "9085     [forward, x = self.dec_conv3(self.unpool3(x, i...\n",
       "9086                                   [ReLu, ReLu(w.x+b)]\n",
       "9087     [[bacth_size, 10], batch_size, 10, output[0] =...\n",
       "9088     [import torch.nn.functional as F\\r\\n# [bs, cs,...\n",
       "9089                  [--n_channels, args.n_chanels, 1, 3]\n",
       "9090                       [state_dict, load_state_dict()]\n",
       "9091     [pip install . --user\\r\\n, pip list, keras-ret...\n",
       "9092     [BertModel, BertModelForSequenceClassification...\n",
       "9093     [[:], for i in range (batch):\\r\\n      for j i...\n",
       "9094         [pip install numpy==1.18\\r\\n, torch, pytorch]\n",
       "9095     [collate_fn, __getitem__, batch_size, torch.st...\n",
       "9096     [import torch\\r\\nbatch = 2\\r\\nnum_nodes = 4\\r\\...\n",
       "9097                                                   NaN\n",
       "9098                                                   NaN\n",
       "9099     [numpy.unique, import torch\\r\\nimport numpy as...\n",
       "9100     [batch_size=8, .backward(), step(), zero_grad(...\n",
       "9101     [x = torch.randn(())\\r\\ntorch.t(x)\\r\\n#tensor(...\n",
       "9102     [non_blocking=True, index = index.cuda(non_blo...\n",
       "9103                                                   NaN\n",
       "9104                                                   NaN\n",
       "9106     [torch.randn(2, 3, 3)\\r\\n&gt; tensor(\\r\\ntenso...\n",
       "9107                                    [torch.load, .png]\n",
       "9108     [torch.sparse, torch.sparse.FloatTensor, spars...\n",
       "9109                                [BATCH_SIZE, EPS, EPS]\n",
       "9110                                   [n_frames_per_step]\n",
       "9112     [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "9114     [tensor = torch.tensor(np.random.rand(100,64, ...\n",
       "9115                                                   NaN\n",
       "9116                                                   NaN\n",
       "9117                                                   NaN\n",
       "9118     [RUN mkdir -p /home/&lt;username&gt;/.cache/to...\n",
       "9119     [max_length=5, max_length, [CLS], [SEP], max_l...\n",
       "9120     [if ext not in [\".zip\", \".7z\"] and not check_i...\n",
       "9121     [def cross_entropy(y_hat, y):\\r\\n    return - ...\n",
       "9122     [list(network.parameters()), [param.grad for p...\n",
       "9123     [from transformers import BertForSequenceClass...\n",
       "9124     [\\r\\nfor epoch in range(epochs):\\r\\n    train_...\n",
       "9125     [Init signature: torch.nn.Linear(in_features: ...\n",
       "9126     [from torch.utils.data import DataLoader, Data...\n",
       "9127     [[0, 0.2), [0.2, 0.4), [0.4, 0.9), [0.9, 1.0],...\n",
       "9128     [bisect, bisect, O(log n), from bisect import ...\n",
       "9129     [Module, torch_ref, super(SyNet, self).__init_...\n",
       "9130     [np.broadcast_to,  import numpy as np\\r\\n x = ...\n",
       "9131     [np.tile,  x = np.range(5)\\r\\n x = np.expand_d...\n",
       "9132             [numpy.newaxis, y = x[:, np.newaxis]\\r\\n]\n",
       "9133                                                   NaN\n",
       "9134     [class CustomCallback(keras.callbacks.Callback...\n",
       "9135                                                   NaN\n",
       "9136     [p, p = p - self.alpha * (x_normal - x_tilde)\\...\n",
       "9137     [The conflict is caused by:\\r\\n    The user re...\n",
       "9138     [$ bat requirements.txt \\r\\n───────┬──────────...\n",
       "9140     [ class ChestXRayDataset(torch.utils.data.Data...\n",
       "9141     [RobertaForSequenceClassification, roberta-bas...\n",
       "9142     [retain_graph=True, .backward, c.backward(reta...\n",
       "9143     [Y_tensor = torch.tensor(Ys)\\r\\nprint(Y_tensor...\n",
       "9144     [BertModel, BertForSequenceClassification, Ber...\n",
       "9145     [from transformers import BertModel, BertConfi...\n",
       "9146     [requires_grad, for param in model.parameters(...\n",
       "9147     [detach, detach x2, x1, MyEnsemble, modelB, de...\n",
       "9148     [model = Model.load(modelName, ['rect'])\\r\\n, ...\n",
       "9149                                                   NaN\n",
       "9150                                 [scatter_add, gather]\n",
       "9151     [cv2.imread, np.uint8, import torchvision.tran...\n",
       "9152                                                   NaN\n",
       "9153     [idx1, idx_last, t[(idx1, ...) + tuple(idx_las...\n",
       "9154                                                   NaN\n",
       "9155     [import torch \\r\\nimport numpy as np\\r\\nimport...\n",
       "9156     [torch.utils.data.WeightedRandomSampler, torch...\n",
       "9157     [from transformers import BertModel\\r\\nclass C...\n",
       "9158     [hidden_features, import seaborn as sns\\r\\nimp...\n",
       "9159     [torch.Tensor.backward, torch.autograd.backwar...\n",
       "9163                                                   NaN\n",
       "9164     [label = torch.full((b_size,), real_label, dev...\n",
       "9165                                                   NaN\n",
       "9167     [class CNN(nn.Module):\\r\\n    \\r\\n    def __in...\n",
       "9169     [m, # channel first tensors\\r\\na = torch.ones(...\n",
       "9170     [from PIL import Image\\r\\nimport os\\r\\nfrom pa...\n",
       "9171     [tmp_tensor = torch.unsqueeze(tmp_tensor, 0), ...\n",
       "9172     [LSTM layer, return_sequences, (batch_size, LS...\n",
       "9174     [Dataloader, DataLoader, L,  trainset = torch....\n",
       "9175     [λ, α=1, α==1, λ, λ, λ, 1-λ, λ, λ, n, n-1, 1, ...\n",
       "9176     [w = np.random.uniform(0, 1)\\r\\nh = np.random....\n",
       "9177     [torchviz, grad_fn, gra_fn, torchviz, torch.ca...\n",
       "9178     [numpy, labels_batch.cpu().numpy(), labels_bat...\n",
       "9180     [torch.cumsum, mask = (x == 1).to(x)  # mask w...\n",
       "9181                [vgg16.eval()\\r\\nvgg16_seq.eval()\\r\\n]\n",
       "9183     [AT_CHECK, TORCH_CHECK, (base) mona@mona:~/res...\n",
       "9184     [def cycle(iterable):\\r\\n    while True:\\r\\n  ...\n",
       "9185     [128x28x28, reconstructed = x.reshape(128, 1, ...\n",
       "9186                                                   NaN\n",
       "9187     [nn.Module, .parameters(), &lt;&lt; [x for x i...\n",
       "9188                                                   NaN\n",
       "9189                                                   NaN\n",
       "9190     [stack, t, l, t = torch.rand(2,5,3)\\r\\nl = tor...\n",
       "9191     [L2, torch.optim, weight_decay, nn.Embedding, ...\n",
       "9192     [__getitem__, batch[0], batch[1], self.x, self...\n",
       "9193                                                   NaN\n",
       "9194     [initHidden, (1, 1, 256), def initHidden(self)...\n",
       "9195     [broadcast, t = torch.randn((64,100)).view(640...\n",
       "9196     [t, 6400, t = torch.randn((64,100)).unsqueeze(...\n",
       "9197                                                   NaN\n",
       "9198     [Conv2d, SeparableConv2d, kernel=(3,3), Net(),...\n",
       "9199     [compile_commands.json, cmake -DCMAKE_EXPORT_C...\n",
       "9200     [nn.Softmax, nn.Modules, nn.LSTM, self.hidden_...\n",
       "9201     [output = nn.Softmax(self.fc3(output)), output...\n",
       "9202     [nn.softmax, F.softmax, torch.nn.functional as...\n",
       "9203     [x3.grad, .grad, .grad, autograd.backward(), ....\n",
       "9204                                                   NaN\n",
       "9205     [datasets.ImageFolder(), dataset\\r\\n   train_d...\n",
       "9206     [batch, i, a[i]&lt;-&gt;b[0], a[i]&lt;-&gt;b[1...\n",
       "9207               [image, image, showbbox, get_transform]\n",
       "9208     [blah, A.shape[0], A.shape[1], R = torch.stack...\n",
       "9209     [nn.AdaptiveAvgPool2d((N, H, W)), nn.AdaptiveM...\n",
       "9210     [(torch.Size([1, 4, 64, 64]), # conv layer (de...\n",
       "9211                                                   NaN\n",
       "9212     [run_clm.py,     def tokenize_function(example...\n",
       "9213     [import torch\\r\\nc, m, n = input_size[0], inpu...\n",
       "9214     [train_features = torch.Tensor(X_train_arr)\\r\\...\n",
       "9215                                                   NaN\n",
       "9216     [TensorDataset, import torch\\r\\nfrom PIL impor...\n",
       "9218     [(Batch, Height, Width, Channels), (Batch, Cha...\n",
       "9219                                                   NaN\n",
       "9220                                                   NaN\n",
       "9221     [I, X, I = [torch.tensor(40), torch.tensor(42)...\n",
       "9223     [dice = torch.mean(2. * (intersection + smooth...\n",
       "9224     [      [3]  # the two values in the last dimen...\n",
       "9227     [torch.corrcoef, numpy.corrcoef, import numpy ...\n",
       "9229         [def foward(self, x):, def forward(self, x):]\n",
       "9230                                           [torch_xla]\n",
       "9232     [nn.Embedding, 300, (1, 4, 300), 50, (1, 4, 4,...\n",
       "9233     [EXTRA_PIP_PACKAGES, EXTRA_CONDA_PACKAGES, EXT...\n",
       "9234     [should_get_same_class=0, __getitem__, Inferen...\n",
       "9235     [8267, 8267x4x1, dim=1, dim=2, 8267x4, 4, self...\n",
       "9236     [X_train, X_valid, y_train, y_valid = train_te...\n",
       "9237     [getattr(model, name).weight\\r\\n, model.name.w...\n",
       "9238     [In[2]: import torch\\r\\n  ...: a = torch.Tenso...\n",
       "9239     [import torch\\r\\na = torch.Tensor(\\r\\n     [[5...\n",
       "9240                                                   NaN\n",
       "9242                                 [.detach(), detach()]\n",
       "9243     [conv1d, conv2d, w&gt;0, h=1, w&gt;0, h&gt;0, ...\n",
       "9244     [deg, int, pow, 2, -1, 0.5, deg, deg = deg.flo...\n",
       "9245                                                   NaN\n",
       "9246                                                   NaN\n",
       "9247               [!pip install transformers~=2.11.0\\r\\n]\n",
       "9248     [torch.utils.data.Dataset, class MyDataset(Dat...\n",
       "9249                              [batch_size, batch_size]\n",
       "9250     [forward, nn.ModuleList, self.blocks, nn.Seque...\n",
       "9252     [tf.cumsum(alpha, axis = 1)  \\r\\ntorch.cumsum(...\n",
       "9253     [image = Image.fromarray(image), Image.fromarr...\n",
       "9254                                                   NaN\n",
       "9256                                                   NaN\n",
       "9260     [max, attention_mask, pooled = torch.max((toke...\n",
       "9261     [#iterate over the last 4 layers and get embed...\n",
       "9262     [input_mask_expanded = attention_mask.unsqueez...\n",
       "9263                   [groups, in_channels, out_channels]\n",
       "9264                               [pip install torch\\r\\n]\n",
       "9266     [.npy, (Ux_i, Uy_i, Uz_i), i, index, class Fie...\n",
       "9267                                                   NaN\n",
       "9268     [# pass through LSTM layers\\r\\nlstm_out, hidde...\n",
       "9269                   [net.paramters(), net.parameters()]\n",
       "9270                                                   NaN\n",
       "9271     [model = tf.keras.Sequential([ \\r\\n  tf.keras....\n",
       "9273     [CategoricalCrossEntropyLoss, CrossEntropyLoss...\n",
       "9274                                                   NaN\n",
       "9275                                                   NaN\n",
       "9277     [n_input_channels=1, 1x6x7, n_input_channels=3...\n",
       "9278     [model = MultiLayerPerceptron(X_train.shape[1]...\n",
       "9279     [    import torch.nn.functional as F\\r\\n\\r\\n  ...\n",
       "9280     [new_shape=(-1,)+tensor_4d.shape[2:]\\r\\n\\r\\nou...\n",
       "9281     [loss_G.backward(), loss_G.backward(retain_gra...\n",
       "9282     [fastai, AdamW, SGD, fit_one_cycle, fastai, 5e...\n",
       "9284                                            [torch.py]\n",
       "9286     [x = x.permute(1,0,2,3)\\r\\nx = F.interpolate(x...\n",
       "9287     [import numpy\\r\\nimage = numpy.array([[246,  5...\n",
       "9288     [argsort, idx = np.argsort(probs, axis=1)[:,-5...\n",
       "9289                  [np.argpartition(probs,-5)[-5:]\\r\\n]\n",
       "9290     [test_loader, train_loader , for epoch in rang...\n",
       "9292                                                   NaN\n",
       "9293                                                   NaN\n",
       "9294     [tr_logits = tr_logits.detach().cpu().numpy(),...\n",
       "9295                                                   NaN\n",
       "9296     [x_1, x_2, np.einsum('bijc,bijd-&gt;bcd', x_1,...\n",
       "9297     [[batch_size, c=1, h=28, w=28], batch_size, F....\n",
       "9298                        [model = model.to(device)\\r\\n]\n",
       "9299     [torch.tensor, Variable, output, target, mu, v...\n",
       "9300     [class MyZeroOneLayer(nn.Module):\\r\\n  def __i...\n",
       "9301     [&lt;object-class&gt; 0.5 0.5 1 1\\r\\n, from im...\n",
       "9302     [for name, param in bert.named_parameters():  ...\n",
       "9303     [y = torch.Tensor([[10,6,3]])\\r\\nm = torch.dis...\n",
       "9304     [numpy.array, torch.Tensor, input_tensor = tor...\n",
       "9305     [numpy.array, torch.Tensor, input_tensor = tor...\n",
       "9306     [datascience-notebook, C:users\\amtre, Document...\n",
       "9307     [classifier, discriminator, classifier, discri...\n",
       "9309     [loss, self.log_metrics(epoch, accuracy, loss,...\n",
       "9310     [A = torch.ones(1,2,3)\\r\\nb_vals = torch.tenso...\n",
       "9311     [grad_input, backward, Model, input, input, gr...\n",
       "9312                                                 [.pt]\n",
       "9314     [loss = nn.BCEWithLogitsLoss()(outputs, target...\n",
       "9315                                                   NaN\n",
       "9316     [a = torch.randn(400, 32, 400)\\r\\nb = torch.ra...\n",
       "9317                                                   NaN\n",
       "9318                                             [300x300]\n",
       "9319                                                   NaN\n",
       "9320     [.requires_grad, False, for layer in vgg16.fea...\n",
       "9321             [weight_dict.update(new_weight_dict)\\r\\n]\n",
       "9322     [# Create empty VGG16 model (random weights)\\r...\n",
       "9323     [for layer in vgg16.features:\\r\\n    if (hasat...\n",
       "9324     [loss.backward(), requires_grad=True, optimize...\n",
       "9325     [torch.autograd, torch.autograd.functional.hes...\n",
       "9326     [autograd.grad, create_graph, True, grad, env_...\n",
       "9327                                                   NaN\n",
       "9328     [@register_model('simple_lstm')\\r\\nclass Simpl...\n",
       "9329              [fairseq/fairseq/models, fairseq/models]\n",
       "9333     [torch.autograd.grad, y, [torch.autograd.grad(...\n",
       "9334     [    def forward(self, x):\\r\\n        x = self...\n",
       "9335     [BertForSequenceClassification, BertModel, Ber...\n",
       "9336     [torch.cat(), def forward(self, x):\\r\\n    x1 ...\n",
       "9337     [nn.CrossEntropyLoss, label, torch.Long, torch...\n",
       "9338     [torch.LongTensor, label = tensor([0.]).type(t...\n",
       "9339     [nn.CrossEntropyLoss(), torch.LongTensor, labe...\n",
       "9340                                         [python, pip]\n",
       "9342                        [x = torch.rand((1, C, W, H))]\n",
       "9343     [ReLU, 0, Tanh, import torch\\r\\nimport torch.n...\n",
       "9344     [torch.autograd.functional.hessian(func, input...\n",
       "9345                                                   NaN\n",
       "9346     [length &lt; 1024, length &lt; 1024, kernel_si...\n",
       "9347     [$ PIP_FIND_LINKS=\"https://download.pytorch.or...\n",
       "9348     [in_channels, Con2d, Conv2d, in_channels, 256*...\n",
       "9349     [BasicConv2d, class Inception(nn.Module):\\r\\nd...\n",
       "9350     [Normalize(mean=[0.485, 0.456, 0.406], std=[0....\n",
       "9351     [nn.CrossEntropyLoss(), Long, Double, single_l...\n",
       "9352     [inputs, outputs, import torch\\r\\nimport torch...\n",
       "9353     [train_ds_no_aug = ImageFolder('content/train'...\n",
       "9354                                                   NaN\n",
       "9355     [# BaseFeaturesExtractor class\\r\\nimport gym\\r...\n",
       "9356     [y, y = torch.empty(1, 21)\\r\\n, list, y = [tor...\n",
       "9357     [nn.Linear(), Feedforward, class Feedforward(n...\n",
       "9358     [math.cos, math.sin, np.sin, np.cos, torch.sin...\n",
       "9359     [t = torch.tensor([10, 20])\\r\\nprint(t.item())...\n",
       "9360                                                   NaN\n",
       "9361     [pip freeze &gt; requirements.txt\\r\\n, https:/...\n",
       "9362     [data.DataLoader(..., generator=torch.Generato...\n",
       "9363     [torch.set_default_tensor_type('torch.cuda.Flo...\n",
       "9364     [self.fc, def forward(self, x):\\r\\n    ....\\r\\...\n",
       "9365                                                   NaN\n",
       "9369                                    [loss += loss_val]\n",
       "9370     [    model = FasterRCNN(backbone,\\r\\n         ...\n",
       "9371     [44  A = torch.mm(feats.t(), feats) + 1e-05 * ...\n",
       "9373     [tensor, storage, tensor, storage, stride, [1 ...\n",
       "9374     [NCHW, NHWC, stride, stride, bytes, import num...\n",
       "9376     [mdl.train(), momentum, track_running_stats, F...\n",
       "9377     [batch_norm.reset_running_stats(), def reset_a...\n",
       "9379                                                   NaN\n",
       "9380                                                   NaN\n",
       "9381     [__len__, header=None, __init__, self.data_len...\n",
       "9383     [device = \"cuda:0\"\\r\\nmodel = model.to(device)...\n",
       "9384     [eval, with open(\"./arrays/tensor.txt\",\"r\") as...\n",
       "9385                                [19+19+6+16+8+3+19=90]\n",
       "9386                                                   NaN\n",
       "9387                                 [torch==1.1.0, 1.7.1]\n",
       "9388          [target = T.ToTensor()(target), __getitem__]\n",
       "9389                                  [shift_tokens_right]\n",
       "9390     [torch.take, def convert_inds(img_a,img_b,patc...\n",
       "9391     [seq_idx = np.arange(best_bboxes.size)\\r\\nfilt...\n",
       "9392     [def try_compute_model(input):\\r\\n    try:\\r\\n...\n",
       "9393     [import torch\\r\\nfrom contextlib import contex...\n",
       "9396                                                   NaN\n",
       "9397     [slice, import numpy as np\\r\\nimport torch\\r\\n...\n",
       "9398     [collate_fn, list, ['sentences'], # [...]\\r\\ne...\n",
       "9399     [Dataset, class MyDataset(torch.utils.data.Dat...\n",
       "9400                                                   NaN\n",
       "9401                                                   NaN\n",
       "9402                                                   NaN\n",
       "9404     [L, U, torch.tril, torch.triu, L = torch.tril(...\n",
       "9405                                                   NaN\n",
       "9406     [[tool.poetry.dependencies]\\r\\npython = \"^3.8\"...\n",
       "9407     [curl -sSL https://raw.githubusercontent.com/p...\n",
       "9408                                                   NaN\n",
       "9409     [self.conv(x), torch.Size([32, 64, 2, 2]), 32*...\n",
       "9410     [transform = transforms.Compose([transforms.Re...\n",
       "9412                                     [3.6.13, PyTorch]\n",
       "9413     [forward-mode, reverse-mode, hybrids, tape-bas...\n",
       "9414     [from PIL import ImageOps\\r\\n \\r\\ngray_image =...\n",
       "9415     [libcusparse, aten/src/ATen/native/sparse/cuda...\n",
       "9418     [device = torch.device('cuda' if torch.cuda.is...\n",
       "9419                                                  [()]\n",
       "9420     [import torch\\r\\n# t1.shape = (4,1,3)\\r\\nt1 = ...\n",
       "9421     [numpy.recarry, pandas.DataFrame.to_records, ....\n",
       "9422     [loader = DataLoader(dataset, batch_size=args....\n",
       "9424     [python fixNvPe.py --input=C:\\Users\\user\\AppDa...\n",
       "9425     [import multiprocessing\\r\\nmultiprocessing.cpu...\n",
       "9426     [import torch, import torch\\r\\n\\r\\nif __name__...\n",
       "9427     [conda install pytorch torchvision torchaudio ...\n",
       "9428     [transpose(), [T,H,W,2] -&gt; [T,2,H,W], grid,...\n",
       "9429     [def grid2im(grid):\\r\\n    \"\"\"Reshape a grid t...\n",
       "9430                                                   NaN\n",
       "9431     [package_name/\\r\\n  package_name/\\r\\n    __ini...\n",
       "9432     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9433     [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "9434     [float32, float64, torch.set_printoptions(prec...\n",
       "9436     [encoder_states = tuple(hidden_state.transpose...\n",
       "9437     [n,l=2,3\\r\\narr=np.zeros((n,n,3,l,l))\\r\\n\\r\\nf...\n",
       "9438     [NameError, MNIST, MINST, import torch\\r\\nimpo...\n",
       "9439     [y_pred = (y_pred &gt; 0).float().requires_gra...\n",
       "9440     [torch.is_floating_point, assert torch.is_floa...\n",
       "9441                                                   NaN\n",
       "9442                                                   NaN\n",
       "9443                                                   NaN\n",
       "9444     [param_bytes * (history_size + 1) bytes, histo...\n",
       "9445     [waveform, sample_rate = torchaudio.load('test...\n",
       "9446     [(...,freq,frame), n_fft/2 + 1, inverse_mel_pr...\n",
       "9447     [specgram, (…, freq, frames), freq, n_fft // 2...\n",
       "9448     [plt, import torch, imshow, import torch, imshow]\n",
       "9449     [&amp;, torch, c = (a[:, 0] &lt; b[:, 1]) &amp...\n",
       "9450     [t = torch.tensor(...).reshape(320, 480, 3)\\r\\...\n",
       "9451     [t = torch.tensor(...).permute(1, 2, 0).numpy(...\n",
       "9452     [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "9453     [pc, (NUM_POINTS, 4), (X, Y, Z, C), sklearn, f...\n",
       "9454     [tsv, src_fp, tgt_fp = \"source/file/path.txt\",...\n",
       "9455     [torch.ops.torch_cluster.random_walk, pos_samp...\n",
       "9456     [img = Image.open(\"labeled-data/train_moth/mot...\n",
       "9457     [t_img = transforms(image)\\r\\nt_img = torch.ca...\n",
       "9458     [super(SingleNN, self).__init__(), super(NN, s...\n",
       "9459                              [EncoderRNN, DecoderRNN]\n",
       "9460     [self.transformer_encoder, _generate_square_su...\n",
       "9461                    [_generate_square_subsequent_mask]\n",
       "9462     [image, Nb, Nv, inC, inH, inW = image.shape\\r\\...\n",
       "9463     [RGB, image_loader, image = Image.open(image_n...\n",
       "9464     [batch_size*4*height*width, batch_size*3*heigh...\n",
       "9465     [and pipe its output with torch.nn.Softmax, to...\n",
       "9466     [class ConvolutionalNetwork(nn.Module):\\r\\n   ...\n",
       "9467     [study.optimize(autotune, n_trials=1)\\r\\n, def...\n",
       "9468                             [backward, loss.tolist()]\n",
       "9469     [train_loader = torch.utils.data.DataLoader(tr...\n",
       "9470     [start_time = time.time()\\r\\n\\r\\nwith torch.no...\n",
       "9471     [dL/dy_j, j&lt;n, y_j -= alpha * dL/dy_j, z, z...\n",
       "9472     [p=8, 1. x2 = x*x\\r\\n2. x4 = x2*x2\\r\\n3. x8 = ...\n",
       "9473     [out = x ** np.arange(p.shape[0]), np.cumprod,...\n",
       "9476     [m, import torch\\r\\n\\r\\nvals=[2,8]#let's assum...\n",
       "9477                                                   NaN\n",
       "9478                                      [sizeof(long)=4]\n",
       "9479     [cpu/torch-1.10.1-cp36-none-macosx_10_9_x86_64...\n",
       "9480     [-f https://download.pytorch.org/whl/torch_sta...\n",
       "9481     [from torch.nn.utils.rnn import pad_sequence\\r...\n",
       "9483     [logging, parent, root, root, Logger.info, han...\n",
       "9484                                [logging, basicConfig]\n",
       "9485     [y_sorted, y_sort_idx = y.sort(dim=1, descendi...\n",
       "9486                                                   NaN\n",
       "9487     [    pred_sigmoid = pred.sigmoid()\\r\\n    targ...\n",
       "9488     [F_loss = self.alpha * (1-pt)**self.gamma * BC...\n",
       "9489     [a != a\\r\\n&gt;&gt; tensor([[False, False],\\r\\...\n",
       "9490     [dcgan_d.pth, dcgan_g.pth,   torch.save(gen.st...\n",
       "9492     [nn.Module, __getattr__, component, Lin2.__dic...\n",
       "9494                                                   NaN\n",
       "9495                               [torch.nn.SmoothL1Loss]\n",
       "9497                                                   NaN\n",
       "9498                                                   NaN\n",
       "9499     [n X d, desired_tensor, n = 2\\r\\nd = 5\\r\\nrand...\n",
       "9502     [pretrained=True, inception_v3, pretrained=Fal...\n",
       "9504     [requires_grad_, requires_grad_, xt, not defin...\n",
       "9506          [plt.imshow(images[6].permute(1, 2, 0))\\r\\n]\n",
       "9507     [import torch\\r\\nfrom torchvision.models impor...\n",
       "9508     [nn.Module, training, teacher_training, traini...\n",
       "9509            [import cv2\\r\\nprint(cv2.__version__)\\r\\n]\n",
       "9510     [model.children(), def init_weights(m):\\r\\n   ...\n",
       "9511     [def original_model(features, targets):\\r\\n   ...\n",
       "9512     [def translate_sentence(model, sentence, SRC, ...\n",
       "9513                                                   NaN\n",
       "9514     [target.shape # torch.Size([10, 1])\\r\\n, targe...\n",
       "9515     [at::Tensor finput = at::empty({0},input.optio...\n",
       "9516     [for epoch in range(2):\\r\\n    for i, data in ...\n",
       "9517                                                   NaN\n",
       "9518     [class RBM(nn.Module):\\r\\n    '''\\r\\n    This ...\n",
       "9519     [random_split, torch.utils.data, Dataset, Data...\n",
       "9520          [mitmovie_pt_distilbert_uncased/results\\r\\n]\n",
       "9521     [from transformers import AutoTokenizer, AutoM...\n",
       "9522     [sudo USE_ROCM=1 USE_LMDB=1 USE_OPENCV=1 MAX_J...\n",
       "9523     [maxpool, conv, padding = 0, padding = int(pad...\n",
       "9525        [if __name__ == '__main__':\\r\\n    main()\\r\\n]\n",
       "9526     [num_workers, 0, DataLoader, trainloader = tor...\n",
       "9527     [import torch.multiprocessing as mp, mp.use_st...\n",
       "9528     [Configuration type, Dynamic Library (dll), Li...\n",
       "9529     [X = np.array([[1,2],[3,4],[5,6],[6,7]])\\r\\n\\r...\n",
       "9531     [kernel_size=1, kernel_size=3, self.branch2 = ...\n",
       "9532     [optimizer.zero_grad()\\r\\n, for i in range(10)...\n",
       "9533                                                   NaN\n",
       "9534                                                   NaN\n",
       "9536     [self.output, class Net(torch.nn.Module):\\r\\n ...\n",
       "9537     [neg_pears_loss = Neg_Pearson()\\r\\nloss = neg_...\n",
       "9538     [Neg_Pearson, __init__, self, loss_ecg = Neg_P...\n",
       "9539     [images = self.data.iloc[idx, 1:-1].values.ast...\n",
       "9540     [# Forward Pass\\r\\noutputs = model(images.floa...\n",
       "9541     [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "9542     [[1, 1, 0, 0, 0], [0, 1, 0, 0, 1] - multilabel...\n",
       "9544                                                   NaN\n",
       "9545     [unique_no_split_tokens, from_pretrained, #fro...\n",
       "9546     [model = torch.hub.load('pytorch/vision:v0.6.0...\n",
       "9547     [(classifier): Sequential(\\r\\n   ...\\r\\n   (6)...\n",
       "9548     [torchvision.transforms, ToTensor(), numpy.arr...\n",
       "9549     [hidden[0], hidden = ( torch.zeros((batch_size...\n",
       "9552     [import torch.nn.functional as F\\r\\n\\r\\ndef lo...\n",
       "9553     [import io\\r\\nimport numpy as np\\r\\nfrom torch...\n",
       "9554     [torch.float32, FloatTensor, x, weight, bias, ...\n",
       "9555     [float32, double, data_X = np.array(data.iloc[...\n",
       "9556     [wd*w, wd, # Ist: Adam weight decay implementa...\n",
       "9557     ['true ', label_map, Data[LABEL_COLUMN] = Data...\n",
       "9559     [hidden = torch.zeros(layers, batch_size, hidd...\n",
       "9560                                                   NaN\n",
       "9561     [!conda create -n easyocr python=3.8\\r\\n\\r\\n!c...\n",
       "9562                                                   NaN\n",
       "9563     [(32, 3, 128), import torch.nn as nn\\r\\nimport...\n",
       "9564     [einsum, torch.einsum('ijk, ikl-&gt;ijl', mats...\n",
       "9565     [torch.cumprod, import torch\\r\\n\\r\\nt = torch....\n",
       "9566     [list(), model.save_dict(), save_pretrained(),...\n",
       "9567     [BertModel, set(), unique_labels = set([label ...\n",
       "9568                                                   NaN\n",
       "9569                                                   NaN\n",
       "9570     [# Training images and annotations\\r\\n'train_i...\n",
       "9571                                                   NaN\n",
       "9572     [if \"y\":\\r\\n    return data, target\\r\\nelse:\\r...\n",
       "9573             [forward(), self.encode(x.view(-1,1998))]\n",
       "9574     [DataParallel, module, model.conv3., model.mod...\n",
       "9575                                                   NaN\n",
       "9576     [isnan(), any(), tensor, filtered_tensor = ten...\n",
       "9577     [ModuleList, from torch import nn\\r\\nfrom torc...\n",
       "9578     [t[torch.arange(t.shape[0]).unsqueeze(1), inde...\n",
       "9579     [msk1 = msk1.numpy()\\r\\n, ValueError: Floating...\n",
       "9580     [import torch\\r\\nclass DeviceDict:\\r\\n    def ...\n",
       "9581     [class DeviceDict(dict):\\r\\n\\r\\n    def __init...\n",
       "9583     [None, hidden_state = torch.zeros(size=(num_la...\n",
       "9584               [[batch_size], [batch_size, n_classes]]\n",
       "9585                                                   NaN\n",
       "9586     [last_hidden_state, model.encoder(input_ids=s,...\n",
       "9587     [y_pred = torch.sigmoid(weights@inputs + bias)...\n",
       "9588                                 [nn.CrossEntropyLoss]\n",
       "9589     [class MyDataset(torch.utils.data.Dataset):\\r\\...\n",
       "9590                                                   NaN\n",
       "9591     [unsqeeze, 0, 0, before = torch.tensor(..., dt...\n",
       "9592     [torch.Tensor.expand, b = a1.expand([2, 3, 3, ...\n",
       "9593                                                   [a]\n",
       "9594     [L = Feedforward(2,10)\\r\\nf = Feedforward(3,9)...\n",
       "9595     [def cov(x, rowvar=False, bias=False, ddof=Non...\n",
       "9596     [nn.moduleDict, forward, nn.Sequential, Ordere...\n",
       "9597     [to_dense, s = torch.sparse_coo_tensor(i, v, [...\n",
       "9598                                                   NaN\n",
       "9599     [def linear_flops_counter_hook(module, input, ...\n",
       "9600                                                   NaN\n",
       "9601                                                   NaN\n",
       "9602                                                   NaN\n",
       "9603     [model.hidden = model.init_hidden(hidden_dim),...\n",
       "9604     [ar = torch.stack(\\r\\n    (index, vector([inde...\n",
       "9605     [4, import pandas as pd\\r\\nimport torch\\r\\n\\r\\...\n",
       "9606     [A = torch.randint(0,5,(5,))\\r\\nC = (A.view(1,...\n",
       "9607     [import torch\\r\\nA = torch.randint(0, 5, (3, 2...\n",
       "9608                                     [768*num_classes]\n",
       "9609     [ROC AUC = 0.98, train loss = 0.0988, validati...\n",
       "9610                                                   NaN\n",
       "9611     [import torch\\r\\n\\r\\nembeddings = torch.nn.Emb...\n",
       "9612     [x = tf.reshape(x, [16, 50, 36, 1])\\r\\nx = tf....\n",
       "9613                                                   NaN\n",
       "9614                                              [Tensor]\n",
       "9615                                           [multi_dot]\n",
       "9616     [from torch.linalg import multi_dot\\r\\n\\r\\nmul...\n",
       "9617     [torch/nn/modules/module.py, parameters(), Go ...\n",
       "9618                          [torch.nn.Module.parameters]\n",
       "9619     [builder.add_softmax(name=\"softmax\", input_nam...\n",
       "9620                                                   NaN\n",
       "9621     [torch.autograd.Function, forward, backward, @...\n",
       "9622                                                   NaN\n",
       "9623                                          [self.vocab]\n",
       "9624     [autograd.grad, create_graph, True, ic, torch....\n",
       "9625                                                   NaN\n",
       "9626                                                   NaN\n",
       "9627     [def get_model():\\r\\n    model = models.vgg16(...\n",
       "9628     [nn.Module.named_parameters, nn.Module.paramet...\n",
       "9629     [from coremltools.converters.mil import Builde...\n",
       "9630     [torch.int_repr(), import torch\\r\\nimport nump...\n",
       "9631     [training_epoch_end(), validation_epoch_end(),...\n",
       "9632              [training_step_end, validation_step_end]\n",
       "9633                                                   NaN\n",
       "9634     [numpy, numpy, tensorflow2.x, pytorch, numpy, ...\n",
       "9635     [from tensorflow.python.ops.numpy_ops import n...\n",
       "9636                                                   NaN\n",
       "9637     [for param_group in optimizer.param_groups:\\r\\...\n",
       "9638                                                   NaN\n",
       "9639     [conda list, (pytorch) C:\\User, PS C:\\User, Se...\n",
       "9640     [pytorch_project, conda install pytorch torchv...\n",
       "9641     [torchbiggraph, import json\\r\\n    \\r\\ndef pre...\n",
       "9642                                     [parse_config.py]\n",
       "9643     [auto tensor = torch::linspace(0, 10, 10).inde...\n",
       "9644                                                   NaN\n",
       "9645                                                   NaN\n",
       "9646                                                   NaN\n",
       "9647                                                   NaN\n",
       "9648     [feature_sizes, # Given that:\\r\\nfeature_sizes...\n",
       "9649     [Input: (N,C) where C = number of classes\\r\\nT...\n",
       "9650                                                   NaN\n",
       "9651                                                   NaN\n",
       "9653                                                   NaN\n",
       "9655     [def view_as_windows_torch(image, shape, strid...\n",
       "9656                                                   NaN\n",
       "9657                                                   NaN\n",
       "9658     [ctx.save_for_backward, forward(), backward(),...\n",
       "9659     [glob.glob, glob.glob, os.listdir, self.img_fi...\n",
       "9660     [sequences[torch.arange(len(sequences)), selec...\n",
       "9661     [torch.gather, sequences.gather(dim=1, index=t...\n",
       "9663                                                   NaN\n",
       "9664                                                   NaN\n",
       "9665     [nn.ModuleList, nn.ModuleDict, nn.Module, impo...\n",
       "9666     [3.7253e-09 / 0.0398, torch.finfo(torch.float3...\n",
       "9667     [tensor.contiguous(), x2 = x_all_import['x_all...\n",
       "9668                                                   NaN\n",
       "9669     [output_add = 1d_tensor[:, None, None] + 3d_te...\n",
       "9670     [ptflops, from ptflops import get_model_comple...\n",
       "9671     [model = YourModelClass()\\r\\nmodel.load_state_...\n",
       "9672     [def step(self, action):\\r\\n    # Check if age...\n",
       "9674     [a.T.reshape(shape[::-1]).T, a,  a = np.arange...\n",
       "9675     [from torch.distributions.kl import _KL_REGIST...\n",
       "9676     [-3, (b, c, h, w), b, c, h, w, torch.cat(), di...\n",
       "9677     [model=torch.load('corelK_model_0.pt')\\r\\nmode...\n",
       "9680     [def get_scale_mat(m, device, dtype):\\r\\n    s...\n",
       "9681     [IterableDataset, import numpy as np\\r\\nfrom t...\n",
       "9682     [Storage, FloatStorage.from_file, import torch...\n",
       "9683     [np.save, np.save('data.npy', x)\\r\\nretrieved_...\n",
       "9685     [.8.0a0+342069f, 1.8.0., torch.cat, torch.cat(...\n",
       "9686     [DataLoader, shuffle=True, self.add, shuffle=T...\n",
       "9688     [input_list=torch.tensor([])\\r\\noutput_list=to...\n",
       "9689     [train_dl = DataLoader(dataset, batch_size=32,...\n",
       "9690     [if __name__ == '__main__' and '__file__' in g...\n",
       "9691     [num_workers &gt; 0, num_workers = 0, if __nam...\n",
       "9692     [m, theta = atan(1/m), get_shear_mat, ax=0, ax...\n",
       "9693                                                   NaN\n",
       "9694                                                   NaN\n",
       "9696     [state_dict(), Module, dict, weight, bias, imp...\n",
       "9698                                                   NaN\n",
       "9699     [!pip install --pre torch torchvision -f https...\n",
       "9700     [    norm_landmarks = transforms.Normalize(0.4...\n",
       "9701     [train_CIFAR10, valid_dataloader, CIFAR10_test...\n",
       "9702     [self.maxpool, self.maxpool = nn.MaxPool2d(2),...\n",
       "9703     [self.maxpool = nn.MaxPool2d(2), self.maxpool ...\n",
       "9704     [val totRows = rdd_df.count\\r\\n\\r\\nval maxRows...\n",
       "9706     [import torch\\r\\n\\r\\nconv = torch.nn.Conv1d(1,...\n",
       "9707     [%load_ext tensorboard\\r\\n, %tensorboard --log...\n",
       "9708     [torch.multiprocessing.set_start_method('spawn...\n",
       "9709     [no_grad, with torch.no_grad():\\r\\n    valid_m...\n",
       "9710     [wrap, np.pad(x, ((0,0),(1,1)), mode='wrap')\\r...\n",
       "9711     [ a = torch.randint(0, 9, (1, 3, 3))\\r\\n a\\r\\n...\n",
       "9712                                                   NaN\n",
       "9713     [for i in range(len(train_dataset)):\\r\\n    la...\n",
       "9714     [import torch\\r\\nfrom torchvision import trans...\n",
       "9715     [mean, std, image_arr = []\\r\\nfor i in range(l...\n",
       "9716                                                   NaN\n",
       "9717     [sudo rmmod nvidia_uvm, sudo modprobe nvidia_uvm]\n",
       "9718     [[600], [8, 600, 800, 3], # (N, 600, 800, 3) -...\n",
       "9719     [nn.Linear(7500, 4950)\\r\\n, nn.Flatten, images...\n",
       "9720                                                   NaN\n",
       "9721     [images_data, uint8, float, (images_data * 1.0...\n",
       "9722     [DataLoader, iter(train_loader), next, next(it...\n",
       "9723     [import torch\\r\\n\\r\\n\\r\\ndef beam_search_decod...\n",
       "9724     [#pip install pytorch-beam-search\\r\\nfrom pyto...\n",
       "9725     [!git clone https://github.com/cocodataset/coc...\n",
       "9726                                                   NaN\n",
       "9727     [unfold, t.unfold(0,4,2)\\r\\n, tensor([[ 1.,  2...\n",
       "9728     [gru1, ....\\r\\ngru1_opt.step()\\r\\ngru1_output,...\n",
       "9729     [a = torch.randn(1,305760)\\r\\nN = a.shape[1]\\r...\n",
       "9731                                                   NaN\n",
       "9732     [NeuralNetBinaryClassifier, y, (x, 1), (x,), y...\n",
       "9733     [train_loader = torch.utils.data.DataLoader(tr...\n",
       "9734     [MothLandmarksDataset, Dict, sample, torchvisi...\n",
       "9737                                                   NaN\n",
       "9738                                      [rebuild_tensor]\n",
       "9739     [raw = self.data_frame.values[idx].astype(np.f...\n",
       "9740                           [bounding box, class label]\n",
       "9741     [emotion_detector = EmotionRecognition(device=...\n",
       "9742     [emotion_detector = EmotionRecognition(device=...\n",
       "9743                                        [which python]\n",
       "9744     [mxnet.nd.Convolution, from mxnet import nd\\r\\...\n",
       "9746     [a[:, 0], a[:, 1], a[i, 0], a[i, 1], a[:, 0], ...\n",
       "9747     [[c, d], [a, b], [c, d], [a, b], [[a,b], [c,d]...\n",
       "9748                                                   NaN\n",
       "9749     [a, b, c, 1000 x 1000, NumPy, PyTorch, Python,...\n",
       "9750     [mat = [[1,2,3],[4,5,6],[7,8,9],[10,11,12],[13...\n",
       "9751     [playing, play, ##ing, tokenized_sentence = to...\n",
       "9752     [transforms.Resize, PIL.Image, input, img, tor...\n",
       "9753     [output = model(data.float())\\r\\nlabels = outp...\n",
       "9754     [nn.Module, class Model(nn.Module):\\r\\ndef __i...\n",
       "9755     [mean(A[..., i:i+80, j:j+80] - B) = mean(A[......\n",
       "9756                                                   NaN\n",
       "9757                                                   NaN\n",
       "9758     [def reset_parameters(self) -&gt; None:\\r\\n   ...\n",
       "9759                                                   NaN\n",
       "9761     [area, torch.nn.functional.interpolate, 1/area...\n",
       "9763                                                   NaN\n",
       "9764                                               [colab]\n",
       "9766                                                   NaN\n",
       "9767                                                   NaN\n",
       "9768     [leaf, tensor.is_leaf, requires_grad, False, r...\n",
       "9769                                                   NaN\n",
       "9771                                                   NaN\n",
       "9772     [torch.float64, torch.double, torch.float32, t...\n",
       "9773       [FROM python:latest\\r\\n, FROM python:3.7.4\\r\\n]\n",
       "9774                                                   NaN\n",
       "9775     [0th, 1, output = net(input)\\r\\n\\r\\nbinary_mas...\n",
       "9776     [[batch, 32, 7, 7], [batch, 32, 16, 16], resha...\n",
       "9777     [nn.Linear, 32*16*16, 32, 16, Conv2d, print(x....\n",
       "9778     [torch.tensor(), torch.tensor(), torch.stack()...\n",
       "9779     [# Solution is this wrapper function\\r\\ndef mo...\n",
       "9781                                                   NaN\n",
       "9782     [unfold, t.unfold(0,4,1).transpose(2,1)\\r\\n, t...\n",
       "9783     [Sample_Class, PIL.Image, accimage.Image, defa...\n",
       "9784     [import torchvision, torch\\r\\nfrom torchvision...\n",
       "9785     [v, i = torch.topk(a.flatten(), 3)\\r\\nprint (n...\n",
       "9786     [flatten, topk, def descalarization(idx, shape...\n",
       "9787     [print(a)\\r\\ntensor([[4, 9, 7, 4, 0],\\r\\n    [...\n",
       "9788     [    np.random.seed(42)\\r\\n    torch.manual_se...\n",
       "9789     [Conv1d, [batch_size, in_channels, data_dimens...\n",
       "9790     [import torch\\r\\nimport torch.nn as nn\\r\\nx = ...\n",
       "9792                                                   NaN\n",
       "9793     [import torch\\r\\nfrom transformers import Bert...\n",
       "9794     [ import numpy as np\\r\\n import torch\\r\\n from...\n",
       "9795     [x, x, Tensor, Tensor, autograd, torch.ones(n,...\n",
       "9797     [nn.Identity, no-op, class Residual(torch.nn.M...\n",
       "9798                                                   NaN\n",
       "9799                                                   NaN\n",
       "9800                                                   NaN\n",
       "9801     [gcloud compute --project=${PROJECT_ID} instan...\n",
       "9803                                                   NaN\n",
       "9804     [nn.CrossEntropyLoss, X, ce_loss(X * 1000, tor...\n",
       "9805     [def compute_crossentropyloss_manual(x,y0):\\r\\...\n",
       "9806     [import os\\r\\nos.environ[\"KMP_DUPLICATE_LIB_OK...\n",
       "9808                                    [CIFAR10/CIFAR100]\n",
       "9809     [optimizer.step(), optimizer.step(), softmax, ...\n",
       "9810     [.pt, torch.load('models/model.pt', map_locati...\n",
       "9811     [Foo, Foo, class Foo(object):\\r\\n  def __init_...\n",
       "9812                                       [.pt, .pt, .pt]\n",
       "9813     [torch.nn.init, nn.init.normal_, \"gaussian\", n...\n",
       "9814                                                   NaN\n",
       "9817                                                   NaN\n",
       "9819     [theta, torch.nn.functional.affine_grid, torch...\n",
       "9820     [x = torch.tensor([[0, 1],\\r\\n            [2, ...\n",
       "9821     [import torchvision.transforms.functional as T...\n",
       "9822     [train_data = np.array([np.sin(time), np.cos(t...\n",
       "9823     [name: torch\\r\\nchannels:\\r\\n  - pytorch\\r\\n  ...\n",
       "9824     [reshape, import torch\\r\\nimport numpy as np\\r...\n",
       "9825     [n, torch.nonzero(),  n = 2\\r\\n a[a.nonzero(as...\n",
       "9826     [dtypes, snake_case, my_dataset, net, CamelCas...\n",
       "9828     [output = net(input), model, output = net.modu...\n",
       "9829     [CUDA_LAUNCH_BLOCKING=1 python script.py, CUDA...\n",
       "9830                                                   NaN\n",
       "9832     [batch_size, torch.Size([batch_size]), [0, ......\n",
       "9835     [toTensor, maxpool, view, 28x28x1, BxCxWxH, nn...\n",
       "9836     [conda, - https://conda.anaconda.org/pytorch/w...\n",
       "9837     [math.floor, math.ceil, import math\\r\\n\\r\\n# f...\n",
       "9839     [rand_mat = torch.rand(n, d)\\r\\nk_th_quant = t...\n",
       "9840     [BertForSequenceClassification, from transform...\n",
       "9841     [from torch.optim import SGD\\r\\n\\r\\nmodel = .....\n",
       "9842     [from tensorflow import keras\\r\\nfrom transfor...\n",
       "9843     [a,b, (m,n), m = d( a[None, :, :], b[:, None, ...\n",
       "9845                   [nn.BatchNorm2d, __init__, forward]\n",
       "9846     [__len__, Dataset, def __len__(self):\\r\\n    r...\n",
       "9847                                                   NaN\n",
       "9848     [nn.MSELoss, nn.MSELoss, torch.nn.functional.m...\n",
       "9849     [m = MyMod()\\r\\ntorch.save(m.state_dict(), 'my...\n",
       "9850     [def save_model_txt(model, path):\\r\\n    fout ...\n",
       "9851     [def save_model_json(model, path):\\r\\n    actu...\n",
       "9852     [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "9853     [if torch.cuda.is_available():\\r\\n    generato...\n",
       "9854     [CrossEntropyLoss,  loss = nn.CrossEntropyLoss...\n",
       "9855     [nn.Linear, self.classifier, [10.3, -3.5, -12....\n",
       "9856     [softmax, prob = torch.nn.functional.softmax(m...\n",
       "9857     [matmul, with torch.no_grad():\\r\\n  depth_arra...\n",
       "9858     [self.save_hyperparameters('n_channels', 'n_cl...\n",
       "9859     [class MyClass():\\r\\n    def __init__(self, co...\n",
       "9860     [class MyClassBase():                         ...\n",
       "9861     [class MyClass():\\r\\n    def __init__(self, co...\n",
       "9862     [model2 = MyClass(2, 'B')\\r\\n, model2 = MyClas...\n",
       "9863                                                   NaN\n",
       "9864                                                   NaN\n",
       "9865     [optimizer.zero_grad(), optimizer.step(), mode...\n",
       "9866                                                   NaN\n",
       "9867     [BCEWithLogitsLoss, class LSTMClassifier(nn.Mo...\n",
       "9868                                                   NaN\n",
       "9871                                                   NaN\n",
       "9872                                                   NaN\n",
       "9873            [layer0.to('cuda:0'), layer1.to('cuda:1')]\n",
       "9874     [DataParallel, DataParallel, main.py, python m...\n",
       "9875                                                   NaN\n",
       "9876     [torch.cat(), out=, pt_num, requires_grad, req...\n",
       "9877     [cur_scores[1:] *= 0\\r\\n, cur_scores = conf_pr...\n",
       "9878     [t = torch.tensor([1., 0., 0., 1., 0., 1., 1.]...\n",
       "9879     [hidden_dim = 128 to 512\\r\\nlayer_dim = 2 to m...\n",
       "9881                                                   NaN\n",
       "9882                                              [Conv3d]\n",
       "9883     [batch_size, # load data into a DataFrame usin...\n",
       "9884                                                   NaN\n",
       "9885     [def average_parameters_vector(model_list):\\r\\...\n",
       "9886                                                   NaN\n",
       "9887     [Subset, Dataset, train_subset, val_subset = t...\n",
       "9888     [train_test_split, sklearn, import torchvision...\n",
       "9889                                                   NaN\n",
       "9890                                                   NaN\n",
       "9891     [conda activate myenv\\r\\n\\r\\ntorch.version.cud...\n",
       "9892     [torch.version.cuda\\r\\n, conda remove pytorch ...\n",
       "9893     [import matplotlib.pyplot as plt\\r\\nimport num...\n",
       "9894     [w = torch.tensor([2.], requires_grad=True)\\r\\...\n",
       "9895                                     [__init__, Saver]\n",
       "9896                                [CUDA_VISIBLE_DEVICES]\n",
       "9897                                                   NaN\n",
       "9898     [xy_trainPT = torchvision.datasets.MNIST(\\r\\n ...\n",
       "9899                              [ImageFolder, root, get]\n",
       "9900     [def stream_training(filepath, epochs=100):\\r\\...\n",
       "9902     [model = nn.Sequential(...), modelDp.parameter...\n",
       "9904                                [torch.Tensor.ones(1)]\n",
       "9905     [conda install pytorch==1.0.1 torchvision==0.2...\n",
       "9906     [# CUDA 9.0\\r\\nconda install pytorch==1.0.1 to...\n",
       "9907     [pip install torchaudio\\r\\n, Collecting torcha...\n",
       "9909                                                   NaN\n",
       "9910     [import torch\\r\\nimport torch.nn as nnn\\r\\nfc1...\n",
       "9911     [self.fc1 = nn.Linear(20, 64)\\r\\n, nn.Linear, ...\n",
       "9912                                                   NaN\n",
       "9913     [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "9914                                                   NaN\n",
       "9915     [y_pred = self.linear1(x)\\r\\n, y_pred =  F.rel...\n",
       "9916                                                   NaN\n",
       "9917     [.send(), .federate(), .location, ._objects, V...\n",
       "9918     [# CREATE THE UNFOLDED IMAGE SLICES\\r\\nI = ima...\n",
       "9919     [torch.nn.functional.fold, torch.nn.functional...\n",
       "9920     [import torch\\r\\ndef get_weighted_imgs(points,...\n",
       "9921     [def preprocess_function(examples):\\r\\n   #fun...\n",
       "9923     [from transformers import DataCollatorForToken...\n",
       "9925     [neural_renderer_pytorch, pytorch, pytorch, ne...\n",
       "9926     [AT_CHECK, AT_ASSERT, at_assert_fix, (base) mo...\n",
       "9927     ['''\\r\\n# I changed your code a little bit to ...\n",
       "9928     [ with torch.set_grad_enabled(is_train == \"tra...\n",
       "9929     [conda config --prepend channels https://publi...\n",
       "9930     [forward, DropoutLayer, else, flatten, Flatten...\n",
       "9931                     [nn.Sequential(Flatten()), nx786]\n",
       "9932                                                   NaN\n",
       "9933     [array.islice(start, end), __iter__, def __ite...\n",
       "9934     [torch.autograd.functional.hessian(), import t...\n",
       "9935     [output = torch.zeros_like(src)\\r\\nfor index i...\n",
       "9936     [def mask_max_pool(embeddings, mask):\\r\\n'''\\r...\n",
       "9937             [pip install torchtext==0.5.0 --user\\r\\n]\n",
       "9938     [simpletransformers, pip install --upgrade sim...\n",
       "9941     [alpha, iterations, # Create data:\\r\\nimport s...\n",
       "9942     [rgb_cov, torch.cholesky, import torch\\r\\ndef ...\n",
       "9943     [torch.Tensor(list), for (i,v) in zip(indices,...\n",
       "9944     [indices, indices = torch.tensor([(0,0),(1,0),...\n",
       "9945                                                   NaN\n",
       "9946     [import torch\\r\\nimport torch.nn.functional as...\n",
       "9947     [BS=2\\r\\nclass M(nn.Module):\\r\\n    def __init...\n",
       "9948     [model.py, trainer.ipynb, import sys  \\r\\nsys....\n",
       "9950                                                   NaN\n",
       "9951                                                   NaN\n",
       "9954                       [torch.mode(y, dim = 1)[0]\\r\\n]\n",
       "9955                                                   NaN\n",
       "9956     [lstm = nn.LSTM(input_size=26, hidden_size=128...\n",
       "9957     [loss_axis.append(loss_list), loss_axis.append...\n",
       "9958                                                   NaN\n",
       "9960     [forward(), def forward(self, x, h=None):\\r\\n ...\n",
       "9961     [conda env with python 3.8, pip install from w...\n",
       "9962                                                   NaN\n",
       "9963     [$ conda install -c conda-forge torchvision\\r\\...\n",
       "9964     [a.index_put(indices=[torch.tensor([1, 0]), to...\n",
       "9965     [dataset_full = torchvision.datasets.FashionMN...\n",
       "9966     [idx = dataset.train_labels == 1\\r\\ndataset.tr...\n",
       "9967     [dataset.train_labels, dataset.data, DataLoade...\n",
       "9968     [pipenv run pip install &lt;package&gt;, pipen...\n",
       "9969     [[[source]]\\r\\nname = \"pytorch\"\\r\\nurl = \"http...\n",
       "9970     [verify_ssl = true, --extra-index-url, pipenv ...\n",
       "9971     [...\\r\\n[[source]]\\r\\nurl = \"https://download....\n",
       "9972                                      [None, __init__]\n",
       "9973        [pip3 install torch==1.4.0 torchvision==0.5.0]\n",
       "9974     [pip install torch===1.6.0 torchvision===0.7.0...\n",
       "9975     [3, 1, 4 x 4, 2 x 2, 3 x 3, 2 x 2, padding=1, ...\n",
       "9976     [padding=1, import numpy\\r\\nimport torch\\r\\nim...\n",
       "9977     [import torch\\r\\nimport torchvision\\r\\nmodel =...\n",
       "9978     [w, b, torch.float32, data_input, from_numpy, ...\n",
       "9980     [help(), import torch\\r\\nt = torch.tensor([1,2...\n",
       "9981     [.numpy(), import numpy as np\\r\\n\\r\\nndarray =...\n",
       "9982     [sudo vi /etc/default/grub\\r\\n, #GRUB_CMDLINE_...\n",
       "9984                                                   NaN\n",
       "9985     [torch.arange, X  = torch.arange(0,6.28)\\r\\nx\\...\n",
       "9986     [Tensor.permute, def reshape_fortran(x, shape)...\n",
       "9987     [permute, reshape, numpy, reshape, import nump...\n",
       "9988     [to_sparse, a = torch.tensor([[5, 7], [9, 11]]...\n",
       "9989                                 [binary crossentropy]\n",
       "9990                                 [binary crossentropy]\n",
       "9991     [exploding gradient, model.lm_out.weight\\r\\n\\r...\n",
       "9992     [V = torch.tensor(self.W - self.lambda_ * torc...\n",
       "9993     [return -0.5 * V.inverse().mm(self.b + self.la...\n",
       "9994             [    L.append(output.detach().cpu())\\r\\n]\n",
       "9995     [import torch\\r\\nimport os\\r\\nimport numpy as ...\n",
       "9996     [eval, t = eval(\"tensor([[1,2,3],[4,5,6]], dev...\n",
       "9997                                                   NaN\n",
       "9998                                                   NaN\n",
       "9999     [amp, amp, step, step, loss.backward(), optimi...\n",
       "10000                                                  NaN\n",
       "10002    [drop_last, drop_last=True, number_of_training...\n",
       "10003    [model.to(device)\\r\\n, to, model = model.to(de...\n",
       "10004                                                  NaN\n",
       "10005    [np.linalg.det, def complex_det(A):\\r\\n    def...\n",
       "10007    [True, selectors, indices = torch.masked_fill(...\n",
       "10008    [Numpy, dataframe, to_numpy(), train_dl = Data...\n",
       "10009    [item['labels'] = torch.tensor(self.encodings[...\n",
       "10010                                                  NaN\n",
       "10011                                                  NaN\n",
       "10012                                                  NaN\n",
       "10013    [class MyModelParallelNetwork(nn.Module):\\r\\n ...\n",
       "10014    [device = torch.device('cuda' if torch.cuda.is...\n",
       "10015    [from transformers import AutoTokenizer\\r\\n\\r\\...\n",
       "10016                                                  NaN\n",
       "10017                                                  NaN\n",
       "10018    [import unittest\\r\\nimport torch\\r\\nfrom Seman...\n",
       "10019    [c10:Dict, at, auto value_a = output.at(key_a)...\n",
       "10022    [volatile, Variable, volatile=True, autograd, ...\n",
       "10023    [torch.load, torch.save, io.BytesIO, import io...\n",
       "10024    [import torch\\r\\n\\r\\nbs = 8\\r\\na = torch.zeros...\n",
       "10025    [ import math\\r\\n math.sin(2 * math.pi)\\r\\n-2....\n",
       "10026    [b = a.permute(1,0,2).contiguous().view(a.shap...\n",
       "10027    [a = torch.tensor([[[1, 2, 3], [4, 5, 6], [4, ...\n",
       "10028                                                  NaN\n",
       "10029                                                  NaN\n",
       "10030                                                  NaN\n",
       "10031                                                  NaN\n",
       "10032                                                  NaN\n",
       "10033                                                  NaN\n",
       "10034    [nlp = pipeline(\"question-answering\", model=BE...\n",
       "10035    [from transformers import AutoTokenizer, AutoM...\n",
       "10036                                                  NaN\n",
       "10037    [ __len__, __getitem__, from torchvision.model...\n",
       "10038                                                  NaN\n",
       "10039                                                  NaN\n",
       "10042    [batch_size = 48, batch_size=1, num_workers=0,...\n",
       "10043                                              [dtype]\n",
       "10044    [accuracy = ((torch.argmax(output,dim=1)==trg_...\n",
       "10045    [Models.py, class Transformer(nn.Module):\\r\\n ...\n",
       "10046                                              [index]\n",
       "10047    [# ... Setup your network, load the input\\r\\n#...\n",
       "10048                                                  NaN\n",
       "10049    [max, d(max_value)/d(v), max_value==v, d(max_i...\n",
       "10050    [a, b = torch.randn(2, requires_grad=True).unb...\n",
       "10051                       [Runtime &gt; Change runtime.]\n",
       "10052    [.contiguous(), contiguous, import torch\\r\\nW ...\n",
       "10053    [nums = [0]*10\\r\\nfor i in range(60000):\\r\\n  ...\n",
       "10054                                                  NaN\n",
       "10055    [torch.nn.Module.named_parameters, torch.nn.Mo...\n",
       "10057    [nvcc, nvidia-smi, conda, CUDA 10.2, conda lis...\n",
       "10058                                  [conda install\\r\\n]\n",
       "10059    [client_model = keras.models.Sequential([keras...\n",
       "10061    [add_hparams, 1599742915.9712806, 2020-09-10 1...\n",
       "10062    [torch.utils.data.Dataset, import torch\\r\\nfro...\n",
       "10063    [img, target, img, int, dataloader, dataset, L...\n",
       "10065    [to, labels = torch.tensor(labels).to(device),...\n",
       "10066    [torch.manual_seed(0), np.random.seed(0), torc...\n",
       "10067    [batch_first=True, batch_first=False, import t...\n",
       "10069    [loss = loss_function(tag_scores, l.view(-1,1)...\n",
       "10070    [import torch\\r\\n\\r\\nx1 = torch.tensor(1).floa...\n",
       "10071    [cd /home/parikshit/.local/lib/python3.6/site-...\n",
       "10072    [cd /home/parikshit/.local/lib/python3.6/site-...\n",
       "10073    [grad, L, x = x - learning_rate * x.grad, [0.1...\n",
       "10074                                                  NaN\n",
       "10075    [torch.nn.Module.parameters(), torch.nn.parame...\n",
       "10077    [class Generator(nn.Module):\\r\\n    __main: nn...\n",
       "10078                                                  NaN\n",
       "10079                                                  NaN\n",
       "10080    [[item[0] for item in your_list]\\r\\n, li = [[t...\n",
       "10081    [\\r\\nimport torch\\r\\nimport numpy as np\\r\\nx =...\n",
       "10082    [reduction='sum', reduction='mean', reduction=...\n",
       "10083    [cudatoolkit, conda, conda install pytorch tor...\n",
       "10084    [ $ ubuntu-drivers devices\\r\\n== /sys/devices/...\n",
       "10085    [self.channels_dnsnets, list, state_dict, self...\n",
       "10086                                                  NaN\n",
       "10087                                                  NaN\n",
       "10088                        [NeuralNet, NeuralNet, score]\n",
       "10089    [score(), scoring='neg_mean_squared_error', r ...\n",
       "10090    [import torch\\r\\na = torch.zeros(300000000, dt...\n",
       "10091    [def pretty_size(size):\\r\\n    \"\"\"Pretty print...\n",
       "10092      [cuda = torch.device('cuda')\\r\\na.to(cuda)\\r\\n]\n",
       "10093    [import gc\\r\\nimport torch\\r\\ngc.collect()\\r\\n...\n",
       "10094                           [torch.cuda.empty_cache()]\n",
       "10095    [#include &lt;torch/extension.h&gt;\\r\\n\\r\\nflo...\n",
       "10097    [tensor.accessor&lt;scalar_dtype, num_dimensio...\n",
       "10098    [with torch.no_grad(), no_grad, with torch.no_...\n",
       "10099    [self.net, import torch\\r\\nimport torch.nn as ...\n",
       "10100    [a @ b.t(), torch.diag(a @ b.t()), torch.einsu...\n",
       "10101    [torch, np.einsum, @, In [147]: a = np.arange(...\n",
       "10102    [train_x_0.npy, train_x_1.npy, dataloader, fro...\n",
       "10103    [target, torch.max, torch.argmax, tmp_input = ...\n",
       "10105    [torch.tensor, float, tr_mat = torch.tensor(\\r...\n",
       "10106    [net = UNet(8) # network object having 8 class...\n",
       "10107    [t, model = nn.Linear(1, 1, bias=False)\\r\\n\\r\\...\n",
       "10109    [interpolate, transforms, size=(28, 28), mode,...\n",
       "10110                                                  NaN\n",
       "10112    [  if use_loop == False:\\r\\n      z = torch.bm...\n",
       "10113    [docker run --rm --gpus all nvidia/cuda nvidia...\n",
       "10114    [deploy:\\r\\n  resources:\\r\\n    reservations:\\...\n",
       "10115    [class PadEven(nn.Module):\\r\\n    def __init__...\n",
       "10116    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "10117    [@njit(cache=True)\\r\\ndef indexFunc(array, ite...\n",
       "10118    [        train_loader = torch.utils.data.DataL...\n",
       "10119    [1, new_val = (old_val - old_mean) / old_stdev...\n",
       "10120    [StandardScaler, STD=1, Mean=0, MinMaxScaler, ...\n",
       "10121    [A_var = np.zeros_like(A)\\r\\n, dist_A = torch....\n",
       "10122    [BertForSequenceClassification, tokenizer = Be...\n",
       "10124    [k=100, k=15, class BootstrappedCE(nn.Module):...\n",
       "10125    [functional, torch.nn.functional.cross_entropy...\n",
       "10126                                                  NaN\n",
       "10127                                                  NaN\n",
       "10129                                                  NaN\n",
       "10131    [torch.cdist, res = torch.cdist(mat, mat2.perm...\n",
       "10132    [@, mat @ mat2\\r\\n, ||m_i - v||^2, m_i, M, v, ...\n",
       "10133                                                  NaN\n",
       "10134    [lengths, cost_function.prediction_loss, (torc...\n",
       "10135                              [1/num_elements, 1/707]\n",
       "10136             [multiprocessing, torch.multiprocessing]\n",
       "10137    [import cv2\\r\\nimport numpy as np\\r\\nfrom tqdm...\n",
       "10138    [torch.save(net.state_dict(), &lt;save_path&gt...\n",
       "10140    [SparseCategoricalCrossentropy, CrossEntropyLo...\n",
       "10141                                                  NaN\n",
       "10142                                                  NaN\n",
       "10143                                                  NaN\n",
       "10144                                                  NaN\n",
       "10145    [mask = torch.tensor([[[1, 1, 1, 0]], [[1, 0, ...\n",
       "10146    [    def forward(self,x, y, lengths, mask):\\r\\...\n",
       "10148    [class DummyModule_1(nn.Module):\\r\\n    def __...\n",
       "10149     [writer.add_image('image', np.ones((3,3,3)), 0)]\n",
       "10150                                                  NaN\n",
       "10151    [import numpy as np\\r\\n\\r\\n# 2 forward passes,...\n",
       "10152    [torch, numpy,   x = torch.Tensor(...) # Fill-...\n",
       "10153    [elif l[0] == 'output_bias':\\r\\n    pointer = ...\n",
       "10154                                                  NaN\n",
       "10155                                                  NaN\n",
       "10156                                                  NaN\n",
       "10159    [requires_grad, True, .to(device), .cuda(), .c...\n",
       "10160    [gcloud beta notebooks instances create cuda11...\n",
       "10161    [import wandb\\r\\nwandb.init(sync_tensorboard=T...\n",
       "10162                                             [img_in]\n",
       "10163                                                  NaN\n",
       "10164    [lights = torch.normal(0, 1, size=[100, 3], de...\n",
       "10165    [conda, conda, (base) pointr@alienware:~/anaco...\n",
       "10166                                                  NaN\n",
       "10167    [itertools.islice(), SequentialSampler, shuffl...\n",
       "10168                      [cuPy.cuda.Device(1).use()\\r\\n]\n",
       "10169    [def save_checkpoint(model, optimizer, save_pa...\n",
       "10170    [@, @, numpy, matmul, y, [50,2], [2,1], [50,1]...\n",
       "10171    [ImgDataset.__getitem__(), ImgDataset.__getite...\n",
       "10172    [sync; echo 3 &gt; /proc/sys/vm/drop_caches, m...\n",
       "10173                                                  NaN\n",
       "10174                                      [torch.reshape]\n",
       "10175    [z = torch.narrow(x,1,0,512)\\r\\nz.shape\\r\\ntor...\n",
       "10176    [CrossEntropyLoss, (N, C, ...), preds, (batch_...\n",
       "10177    [model = AlbertModel.from_pretrained\\r\\n, mode...\n",
       "10178    [predictions, targets = [], []\\r\\nfor images, ...\n",
       "10179    [x = x.view(-1, 1024), x = x.view(-1, 1024)\\r\\...\n",
       "10180    [y = x + 2, z = y * y * 3, 3 * (x+2)^2, out = ...\n",
       "10181    [torch.randn, a = torch.ones([2, 2], dtype=tor...\n",
       "10182                [torch.randn(2,2), torch.Tensor(arr)]\n",
       "10183    [Process, from torch.multiprocessing import Po...\n",
       "10184     [celery -A your_proj worker -P solo -l info\\r\\n]\n",
       "10185    [CELERYD_FORCE_EXECV, &lt;4.0, CELERYD_FORCE_E...\n",
       "10186    [optimizer = optim.Adam(ma.parameters(), lr=0....\n",
       "10187    [for epoch in range((args.start_epoch+1), args...\n",
       "10188    [loss=criterion(y_pred,y.flatten())\\r\\n, loss=...\n",
       "10189    [Nan, Infy, learning_rate = 0.001, batch_size ...\n",
       "10190    [loss_f = nn.MSELoss()\\r\\n, loss_f = nn.MSELos...\n",
       "10191                                   [pytorch, pytorch]\n",
       "10192    [reset_parameters, for layer in model.children...\n",
       "10193    [def lp_norm(mdl: nn.Module, p: int = 2) -&gt;...\n",
       "10194    [dic = Model.state_dict()\\r\\nfor k in dic:\\r\\n...\n",
       "10195    [to_event(n), import torch\\r\\nimport pyro\\r\\ni...\n",
       "10197                       [torch.unsqueeze(input_ids,0)]\n",
       "10198                                                  NaN\n",
       "10199    [alpha = torch.tensor([])\\r\\n\\r\\nIn[5]:  alpha...\n",
       "10200    [torch.empty(5,3,0)\\r\\n tensor([], size=(5, 3,...\n",
       "10202    [outs = []\\r\\nfor x, y in zip(X, Y):  # X, Y c...\n",
       "10203    [array = torch.randint(10, (4,4))\\r\\nmask = to...\n",
       "10204    [torch.nanmedian, def masked_median(x, mask, d...\n",
       "10205                                                  NaN\n",
       "10206    [torch.tensor, scipy.ndimage.rotate, torch.ten...\n",
       "10207    [import torch\\r\\nf = torch.tensor([1, 0, 0, 0,...\n",
       "10209    [torch.nn.Linear, torch.nn.Module, __call__, t...\n",
       "10212    [load_state_dict(), net1=LSTM_net(input_size=5...\n",
       "10213    [edge_index, max, Net, import torch\\r\\nimport ...\n",
       "10214    [img = Image.open(img_path)\\r\\nimg = img.conve...\n",
       "10215                                                  NaN\n",
       "10216    [input, input, import torch\\r\\nfrom torch.nn i...\n",
       "10217                                                  NaN\n",
       "10218    [model = GPT2LMHeadModel.from_pretrained('dist...\n",
       "10220    [.parameters(), X = torch.nn.Conv2d(in_channel...\n",
       "10221                                                  NaN\n",
       "10222                                                  NaN\n",
       "10223    [for param in model.parameters():\\r\\n    param...\n",
       "10224    [from torchtext import data\\r\\nfrom torchtext ...\n",
       "10225                                                  NaN\n",
       "10226                                                  NaN\n",
       "10227    [__getitem__, transform = transforms.Compose([...\n",
       "10228    [osp.realpath(\"__file__\"), osp.realpath(__file...\n",
       "10229                                 [__file__, __file__]\n",
       "10230    [torch.tensor, np.ndarray, torch.tensors, np.n...\n",
       "10232    [import torch\\r\\ntensor = torch.rand(2)\\r\\nnum...\n",
       "10233                            [train, Trainable, train]\n",
       "10234    [# This is to create the Dataset\\r\\nfrom torch...\n",
       "10235                                                  NaN\n",
       "10236             [grad_fn= &lt;CatBackward&gt;, torchviz]\n",
       "10237    [        degenerate_boxes = boxes[:, 2:] &lt;=...\n",
       "10238    [[-1, 1], import torch\\r\\nimport torch.nn.func...\n",
       "10239    [@staticmethod\\r\\ndef forward(self, loc_data, ...\n",
       "10240                                                  NaN\n",
       "10241    [torch.unique_consecutive, cat, # We want to f...\n",
       "10242    [    class VideoRNN(nn.Module):\\r\\n    def __i...\n",
       "10243    [seq_len = 10, batch_size, 143, batch_size = 2...\n",
       "10244                                                  NaN\n",
       "10245    [score.retain_grad(), register_hook, if score....\n",
       "10248                                                  NaN\n",
       "10249    [jax.jacfwd, jax.jacrev, jax.jvp, jax.vjp, Rᴺ ...\n",
       "10250    [A 500-type error (e.g. 500, 501, 502, 503, et...\n",
       "10251    [-J, def Arrow_Hurwicz_algorithm(dim,NMC,S12,i...\n",
       "10254    [nn.Modules, unsqueeze, t_img, flatten, layer,...\n",
       "10255    [model(t_img), model(t_img[None])\\r\\n, [1,3,22...\n",
       "10256    [$ seq 1 4 | parallel -j4 -u taskset -c {%} &l...\n",
       "10257    [taskset, parallel, parallel, my_bash_script.s...\n",
       "10258    [...\\r\\nFile \"stanza/pipeline/depparse_process...\n",
       "10259    [multiprocessing.Pool, semaphore = mp.BoundedS...\n",
       "10261                                                  NaN\n",
       "10262                                                  NaN\n",
       "10264    [train, val = train.reset_index(drop=True), va...\n",
       "10265    [torch.lstq(a, b), np.linalg.lstsq(a, b), a = ...\n",
       "10266    [self.imgs_folder = img_folder\\r\\n\\r\\nself.img...\n",
       "10268    [pip show torch, Name: torch\\r\\nVersion: 1.3.1...\n",
       "10270    [img[indices[:,0], indices[:,1]]\\r\\ntensor([[ ...\n",
       "10271    [layers = [\\r\\n    nn.Conv2d(in_channels, midd...\n",
       "10272                                                  NaN\n",
       "10273    [DataLoader, Dataset, InfDataloader, class Inf...\n",
       "10274                                                  NaN\n",
       "10278    [import tracemalloc\\r\\ntracemalloc.start()\\r\\n...\n",
       "10279    [features, .append, torch.cat(), import torch\\...\n",
       "10280    [tensors, torch.Tensor.numpy, features = np.ar...\n",
       "10281    [CMD, nvidia/cuda, --no-install-recommends, ap...\n",
       "10282    [/usr/local/lib/python/site-packages/, /usr/lo...\n",
       "10283                                                  NaN\n",
       "10284    [def filelist(root, file_type):\\r\\n    flist =...\n",
       "10285    [torchvision.transforms.Resize(), PIL.Image.BI...\n",
       "10286                                      [view, reshape]\n",
       "10287                                                  NaN\n",
       "10289    [for operation in self.hidden:\\r\\n            ...\n",
       "10290    [print (model.hidden1.weight, model.hidden1.bi...\n",
       "10291     [Word2Vec, compute_loss=True, gensim-3.8.3, 0.0]\n",
       "10292    [F.pad(), tf.pad(), padding size, last dimensi...\n",
       "10293    [IndexError: too many indices for tensor of di...\n",
       "10294    [f(x,y), x, y, -1, x, register_hook, x.registe...\n",
       "10295    [n, torch.meshgrid, n, m = 10, 20   # arbitrar...\n",
       "10296                                                  NaN\n",
       "10297    [python api.py, gunicorn -w 2 api:app -k uvico...\n",
       "10298    [#include &lt;iostream&gt;\\r\\n#include &lt;alg...\n",
       "10299    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "10300    [float, TensorOptions, int N_SAMPLES = 10;    ...\n",
       "10301                                     [nn.BatchNorm1d]\n",
       "10302                                                  NaN\n",
       "10303    [forward, PyTorch, from typing import Callable...\n",
       "10305                                                  NaN\n",
       "10306    [/yourFileDir \\r\\no3_batch_1.hdf5\\r\\no3_batch_...\n",
       "10307    [\\r\\nclass MyContainer:\\r\\n  def __init__(self...\n",
       "10308    [img = torch.from_numpy(img).float() #use appr...\n",
       "10309    [torch.tensor, torch.reshape, torch.tensor, im...\n",
       "10310                                                  NaN\n",
       "10311    [torch::Tensor::is_same(const torch::Tensor&am...\n",
       "10313    [tensorboard, pip install tensorboard\\r\\n, ten...\n",
       "10314                                                  NaN\n",
       "10315    [net.eval(), def infer(net, name):, net.eval()...\n",
       "10316    [torch.nn.CrossEntropyLoss(reduction = \"sum\")\\...\n",
       "10317    [model.load_state_dict(torch.load(model_path))...\n",
       "10318                                      [torch.topk, k]\n",
       "10319    [num_workers, DataLoader, Manager, DataLoader,...\n",
       "10320    [output = model(images), non_blocking=True, to...\n",
       "10322                                                  NaN\n",
       "10324    [print(X_test.shape)\\r\\n(3071, 128, 128, 3)\\r\\...\n",
       "10325                                                  NaN\n",
       "10326    [for l in range(L):\\r\\n    mask = R[m[l-1], m[...\n",
       "10330    [    def init_hidden(self, batch_size = 1):\\r\\...\n",
       "10331    [self.hidden_0, class LSTM_net(nn.Module):\\r\\n...\n",
       "10332    [self, this, __call__, class A:\\r\\n    def __i...\n",
       "10333    [dataLoader = [[[img1_part1],[img1_part2],[img...\n",
       "10334    [def make_parts(full_image):\\r\\n    # some cod...\n",
       "10335    [pip install torchsummary\\r\\n, from torchsumma...\n",
       "10336    [import torch\\r\\nfrom torch import nn\\r\\nconv ...\n",
       "10337    [torch.nn.Parameter(), import torch\\r\\nfrom to...\n",
       "10338    [aws ecr get-login-password --region ${region}...\n",
       "10340    [rot_mat, backward(), import torch\\r\\nimport n...\n",
       "10341                                                  NaN\n",
       "10342    [    **resConv = models.resnet50(pretrained=Tr...\n",
       "10343    [# instantiate you encoder (repeat these steps...\n",
       "10344    [tensors, MNIST, tensor, MNIST, shuffle=True, ...\n",
       "10345    [forward, forward, forward, \\r\\nclass MyResNet...\n",
       "10346    [x = torch.tensor([1, 2, 3])\\r\\nx.shape\\r\\n, t...\n",
       "10347    [k, (2, 3, 4, 4), torch.argmax, axis=1, (2, 4,...\n",
       "10348                                      [keepdims=True]\n",
       "10349                                                  NaN\n",
       "10351    [hidden, hidden, LSTM, zero, class LSTM(nn.Mod...\n",
       "10352    [ModuleList, list, self.convs, x_convs = self....\n",
       "10353    [nn.Sequential, nn.ModuleList, nn.ModuleList, ...\n",
       "10354    [forward, gradient, main worker, model, model,...\n",
       "10355             [transformers, python3 setup.py install]\n",
       "10356                                                  NaN\n",
       "10357    [x_y_offset = (\\r\\n    torch.cat((x_offset, y_...\n",
       "10358    [Tensor.unfold, nn.functional.pad, import torc...\n",
       "10360    [PyTorch 1.6.0, import torch\\r\\nimport torch.n...\n",
       "10361    [# input is a T * K tensor\\r\\ninput = torch.on...\n",
       "10363                                              [torch]\n",
       "10364    [|t| + |d| &lt;&lt; |S|^2, (|t|+|d|) / |S|^2 =...\n",
       "10365    [MSE = torch.nn.MSELoss()\\r\\ncrossentropy = to...\n",
       "10366    [np.append(), #outside epochs loop\\r\\nMAE_for_...\n",
       "10367            [torch.jit.script, attributes, torch.jit]\n",
       "10370                                                  NaN\n",
       "10372                                                  NaN\n",
       "10373    [error = torch.abs(preds - targets).sum().data...\n",
       "10374                                                  NaN\n",
       "10375    [cfg.merge_from_file(\"YOUR CONFIG FILE\"), cfg....\n",
       "10376                                                  NaN\n",
       "10378    [nn.CrossEntropyLoss(), # official example\\r\\n...\n",
       "10379    [loss = criterion(outputs, targets)\\r\\n, loss ...\n",
       "10380    [for epoch in range(50):  # loop over the data...\n",
       "10381    [torch.index_add, labels = torch.tensor([0, 1,...\n",
       "10382    [def get_repeated_labels(label_list):\\r\\n    \"...\n",
       "10383    [    for i in range(1, len(dec_channels)):\\r\\n...\n",
       "10384    [xarray, dask, X = xarray.open_dataset(\"Test_f...\n",
       "10385    [labels = [0, 1, 2, 1, 0, 2, 1]\\r\\n\\r\\ndct = {...\n",
       "10386    [labels = [\"red\", \"blue\", \"green\"]\\r\\ndataset ...\n",
       "10387                                                  NaN\n",
       "10388    [B.max(dim=3)[0].max(dim=2)[0].max(dim=0)[0]\\r\\n]\n",
       "10389    [torch, certifi==2020.6.20\\r\\nchardet==3.0.4\\r...\n",
       "10391    [for i in range(50):\\r\\n    for phase in ['tra...\n",
       "10392    [np.ones((len(a),M,N)) * a[:,None,None]\\r\\n, n...\n",
       "10393    [expand, a_t = torch.from_numpy(a)\\r\\n\\r\\na_t[...\n",
       "10394                    [nn.Module, parameters(), Linear]\n",
       "10395                                                  NaN\n",
       "10396    [Tensor.reshape, data, 10, (4, 150, 10), win_s...\n",
       "10397                                                  NaN\n",
       "10398    [tensorflow, tensorboard, tensorboardx, tensor...\n",
       "10399                                        [tensorboard]\n",
       "10400    [conda uninstall tensorflow\\r\\nconda uninstall...\n",
       "10401    [conda install, pip install, from torch.utils....\n",
       "10402    [conda uninstall tensorboard, conda install te...\n",
       "10403                                          [- cpuonly]\n",
       "10404                                                  NaN\n",
       "10405                 [torch.no_grad(), eval(), no_grad()]\n",
       "10406    [torch.no_grad(), torch.no_grad(), torch.no_gr...\n",
       "10407    [if, for loop,  import torch\\r\\n a = torch.ran...\n",
       "10408                                                  NaN\n",
       "10409                                                  NaN\n",
       "10410    [reshape, shape, strides, dtype, view, In [513...\n",
       "10411    [train_dataset = torchvision.datasets.MNIST(ro...\n",
       "10413    [import torch.utils.mobile_optimizer as mobile...\n",
       "10414    [for b, (X_train, y_train) in enumerate(train_...\n",
       "10415    [def, class, class GaussianBlur(torch.nn.Modul...\n",
       "10416    [t.sum(dim=(0,1))\\r\\ntensor([3, 3, 3])\\r\\n, t....\n",
       "10417            [t.sum(0).sum(1).tolist()\\r\\n, [3, 3, 3]]\n",
       "10418    [ import torch\\r\\n torch.nn.MSELoss()(torch.ra...\n",
       "10419                                                  NaN\n",
       "10420    [transform, `dataset = torchvision.datasets.Im...\n",
       "10421    [Image.open, torch DataLoader, import numpy as...\n",
       "10422    [transforms.Normalize, transforms.ToTensor, Ra...\n",
       "10423    [transforms.Normalize([0.5,],[0.5,]), transfor...\n",
       "10424    [import numpy as np\\r\\n\\r\\n% sum over columns\\...\n",
       "10425                                                  NaN\n",
       "10427    [copy_, ...\\r\\n//pinned = gpu.to(torch::kCPU, ...\n",
       "10428                                                  NaN\n",
       "10430                                                  NaN\n",
       "10432    [(B, C, ...), mean, std, C, import torch\\r\\n\\r...\n",
       "10433    [import torch\\r\\nimport numpy as np\\r\\n\\r\\ndef...\n",
       "10434    [r, m, r = i_{d-1} m**(d-1) + i_{d-2} m**(d-2)...\n",
       "10435    [a[:,*idx], a[(slice(None), *idx)]\\r\\n, x[(exp...\n",
       "10436    [sample = Image.open(path)\\r\\nsample = np.asar...\n",
       "10437    [[0, 1, 9, 9, 9, 9], [5, 6, 5, 5, 9, 9]\\r\\n[2 ...\n",
       "10438                                                  NaN\n",
       "10439    [from torchsummary import summary, summary(mod...\n",
       "10440    [torch.device('cuda' if torch.cuda.is_availabl...\n",
       "10441    [class MyDataset(IterableDataset):\\r\\n\\r\\n    ...\n",
       "10442    [torch.Tensor.split, arr1 = np.array([[1.,2,3]...\n",
       "10443                                                  NaN\n",
       "10446                   [torch.nn.Module, eval, nn.Module]\n",
       "10447    [torchvision.transforms.GaussianBlur(kernel_si...\n",
       "10448    [transforms.Resize((w, h)), transforms.CenterC...\n",
       "10449                                                  NaN\n",
       "10450    [import sys\\r\\n\\r\\nimport numpy as np\\r\\n\\r\\ni...\n",
       "10451                                                  NaN\n",
       "10452    [longest_first, cut from the right, longest_fi...\n",
       "10453                                                  NaN\n",
       "10454                                                  NaN\n",
       "10455    [torch.utils.data.Subset, top_five = torch.uti...\n",
       "10456    [Dataset, Dataset, DataLoader, from torch.util...\n",
       "10457                                                  NaN\n",
       "10458    [torch.save, perturbed_image, label, Dataset, ...\n",
       "10459                                                  NaN\n",
       "10462                                            [numel()]\n",
       "10463    [dataset, x = 'data'\\r\\ndataset = datasets.Ima...\n",
       "10464    [from torchvision import datasets, transforms\\...\n",
       "10465    [targets, train_labels, from torchvision impor...\n",
       "10466                                                  NaN\n",
       "10468                                                  NaN\n",
       "10469                  [list(model.parameters())[0].shape]\n",
       "10470    [Sentences, lables, ###tokenizer = XLNetTokeni...\n",
       "10471                                                  NaN\n",
       "10472                                                  NaN\n",
       "10474    [                outputs, past_outputs = self....\n",
       "10475    [context, return torch.embedding(weight, input...\n",
       "10476                                                  NaN\n",
       "10477    [Trainer, TensorBoardLogger, Trainer, from pyt...\n",
       "10478    [\\r\\n# let's say img is a 3D numpy array\\r\\nim...\n",
       "10479                  [images, images.float(), int, long]\n",
       "10480    [thing, x.clone().detach(), torch.tensor(x), t...\n",
       "10481    [[tensor([1, 2, 3, 4, 5]), tensor([2, 3]), ten...\n",
       "10482    [.to, requires_grad, Variable, requires_grad, ...\n",
       "10483                    [.max(1)[1], .max(1), [1], (1,1)]\n",
       "10484    [nn.Upsample, nn.functional.interpolate, nn.fu...\n",
       "10486    [cv2, def __getitem__(self, idx):\\r\\n    impor...\n",
       "10487    [linux@linux:~# fallocate -l 32G /tmp/swap\\r\\n...\n",
       "10488    [einsum, np.einsum('ij,ikj-&gt;ik', A, B) # or...\n",
       "10489    [(np.expand_dims(A, 1) * B).sum(axis=2)\\r\\n, A...\n",
       "10490    [model(x), model.forward(x), cuda(), n_epochs ...\n",
       "10491    [xxxForSequenceClassification, xxxForSequenceC...\n",
       "10492    [print([p.requires_grad for p in bert_distil.d...\n",
       "10493    [policy_loss, policy_loss + 0.5 * value_loss, ...\n",
       "10494    [from google.colab import drive\\r\\ndrive.mount...\n",
       "10495    [from skimage.util.shape import view_as_window...\n",
       "10496    [for param in net.parameters():\\r\\n    print(t...\n",
       "10497                     [model = nn.Linear(784, 10)\\r\\n]\n",
       "10498    [w.grad, dw_list.append(w.grad.detach().cpu()....\n",
       "10499    [A, torch.einsum('bij,ji-&gt;b', A, B)\\r\\n, te...\n",
       "10500    [device = torch.device('cuda' if torch.cuda.is...\n",
       "10501            [roi_heads, torchvision/models/detection]\n",
       "10502    [FasterRCNN, box_predictor, cls_score, bbox_pr...\n",
       "10503                                                  NaN\n",
       "10504    [loss, loss = loss(preds, ys), _loss = loss(pr...\n",
       "10505    [train_loader, train_loader, data = [self.data...\n",
       "10506                                                  NaN\n",
       "10507    [import torch\\r\\nfrom PIL import Image\\r\\nfrom...\n",
       "10508                                                  NaN\n",
       "10509    [def train_model(model, data):\\r\\n    model_op...\n",
       "10510    [# -- Imports -- #\\r\\nimport torch\\r\\n\\r\\nfrom...\n",
       "10512    [with torch.no_grad():\\r\\n    for batch in tqd...\n",
       "10515    [useEffect, const [data, setData] = useState(n...\n",
       "10516    [expand, expand, reshape(size[:2] + (1, 1)), e...\n",
       "10518    [eval(), train(), self.training, def train(sel...\n",
       "10519    [ModuleList, \\r\\nimport torch\\r\\nimport torch....\n",
       "10520    [list_layers = model.named_children()\\r\\n, par...\n",
       "10522                                                  NaN\n",
       "10523    [max_node, counter = 0, 0\\r\\nbatch_size, n_day...\n",
       "10525    [conda install -c anaconda cudnn, conda list c...\n",
       "10526                                                  NaN\n",
       "10527                                                  NaN\n",
       "10528                                                  NaN\n",
       "10529                                                  NaN\n",
       "10530    [nn.Softmax, import torch\\r\\n\\r\\nx = torch.ten...\n",
       "10531                                   [(-1, 14), logits]\n",
       "10532    [numba, Tensor.numpy(), ...\\r\\nz = vec_add_odd...\n",
       "10533                   [numba.cuda.as_cuda_array(tensor)]\n",
       "10534    [import torch\\r\\n\\r\\n@torch.jit.script\\r\\ndef ...\n",
       "10535                                                  NaN\n",
       "10536                                                  NaN\n",
       "10537    [nn.Sequential, __init__(), class CNN(nn.Modul...\n",
       "10538                                                  NaN\n",
       "10539          [BatchNorm, Dropout, .eval(), eval, eval()]\n",
       "10540    [cfg = get_cfg()\\r\\ncfg.merge_from_file(model_...\n",
       "10541    [import numpy\\r\\nfrom scipy.optimize import mi...\n",
       "10542    [-=, -=, .no_grad(), SubBackward, grad_fn, imp...\n",
       "10546    [ X = np.array([[[ 0,  1],\\r\\n                ...\n",
       "10547    [import torch\\r\\nfrom torch.ults.data import D...\n",
       "10548    [w = F.avg_pool2d(x3, x3.size(2))\\r\\n, w = F.a...\n",
       "10549                                       [.whl, cu102/]\n",
       "10550    [A = torch.rand(1, N)\\r\\nB = torch.rand(N, M, ...\n",
       "10551    [#this gives you 2-D array (M,M)\\r\\nnp.einsum(...\n",
       "10552                                                  NaN\n",
       "10553    [import torch \\r\\n\\r\\na = torch.zeros(100,100,...\n",
       "10554             [torch.cuda.empty_cache(), empty_cace()]\n",
       "10555    [x, conv, forward, def forward(self, x):\\r\\n  ...\n",
       "10556                [train, /opt/ml/model, /opt/ml/model]\n",
       "10557    [import boto3\\r\\n\\r\\ns3 = boto3.client('s3')\\r...\n",
       "10558                                                  NaN\n",
       "10559    [AutoModelForCausalLM, AutoModelForMaskedLM, A...\n",
       "10560                                                  NaN\n",
       "10561                                                  NaN\n",
       "10563    [list(model.parameters())[0].shape # weights o...\n",
       "10564    [s = pd.Series(a)\\r\\n, s.groupby(s).apply(lamb...\n",
       "10565    [a = np.random.randint(0,10,20)\\r\\nprint(a)\\r\\...\n",
       "10566               [torchvision, pip install torchvision]\n",
       "10567    [conda install pytorch torchvision -c soumith\\...\n",
       "10568    [def init_weights(m):\\r\\n    if type(m) == nn....\n",
       "10569    [# how the comunity usually does the import:\\r...\n",
       "10570    [batch_size=1, board = t.rand([1, 1, 16, 16])\\...\n",
       "10571    [.targets, TensorDataset, train_dataset.tensor...\n",
       "10572    [nn.RNN, nn.RNN, (num_layers * num_directions,...\n",
       "10573    [torch.cat((hidden[-2,:,:], hidden[-1,:,:]), d...\n",
       "10574    [torch.FloatTensor, torch.LongTensor, y = torc...\n",
       "10575                                                  NaN\n",
       "10576    [# load trained model:\\r\\nmodel = Classifier({...\n",
       "10577    [C:\\Program Files\\NVIDIA GPU Computing Toolkit...\n",
       "10578    [ for batch, target in train_loader:\\r\\n      ...\n",
       "10581    [Trainer, gpus=N, # train on 8 GPUs (same mach...\n",
       "10582    [torch.optim.lr_scheduler.ReduceLROnPlateau, m...\n",
       "10583    [torch.optim.lr_scheduler import _LRScheduler\\...\n",
       "10584    [import matplotlib.pyplot as plt\\r\\n\\r\\ndef my...\n",
       "10585                                        [MemoryError]\n",
       "10586    [import torch\\r\\nscores = [torch.rand(2, 3)]\\r...\n",
       "10587    [scores, scores = [s[tuple(k.t())] for s, k in...\n",
       "10588             [torch.utils.checkpoint, custom_forward]\n",
       "10589                                                  NaN\n",
       "10590    [mean, std, ImageNet, [-1, 1], mean, std, 0, 1...\n",
       "10591                                                  NaN\n",
       "10592    [import torch\\r\\n\\r\\ndef construct_jacobian(y,...\n",
       "10593                                                  NaN\n",
       "10594    [h0, co, def init_hidden(self):\\r\\n    weight ...\n",
       "10595    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "10596                                                  NaN\n",
       "10597    [torch.where, import torch\\r\\n\\r\\npred = torch...\n",
       "10598    [len(loader.dataset), len(loader), import torc...\n",
       "10599    [train_loader, valid_loader, train_dataset, va...\n",
       "10600    [torch.triu(), x = torch.randn(5, 5, requires_...\n",
       "10601    [/install/lib/python3.6/site-packages/torch/st...\n",
       "10602    [torch.save(model, PATH)\\r\\n, model = torch.lo...\n",
       "10604                                                  NaN\n",
       "10605    [return_inverse, numpy.unique, y = [ 1, 6, 5, ...\n",
       "10606    [result = source[indices[..., 0], indices[...,...\n",
       "10608                                                  NaN\n",
       "10609    [nn.LSTMCell, (batch_size, hidden_size), (1, h...\n",
       "10610    [torchvision, pip install --upgrade torchvisio...\n",
       "10612    [loss.backward(), loss = criterion(outputs,tar...\n",
       "10614    [self.linear = nn.Linear(...), __setattr__, nn...\n",
       "10615                     [        super().__init__()\\r\\n]\n",
       "10616    [Tensor, SimilarityModel::forward(), this-&gt;...\n",
       "10617    [import torch\\r\\n\\r\\nindex = [[2, 0, 1], [2, 2...\n",
       "10618    [value_tensor, import torch\\r\\n\\r\\nindex = [[2...\n",
       "10619    [import torch\\r\\n\\r\\nindex = [[2,0,1], [2,2,0]...\n",
       "10620                                                  NaN\n",
       "10621                                                  NaN\n",
       "10622    [self.mean, nn.Parameter, nn.Module, __setattr...\n",
       "10624    [class NeuralNet(nn.Module):\\r\\n    class ExpA...\n",
       "10625    [x = torch.empty(size=(0,3))\\r\\ny = torch.tens...\n",
       "10626    [last_hidden_states = outputs[0]\\r\\ncls_embedd...\n",
       "10627    [PYTORCH, \"C:\\Program Files\\Python37\\Scripts\\p...\n",
       "10628                                                  NaN\n",
       "10629                           [torch.sparse.FloatTensor]\n",
       "10630                                                  NaN\n",
       "10631    [net.zero_grad(), optimizer.zero_grad(), for e...\n",
       "10632                             [outputs = net(batch_X)]\n",
       "10633    [labels, masked_lm_labels, -100, sentence='我爱你...\n",
       "10634    [x = torch.ones(2, requires_grad=True)\\r\\n, y ...\n",
       "10635                                                  NaN\n",
       "10636                                                  NaN\n",
       "10637                                                  NaN\n",
       "10638    [new[:,col_i] = (raw[:,col_i] - raw[:,col_i].m...\n",
       "10639    [File \"/home/anatole2/best/PCEN_pytorch.py\", l...\n",
       "10640    [TensorB[0, 0], [2., 5.], ((TensorA == TensorB...\n",
       "10641                                 [torchvision.models]\n",
       "10642                                               [topk]\n",
       "10643    [flatten(), output = net(x.view(x.shape[0], -1...\n",
       "10645    [state_dict, state_dict, import torch\\r\\nmodel...\n",
       "10646    [(N,∗,in_features), (out_features,in_features)...\n",
       "10647    [product = features.t() * weights + bias\\r\\n, ...\n",
       "10649      [images, net, out = net(images.to(device))\\r\\n]\n",
       "10650    [inputs, labels = data                        ...\n",
       "10651    [input_size, __init__, token_size, encoder, de...\n",
       "10652    [\\r\\nself.fc1 = nn.Linear(16 * 6 * 6, 120)\\r\\n...\n",
       "10653                                                  NaN\n",
       "10654    [parameters_to_prune = (\\r\\n    (model.conv1, ...\n",
       "10655    [for layer_name, param in model.named_paramete...\n",
       "10656    [import torch, torchvision.models\\r\\nmodel = t...\n",
       "10657    [4.05517871e-16, -2.6047e-16, input = V.e.V^T,...\n",
       "10658    [.split, .narrow, t = torch.rand(32, 32, 3, 3)...\n",
       "10659    [def lbp_transform(x):\\r\\n    radius = 2\\r\\n  ...\n",
       "10661                                                  NaN\n",
       "10662    [patches = img_t.unfold(3, kernel, stride).unf...\n",
       "10663                                                  NaN\n",
       "10664    [for i in range(10):\\r\\n  model.zero_grad()\\r\\...\n",
       "10665    [nn.Sequential, self.classifier = nn.Sequentia...\n",
       "10666    [encoded ,   out = self.classifier(decoded)\\r\\...\n",
       "10667    [register_backward_hook(), register_backward_h...\n",
       "10668    [#mount drive onto google colab\\r\\n\\r\\nfrom go...\n",
       "10669               [nn.Conv2d, nn.Flatten(), nn.Linear()]\n",
       "10670    [LazyLinear, Linear, fc_out = nn.LazyLinear(ou...\n",
       "10671    [device.inputs, positions = torch.arange(input...\n",
       "10672    [self.classifier, self.features, BatchNorm2d, ...\n",
       "10673    [numpu = (numpy + 1) * 128\\r\\n, return numpy\\r\\n]\n",
       "10674    [img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\\r...\n",
       "10675              [pred = model\\r\\n, pred = model(x)\\r\\n]\n",
       "10676                                         [nvidia-smi]\n",
       "10677                                             [Ml, ML]\n",
       "10679        [item(), prediction, argmax, prediction, 0-n]\n",
       "10681    [argmax(), import numpy as np\\r\\nnp.unravel_in...\n",
       "10682    [__getitem__, class GTSR43Dataset(Dataset):\\r\\...\n",
       "10683                                                  NaN\n",
       "10684    [for i in range(data.shape[1]):  # dim=1\\r\\n  ...\n",
       "10685    [import torch\\r\\n\\r\\nA = torch.rand(100000, 32...\n",
       "10686    [splitter = [6, 6, 6]\\r\\n\\r\\nA = torch.rand(18...\n",
       "10687                                    [h.detach_()\\r\\n]\n",
       "10688    [ k_lst = torch.zeros([4,4,5])\\r\\n k_lst[torch...\n",
       "10691                                                  NaN\n",
       "10692    [outputs = model(inputs)\\r\\n_, preds = torch.m...\n",
       "10693    [from sklearn.metrics import classification_re...\n",
       "10694    [with torch.no_grad():\\r\\n    model.eval() #IM...\n",
       "10695    [# In test phase, we don't need to compute gra...\n",
       "10696                                                  NaN\n",
       "10698    [print(net), _swish, _fc, class EfficientNet(n...\n",
       "10699    [class CustomUnpickler(pickle.Unpickler):\\r\\n\\...\n",
       "10700                                                  NaN\n",
       "10701    [labels, outputs, correct = 0\\r\\ntotal = 0\\r\\n...\n",
       "10702    [# Vocabulary to our own ID\\r\\ndef to_vocabula...\n",
       "10703    [X_train, Y_train, X_test, Y_test, x = torch.t...\n",
       "10704    [def act(self, state):\\r\\n        state = stat...\n",
       "10705    [rm ctc_entrypoint.cu\\r\\nln -s ctc_entrypoint....\n",
       "10706                     [nn.CrossEntropyLoss(), softmax]\n",
       "10708    [%pip install -v --no-cache-dir --global-optio...\n",
       "10709                                    [resnet101, BERT]\n",
       "10710    [nn.Module, import torch\\r\\nimport torch.nn as...\n",
       "10711    [class PredictFromEmbeddParaSmall(LightningMod...\n",
       "10712    [import torch\\r\\nfrom torch import nn, optim\\r...\n",
       "10713                                                  NaN\n",
       "10714    [CIFAR10, CIFAR10, __getitem__(), class CIFAR1...\n",
       "10715    [sentence_transformers &lt;- import(\"sentence_...\n",
       "10716    [sampler, batch_sampler, WeightedRandomSampler...\n",
       "10717                                          [nn.Linear]\n",
       "10718    [torch.utils.data.IterableDataset, torch.utils...\n",
       "10719    [sample, cv2.imwrite, sample=cv2.imwrite('samp...\n",
       "10720    [torch.nn.Sequential, torch.nn.Module, f = tor...\n",
       "10721    [self.c, self.a, self.b, self.c.storage_offset...\n",
       "10722    [train_transformation = transforms.Compose([tr...\n",
       "10723    [(2000, 10000), torch.nn.Linear, (10000, d_out...\n",
       "10724    [   import torch, torch.nn as nn, torch.optim....\n",
       "10725                                                  NaN\n",
       "10726                                                  NaN\n",
       "10727    [my_transforms = transforms.Compose([  \\r\\n   ...\n",
       "10728         [conda install pytorch=1.4.0 -c pytorch\\r\\n]\n",
       "10729    [    def initialize(self, context):\\r\\n       ...\n",
       "10730    [--Code\\r\\n  --ResNet.py\\r\\n  --Densenet.py\\r\\...\n",
       "10731    [from torch.cuda import is_available\\r\\n\\r\\n\\r...\n",
       "10732    [self.weight = torch.nn.Linear(in_features, ou...\n",
       "10733    [    attn_dists[:,i,:]=attn_dists_tmp.squeeze(...\n",
       "10734    [.cuda(), .cpu(), if cuda_available:\\r\\n  x = ...\n",
       "10735    [to('cpu'), to(torch.device('cpu')), cpu(), to...\n",
       "10736    [torch.sign(x), torch.sign(y), x, y, min, |, m...\n",
       "10738    [ArgumentParser, console, terminal, Juputer, p...\n",
       "10739    [# truncated to the last K timesteps\\r\\nwhile ...\n",
       "10740    [keys = ['module.E.conv1.weight', 'module.E.bn...\n",
       "10741    [padding=(3, 3), import tensorflow as tf\\r\\n\\r...\n",
       "10742          [torch.linalg, torch.linalg.det(input)\\r\\n]\n",
       "10743                                                  NaN\n",
       "10744    [permute, reshape, x.reshape(2, 2, 3).permute(...\n",
       "10745    [torch.split, torch.stack, torch.stack(x.split...\n",
       "10746    [PReLU(x)=max(0,x)+a∗min(0,x)\\r\\n, torch.min, ...\n",
       "10750                                                  NaN\n",
       "10751    [torch.chunk, np.array_split, X = np.array([[1...\n",
       "10752    [def pad_to_divisible_shape(arr, a_r, b_r):\\r\\...\n",
       "10753    [torch.randn(5) #for normal distribution, torc...\n",
       "10754    [import torch\\r\\n\\r\\na = torch.randn(30, 24, 5...\n",
       "10756    [torch.utils.data.sampler.WeightedRandomSample...\n",
       "10757                                            [.cuda()]\n",
       "10758    [import torch\\r\\nfrom torch.nn import Embeddin...\n",
       "10759    [ print(\"Type of data element: \", train_datase...\n",
       "10760    [torch.Tensor, torch.tensor([target]), N, torc...\n",
       "10764    [stratify, train_test_split, y, train_indices,...\n",
       "10765    [from sklearn.model_selection import Stratifie...\n",
       "10766                                                  NaN\n",
       "10767          [my_array = numpy.array(my_array.tolist())]\n",
       "10768    [inference.py, inference.py, result, predictor...\n",
       "10769    [    p.py:38: UserWarning: Using a target size...\n",
       "10770                                                  NaN\n",
       "10771                                                  NaN\n",
       "10772    [log_probs.sum().backward(retain_graph = True)...\n",
       "10773    [network = LeNet()\\r\\n, torch.manual_seed(42)\\...\n",
       "10774                                                  NaN\n",
       "10775                                                  NaN\n",
       "10777    [b, int, a = torch.rand(12, 64, 8, 8, 3) # gen...\n",
       "10778    [init, title_conv, self.title_conv = torch.nn....\n",
       "10779    [self.title_conv, self.title_conv = torch.nn.S...\n",
       "10780                                                  NaN\n",
       "10781                                                  NaN\n",
       "10782    [img = np.fromfile(dir_train + image_name, 'bo...\n",
       "10783    [z, x_norm, mm(x_norm), (1; 0), x_norm = (x; y...\n",
       "10784    [x.item(), float(x), float(), import torch\\r\\n...\n",
       "10786    [from torch.utils.data import Dataset, DataLoa...\n",
       "10787                                                  NaN\n",
       "10789           [def ___init__(self):\\r\\n, init, __init__]\n",
       "10790                                                  NaN\n",
       "10791                              [figsize, dpi=300, mpl]\n",
       "10792    [tensor([[[[1., 1., 1., 1., 1., 1., 0., 1.],  ...\n",
       "10793    [a = torch.tensor([[[-3,  -6, -1],\\r\\n        ...\n",
       "10794    [    for batch_idx, (data, target) in enumerat...\n",
       "10796    [  import spacy.cli \\r\\n  spacy.cli.download(\"...\n",
       "10797    [de, python -m spacy download de\\r\\n, spacy.lo...\n",
       "10798    [return np.mean(np.power(x_opt - outputs, 2), ...\n",
       "10799    [trainset.data.shape\\r\\n, torch.Size([60000, 2...\n",
       "10801    [np.take_along_axis,  N, H, W, C = 10, 20, 30,...\n",
       "10802                                         [torchaudio]\n",
       "10803    [eval, import torch.tensor as tensor\\r\\n\\r\\nev...\n",
       "10804    [pip install https://download.pytorch.org/whl/...\n",
       "10805    [if valid_loss &lt;= valid_loss_min:\\r\\n      ...\n",
       "10806                                                  NaN\n",
       "10807    [nn.KLDivLoss, NLLLoss, nn.functional.log_soft...\n",
       "10808    [xargs, git, cd, Set-Location, cat, Get-Conten...\n",
       "10809    [concatenate, append, names_preds.concatenate(...\n",
       "10810                                                  NaN\n",
       "10812                                                  NaN\n",
       "10813    [t = tensor.rand(2, 2).cuda()# bad\\r\\n(self is...\n",
       "10814    [MetadataCatalog.get(\"train\")\\r\\n, MetadataCat...\n",
       "10815    [with torch.no_grad():\\r\\n    for step, (x, y)...\n",
       "10816                                                  NaN\n",
       "10817    [enumerate, X = torch.tensor([\\r\\n    [-2,4,-1...\n",
       "10818    [x = torch.tensor([ \\r\\n                 [-2,4...\n",
       "10819    [l = tens.tolist()\\r\\n, detach(), l = tens.det...\n",
       "10820    [a, b, a, (10, 2), b, (7, 2), if, def non_inte...\n",
       "10821                                                  NaN\n",
       "10822    [model.weight.data, w = model.weight.data, mod...\n",
       "10823                                                  NaN\n",
       "10824    [model.train(), nll_loss, requires_grad=True, ...\n",
       "10827    [gather, idx, torch.int64, tensor, idx = torch...\n",
       "10828    [shuffle, DataLoader, batch_size, import torch...\n",
       "10829    [indices =  [0,1,2]  # select your indices her...\n",
       "10830                                        [__getitem__]\n",
       "10832          [torch.backends.cudnn.benchmark = True\\r\\n]\n",
       "10833    [if torch.cuda.is_available():\\r\\n    device =...\n",
       "10835                                      [hf_bucket_url]\n",
       "10836    [    def read_vocab(path):\\r\\n        #read vo...\n",
       "10837    [self.conv1, self.conv1 = nn.Conv2d(in_channel...\n",
       "10838                                                  NaN\n",
       "10839            [torch.nn.utils.rnn.pack_padded_sequence]\n",
       "10840                                                  NaN\n",
       "10841    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "10842                                                  NaN\n",
       "10845    [torchvision.transforms.functional.rotate, imp...\n",
       "10846    [criterion, age_loss, gender_loss, race_loss =...\n",
       "10847            [\"torch.float32\" \\r\\n\"torch.float64\"\\r\\n]\n",
       "10848    [last_epoch, .step(),  import torch\\r\\n cc = t...\n",
       "10849    [import torch, pytorch, from __future__ import...\n",
       "10850             [line_profiler, line_profiler, @profile]\n",
       "10852    [[1, 3, 384, 320], [1, 3, 384, 1024], [1, 3, 3...\n",
       "10853    [torch.stack, size = [1024, 1024]\\r\\n\\r\\nretur...\n",
       "10854    [tf.math.reduce_max, import tensorflow as tf\\r...\n",
       "10855    [model = efn.EfficientNet.from_name('efficient...\n",
       "10856                                                  NaN\n",
       "10857                                                  NaN\n",
       "10858    [import cv2\\r\\nimport numpy as np\\r\\n\\r\\nimg =...\n",
       "10859    [dim, torch.mean, torch.std, pixels = torch.ra...\n",
       "10860                                                  NaN\n",
       "10861    [reduce, train_x = torch.cat((torch.cat(list_t...\n",
       "10862    [reduce, import torch as T\\r\\nfrom functools i...\n",
       "10863    [CMD, CMD [ \"python\", \"flaskapp.py\" ]\\r\\nCMD [...\n",
       "10864    [docker run -p 8000:8000 python-barcode, http:...\n",
       "10865                                                  NaN\n",
       "10866    [loss.backward(), loss = Variable(loss, requir...\n",
       "10867                        [.retain_grad(), .backward()]\n",
       "10868    [output = model(input)\\r\\nloss = loss_fn(input...\n",
       "10869    [\"false\", TOKENIZERS_PARALLELISM=false\\r\\n, im...\n",
       "10870                                         [tokenizers]\n",
       "10872                                                  NaN\n",
       "10873                                                  NaN\n",
       "10874                                                  NaN\n",
       "10875    [np.squeeze(), squeeze, import numpy as np\\r\\n...\n",
       "10876    [nn.CrossEntropy()(input, target), input, batc...\n",
       "10877    [predicted = torch.argmax(output, dim=1), labe...\n",
       "10878    [1, Tensor, Tensor, 0, 1, Tensor, x = torch.te...\n",
       "10879    [This criterion expects a class index in the r...\n",
       "10880    [loader, pillow, Image.open(path), 45, import ...\n",
       "10881    [torch.var(x, axis=(2,3), keepdims=True, unbia...\n",
       "10882    [dtype, torch.float32, boxes, torch.float64, ....\n",
       "10883    [', gcloud compute instances create instance-4...\n",
       "10884    [mytensor = mytensor.double(), mymodel = mymod...\n",
       "10885    [coords = coords.long()\\r\\ngrid[coords[0],coor...\n",
       "10886    [coords = [[0, 0, 1, 2],\\r\\n         [0, 2, 2,...\n",
       "10888                                                  NaN\n",
       "10890    [output = net(input)\\r\\nloss_fn = torch.min\\r\\...\n",
       "10891    [2, 2, 2, 2, 1, 0, ReduceLROnPlateau, 0, 1, Cr...\n",
       "10892                                                  NaN\n",
       "10893    [label = self.frame.iloc[idx, 1], image, label...\n",
       "10894    [class myLoss(torch.nn.Module):\\r\\n\\r\\n    def...\n",
       "10895    [#load net1 model partially\\r\\ncheckpoint = to...\n",
       "10896    [implementation 'org.pytorch:pytorch_android:1...\n",
       "10897                                                  NaN\n",
       "10898    [nn.functional.conv2d, # suppose kernel.shape ...\n",
       "10899                                                  NaN\n",
       "10900                                                  NaN\n",
       "10901                 [rnn_out = torch.stack(rnn_out)\\r\\n]\n",
       "10903    [torch.gather, idx = torch.argmax(x, dim=1, ke...\n",
       "10904          [y[T.arange(3), x_argmax], T.max(x, dim=1)]\n",
       "10905    [PIL.Image.frombuffer(), from PIL import Image...\n",
       "10906    [numpy, cv2, import numpy as np\\r\\nimport cv2\\...\n",
       "10907                      [pic = pic.astype('uint8')\\r\\n]\n",
       "10908    [to_pil_image, np.{uint8, int16, uint32, float...\n",
       "10909    [num_epochs = 100\\r\\nfor epoch in range(num_ep...\n",
       "10910    [c = a[:, 2:3], c = a[:, [2]], .storage().data...\n",
       "10911    [# Load intial pretrained model\\r\\nmodel = Ref...\n",
       "10912    [ConvBNReLU, torchvision, from torchvision.mod...\n",
       "10913                                                  NaN\n",
       "10914    [from biobert_embedding.embedding import Biobe...\n",
       "10915                                                  NaN\n",
       "10916    [writer = SummaryWriter(osp.join('runs', 'hell...\n",
       "10917                                                  NaN\n",
       "10918    [ class Foo(object):\\r\\n...     pass\\r\\n class...\n",
       "10919                                          [Unpickler]\n",
       "10920    [import cloudpickle\\r\\n\\r\\nclass Foo(object):\\...\n",
       "10921                                                  NaN\n",
       "10922    [pipenv install torchvision \\r\\n, torch   torc...\n",
       "10923    [a = torch.as_tensor([[0,0],[0,1],[0,2],[1,3],...\n",
       "10924    [a = torch.tensor(list(range(0, 10)))\\r\\nb = t...\n",
       "10925                                                  NaN\n",
       "10926                                                  NaN\n",
       "10927    [[in_channels,1,1], weights = number of kernel...\n",
       "10928                                                  NaN\n",
       "10930    [StepLR, opt = torch.optim.Adam(MM.parameters(...\n",
       "10931    [x = np.random.rand(3,3,3,3,3)\\r\\nelem = x[:, ...\n",
       "10932    [list(permutations(range(3), 3)), 0,1,2, from ...\n",
       "10933    [target_link_libraries(${TARGET_NAME} nvonnxpa...\n",
       "10934                                                  NaN\n",
       "10935                                                  NaN\n",
       "10936    [train_data = torchvision.datasets.ImageFolder...\n",
       "10938    [pt1, pt2, cv2.rectangle, fig, ax = plt.subplo...\n",
       "10939                                                  NaN\n",
       "10941    [dtype, int64, img = np.array([pixel_frame.ilo...\n",
       "10943                                                  NaN\n",
       "10944                                                  NaN\n",
       "10945    [iter(), __iter__(), iris_loader, next(), __ne...\n",
       "10946                                                  NaN\n",
       "10947                                                  NaN\n",
       "10948    [x_train_cross_val = torch.cat((*x_train_folds...\n",
       "10951    [        image = np.array(Image.open(img_path)...\n",
       "10952                         [image.permute(1, 2, 0)\\r\\n]\n",
       "10953                                                  NaN\n",
       "10954    [pad_to_max_length, from transformers import B...\n",
       "10955    [ conda install https://anaconda.org/conda-for...\n",
       "10956          [pip install --upgrade huggingface-hub\\r\\n]\n",
       "10958    [def test(dataset, dataloader):\\r\\n    net.eva...\n",
       "10959    [ValueError                                Tra...\n",
       "10960                                                  NaN\n",
       "10961    [for i in range(20):\\r\\n    Y=w0+w1*x+w2*x**2+...\n",
       "10962             [x = x.double(), x.grad, double(), x, x]\n",
       "10963    [The .grad attribute of a Tensor that is not a...\n",
       "10964    [import torch.nn as nn\\r\\n\\r\\nmodel1 = nn.Sequ...\n",
       "10965                                                  NaN\n",
       "10966    [x = torch.autograd.Variable(torch.Tensor([1.0...\n",
       "10967    [training_args = TrainingArguments(\\r\\n    out...\n",
       "10968    [    evaluation_strategy =‘steps’,\\r\\n    eval...\n",
       "10969    [training_args = TrainingArguments(\\r\\n    out...\n",
       "10970    [for param in MobileNet.parameters():\\r\\n    p...\n",
       "10971    [requires_grad_, class RetinaNet(torch.nn.Modu...\n",
       "10972    [b, # Assign a new object to b : b*2\\r\\n b = t...\n",
       "10973    [b = torch.empty(1)\\r\\na = b\\r\\nprint(a.data_p...\n",
       "10974                     [op = F.sigmoid(op)\\r\\n, 0.5, 0]\n",
       "10975                      [python, pytorch, import torch]\n",
       "10976    [args.save_dir, None, os.path.exists, None,  i...\n",
       "10977    [save_dir, python train_distribute.py --save_d...\n",
       "10978                                                  NaN\n",
       "10980                                                  NaN\n",
       "10981                                                  NaN\n",
       "10983                              [with torch.no_grad():]\n",
       "10984    [with torch.no_grad(), 1.6.0, torch.nn.Conv2d,...\n",
       "10985                                                  NaN\n",
       "10986    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "10987    [action_values, action=torch.argmax(action_val...\n",
       "10990                                                  NaN\n",
       "10991    [bias, nn.Parameter, model.parameters(), model...\n",
       "10993    [x = (x - x.mean()) / x.std(), y_train / y_tes...\n",
       "10994    [torch.utils.data.TensorDataset, train_x, trai...\n",
       "10995    [(value - mean) / std), value * mean + std, im...\n",
       "10996    [torch.einsum, e1 = torch.einsum('ik, jl', tor...\n",
       "10997    [idx = activation.sum(1) == counter\\r\\nfeature...\n",
       "10998    [outputs_to_concat = []\\r\\nfor x in range(len(...\n",
       "10999    [cifar10_train, cifar10_test, train_transform,...\n",
       "11000    [MobileNet.classifier = nn.Sequential(nn.Linea...\n",
       "11001    [train_loss     += imgs.size(0)*criterion(logi...\n",
       "11002    [import torch.nn as nn\\r\\n\\r\\ncuda0 = torch.de...\n",
       "11003    [transform = transforms.Compose(\\r\\n    [trans...\n",
       "11004    [    …\\r\\n        if self.call_is_even :\\r\\n  ...\n",
       "11005                                                  NaN\n",
       "11006    [next_token = torch.multinomial(F.softmax(filt...\n",
       "11007    [from transformers import RobertaTokenizer\\r\\n...\n",
       "11008    [dir_name = \"distilroberta-tokenizer\"\\r\\n\\r\\ni...\n",
       "11009                                   [RMSprop, RMSProp]\n",
       "11011    [numpy, numpy.random.choice, replace=False, to...\n",
       "11012    [    model = models.Sequential()\\r\\n    model....\n",
       "11013                                   [memory intensive]\n",
       "11014                              [next(iter(test_data))]\n",
       "11015    [PyTorch, clip_grad_norm, loss, output, loss.b...\n",
       "11016    [opt, requires_grad, False, for param in red_m...\n",
       "11018                                             [nbatch]\n",
       "11019    [(x, y), x, (C,L), N, C, L = 5, 3, 10\\r\\ndatas...\n",
       "11020    [collate_fn, BatchSampler, dataset = HD5Datase...\n",
       "11021    [lr, override, diffopt.step, def test_parametr...\n",
       "11024    [ImageLoader, |\\r\\n|__train\\r\\n|   |\\r\\n|   |_...\n",
       "11026    [model.classifier, model.fc, LogSoftmax(), nn....\n",
       "11027    [input, batch_size, add_graph, add_graph, inpu...\n",
       "11028    [writer_semisuper.add_image, data_transforms =...\n",
       "11029    [import numpy as np\\r\\n\\r\\nb = 128\\r\\n\\r\\nembe...\n",
       "11030    [def imshow(inp, title=None):\\r\\n    inp = inp...\n",
       "11031    [Ellipsis, ndarray, tensor, prediction, [batch...\n",
       "11032    [image = cv2.imread('my_image.jpg')\\r\\nheight,...\n",
       "11033                                                  NaN\n",
       "11034    [forward, nn.Sequential, self.criterion = nn.N...\n",
       "11035    [self.criterion, nn.NLLLoss, y, loss = self.cr...\n",
       "11036    [super().__init__(), self.add_module(key, modu...\n",
       "11038                                                  NaN\n",
       "11039    [torch.clone(), detach(), torch.tensor.detach(...\n",
       "11041    [collator, data_collator, None, class Trainer:...\n",
       "11042    [flowers_idx.csv, flowers_label.csv, import os...\n",
       "11043     [out = self.cnn1(x), out = self.cnn1(x.float())]\n",
       "11045    [CosineAnnealingWarmRestarts, self.optimizer, ...\n",
       "11046    [CosineAnnealingWarmRestarts, η max, import ma...\n",
       "11047    [in_channels, torch.unsqueeze, Variable, for i...\n",
       "11048                                                  NaN\n",
       "11050    [test_out[:, -1, :], test_h, y, Ht, test_out[:...\n",
       "11051    [index_add, unique, # inputs\\r\\nx = torch.aran...\n",
       "11052    [train_data = torchvision.datasets.ImageFolder...\n",
       "11053    [&gt;conda create -n yourenvname python=x.x an...\n",
       "11054                                                  NaN\n",
       "11055    [nn.CrossEntropyLoss, nn.MSELoss, nn.CrossEntr...\n",
       "11056       [nvidia-smi\\r\\n, sudo kill -9 &lt;pid&gt;\\r\\n]\n",
       "11057    [flatten, nn.Linear, forward, def forward(self...\n",
       "11058    [linearRegression, nn.Linear(3*227*227, 1), 3*...\n",
       "11059                                                  NaN\n",
       "11060    [datasets.ImageFolder, inp, inp[0], inp[1], ex...\n",
       "11061    [nn.Conv3d, torch.Tensor.permute, # From: [bat...\n",
       "11062    [for (auto param_group : optimizer.param_group...\n",
       "11063    [.detach, a.data_ptr() == a_detached.data_ptr(...\n",
       "11064    [detach, a.clone().detach(), a, a.detach().clo...\n",
       "11065    [sign = t.sign()\\r\\nt = t.abs_().clamp_(min_ma...\n",
       "11066    [output = torch.sign(t) * torch.clamp(torch.ab...\n",
       "11067    [transforms.ToPILImage, img_transform = transf...\n",
       "11068    [criterion = nn.BCELoss()\\r\\noptim = torch.opt...\n",
       "11069    [retain_graph=True, retain_graph=True, require...\n",
       "11070                                                  NaN\n",
       "11071    [torch.mm(X1, self.Wx), 3 x 5, 4 x 5, torch.mm...\n",
       "11072    [BasicRNN, Y0, Y0, h0, Y1, h1, nn.RNNCell, Bas...\n",
       "11073                   [torch==1.5.0, torch==1.5.0+cu101]\n",
       "11074    [torch.nn.Sequential, self.nets=torch.nn.Seque...\n",
       "11075    [multiprocessing.set_start_method('spawn'), if...\n",
       "11076    [nn.Transformer.forward, src, src_key_padding_...\n",
       "11077    [CartPole-v0, CartPole-v0,  _, reward, self.do...\n",
       "11078    [weights = torch.from_numpy(weights).T\\r\\nbias...\n",
       "11081    [backward, fnet.parameters(time=T), task_num, ...\n",
       "11082    [.backward(), retain_graph=True, .backward(), ...\n",
       "11086    [torch.Size([32, 10]) torch.Size([32]), trainl...\n",
       "11087    [nn.MSELoss(), nn.CrossEntropyLoss(), [10], [1...\n",
       "11088                                                  NaN\n",
       "11089    [print(model), .named_children(), __init__, cl...\n",
       "11090                                                  NaN\n",
       "11091    [Offsets = torch.tensor(Offsets)\\r\\nshifts = O...\n",
       "11092    [input, Tensor.transpose, input = input.transp...\n",
       "11093    [[batch_size, sequence_length, embedding_dim]....\n",
       "11094    [(6, 512, 768), input.unsqueeze(1), def forwar...\n",
       "11095    [t.shape\\r\\ntorch.Size([1, 36])\\r\\n\\r\\nt = tor...\n",
       "11096                       [t[t!=t[0,3]]\\r\\n, cat, [0,3]]\n",
       "11097                      [y = x[:, np.r_[:3, 4:36]]\\r\\n]\n",
       "11099    [torchvision.transforms.ToTensor, torch.from_n...\n",
       "11100                                                  NaN\n",
       "11101    [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "11103    [softmax, import torch.nn.functional as F\\r\\n....\n",
       "11105                                                  NaN\n",
       "11106    [w1, w1.grad, w1.grad\\r\\n# =&gt; tensor([[0., ...\n",
       "11107    [from torch.utils.data import DataLoader, Data...\n",
       "11108    [deepcopy, from torch.utils.data import DataLo...\n",
       "11109    [pip, conda, conda install pytorch torchvision...\n",
       "11110    [sudo apt install -y nvidia-cuda-toolkit\\r\\n, ...\n",
       "11111                                         [nvidia-smi]\n",
       "11112                               [CUDA_VISIBLE_DEVICES]\n",
       "11113    [sudo pacman -U --noconfirm  cuda-11.6.2-1-x86...\n",
       "11114    [sudo apt-get remove --purge nvidia*\\r\\n, wget...\n",
       "11116    [(16, 1), (16, 2), resnet18, (16, 2), (16, 2),...\n",
       "11117    [(H x W x C), (C x H x W), image = torchvision...\n",
       "11118                                                  NaN\n",
       "11119    [module.weight, torch.nn.Parameter, module.wei...\n",
       "11120                                                  NaN\n",
       "11122    [prediction = net(X_train), X_train, X_train =...\n",
       "11123    [input[I] = S, input = torch.tensor([[2, 3], [...\n",
       "11124    [import torch\\r\\n\\r\\ninp = torch.tensor([[2,3]...\n",
       "11126    [permute, unsqueeze, import torch\\r\\n\\r\\nx = t...\n",
       "11127    [MultivariateNormal, (N, D), cov, (N, D, D), N...\n",
       "11128                                                  NaN\n",
       "11129                                                  NaN\n",
       "11132    [classificadorFinal, inputs, __init__, activat...\n",
       "11133    [nn.ReLU(), ResidualBlock, ResidualBlock, self...\n",
       "11134    [macOS Catalina, protobuf version 3.8.0, 2.0.0...\n",
       "11135    [pip3 uninstall protobuf\\r\\npip3 install proto...\n",
       "11136    [!python -m detectron2.utils.collect_env, ----...\n",
       "11137    [img = self.transforms(img)\\r\\n, img, target =...\n",
       "11138          [copy, pasting, vision/reference/detection]\n",
       "11139    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "11140    [test_data = torch.Tensor(test)\\r\\nraw_preds =...\n",
       "11141                                                  NaN\n",
       "11142                                                  NaN\n",
       "11143    [size, size, import torch\\r\\nfrom typing impor...\n",
       "11144    [def rename_attribute(obj, old_name, new_name)...\n",
       "11145    [import tensorflow as tf\\r\\ntensor = [[1., 2.]...\n",
       "11146    [images, data, get_similarity, pred=[get_simil...\n",
       "11147    [model.chosen_layer.register_forward_hook(prin...\n",
       "11148                                                  NaN\n",
       "11149                               [torch.nn.utils.prune]\n",
       "11151    [x = x.view(x.size(0), -1, 11, 8)\\r\\n, x = x.u...\n",
       "11152    [__getitem__, class LoadDataset(Dataset):\\r\\n ...\n",
       "11153    [.targets, print(dict(Counter(dataset.targets)...\n",
       "11154    [dataset, ImageFolder, dataset = MyDataset() #...\n",
       "11155                                                  NaN\n",
       "11156    [20, batch = 20, seq_len, seq_len = 1, 20, (64...\n",
       "11157    [class Rnn(nn.Module):\\r\\n    def __init__(sel...\n",
       "11158                                                  NaN\n",
       "11159    [tokenizers, word_ids, word, subword, BPE, Uni...\n",
       "11160    [from transformers.tokenization_roberta import...\n",
       "11161                                                  NaN\n",
       "11162    [torch-0.1.2.post2.tar.gz, pip install torch==...\n",
       "11163    [conda create --name test python=3.5\\r\\nconda ...\n",
       "11165    [BertResNet, __init__, self, def __init__(self...\n",
       "11166    [E, E, E, C = A.mm(B)\\r\\n\\r\\n# Ensure that E i...\n",
       "11167                           [sigmoid, relu, LeakyRelu]\n",
       "11168    [    with torch.no_grad():\\r\\n        for i in...\n",
       "11169    [output, target_seq, nn.CrossEntropyLoss, nn.M...\n",
       "11170    [CUB, CUB_HOME, CUB_HOME, nvcc.exe, CUB_HOME, ...\n",
       "11171    [image, image = pil_image.unsqueeze(0)\\r\\nimag...\n",
       "11172    [labels = {'id1':0,'id2':2,'id3':1,'id4':3} ##...\n",
       "11174                                                  NaN\n",
       "11175    [x = torch.tensor([\\r\\n    [1, 2, 3, 4, 3, 3, ...\n",
       "11176    [AlexNet, RunTimeError: Error(s) in loading st...\n",
       "11177    [sudo apt-get purge nvidia-*\\r\\nsudo apt-get r...\n",
       "11180    [torchtext, build_vocab(), import torch\\r\\nfro...\n",
       "11181    [l = []\\r\\nl.append(datasets.ImageFolder(file_...\n",
       "11183          [Y = np.expand_dims(u_actual, axis=-1)\\r\\n]\n",
       "11184    [pip install torch===1.5.0 -f https://download...\n",
       "11185    [nn.CrossEntropyLoss, nn.Linear(1000, 200),\\r\\...\n",
       "11186    [    hf = self.bnh(hf) if type(hf) == torch.Te...\n",
       "11188    [Vocab, torchscript.jit, @torch.jit.script\\r\\n...\n",
       "11189                                        [x1, x2, del]\n",
       "11190    [in_dict = {\"train\": [{\"input\": [[3, 1, 2], [3...\n",
       "11191                                                  NaN\n",
       "11192    [[:2::2], In [233]: arr = np.arange(1,11)     ...\n",
       "11194    [tf.concat, torch.cat, tf.concat(values, axis,...\n",
       "11195    [lstm = nn.LSTM(\\r\\n    input_size = ?, \\r\\n  ...\n",
       "11196                            [tf.expand_dims(x, axis)]\n",
       "11197    [tf.expand_dims(\\r\\n    input, axis, name=None...\n",
       "11198    [h_relu, grad_h_relu = grad_k.mm(w1.t())\\r\\n, ...\n",
       "11199    [a=[torch.tensor([[29733, 20720,     2]])]\\r\\n...\n",
       "11200    [__getitem__, class MyData(Dataset):\\r\\n    de...\n",
       "11201    [a b c d, a b c -&gt; d, y, a -&gt; b\\r\\na b -...\n",
       "11202    [torch.add(input, value=1, other, out=None), d...\n",
       "11203                                                  NaN\n",
       "11204                                                  NaN\n",
       "11205    [from typing import Tuple\\r\\n\\r\\nimport torch\\...\n",
       "11206               [out_ch*2 == in_ch, x, BatchNorm+ReLU]\n",
       "11208                                                  NaN\n",
       "11209    [state_dict, state_dict, torch.optim.Optimizer...\n",
       "11210    [import pickle\\r\\nfrom torch.utils.data import...\n",
       "11211    [nn.CrossEntropyLoss, nn.CrossEntropyLoss(weig...\n",
       "11212    [.backward(), .backward(), D_gen, D_real, requ...\n",
       "11213    [self.conv1 = nn.Conv2d(in_channels=1, out_cha...\n",
       "11214    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11215                                            [grad_w2]\n",
       "11216                                               [.pth]\n",
       "11217    [classname.find('Conv'), .weight, classname.fi...\n",
       "11218    [fil = torch.tensor([[1/9,1/9,1/9],[1/9,1/9,1/...\n",
       "11219    [a = torch.nn.functional.one_hot(tnsr, num_cla...\n",
       "11220    [Tensor.scatter_, .permute, def batch_tensor_t...\n",
       "11221    [data[indices_dim0, indices_dim1], data[indice...\n",
       "11222    [from engine import train_one_epoch, evaluate\\...\n",
       "11223    [nn.Conv2d(3, 64, kernel_size=3, bias=False)\\r...\n",
       "11224    [from transformers import BertModel\\r\\nmodel =...\n",
       "11225                                       [batch_size=2]\n",
       "11226    [t[tuple(l)], t\\r\\ntensor([[1, 2, 3],\\r\\n     ...\n",
       "11227    [def list_as_index(t, l):\\r\\n    if not l:\\r\\n...\n",
       "11228                                                  NaN\n",
       "11229    [loss.backward(), loss = F.nll_loss(F.log_soft...\n",
       "11230    [nn.BatchNorm2d, nn.BatchNorm1d, self.classifi...\n",
       "11231    [-1, -1, 32 * 24 = 768, self.fc1 = nn.Linear(2...\n",
       "11232                                                  NaN\n",
       "11234                                                  NaN\n",
       "11235    [nn.CrossEntropyLoss, nn.LogSoftmax(), nn.NLLL...\n",
       "11237    [numpy, import torch\\r\\nimport numpy as np\\r\\n...\n",
       "11238    [inner_group_num, config = AutoConfig.from_pre...\n",
       "11239    [torch.nonzero, as_tuple=True, torch.long, tor...\n",
       "11240    [x = x[:, -1, :]\\r\\n, x, batch_first, False, x...\n",
       "11241    [.npy, array_1, numpy_array_1.npy, np.save('nu...\n",
       "11242                                                  NaN\n",
       "11243    [numpy.ix_(), S, torch.meshgrid(), # input ten...\n",
       "11244    [requires_grad=True, optimizer.step(), self.we...\n",
       "11246                                                  NaN\n",
       "11247                                                  NaN\n",
       "11248                           [make_datalist, local_var]\n",
       "11249    [nn.Linear, dtype=torch.float, train = torch.t...\n",
       "11250    [eval(), w = g . v\\r\\n, w, import torch\\r\\nimp...\n",
       "11252                                                  NaN\n",
       "11253             [l_conv7.reshape(batch_size, -1, 4)\\r\\n]\n",
       "11254    [int, dtype, # input tensors to work with\\r\\nI...\n",
       "11255    [old_values, mask = old_values == old_new_valu...\n",
       "11257                                                  NaN\n",
       "11258    [torch.from_numpy, apply, df[\"new_feature\"] = ...\n",
       "11259    [df['new_feature'] = df.values.tolist()\\r\\n,  ...\n",
       "11260                                                  NaN\n",
       "11261    [x, b, c, d, h, w, (x, y, z, 1), (0, 0, 0, 1),...\n",
       "11262    [self.features = nn.Sequential(\\r\\n           ...\n",
       "11263    [kernel size, stride, dilation, padding, paddi...\n",
       "11264    [\\r\\nmodel = nn.Sequential(\\r\\n    nn.Conv2d(3...\n",
       "11265    [conv2d, padding = 'same', keras, stride = 2, ...\n",
       "11267    [target[j, b_pact[j]], torch.Size([]), maxq[j]...\n",
       "11268                                                  NaN\n",
       "11269    [nn.Conv1d, depth_2, def calculate_output_leng...\n",
       "11270                                                  NaN\n",
       "11271    [nn.CrossEntropyLoss, log(Softmax(x), nn.LogSo...\n",
       "11272    [nn.CrossEntropyLoss, torch.long, torch.int64,...\n",
       "11273    [torch::Tensor t0 = output.toTuple()-&gt;eleme...\n",
       "11274    [xb = xb.view(-1, 32*32) \\r\\n, xb = xb.view(-1...\n",
       "11275    [num_classes = 10\\r\\n, xb = xb.view(-1, 64*8*8...\n",
       "11276    [p, n x n, import numpy as np\\r\\nfrom scipy im...\n",
       "11277    [n = X.shape[0]\\r\\nintersection_dict = {}\\r\\nf...\n",
       "11278    [ import torch\\r\\n\\r\\n torch.manual_seed(42)\\r...\n",
       "11279    [nn.AdaptiveAvgPool2d((None,1)), nn.AdaptiveAv...\n",
       "11281    [def predict(model, dataloader):  \\r\\n  # Set ...\n",
       "11282                                                  NaN\n",
       "11283                                                  NaN\n",
       "11284    [# For saving your model\\r\\n\\r\\nstate = {\\r\\n ...\n",
       "11285                     [torch.nn.Linear, torch.nn.LSTM]\n",
       "11286    [tf.clip_by_value, clamp_, t = tf.constant([[-...\n",
       "11288    [nn.Conv2d(16, 16, 3, padding = 1)  # stride =...\n",
       "11289    [isObj = 1 if 'obj' in f else 0\\r\\nisNotObj = ...\n",
       "11290    [state, cuda, cpu, map_location, map_location=...\n",
       "11291    [pip install torch==1.5.0+cpu -f https://downl...\n",
       "11292    [.clamp(min=0), q = tf.clip_by_value(q, 0, tf....\n",
       "11293    [model2(model1(input)), retrain_graph=True, re...\n",
       "11294    [barch = tuple(b.to(device) for b in batch)\\r\\...\n",
       "11295    [nn.Module, nn.Sequential, model = torch.nn.Se...\n",
       "11296                 [learn.TTA, log_preds, y, learn.TTA]\n",
       "11297                                                  NaN\n",
       "11298          [output.size(), output = output.squeeze(0)]\n",
       "11299    [m1, m2, 1024 != 4, self.classifier = nn.Seque...\n",
       "11300    [output = model(inputs, batch_size)\\r\\n, outpu...\n",
       "11301    [import pandas as pd\\r\\nimport torch\\r\\nimport...\n",
       "11302    [customDataset, loader = torch.utils.data.Data...\n",
       "11303    [train_data = torchvision.datasets.ImageFolder...\n",
       "11304    [super(), class LSTMCell(nn.Module):\\r\\n\\r\\n  ...\n",
       "11305    [torch.zeros(2048), torch.zeros(1, 2048), o, m...\n",
       "11307    [images.grad.data.zero_()\\r\\n, images.grad = N...\n",
       "11308    [with torch.no_grad():\\r\\n  #here goes the cod...\n",
       "11309    [x = torch.randn(3,requires_grad=True).cuda()\\...\n",
       "11310    [model1, model2, 1.5, &lt;your_torch_install&g...\n",
       "11311    [pip install openvino-dev[pytorch,onnx]\\r\\n, d...\n",
       "11312                   [conda install PyTorch -c PyTorch]\n",
       "11313    [python3 -m venv pytorch-env\\r\\npytorch-env\\Sc...\n",
       "11315    [__init__, class SampleDataset(Dataset):\\r\\n  ...\n",
       "11317    [logits, forward, BertForPretraining, self.cls...\n",
       "11318    [relu(x) = max(0, x)\\r\\nbn(x) = (x - mu) / sig...\n",
       "11319    [nn.CrossEntropyLoss, torch.Tensor, reduction,...\n",
       "11320    [lstm_out, lstm_out[-1, :, :], inps, out, out[...\n",
       "11321    [row_idx = torch.tensor([0, 0, 1, 0, 0, 1, 2, ...\n",
       "11322    [init, input_size = 5\\r\\nhidden_size = 10\\r\\n\\...\n",
       "11323    [path='//content//drive//My\\ Drive//Colab\\ Not...\n",
       "11324                                                  NaN\n",
       "11325                                                  NaN\n",
       "11326    [RuntimeError: Calculated padded input size pe...\n",
       "11327                                                  NaN\n",
       "11328    [torch.equal(w.grad, x) # =&gt; True\\r\\n\\r\\nto...\n",
       "11330    [main_worker, cudnn.benchmark, cudnn.determini...\n",
       "11331    [x, t, M, theta, M = nn.Sequential(....) # dec...\n",
       "11332                                                  NaN\n",
       "11334    [torch.save, state_dict(), checkpoint = {'mode...\n",
       "11335    [def save_for_meta_learning(args, ckpt_filenam...\n",
       "11336    [if __name__ == '__main__':\\r\\n    freeze_supp...\n",
       "11337    [README.md, README.md, requirements.txt, eval_...\n",
       "11338    [# def get_arguments():\\r\\n#     parser = argp...\n",
       "11339    [RuntimeError: Attempting to deserialize objec...\n",
       "11340    [map_location, model.load_state_dict, torch.lo...\n",
       "11341    [param_groups, _LRScheduler, with _enable_get_...\n",
       "11342    [m = EfficientNet.from_pretrained('efficientne...\n",
       "11343                                                  NaN\n",
       "11345    [learn.data.add_test(df['Contact_Text'])\\r\\npr...\n",
       "11346    [torch.nn.Embedding, torch.nn.Embedding, torch...\n",
       "11347    [IndexError: index out of range in self,     e...\n",
       "11348    [import sys\\r\\nbase = 'Win32GUI' if sys.platfo...\n",
       "11349                                                  NaN\n",
       "11350    [features = np.array([\\r\\n    [1, 2, 3, 4],\\r\\...\n",
       "11351    [n_id, z_sparse, # N, n, m = 2078,100, 64\\r\\nr...\n",
       "11352                               [+, __init__, forward]\n",
       "11353                                                  NaN\n",
       "11354                                                  NaN\n",
       "11355                                                  NaN\n",
       "11356    [for id_user in range(nb_users):\\r\\n    v = tr...\n",
       "11357    [conda install pytorch torchvision cpuonly -c ...\n",
       "11358    [RuntimeError: cuDNN error: CUDNN_STATUS_INTER...\n",
       "11359    [conda install pytorch torchvision cudatoolkit...\n",
       "11360    [optimizer.zero_grad(), .backward(), None, req...\n",
       "11361    [import numpy as np\\r\\nimport torch\\r\\n\\r\\n\\r\\...\n",
       "11362    [Conv2d, input, output, output[0][0,...], inpu...\n",
       "11363                                                  NaN\n",
       "11364                                                  NaN\n",
       "11365    [self, class item():# create a random class\\r\\...\n",
       "11366    [transformers.Trainer.train(), model, predict_...\n",
       "11367      [nn.MSELoss, mse_i = (input_i - target_i) ** 2]\n",
       "11368    [for step in range(10000):\\r\\n    artist_paint...\n",
       "11369                                                  NaN\n",
       "11371    [conda install pytorch torchvision cudatoolkit...\n",
       "11372    [Conv1d, Conv2d, 3x3, kernel_size=3, 256, kern...\n",
       "11374                                                  NaN\n",
       "11375    [numpy, nonzero, flatten, a = torch.tensor([[1...\n",
       "11376    [m x n x 2, n = a.shape[0] # 3\\r\\nm = b.shape[...\n",
       "11379                                                  NaN\n",
       "11380    [conda install pytorch torchvision cpuonly -c ...\n",
       "11381    [self, find_option, # This is the option menu ...\n",
       "11382    [class AlexNet(nn.Module):\\r\\n\\r\\n    def __in...\n",
       "11383    [bmm, bmm, - func: bmm(Tensor self, Tensor mat...\n",
       "11384                                                  NaN\n",
       "11386                                                  NaN\n",
       "11387    [source_tensor = source_tensor.view(-1, self.b...\n",
       "11388    [%timeit, %timeit, a, a, a, torch.where, #this...\n",
       "11389    [from transformers import BertTokenizer, BertF...\n",
       "11390    [a * (b &lt;= 0.5)\\r\\n, In [1]: import torch\\r...\n",
       "11391    [torch.where, import torch\\r\\na = torch.rand(3...\n",
       "11396    [class ReflectionPad2D(tf.keras.layers.Layer):...\n",
       "11397              [F, F, import torch.nn.functional as F]\n",
       "11398    [nn.MSELoss(), nn.MSELoss(), loss_fn = nn.MSEL...\n",
       "11399    [loss_function, def loss_function (predicted_x...\n",
       "11400               [pil_img = pil_img.convert(\"RGB\")\\r\\n]\n",
       "11401    [pil_im = pil_im.resize((224, 224), Image.ANTI...\n",
       "11402                                                  NaN\n",
       "11403        [torch.exp, perplexity = torch.exp(loss)\\r\\n]\n",
       "11404    [FORWARD_HAS_DEFAULT_ARGS, torch::Tensor, std:...\n",
       "11407    [img=images[0], img=images[0:1, ...]  # select...\n",
       "11408                       [loss, loss, backward(), loss]\n",
       "11409    [train, FixedModule, eval, train(False), Fixed...\n",
       "11410    [train, from torch import nn\\r\\n\\r\\nclass Fixe...\n",
       "11411                                                  NaN\n",
       "11412                                                  NaN\n",
       "11413    [# model released before 2019.09.09 should use...\n",
       "11414    [filedialog, PIL, from tkinter import filedial...\n",
       "11415    [rnn, pad_sequence, ary\\r\\narray([list([1, 2, ...\n",
       "11416                                 [0.001, 0.001, 1e-5]\n",
       "11417    [self.classifier = nn.Sequential(\\r\\n    nn.Dr...\n",
       "11418    [euler_angles = [ea0, ea1, ea2]\\r\\ntranslation...\n",
       "11419    [np.roll(current_seq, -1, 1), current_seq, cur...\n",
       "11420    [nn.LSTM, input, (h_0, c_0), h_0, c_0, hidden_...\n",
       "11421    [torch.FloatTensor, torch.FloatTensor(T[-20:])...\n",
       "11422    [ReLU(X.W+B), ReLU((ReLU((ReLU(X.W1+B1)).W2+B2...\n",
       "11423    [CrossEntropyLoss, CrossEntropyLoss, batch_siz...\n",
       "11424    [torch.cat, embeddings, avg, torch.unsqueeze, ...\n",
       "11425    [X = torch.arange(24).view(4, 3, 2)\\r\\nprint(X...\n",
       "11426    [torch.mul(X, mask.unsqueeze(-1))\\r\\n, tensor(...\n",
       "11427                                           [avg_pool]\n",
       "11428    [dummy_input = torch.zeros(100), dummy_input =...\n",
       "11429                                            [pytorch]\n",
       "11430    [nn.CrossEntropyLoss, nn.Softmax, nn.CrossEntr...\n",
       "11431    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "11432    [nll_loss, output, target_var, target_var, los...\n",
       "11433                                 [torch.version.cuda]\n",
       "11434    [nn.LSTM, batch_first=True, self._lstm = nn.LS...\n",
       "11435    [padding=(1, 0, 0), self.conv2 = nn.Conv3d(8, ...\n",
       "11436    [rnn.pad_sequence, torch.nn.functional.pad, im...\n",
       "11437    [PadIfNeeded, import albumentations as A\\r\\nfr...\n",
       "11438    [# mean-squared error loss\\r\\ncriterion = nn.M...\n",
       "11439    [torch.cat, dim=0, initialize_gan, self.discri...\n",
       "11440    [def initialize_gan(self):, self.meta_g == Gen...\n",
       "11441    [setup.py, REQUIRED_PACKAGES = ['torchvision==...\n",
       "11442                             [pip3 install torch\\r\\n]\n",
       "11443    [Speller.forward, raw_pred_seq.append(raw_pred...\n",
       "11444    [            returns = returns[::-1]\\r\\n      ...\n",
       "11445    [dtype, PIL.Image, h, w, h, w, img = Image.fro...\n",
       "11447    [missing_keys, unexpected_keys, missing_keys=[...\n",
       "11448    [torch, torch, numpy, torch.float64, np.float6...\n",
       "11449    [nn, nn.Module, 'B', nn.ModuleDict, self.sub_m...\n",
       "11450                                 [num_workers &gt; 1]\n",
       "11451    [R[0], B[0], C[0] = environment.step()\\r\\n, [a...\n",
       "11452    [[batch_size, channels, w, h], channels==3, ar...\n",
       "11453    [resnet.train(False), resnet.eval(), no_grad()...\n",
       "11455    [conda install pytorch torchvision cpuonly -c ...\n",
       "11456                             [!pip install torch\\r\\n]\n",
       "11457    [i=20\\r\\nj=30\\r\\nz = np.zeros((50,50))\\r\\nwhil...\n",
       "11458    [a = torch.randn(10, 1000, 1, 4)\\r\\nb = torch....\n",
       "11459    [DataLoader, Dataset, Dataset, __len__, __geti...\n",
       "11460                                                  NaN\n",
       "11461    [train_accuracy = (train_predict.cpu().numpy()...\n",
       "11462                                                  NaN\n",
       "11463                                                  NaN\n",
       "11464                                                  NaN\n",
       "11465                                                  NaN\n",
       "11466                                                  NaN\n",
       "11467    [vec, (1, n), max_score = vec[0, argmax(vec)]\\...\n",
       "11468    [[1], [5], [1],        *   &lt;- input\\r\\n   /...\n",
       "11469    [nn.utils.rnn.pack_padded_sequence, batch_firs...\n",
       "11470    [W_x, W_h, bias=True, np.tanh, torch.tanh, h_t...\n",
       "11471    [a = torch.rand(10, 3, 20, 20)\\r\\nplt.imsave(\"...\n",
       "11472    [images=img_tensor.cpu().numpy()[0]\\r\\nimages ...\n",
       "11473    [from torchvision import transforms\\r\\n, datas...\n",
       "11475    [def train_fn(data_loader, model, optimizer, d...\n",
       "11476    [def __getitem__(self, item):\\r\\n        revie...\n",
       "11477    [module.parameters(), nn.Parameter, nn.Paramet...\n",
       "11478    [optimizer.zero_grad(), def train(epoch, model...\n",
       "11479    [softmax, def forward(self, X): \\r\\n    X = F....\n",
       "11481    [nn.DataParallel, module, module., class Neste...\n",
       "11482    [DataParallel, module., DataParallel, model = ...\n",
       "11483    [requires_grad=True, weight = torch.randn((2, ...\n",
       "11484    [a = torch.rand(10, requires_grad=True)\\r\\n, a...\n",
       "11485    [&lt; 0.4, &gt; 0.4, checkpoint = torch.load(a...\n",
       "11488    [dynamic_axes, torch.onnx.export, torch.onnx.e...\n",
       "11490    [curl https://raw.githubusercontent.com/pytorc...\n",
       "11491    [!pip uninstall -y torch\\r\\n!pip install torch...\n",
       "11492    [chain, itertools.chain(*iterables)\\r\\n\\r\\n   ...\n",
       "11494    [tensor * 2, cpu_tensor * tensor(2, device='cu...\n",
       "11495                                                  NaN\n",
       "11496    [320 x 1 x 64 x 64, x = self.pool(f.relu(self....\n",
       "11497    [CIFAR10, ResNet, CIFAR10, Adam, Adadelta, SGD...\n",
       "11498    [pip install torch==1.5.0+cpu torchvision==0.6...\n",
       "11499    [-f https://download.pytorch.org/whl/torch_sta...\n",
       "11500    [-f https://download.pytorch.org/whl/torch_sta...\n",
       "11501         [FROM python:3, Dockerfile, From python:3.7]\n",
       "11502    [nn.CrossEntropyLoss, self.encoder_softmax = n...\n",
       "11503                                                  NaN\n",
       "11504    [Encoder(), .forward(), enc = Encoder()\\r\\ninp...\n",
       "11505    [Encoder(), net, trained_encoder = net.fc1\\r\\n...\n",
       "11506    [torchvision.transforms.Lambda, def erase_midd...\n",
       "11508    [def eval(file):\\r\\n    image = cv2.imread(fil...\n",
       "11509    [torch.hub.load, map_location, map_location, t...\n",
       "11513    [reader_npz, def reader_npz(path):\\r\\n    with...\n",
       "11514    [def foo():\\r\\n    my_tensor = torch.tensor([1...\n",
       "11515                                                  NaN\n",
       "11516    [pip install torchdata\\r\\n, torch.utils.data.D...\n",
       "11517           [torch.unfold(dimension, size, step) \\r\\n]\n",
       "11518    [i, a[:,:,:,i:i+10,:]\\r\\n, tensor_3, a[:,:,:,3...\n",
       "11519    [.detach(), prediction = policy_model(torch.fr...\n",
       "11520    [torch.set_grad_enabled(True)  # Context-manag...\n",
       "11521    [requires_grad=True, import numpy as np\\r\\nimp...\n",
       "11522    [nn.LSTM, torch.nn.utils.rnn.pack_padded_seque...\n",
       "11523                                       [len(x[0]), 3]\n",
       "11524                                          [len, list]\n",
       "11526    [zero_grad, import torch\\r\\n\\r\\nX = torch.rand...\n",
       "11527    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "11528    [0 0.20198837077617646\\r\\n1 0.1763681819438934...\n",
       "11529    [class SiameseCNN(nn.Module):\\r\\n    def __ini...\n",
       "11531    [torch.topk, k, values, indices, x = torch.ara...\n",
       "11532    [ import torch\\r\\n import torch.nn as nn\\r\\n c...\n",
       "11533                                                  NaN\n",
       "11534    [loss1, (sum(accumulated_loss1) + loss2).backw...\n",
       "11535                [COPY data/ /data/, COPY data /data/]\n",
       "11536    [torch.stack(), import torch\\r\\n\\r\\nM = []\\r\\n...\n",
       "11537    [ref = np.arange(3*4*5).reshape(3,4,5) # numpy...\n",
       "11538    [tf.gather_nd, batch_dims, interpolate, [C, H,...\n",
       "11539    [pos, bs = 2\\r\\nH = 4\\r\\nW = 6\\r\\nC = 3\\r\\ninp...\n",
       "11540    [def gather_nd_torch(params, indices, batch_di...\n",
       "11541    [(248, 1, 108), (1, 1, 248*108), batch, torch....\n",
       "11542    [nn.CrossEntropyLoss, out = F.softmax(self.lin...\n",
       "11543                                                  NaN\n",
       "11544    [criterion = Loss(weight_geo, weight_angle, ge...\n",
       "11545    [torch.utils.data.Dataset, __getitem__, class ...\n",
       "11546    [acc = corrects.sum()/len(corrects)\\r\\n, corre...\n",
       "11547    [corrects, acc = corrects.sum() / len(corrects...\n",
       "11549    [result = torch.sum(torch.stack([x, y, ...]), ...\n",
       "11550    [add_, a = torch.randn(5)\\r\\nb = torch.randn(5...\n",
       "11551    [import functools\\r\\nimport operator\\r\\n\\r\\nli...\n",
       "11552    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "11553    [def get_current_lr(optimizer, group_idx, para...\n",
       "11554                                                  NaN\n",
       "11555    [np.argpartition, def partition_assign(a, n):\\...\n",
       "11556    [n, def tensor_threshold(tensor, n):\\r\\n    th...\n",
       "11557    [torch.topk, 1, t = torch.tensor([[0.8, 0.1, 0...\n",
       "11559                                                  NaN\n",
       "11560    [seq_length x seq_length, torch.nn.Softmax(dim...\n",
       "11561    [seq_length x embed_size, embed_size x seq_len...\n",
       "11562    [numpy.array, .shape,  import numpy as np\\r\\n ...\n",
       "11563                                                  NaN\n",
       "11564    [libcuda.so, libcudart.so, nvcc, nvidia-smi, n...\n",
       "11565    [nvcc, $PATH, $PATH, ~/.bashrc, export PATH=/u...\n",
       "11566    [export PATH=/usr/local/cuda-10.2/bin:/opt/nvi...\n",
       "11567                                                  NaN\n",
       "11570    [_rejection_sample, torch.distributions, .spec...\n",
       "11571    [pd.read_csv(csv_file), img_path = os.path.joi...\n",
       "11572                                                  NaN\n",
       "11573                                                  NaN\n",
       "11574    [bidirectional=True, nn.LSTM, torch.nn.utils.r...\n",
       "11575    [optimizer = optim.Adam([\\r\\n    {'params': ne...\n",
       "11576    [a[index], chunk = n // 10  # the largest chun...\n",
       "11577                                                  NaN\n",
       "11578                                                  NaN\n",
       "11579                                                  NaN\n",
       "11580    [pytorch-cpu, 1.1.0, 1.5.0, conda install pyto...\n",
       "11581                                                  NaN\n",
       "11582    [SSH, rsync, rsync\\r\\n  local-file user@remote...\n",
       "11583    [next_action, if self.ddqn:\\r\\n    Q_next = (1...\n",
       "11584    [torch.cat, unsqueeze, import torch\\r\\n\\r\\nfir...\n",
       "11585    [eq, torch.Tensor, np.ndarray, pred_flat, torc...\n",
       "11587                                                  NaN\n",
       "11588     [NLLLoss, y, NLLLoss, nn.LogSoftmax, nn.Softmax]\n",
       "11589    [#Makes a copy of the weights of the selected ...\n",
       "11590    [y_label = torch.tensor(int(self.annotations.i...\n",
       "11591    [lam = torch.rand(batch_size)\\r\\n, lam = torch...\n",
       "11592    [lam[index] * x, x, torch.Size([64, 3, 256, 25...\n",
       "11593    [runtime: python\\r\\nenv: flex\\r\\nentrypoint: g...\n",
       "11594    [for epoch in range(num_epochs):\\r\\n    # trai...\n",
       "11595    [x = torch.tensor(list(map(float, line.split('...\n",
       "11596                                         [fromstring]\n",
       "11597    [1.5.0, pip uninstall torch\\r\\npip install tor...\n",
       "11598                                              [tmpfs]\n",
       "11599                                                  NaN\n",
       "11600    [reshape, view, permute, reshape, view, shape,...\n",
       "11601    [fc1, fc2, num_classes, num_classes = 200\\r\\nm...\n",
       "11602    [DistilBertForSequenceClassification, torch.Si...\n",
       "11603    [nn.Module, class Net(nn.Module):\\r\\n    def _...\n",
       "11604                        [from torch import optim\\r\\n]\n",
       "11605                        [nn.Softmax(-1), torch.max()]\n",
       "11606    [torch.multinomial, torch.distributions, from ...\n",
       "11607    [conda, standalone conda, standalone-conda.exe...\n",
       "11608                           [_, torch.add, torch.add_]\n",
       "11609    [[0, 1, 2, 3, ..., N], maximum, argmax, def ac...\n",
       "11611    [    (pooler): BertPooler(\\r\\n      (dense): L...\n",
       "11612    [dof, x_index = torch.arange(3).unsqueeze(1).e...\n",
       "11613    [x.shape\\r\\ntorch.Size([1, 56, 128, 128])\\r\\n\\...\n",
       "11614    [import torch\\r\\nimport torchvision.transforms...\n",
       "11615    [padding_masking = batch &gt; 0\\r\\n, padding_m...\n",
       "11616    [pad_token_id = 0\\r\\nbatch = torch.tensor([\\r\\...\n",
       "11617    [y = (x * x).sum(axis=0)\\r\\n, np.einsum, x * x...\n",
       "11618    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "11619                           [List index out of range.]\n",
       "11620    [torch                    1.5.0+cu101    \\r\\nt...\n",
       "11621    [a = torch.rand(8, 1, 128)\\r\\nb = torch.rand(8...\n",
       "11622    [torch.arange, output[torch.arange(output.size...\n",
       "11623    [index = torch.tensor([23, 10,  3,  3,  1,  1,...\n",
       "11626                                                  NaN\n",
       "11627    [summary, summary, base_model, layer0, base_mo...\n",
       "11631                 [conda install -c fastai fastai\\r\\n]\n",
       "11632                                                  NaN\n",
       "11633    [a[a[:, 0].sort()[1]]\\r\\n, tensor([[3., 5.],\\r...\n",
       "11634    [torch.stack(sorted(a, key=lambda a: a[0]))\\r\\...\n",
       "11635    [moveaxis, a = np.empty([20000, 69, 69, 3])\\r\\...\n",
       "11636    [comparison = torch.tensor(range(max_idx))\\r\\n...\n",
       "11637    [torch/nn/parameter.py, result = type(self)(se...\n",
       "11638    [nn.Conv2D, class MorphNetwork(nn.Module):\\r\\n...\n",
       "11639                                                  NaN\n",
       "11640                                                  NaN\n",
       "11641    [x, [1, 3, height, width], x.unfold(1, size, s...\n",
       "11642                                                  NaN\n",
       "11643                                                  NaN\n",
       "11644                        [pip install torchvision\\r\\n]\n",
       "11645                                                  NaN\n",
       "11646    [for images, label in enumerate (train_loader)...\n",
       "11647    [images, label in (train_loader) \\r\\n, images,...\n",
       "11648     [weight_decay, weight_decay, weight_decay, 1e-4]\n",
       "11649                                                  NaN\n",
       "11650    [linear1 = nn.Linear(d,d), (d,l), X.shape = (l...\n",
       "11652    [random_split, torch.utils.data.Subset, import...\n",
       "11654    [self.attention = MultiHeadAttention(), self.t...\n",
       "11655    [import torch as T\\r\\n\\r\\ndef h_poly_helper(tt...\n",
       "11656    [import torch\\r\\n\\r\\ndef h_poly(t):\\r\\n    tt ...\n",
       "11657                                                  NaN\n",
       "11658                                                  NaN\n",
       "11659    [% AverageRecall given 100 detections per imag...\n",
       "11660    [torch.optim.lr_scheduler.StepLR(optimizer, 1,...\n",
       "11661    [torch.optim.lr_scheduler.StepLR, params, loss...\n",
       "11662    [0.81, 1.1.0, scheduler.step(), optimizer.step...\n",
       "11663                                                  NaN\n",
       "11664                            [squeeze, unsqueeze, dim]\n",
       "11665    [unsqueeze(), 1, squeeze, 1, shape, import tor...\n",
       "11666    [torch.unsqueeze(input, dim), Tensor, a = torc...\n",
       "11668    [list(model.parameters())[0].grad\\r\\n, tensor(...\n",
       "11669                                   [state_dim, 5, 10]\n",
       "11670    [modules, train_and_evaluate, .py, model_util....\n",
       "11671    [torch.save(model, PATH), pickle, __main__, NN...\n",
       "11672    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "11673    [def average_gradients(model):\\r\\n    size = f...\n",
       "11678                                                  NaN\n",
       "11679                       [res, X, nn.BatchNorm2d, relu]\n",
       "11680    [align_corners = True, align_corners = True, g...\n",
       "11681    [conda install -c pytorch -c fastai fastai, co...\n",
       "11682    [no_check=True, import warnings\\r\\nwarnings.fi...\n",
       "11683    [LightningModule, torch.nn.Module, cuda(), eva...\n",
       "11684    [img = torch.from_numpy(img).float().unsqueeze...\n",
       "11685    [X_test, X_test, X_test = torch.Tensor(X_test....\n",
       "11686    [train, torch.utils.data.Dataset, dataset[5], ...\n",
       "11687    [t1, t2, [16384, 3, 224, 224], result = t1 * t...\n",
       "11688    [    learn = Learner(data, \\r\\n               ...\n",
       "11689    [from fastai.callbacks import *\\r\\nfrom fastai...\n",
       "11690                                                  NaN\n",
       "11691    [import torch\\r\\n\\r\\nclass MyDataloader(torch....\n",
       "11692    [nn.Linear, nn.Linear(vocab_size, num_labels),...\n",
       "11693                                                  NaN\n",
       "11694                                                  NaN\n",
       "11695    [a * b, torch.mul(a, b), permute(), import tor...\n",
       "11696    [ from PIL import Image\\r\\n import imagehash\\r...\n",
       "11698    [GPU-util, nvidia-smi, init, init, ps, SIGCHLD...\n",
       "11699                                                  NaN\n",
       "11700    [--evaluate_during_training, 0506 12:11:30.021...\n",
       "11701    [ppa:graphics-drivers\\r\\n, wget http://us.down...\n",
       "11702    [# step added for custom embedding\\r\\nself.tok...\n",
       "11703    [[1], [1,1,....1], loss.backward(torch.Tensor(...\n",
       "11704    [if, nn.Sequential, class Building_Blocks(torc...\n",
       "11705    [list, list, from typing import Optional\\r\\nim...\n",
       "11706                [criterion, netG, output, netG, netG]\n",
       "11708                                    [weights, weight]\n",
       "11709    [matmul, [784, 256], [256, 784], nn.Linear, .....\n",
       "11710                 [state_dict = state_dict.copy()\\r\\n]\n",
       "11712    [txt_filename = 'output.txt'\\r\\n\\r\\nwith open(...\n",
       "11713    [torch.DataLoader, __getitem__, # ...\\r\\nprint...\n",
       "11714                                                  NaN\n",
       "11715    [t, arr, id, numpy, C, Python, torch, C++, id(...\n",
       "11716    [torch, X_train = torch.from_numpy(x_train[......\n",
       "11717    [YOUR_PATH_TO_PYTHON_ENV, install_name_tool -a...\n",
       "11718    [https://pytorch.org, pip install torch==1.5.0...\n",
       "11719    [vgg16, labels = Encode(labels)  # torch.Size(...\n",
       "11720    [labels = Encode(labels) ## for example, label...\n",
       "11721    [torch.no_grad(), data, with torch.no_grad():\\...\n",
       "11722    [/tmp/tfe.config, cluster.start()\\r\\n, alice =...\n",
       "11723    [local mode, privileged, 2.80.0, local mode, s...\n",
       "11724    [num_outputs = 1, nn.CrossEntropyLoss(), .forw...\n",
       "11725    [# Load the pretrained model from pytorch\\r\\nv...\n",
       "11726    [vgg16 = models.vgg16(pretrained=True)\\r\\n\\r\\n...\n",
       "11727    [treeEmbedding = register_module&lt;TreeEmbedd...\n",
       "11728                                                  NaN\n",
       "11729    [conv_transpose2d, max_unpool2d, torch.nn.func...\n",
       "11730    [torch.repeat_interleave, t.repeat_interleave(...\n",
       "11731    [final_features = feature_combined.view(1, -1,...\n",
       "11732    [forward_once, forward_once, forward_once, for...\n",
       "11733    [dill, dill, klepto, mystic, sklearn, pytorch,...\n",
       "11734                                   [dill, torch.save]\n",
       "11735    [torch.device('cuda:0'), torch.randn((2,3), de...\n",
       "11736                                                  NaN\n",
       "11738    [MyModel, device, skip_conn, class MyNet(nn.Mo...\n",
       "11739    [!pip install \"torch==1.4\" \"torchvision==0.5.0...\n",
       "11742    [shape, (N,C), C, (N), 0 ≤ targets[i] ≤ C−1, b...\n",
       "11743    [! pip install transformers, pip install trans...\n",
       "11745    [import torch\\r\\n\\r\\nlabels = torch.tensor([0,...\n",
       "11746    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nlab...\n",
       "11747    [scatter_, t = torch.tensor([0,2]).unsqueeze(0...\n",
       "11749    [(batch/index of image, height, width, class_m...\n",
       "11750                                                  NaN\n",
       "11751                                                  NaN\n",
       "11752                [image1.squeeze().permute(1,2,0)\\r\\n]\n",
       "11753    [print(model.fc1(x).size()), fc1, label.size()...\n",
       "11754    [CUDA_LAUNCH_BLOCKING=1 python [YOUR_PROGRAM]\\...\n",
       "11755        [ self.fc3 = nn.Linear(84, num_classes) \\r\\n]\n",
       "11756    [CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when...\n",
       "11757    [for batch_idx, (x, target) in enumerate(train...\n",
       "11758                  [num_classes, main.py, num_classes]\n",
       "11759                            [maximum sequence length]\n",
       "11760    [writer.add_scalars, s, dictionary,  add_scala...\n",
       "11761    [(pid=20839) /home/ubuntu/src/skai-ml/venv/lib...\n",
       "11762                            [F.conv2d(), nn.Conv2d()]\n",
       "11763    [def __init__(self, csv_file, train):\\r\\n\\r\\n ...\n",
       "11764    [def init_hidden(self, batch_size)-&gt;None:\\r...\n",
       "11765    [retain_graph=True, .backward(), .backward(), ...\n",
       "11766                                                  NaN\n",
       "11767    [np.tile, out += np.tile(x, (1,out.shape[1]//x...\n",
       "11770    [CrossEntropyLoss, categorical_crossentropy, f...\n",
       "11771    [class Encoder(nn.Module):\\r\\n    def __init__...\n",
       "11772    [input_seq = input_seq.view(10 ,self.batch_siz...\n",
       "11773    [CrossEntropyLoss, [batch size x number of cla...\n",
       "11774    [&gt; pip install transformers\\r\\n, from trans...\n",
       "11775    [# ... in model (forward pass)...\\r\\n    x = l...\n",
       "11777    [softmax(), fc4(), nn.CrossEntropyLoss(), soft...\n",
       "11778    [torch.nn.ModuleList, append, torch.nn.Module,...\n",
       "11779                                                  NaN\n",
       "11780    [class BasicBlock(nn.Module):\\r\\n    def __ini...\n",
       "11781    [COCOEvaluator, max_dets_per_image, COCOevalMa...\n",
       "11782                                                  NaN\n",
       "11783    [from pytorch_transformers import XLMConfig, X...\n",
       "11784       [PyTorch, src, requirements.txt, transformers]\n",
       "11785    [sklearn.utils.class_weight.compute_class_weig...\n",
       "11786    [(reduction='mean'), ((-math.log(0.7311)*0.36)...\n",
       "11787    [install, conda install -c pytorch pytorch tor...\n",
       "11788                                                  NaN\n",
       "11789                                                  NaN\n",
       "11790                                                  NaN\n",
       "11791                                                  NaN\n",
       "11792    [out = torch::from_blob(outputs[i], {1, num, d...\n",
       "11793    [predictions, torch.Tensor, ([True, False, Fal...\n",
       "11794    [transform = transforms.Compose([\\r\\n    trans...\n",
       "11796    [0.8.0, torchvision, torch.Tensor, torch.nn.Mo...\n",
       "11797    [torch.utils.data.Dataset, pytorch, pillow, to...\n",
       "11798    [torch.cat, torch.tensor, t_b_output = torch.t...\n",
       "11799    [errD_real, D(G(z))&gt;0, D(x)&lt;0, errD_read...\n",
       "11800    [was got input size torch.Size([1, 16]), input...\n",
       "11801                 [BatchNorm, batch_dim, model.eval()]\n",
       "11804    [- L1 = 25 → int((24 + 2*1 - 1*(2 - 1) - 1) / ...\n",
       "11805    [Bert Model transformer with a sequence classi...\n",
       "11806    [for param in self.bert.parameters():\\r\\n    p...\n",
       "11807    [        self.downscale_time_conv = torch.nn.M...\n",
       "11808    [class UnNormalize(object):\\r\\n    def __init_...\n",
       "11809                                                  NaN\n",
       "11810                                                  NaN\n",
       "11811    [y = a*exp(-((x-b)^2)/2c^2), x, a, b, c, y, x,...\n",
       "11812                                                  NaN\n",
       "11813    [    def __call__(self, img):\\r\\n        img =...\n",
       "11814    [def __call__(self, img):\\r\\n        img = np....\n",
       "11817    [lengths, lengths - 1, -1, range(len(lengths))...\n",
       "11818    [nn.Module, self.layers = [nn.Linear(i,p) for ...\n",
       "11819    [keras, for layer in model.layers:\\r\\n    prin...\n",
       "11820    [models.resnext101_32x8d, m1 = models.resnext1...\n",
       "11823                                                  NaN\n",
       "11824    [import torch \\r\\nimport numpy as np\\r\\n\\r\\nso...\n",
       "11825                                                  NaN\n",
       "11826                                                  NaN\n",
       "11827    [len(train_df[\"my_category\"].unique()) == len(...\n",
       "11828    [0.95, 50, torch.nn.softmax, outputs = net(inp...\n",
       "11830    [x, doc, Conv2d, (N, C, H, W), N, C, H, W, tor...\n",
       "11831    [torch.nn.MSELoss(out, target), MSELoss, size_...\n",
       "11832    [CrossEntropyLoss, NLLLoss, target, Long, Runt...\n",
       "11833    [FloatTensor, a = th.tensor([1,1])\\r\\nb = th.t...\n",
       "11834    [torch.no_grad(), def select_action(self, stat...\n",
       "11835    [python 2.7, pytorch, pytorch-cpu, python 2.7,...\n",
       "11836                                     [print(x.shape)]\n",
       "11837    [backward(), yGrad = torch.zeros(1,1)\\r\\ndef e...\n",
       "11838    [class ImageData(Dataset):\\r\\n    def __init__...\n",
       "11839    [torch::data::datasets::Dataset, CustomDataset...\n",
       "11840    [torch.gather, t = torch.tensor([[-0.2,  0.3],...\n",
       "11842    [self.running_mean = (...), self.running_mean....\n",
       "11844                                                  NaN\n",
       "11845    [grad_y[i] = 1., grad_y[i] = 0., grad_y, jacob...\n",
       "11846    [.clone(), torch.Tensor, some_container[slice_...\n",
       "11847                                                  NaN\n",
       "11848    [# Add this in a Google Colab cell to install ...\n",
       "11849    [GPU Runtime, !pip install torch-geometric \\\\r...\n",
       "11851    [addmm, f(x)[0].detach().numpy()\\r\\narray([-0....\n",
       "11852    [e, nn.Module, def __init__(self):\\r\\n    \"\"\"\\...\n",
       "11853    [tensor=tensor.cpu(), index = tensor([[124, 58...\n",
       "11854    [inp =  torch.randn(4, 1040, 161)   \\r\\nindice...\n",
       "11855                                                  NaN\n",
       "11856    [chap&gt; summarize writable\\r\\n5 ranges take ...\n",
       "11857    [super().__init__(self)\\r\\n, super(Model, self...\n",
       "11858    [super(), class Model(nn.Module):\\r\\n    def _...\n",
       "11859    [embedding_output = torch.tensor(embedding_out...\n",
       "11860                                                  NaN\n",
       "11861    [total_loss+= loss.item()*15\\r\\n, total_loss+=...\n",
       "11862                                                  NaN\n",
       "11863    [varOutput, torch.round, nn.Sigmoid(), torch.s...\n",
       "11864    [requires_grad=True, torch.nn.Parameter, a = t...\n",
       "11865    [x = x.view(x.shape[0],x.shape[2],x.shape[1])\\...\n",
       "11866    [import numpy as np\\r\\n\\r\\ndef funct(semembs_a...\n",
       "11867    [import torch\\r\\ntorch.manual_seed(1)\\r\\n\\r\\nb...\n",
       "11868    [loss.backward(), # The indices of the max ope...\n",
       "11869    [import networkx as nx\\r\\n\\r\\nedge_index = tor...\n",
       "11870    [F.conv2d, self.channels[:, 1].size()\\r\\n# =&g...\n",
       "11871    [yhat = torch.max(z.data,1)\\r\\n, torch.argmax(...\n",
       "11872    [ pred = model(image)\\r\\n _, prediction = torc...\n",
       "11873    [import tensorflow as tf\\r\\nimport tensorboard...\n",
       "11874    [rnn = rnn.cuda()\\r\\ntrain_X = train_X.cuda()\\...\n",
       "11875    [image, 3, batch, out_features, 1x3, 3, import...\n",
       "11876                                            [[1,1,1]]\n",
       "11877    [t2 = t1.view(t1.shape[0],-1), t1 = torch.Tens...\n",
       "11878    [tlist, tlist = [t.reshape(-1,1) for t in tlis...\n",
       "11880                                                  NaN\n",
       "11881                                                  NaN\n",
       "11882    [def save_vocab(vocab, path):\\r\\n    import pi...\n",
       "11883    [torch.save(vocab_obj, 'vocab_obj.pth')\\r\\n, v...\n",
       "11884                                                  NaN\n",
       "11885    [torch.save(model.state_dict, 'model_state.pth...\n",
       "11886    [torch.save(model.state_dict, 'model_state.pth...\n",
       "11887                                                  NaN\n",
       "11888    [torch.topk, predicted_indices = [x.item() for...\n",
       "11889    [self.discriminator2.parameters(), for param i...\n",
       "11890    [y, y_hat, cohen_kappa_score, def quadratic_ka...\n",
       "11891    [itos, TEXT.vocab.vectors, Field, Vocab, TEXT....\n",
       "11892                                                  NaN\n",
       "11893                                     [batch_size, 32]\n",
       "11894                                                  NaN\n",
       "11895                                                  NaN\n",
       "11896    [dtype, input, numpy, np.float64, torch.float6...\n",
       "11897    [torch.Generator, gen0 = torch.Generator()\\r\\n...\n",
       "11898    [print('epoch: {} - batch: {}/{} '.format(ep, ...\n",
       "11899    [nn.Parameter, test_nn, convs, self.convs = [n...\n",
       "11900    [#byte\\r\\nb = b'0.06722715'\\r\\n# to string\\r\\n...\n",
       "11901    [text_pair, encode, from transformers import A...\n",
       "11902                              [pip install -U pillow]\n",
       "11903                                                  NaN\n",
       "11904    [torch.tensor, y, x, x = torch.tensor([1., 2.,...\n",
       "11905    [\\r\\n\\r\\nThe databunch object takes training, ...\n",
       "11906    [for p in group['params']:\\r\\n    if p.grad is...\n",
       "11907    [loss = outputs[0], loss, loss = outputs[0].me...\n",
       "11908                                                  NaN\n",
       "11909    [BucketIterator, sort_key, text, wage_label, t...\n",
       "11910            [nn.Module.load_state_dict, strict=False]\n",
       "11911    [  pred = pred.argmax(dim=1, keepdim=True) # g...\n",
       "11912    [    input_ids = tokenizer.encode(question, te...\n",
       "11913    [model1, torch.load, state_dict, Model, def lo...\n",
       "11914                                                  NaN\n",
       "11915                          [g3s.xlarge, num_workers=0]\n",
       "11916                                                  NaN\n",
       "11917    [output = input_array.swapaxes(1,2).reshape(N*...\n",
       "11918    [torch.optim.Optimizer, params, params, Optimi...\n",
       "11919    [for data, label in CifarDataLoader:\\r\\n     d...\n",
       "11920                                                  NaN\n",
       "11924    [self.linear2 = nn.Linear(in_features=100, out...\n",
       "11925    [Tanh\\r\\n\\r\\nclass\\r\\ntorch.nn.Tanh\\r\\n[source...\n",
       "11926    [BatchNorm1d, (N, C), (N, C, L), (N, L), (N,),...\n",
       "11928    [    def forward(self, x):\\r\\n        x = self...\n",
       "11930    [    def max_pooling(input_tensor, max_sequenc...\n",
       "11931    [if, x, y, where, x, y, 0, x ↦ x &gt; 0 ? x : ...\n",
       "11933    [final[\"t-lembeddingXX\"] = final[\"t-lembedding...\n",
       "11936    [padding_idx, padding_idx, padding_idx, num_em...\n",
       "11937    [padding_idx, import torch\\r\\n\\r\\nembedding = ...\n",
       "11938                                                  NaN\n",
       "11939                                                  NaN\n",
       "11940    [model.to(dev), xm.send_cpu_data_to_device(mod...\n",
       "11941    [torch.amax(), import torch\\r\\n\\r\\nx = torch.t...\n",
       "11942    [x, In [58]: x.shape   \\r\\nOut[58]: torch.Size...\n",
       "11943    [torch.max(), max_i_vals, max_i_indices = torc...\n",
       "11944    [def torch_max(x,dim):\\r\\n    s1 = [i for i in...\n",
       "11945    [sqrt, # alpha_l = eta * np.sqrt(grad_W.numel(...\n",
       "11946              [side_inputs[:-45, :] = side_input\\r\\n]\n",
       "11947    [nn.AdaptiveAvgPool2d(1), CrossEntropyLoss, nn...\n",
       "11948    [Tensor.cuda(), tr = tr.cuda()\\r\\ntrtg = trtg....\n",
       "11949    [import torch\\r\\nfrom torch import nn\\r\\nfrom ...\n",
       "11950    [transforms.ToPILImage(), composed = transform...\n",
       "11952                                   [k, k, ##, \\u0120]\n",
       "11953                                                  NaN\n",
       "11954                                           [__init__]\n",
       "11955    [self.__private\\r\\n, self._Test__private\\r\\n, ...\n",
       "11956    [def zero_padding(img, size0, pad1, pad2):\\r\\n...\n",
       "11957    [Dimension = 2, PixelType* rowdata = itk_img-&...\n",
       "11958                                                  NaN\n",
       "11960    [a = torch.randn(3, 5)\\r\\nb = torch.zeros(3, 2...\n",
       "11961    [im_net.features[25].weight.requires_grad = Fa...\n",
       "11962    [loss.backward(), loss.backward(), optimizer.z...\n",
       "11963                                     [length, length]\n",
       "11964    [    '''\\r\\nmodel_name is the model name, such...\n",
       "11965    [model.parameters(), optimizer = Adam(model.pa...\n",
       "11966    [torch.unsqueeze, mask = torch.zeros(5,3, dtyp...\n",
       "11967    [import torch, torch.nn as nn\\r\\n\\r\\nclass L1P...\n",
       "11968    [nn.Module, L1Penalty, forward, import torch, ...\n",
       "11969    [b.obj, nn.Module, b.obj, nn.Module, b.obj, nn...\n",
       "11970    [for i in nn.Conv2d(in_channels=2, out_channel...\n",
       "11971    [list, nn.Modulelist(list), import torch.nn as...\n",
       "11973    [forward(), torch.cat(), conv1 = Conv2dBlock(2...\n",
       "11974    [import torch\\r\\nimport torchvision\\r\\n\\r\\ntra...\n",
       "11975    [X = torch.from_numpy(X)\\r\\ny = torch.from_num...\n",
       "11976    [x, w, out = x @ w.T\\r\\n, unsqueeze, x : torch...\n",
       "11977    [torch.optim, weight_decay, def train_net(epoc...\n",
       "11978    [import torch\\r\\nimport numpy as np\\r\\n\\r\\ntar...\n",
       "11979    [I like hugging animals, [\"I\", \"like\", \"huggin...\n",
       "11981    [t = torch.rand(4,161,325)\\r\\n\\r\\nt = t[..., 1...\n",
       "11982    [permute(), a = torch.randn(28, 28, 8)\\r\\nb = ...\n",
       "11983                [permute, b = a.permute(2, 0, 1)\\r\\n]\n",
       "11984                                                  NaN\n",
       "11985    [.unsqueeze(), torch.cat(), import torch\\r\\n\\r...\n",
       "11988    [x-x_mean/sigma, images, ...\\r\\nimages = image...\n",
       "11989    [import torch\\r\\nx = torch.tensor([[1, 2, 3],\\...\n",
       "11990    [NumPy's, np.take_along_axis, torch.gather, x....\n",
       "11991    [unhandled system error, NCCL_DEBUG=INFO, iZbp...\n",
       "11992                      [a = torch.zeros((3,3)).cuda()]\n",
       "11995    [batch_index, mask_batch, mask, def f(batch_in...\n",
       "11997    [class CustomDataset:\\r\\n    def __getitem__(s...\n",
       "11998    [open, uc?export=download, CSV_GDRIVE_URL, CSV...\n",
       "11999    ['https://drive.google.com/open?id=1ctPKO-_sJb...\n",
       "12000    [km.required_grad_(True), k1, k1_mean.grad, k1...\n",
       "12001    [params, torch.optim.Optimizer, torch.optim.SG...\n",
       "12002    [Rotate, import kornia as tgm\\r\\n\\r\\n# set the...\n",
       "12003    [import os\\r\\nos.environ[\"NCCL_DEBUG\"] = \"INFO...\n",
       "12004    [conda install -c anaconda tensorflow-gpu, ten...\n",
       "12005    [conda install -c conda-forge &lt;library_name...\n",
       "12006    [conda install pytorch torchvision cudatoolkit...\n",
       "12007    [self.hidden = nn.Linear(784, 256), hidden, se...\n",
       "12008    [download_from_url, import os\\r\\nimport torch\\...\n",
       "12010    [import onnx\\r\\nfrom keras.models import load_...\n",
       "12011    [import torch.multiprocessing as mp\\r\\n\\r\\ncla...\n",
       "12012    [List[Dict[Tensor]], Dict, boxes (FloatTensor[...\n",
       "12013    [WeightedRandomSampler, #Let there be 9 sample...\n",
       "12014    [numpy.array, import numpy as np\\r\\nimport tor...\n",
       "12015                                                  NaN\n",
       "12016    [self.layer3 = self.fc(self.layer2), input_lay...\n",
       "12017           [config.hidden_dim, 2 * config.hidden_dim]\n",
       "12018    [advanced indexing, reconstruct_output, inputs...\n",
       "12019     [masked_inputs = inputs * mask.unsqueeze(2)\\r\\n]\n",
       "12020    [c = (torch.stack(list_of_tensors,dim=1)).sque...\n",
       "12021    [scheduler = torch.optim.lr_scheduler.LambdaLR...\n",
       "12022    [torch.nn.functional, torch, self.conv1 = F.co...\n",
       "12023    [a = torch.ones(1,1,84,84)\\r\\nb = torch.ones(1...\n",
       "12024    [nn.RNN, weight_ih_l[k], k, (hidden_size * inp...\n",
       "12025           [nn.Module, torch.from_numpy(), nn.Module]\n",
       "12026    [th.tensor([0]), torch.Long, float, FloatTenso...\n",
       "12027    [from collections import OrderedDict\\r\\n\\r\\ncl...\n",
       "12028    [2018, if, args.rank, args.rank = args.rank * ...\n",
       "12029    [class MaskedSequential(nn.Sequential):\\r\\n   ...\n",
       "12030    [start_indices, end_indices, tensor, start_ind...\n",
       "12031    [torch.cat, n_ranges, tensor_size = 100\\r\\nn_r...\n",
       "12032    [shuffle=True, SubsetRandomSampler, torch.util...\n",
       "12033                              [random.choice, random]\n",
       "12034    [zeros, ones, import torch\\r\\n\\r\\ntensor = tor...\n",
       "12035    [aa = torch.gather(a, 0, indices.unsqueeze(0))...\n",
       "12037    [c = torch.cat([a, b], dim=-1).view(-1, a.shap...\n",
       "12038    [c = torch.zeros(8, 5)\\r\\nc[::2, :] = a   # In...\n",
       "12039    [class ManyDatasetsInOne(Dataset):\\r\\n    def ...\n",
       "12040                                                  NaN\n",
       "12041                                                  NaN\n",
       "12042    [hid_enc = torch.cat([hid_enc[0,:, :], hid_enc...\n",
       "12043    [a_n = a.numpy()\\r\\na_n = np.apply_along_axis(...\n",
       "12045    [19, torch.cat(), data = [torch.tensor([-0.187...\n",
       "12046    [torch.nn.utils.rnn.pad_sequence, # data = [te...\n",
       "12047    [data = [tensor([-0.1873, -0.6180, -0.3918, -0...\n",
       "12048    [from torch.utils.data import IterableDataset\\...\n",
       "12049    [def safe_pil_loader(path, from_memory=False):...\n",
       "12050                                                  NaN\n",
       "12051    [nn.ModuleList(), class Net_par(nn.Module):\\r\\...\n",
       "12052    [bert = transformers.BertForMaskedLM.from_pret...\n",
       "12053                         [pip install --no-cache-dir]\n",
       "12054    [scale, tmpScale, tmpScale[:, j] = torch.from_...\n",
       "12055                                                  NaN\n",
       "12056    [train_set_x_orig, torch.from_numpy(), train_s...\n",
       "12057    [Sampler, import random\\r\\nfrom torch.utils.da...\n",
       "12058    [sampler = ResumableRandomSampler(dataset)\\r\\n...\n",
       "12059                      [import gc\\r\\ngc.collect()\\r\\n]\n",
       "12060                                                  [x]\n",
       "12062    [no_grad, no_grad, no_grad, for epoch in range...\n",
       "12064    [the Elastic Inference enabled PyTorch framewo...\n",
       "12065    [ y = torch.arange(9).reshape(3,3)\\r\\n y\\r\\nte...\n",
       "12068    [# pred: torch.size([64, 2895, 161])\\r\\n# mask...\n",
       "12069    [def PublicTest(epoch):\\r\\n    global PublicTe...\n",
       "12072    [K, K, x, mu_z, Sigma_z, z, x, data_k_vec = da...\n",
       "12073    [nn.CrossEntropyLoss(), (n, c), (64, 10), (n),...\n",
       "12074    [C++, python, unpacking, *, (, ), IntArrayRef,...\n",
       "12075    [def kth_smallest(tensor, indices):\\r\\n    ten...\n",
       "12076                                                  NaN\n",
       "12077    [--samples_per_plugin scalars=0, tensorboard -...\n",
       "12078    [[64,1], [64], loss_func(output, y.flatten().t...\n",
       "12079    [original label dim = torch.Size([64, 1]) &lt;...\n",
       "12080    [None, size(), target = torch.tensor(reward).g...\n",
       "12081    [NaN, float, NaN, float, predictions = predict...\n",
       "12082    [predictions.append(logits.argmax(1))\\r\\nflat_...\n",
       "12083                                                  NaN\n",
       "12084                                [ulimit -Sv 12000000]\n",
       "12085    [matx, [n x m], nearestSrc/Tgt, sumDistSource/...\n",
       "12086    [  x = torch.ones(5, requires_grad=True)\\r\\n  ...\n",
       "12088    [pip install torch===0.4.1 torchvision===0.5.0...\n",
       "12089                                            [pytorch]\n",
       "12090                                                  NaN\n",
       "12091    [[batch_size x 784], 4, nn.Linear(inp, 784), i...\n",
       "12093                                  [[1.0, 0.08, 0.35]]\n",
       "12096    [masked_scatter, mask = torch.zeros(self.X.sha...\n",
       "12097    [Tensor.clone, a = torch.tensor([[0,1,2],[3,4,...\n",
       "12098                                                  NaN\n",
       "12099    [a = torch.ones(4,4)\\r\\nindices = (a == torch....\n",
       "12100    [2d, 1d, x, torch.flatten, torch.nonzero, x = ...\n",
       "12101    [__getitem__, __len__, __getitem__, from torch...\n",
       "12102                                                  NaN\n",
       "12103    [[4.235, -4.805], In [1]: import torch\\r\\nIn [...\n",
       "12104    [import torch\\r\\ntorch.manual_seed(2020)\\r\\n\\r...\n",
       "12105                                                  NaN\n",
       "12106          [(a[..., None] == b).any(-1).nonzero()\\r\\n]\n",
       "12108    [nn.Linear, linear_3_to_1 = nn.Linear(3, 1)\\r\\...\n",
       "12109    [--find-links, requirements.txt, --find-links ...\n",
       "12110    [-f https://download.pytorch.org/whl/torch_sta...\n",
       "12111    [pip install -r req.txt --find-links https://d...\n",
       "12112    [pip3 install torch torchvision torchaudio --e...\n",
       "12113                                                  NaN\n",
       "12114    [tensor.clone(), requires_grad, clone, grad_in...\n",
       "12116    [model.parameters(), nn.Parameter, class ToyMo...\n",
       "12118    [q_pred[torch.arange(q_pred.size(0)), actions....\n",
       "12119    [def plot_to_image(figure):\\r\\n  \"\"\"Converts t...\n",
       "12120                                                  NaN\n",
       "12121    [m, x, o, import torch\\r\\ntorch.manual_seed(20...\n",
       "12122    [a = torch.zeros([2,])     # tensor([0., 0.])\\...\n",
       "12124    [content, resp, https://catdogclassifier.noteb...\n",
       "12125    [log(1 + exp(x)), x, x, exp(50), 5.18e+21, 1, ...\n",
       "12127                                  [print(mask * 1.1)]\n",
       "12128    [Lambda, import torch\\r\\nfrom torchvision.data...\n",
       "12129    [lambda, import torch\\r\\nfrom torchvision.data...\n",
       "12130    [batch size X time steps X input size, batch s...\n",
       "12131    [    self.embedding = nn.Embedding(vocab_size,...\n",
       "12132    [import torch\\r\\n\\r\\nx = [torch.rand((7, 20, 1...\n",
       "12133    [# define a cross validation function\\r\\ndef c...\n",
       "12134    [import torch\\r\\nfrom torch._six import int_cl...\n",
       "12135    [for i in range(0, len(inputs), batch_size):\\r...\n",
       "12136    [torch.zeros(batch_size,100,y,dtype = embedded...\n",
       "12137                                                  NaN\n",
       "12138    [x = x.view(x.shape[0], 3, self.img_height, se...\n",
       "12139    [BertForSequenceClassification, BertPooler, [C...\n",
       "12140    [i.long(), lab.long(), NumClass = 10\\r\\nmask =...\n",
       "12141    [batch_mean = mx.ndarray.sum(batch,axis=0)/(ba...\n",
       "12142    [(h_0, c_0), self.hidden_cell = (torch.zeros(1...\n",
       "12143                            [c = a[pred_masks,:]\\r\\n]\n",
       "12144    [x, tensor, x[0], 0, KeyError, print(Exception...\n",
       "12145    [id, In [4]: hash(tensor(0)) == hash(tensor(0)...\n",
       "12148    [torch, script_generate.sh, # [...]\\r\\npy=pyth...\n",
       "12150    [nn.Conv2d, groups=in_channels, weights, F.con...\n",
       "12151    [plt.imshow(grey[:,:,0] if grey.shape[-1] == 1...\n",
       "12152    [hidden_copy, loss_T, loss_T, grad, loss_T, lo...\n",
       "12153                                                  NaN\n",
       "12155                     [BertEncoder, hidden_states[12]]\n",
       "12158    [long, tensor, vectors, 6, 9, tensors, x, matr...\n",
       "12159    [state_dict, tensor, /pro_gan_pytorch/pro_gan_...\n",
       "12160    [__call__, BartForConditionalGeneration, min_l...\n",
       "12161    [torch.argmax(output, dim=1), batch, LogSoftma...\n",
       "12162    [import torchvision.transforms as transforms\\r...\n",
       "12164    [import torch\\r\\n\\r\\nbatch_input, batch_output...\n",
       "12165    [train_set = CustomDataset(...)\\r\\ntrain_loade...\n",
       "12166                                                [pdb]\n",
       "12167                             [collate_fn, collate_fn]\n",
       "12168                                                  NaN\n",
       "12169    [tgt, Float, Long, go_tokens, torch.int64, Lon...\n",
       "12170                                                  NaN\n",
       "12171    [TORCH_CUDA_ARCH_LIST=\"6.1\" python setup.py in...\n",
       "12172    [using namespace torch;\\r\\n\\r\\nclass DCGANDisc...\n",
       "12173    [__getitem__, class Subset(Dataset):\\r\\n    r\"...\n",
       "12175    [create data_X time: 62.60318350791931  \\r\\ncr...\n",
       "12176    [out, def forward(self, x):\\r\\n    identity = ...\n",
       "12177    [nonzero(), (arr == 0).nonzero()\\r\\n, arr = to...\n",
       "12178    [encoder = Encoder(args).to(device)\\r\\ndecoder...\n",
       "12179                                                  NaN\n",
       "12180    [no_grad, with torch.no_grad():\\r\\n    # No gr...\n",
       "12181    [.cpu(), .cuda(), .to(), self.mat, mat, class ...\n",
       "12182    [scatter, NumRows = len(label)\\r\\nmask = torch...\n",
       "12183    ['model', train_rcnn.py:106, torch.save(model....\n",
       "12184                                                  NaN\n",
       "12185                                                  NaN\n",
       "12186                                                  NaN\n",
       "12187    [21.8416, 161 * 0.1357, import torch\\r\\ntorch....\n",
       "12188    [import torch as pt\\r\\n\\r\\nnum_chan_in = 3\\r\\n...\n",
       "12189    [optimizer, backward(), detach(), tensor.detac...\n",
       "12190                                                  NaN\n",
       "12193    [bins, torch.unique, weights, unique = torch.u...\n",
       "12194    [numpy, isin, pandas.isin, groupby, row, group...\n",
       "12196    [        image = torch.from_numpy(self.images[...\n",
       "12197    [output_c1[output_c1 &gt; 0.5] = x, torch.roun...\n",
       "12198                         [0:51:2 instead of 0::2\\r\\n]\n",
       "12199    [class PositionalEncoding(nn.Module):\\r\\n\\r\\n ...\n",
       "12200    [d_model, div_term, torch.arange(0, d_model, 2...\n",
       "12201    [runtime, version: 2\\r\\n  backend:\\r\\n    buil...\n",
       "12202                     [cudaErrorNoDevice, cudaError_t]\n",
       "12203    [loss.backward(), backward(), optimizer.step()...\n",
       "12204    [SequenceScorer, log, print('P-{}\\t{}'.format(...\n",
       "12205                                                  NaN\n",
       "12206    [return -((value - self.loc) ** 2) / (2 * var)...\n",
       "12207                                                  NaN\n",
       "12208                                                  NaN\n",
       "12209        [vector_repres = nlp('Test text').vector\\r\\n]\n",
       "12210    [x = torch.flatten(x, 1), for name, layer in n...\n",
       "12211    [os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\\r...\n",
       "12212    [[7,5,1,8] for action a,b,c,d\\r\\n, x_train = s...\n",
       "12216    [pip install https://download.pytorch.org/whl/...\n",
       "12217    [# for windows 10, CUDA 10.1\\r\\nconda install ...\n",
       "12219    [Rollback error, conda install pytorch-cpu -c ...\n",
       "12224    [caffe2_model = Caffe2Model.load_protobuf(inpu...\n",
       "12225    [import tensorflow as tf\\r\\nimport tensorboard...\n",
       "12226    [import tensorflow as tf\\r\\nimport tensorboard...\n",
       "12227    [run_seq_blur2.py, list index, sbatch, sbatch,...\n",
       "12228                                                  NaN\n",
       "12229    [Pytorch, F_V.py, if self.device == 'cpu':\\r\\n...\n",
       "12230    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "12231            [depthwise_conv2d, i, i+inputs/2, conv2d]\n",
       "12232    [public List&lt;double&gt; UseOnnxSession(Bitm...\n",
       "12233    [import torch\\r\\nimport tensorflow as tf\\r\\n\\r...\n",
       "12234    [    VERSION = \"20200325\"  #@param [\"1.5\" , \"2...\n",
       "12235    [!pip uninstall torch -y\\r\\n!pip install torch...\n",
       "12236    [def forward(self, inputs, hidden):\\r\\n    emb...\n",
       "12237    [def distance(p1, p2, labels):\\r\\n    p1 = p1....\n",
       "12239    [state, policy1, policy2, logits, state, value...\n",
       "12240    [datasets.DatasetFolder, datasets.ImageFolder,...\n",
       "12241    [ConvTranspose2d, output_padding, nn.ConvTrans...\n",
       "12242    [G = torch.rand(m, n), out.backward(z), z, out...\n",
       "12243    [tensor, result[i] = np.array(img.rotate(rotat...\n",
       "12244    [x.grad.zero_(), torch.optim.Optimizer, optim....\n",
       "12245                                                  NaN\n",
       "12246    ['0.conv', models._modules[\"0\"]._modules.get(\"...\n",
       "12247    [%load_ext tensorboard\\r\\n%tensorboard --logdi...\n",
       "12248    [ImageFolder, __getitem__, class MySpecialData...\n",
       "12249    [pyarrow, *.parquet, pq.ParquetFile, petastorm...\n",
       "12250    [import dask.dataframe as dd\\r\\nfrom dask impo...\n",
       "12251    [y = torch.randn(5, 5)\\r\\nx = torch.zeros((9, ...\n",
       "12253    [torch.onnx.export(model, x, ONNX_FILE_PATH), ...\n",
       "12254    [print(feat32.size()[2:])\\r\\n, F.avg_pool2d(fe...\n",
       "12255    [x = F.avg_pool2d(x, x.shape[2:])\\r\\n, x_shape...\n",
       "12256    [Unable to cast from non-held to held instance...\n",
       "12257    [CUDA_VISIBLE_DEVICES=1, gpu_id=0, model = tor...\n",
       "12258    [output = torch.softmax(output)\\r\\n, dir_name ...\n",
       "12259    [output = model(x1,x2)\\r\\noutput = torch.sigmo...\n",
       "12261    [torch.nn.Conv1d(in_channels, out_channels, ke...\n",
       "12262    [X.shape[0], X.shape[1], X.shape[2], X.shape[0...\n",
       "12264    [%%timeit -r 10 -n 10\\r\\nA[A[:,-1].argsort()]\\...\n",
       "12265    [A = np.array([[0.9133, 0.5071, 0.6222, 3.],\\r...\n",
       "12266    [a = torch.rand(3, 3, requires_grad=True)\\r\\na...\n",
       "12267    [narrow(), def samestorage(x,y):\\r\\n    if x.s...\n",
       "12269    [for i in x:\\r\\n    test.append(next((e for e ...\n",
       "12270    [def foo0(x,v):\\r\\n    test = []\\r\\n    for i ...\n",
       "12271    [test_indexing.py, pytest path/to/test/ --cov ...\n",
       "12273                                                  NaN\n",
       "12274    [B = A.reshape(-1,r,3,s,s).permute(2,3,0,4,1)....\n",
       "12275    [B = A.reshape(2,2,3,2,2).permute(2,3,0,4,1).r...\n",
       "12276    [CMakeLists.txt, pytorch, /scripts/build_mobil...\n",
       "12277                                                  NaN\n",
       "12278    [mask_path = os.path.join(self.root_dir, \"mask...\n",
       "12279    [torchvison.transforms.Normalize, (C, H, W), i...\n",
       "12280    [x&lt;0, &lt;0,     return self.layer4(self.la...\n",
       "12282    [squeeze, (batch, 1280, 1, 1), (batch, 1280), ...\n",
       "12283    [clamp, relu, 0, x = 0, (x.clamp(min=0) - 1.0)...\n",
       "12284    [import torch\\r\\nfrom torch.nn.parameter impor...\n",
       "12285    [bash, source env/bin/activate\\r\\n, set -e, #!...\n",
       "12286    [summary = tf.summary(value=[tf.summary.Value(...\n",
       "12287    [logger.py, train.py, AttributeError: module '...\n",
       "12288    [import tensorflow as tf\\r\\n\\r\\n\\r\\nclass Logg...\n",
       "12289    [range(len(topk_list)), for i, n in enumerate(...\n",
       "12290    [k, k, # Code from OP\\r\\nimport torch\\r\\n\\r\\ne...\n",
       "12291    [torchvision.datasets.ImageNet, root, download...\n",
       "12292    [import torch\\r\\nfrom torch import nn\\r\\nimpor...\n",
       "12293    [t = torch.zeros(5, 5)\\r\\nfor i in range(5):\\r...\n",
       "12294                              [[1, 0, 4, 10], output]\n",
       "12295                                                  NaN\n",
       "12296    [import torch\\r\\n\\r\\nvalue = torch.tensor([\\r\\...\n",
       "12297    [net, model.Model, model = nn.Sequential(net, ...\n",
       "12298    [model = nn.Sequential(nn.ModuleList(net), Cla...\n",
       "12299    [TFBertModel, tensorflow, TFBertModel, !pip in...\n",
       "12300                                                  NaN\n",
       "12301                                                  NaN\n",
       "12302    [floor(x.size(2) / 3), x, x, nn.Conv1d, nn.Max...\n",
       "12303    [import torch\\r\\n\\r\\nS, N, H = 9, 7, 4\\r\\n\\r\\n...\n",
       "12304    [import numpy as np\\r\\nimport torch\\r\\n​\\r\\n# ...\n",
       "12305                                                  NaN\n",
       "12306    [torch.min, import torch\\r\\n\\r\\nvalues = torch...\n",
       "12307    [a = np.random.randint(0,100, 10)\\r\\na\\r\\narra...\n",
       "12308    [import torch\\r\\n\\r\\nresult = torch.empty(6, d...\n",
       "12309    [class ParallelModule(nn.Sequential):\\r\\n    d...\n",
       "12310    [__init__, max(0,x), negative_slope, max(0, x)...\n",
       "12311    [x -----&gt; layer --------+\\r\\n           ^  ...\n",
       "12312                       [depth_divisor, depth_divisor]\n",
       "12313                  [torch.Tensor(list(htxt.values()))]\n",
       "12314    [model = UNet(num_classes = 2, depth=5, in_cha...\n",
       "12315    [torch.Size([64, 60, 1]), [n, 1], nn.CrossEntr...\n",
       "12316    [torchvision.transforms.GaussianBlur(kernel_si...\n",
       "12317    [def gaussian(M, std, sym=True):\\r\\n    if M &...\n",
       "12318    [torch.outer, import torch\\r\\ndef gaussian_fn(...\n",
       "12319    [lengths[i], batch_size = 6\\r\\nn = 5\\r\\n\\r\\npr...\n",
       "12321    [sample(), sample, torch.distributions.normal....\n",
       "12322    [nn.ModuleList(), nn.ModuleList, class MyCell(...\n",
       "12323    [class MyCell(torch.nn.Module):\\r\\n    def __i...\n",
       "12324    [forward, def forward(self, x):\\r\\n        x =...\n",
       "12325    [estimator = PyTorchModel(model_data='#path to...\n",
       "12326                                                  NaN\n",
       "12327    [import torch\\r\\n\\r\\nA = torch.randn([1,3,64,6...\n",
       "12328    [requires_grad=True, grad, None, class VGG(nn....\n",
       "12329                                                  NaN\n",
       "12331    [model.to('cpu')\\r\\n, RuntimeError: Could not ...\n",
       "12333    [ndf = 128\\r\\nz_size = 512\\r\\n\\r\\n# define the...\n",
       "12334    [decoder, x = self.decoder(x), forward, nn.Con...\n",
       "12335    [x, c, x, import numpy as np\\r\\nimport torch a...\n",
       "12336                                                  NaN\n",
       "12337    [output = model(images, targets), output = mod...\n",
       "12338    [x = torch.rand(100,13) \\r\\ncenter = x.size(1)...\n",
       "12339                                         [feat[i, j]]\n",
       "12340                                                  NaN\n",
       "12341                                                  NaN\n",
       "12342                                         [cur_target]\n",
       "12343    [.zero_grad(), retain_graph= True, loss.backwa...\n",
       "12344    [dtype, double, net = net.double()\\r\\n, net(x....\n",
       "12345    [class WienerFilter(T.nn.Module):\\r\\n    def _...\n",
       "12346    [p1.data = alpha * p2.data+ (1 - alpha) * p3.d...\n",
       "12347    [        feature_dim = 15\\r\\n        hidden_si...\n",
       "12348    [input_size, hidden_size, (hidden_size x input...\n",
       "12350    [nn.BatchNorm2d, momentum, track_running_stats...\n",
       "12351    [import torch as t\\r\\n\\r\\nbatch_size = 8\\r\\nim...\n",
       "12352    [    def forward(self, x):\\r\\n    ...\\r\\n     ...\n",
       "12353                                                  NaN\n",
       "12354                                                  NaN\n",
       "12355    [cos = nn.CosineSimilarity(dim=2, eps=1e-6)\\r\\...\n",
       "12357    [import ctypes\\r\\nctypes.cdll.LoadLibrary('caf...\n",
       "12358                                                  NaN\n",
       "12360    [data[1], loss_fn(pred, outputs), class Baseli...\n",
       "12361    [def get_transform(train):\\r\\n  if train:\\r\\n ...\n",
       "12362    [self.out, out_features=1, nn.CrossEntropyLoss()]\n",
       "12363                              [model.init_hidden(13)]\n",
       "12364    [cosine_similarity, torch.mul, torch.unsqueeze...\n",
       "12365    [nn.CosineSimilarity, nn.PairwiseDistance, i, ...\n",
       "12366    [import torch.nn.functional as F\\r\\nx = torch....\n",
       "12367    [[height, width, 3], test_img2 = test_img2.vie...\n",
       "12368    [1e-4, 0.9, 0.999, 0.01, distilbert, Model: \"t...\n",
       "12369    [HuggingFace, import numpy as np\\r\\nimport pan...\n",
       "12370    [tf.data, tensorflow_datasets, dataset_ops.get...\n",
       "12371    [num_labels, TFBertForSequenceClassification.f...\n",
       "12372    [def forward(self, input1, input2, input3):\\r\\...\n",
       "12373    [transforms, torchvision, class, my_dataset, f...\n",
       "12374                                                  NaN\n",
       "12375    [from transformers.tokenization_gpt2 import GP...\n",
       "12376    [10x128, 11x128, new_layer, (11, 128), (11, 12...\n",
       "12377    [ _, target= torch.max(target.data, 1)\\r\\n, _,...\n",
       "12379    [tn + fp = 292(total negative values)\\r\\nfn + ...\n",
       "12380    [torch.where, torch.where(condition, x, y),  x...\n",
       "12381       [value_tensor[decision_tensor==False] = 0\\r\\n]\n",
       "12382    [self.fc1, self.fc1 = nn.Linear(600, 120), sel...\n",
       "12383    [LongTensor, FloatTensor, LongTensor, Yt_train...\n",
       "12384    [5*5*16, x = x.view(x.size(0), 5 * 5 * 16), x ...\n",
       "12385                                          [axis, dim]\n",
       "12386    [import torch\\r\\nimport torchvision\\r\\n\\r\\ncla...\n",
       "12387    [np.take_along_axis, numpy, NumPy's advanced i...\n",
       "12388    [take_along_axis, A = np.array([[ 2, 4, 5, 3],...\n",
       "12389    [A[np.indices(B.shape)[0], B]\\r\\n, [[2 2 4 5]\\...\n",
       "12390                    [torch::nonzero, 30000*80=2.4e+6]\n",
       "12391                          [with torch.enable_grad():]\n",
       "12392                                                  NaN\n",
       "12393    [import torch as t\\r\\n\\r\\nbatch_size = 2\\r\\nti...\n",
       "12394    [requires_grad_(True), rd_torch = torch.from_n...\n",
       "12395                                                  NaN\n",
       "12396                              [torch.save(), clone()]\n",
       "12397    [np.unravel_index(torch.argmax(a), a.shape)\\r\\...\n",
       "12398    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "12399        [Conv2d, conv1(tensor1[None, None, ...])\\r\\n]\n",
       "12400    [x, x * x, x, x=(1, 1), x * x,  x=(1,1)\\r\\n x ...\n",
       "12401                                             [x=x[0]]\n",
       "12403    [torch.utils.data.DataLoader, torch.utils.data...\n",
       "12404    [for epoch in range(10):\\r\\n    for i, (X, y) ...\n",
       "12405    [tensor(0.8598, grad_fn=&lt;DivBackward0&gt;),...\n",
       "12406    [size - (kernel_size - 1) - 1 = size - kernel_...\n",
       "12408                                                  NaN\n",
       "12409    [output = net(inputs)\\r\\n, device, inputs, los...\n",
       "12410    [class Perceptron(nn.Module):\\r\\n     def __in...\n",
       "12411                    [val.data.cpu().numpy()[:,B]\\r\\n]\n",
       "12412    [torch.gather, torch.gather(A, 1, B.unsqueeze_...\n",
       "12413    [nn.CrossEntropy(), nn.Tanh(), Dataloader, Var...\n",
       "12414    [nn.Sequential, nn.Sequential, nn.Sigmoid, nn....\n",
       "12415    [a2b = {a: {b: self.calculate_similarity(vec_a...\n",
       "12416    [from random import random\\r\\nimport numpy as ...\n",
       "12417    [product, itertools, from itertools import pro...\n",
       "12418    [python train.py /manifest/path --save-dir /mo...\n",
       "12419    [# replace this line with the input from your ...\n",
       "12420    [mode, scipy.signal.convolve, mode='valid', co...\n",
       "12421                                                  NaN\n",
       "12422    [labels, labels = labels.to(device)\\r\\n, image...\n",
       "12423                                                  NaN\n",
       "12424    [python -c \"for i in range(67): print(i)\", pyt...\n",
       "12425    [M, v, import torch as t\\r\\nX = t.randn([3, 3]...\n",
       "12427    [reshape, In [29]: lin = np.linspace(-1, 1, 32...\n",
       "12428                                                  NaN\n",
       "12429    [stable=True,  x = torch.tensor([0, 1] * 9)\\r\\...\n",
       "12430                     [forward, __init__, Autoencoder]\n",
       "12431                                                  NaN\n",
       "12432                                                  NaN\n",
       "12433    [cuda_ = \"cuda:0\"\\r\\ndevice = torch.device(cud...\n",
       "12434                                                  NaN\n",
       "12435                                                  NaN\n",
       "12436    [Parameter, torch.Tensor, Tensor.T,  t = torch...\n",
       "12437    [3xNxM, 5xPxQ, &lt;batch_size&gt;, return (ima...\n",
       "12438                                                  NaN\n",
       "12439    [import random\\r\\n\\r\\ninput = [[i if i not in ...\n",
       "12440    [input = np.array([[1, 2, 3],\\r\\n             ...\n",
       "12441                                                  NaN\n",
       "12442    [GeneralizedRCNN, FasterRCNN, eager_outputs(),...\n",
       "12443    [losses = {}\\r\\n    if self.training:\\r\\n     ...\n",
       "12444    [generalized_rcnn.py, torchvision/models/detec...\n",
       "12445    [conv_layer = self.linear_layers_(conv_layer)\\...\n",
       "12446    [optimizer.zero_grad()\\r\\nloss.backward()\\r\\no...\n",
       "12447                                                  NaN\n",
       "12448    [model.fit(), class MyCustomCallback(tf.keras....\n",
       "12450                                                  NaN\n",
       "12451                                                  NaN\n",
       "12452                                                  NaN\n",
       "12453    [@, torch.nn.quantized.functional.linear, torc...\n",
       "12454    [_DataLoaderIter, _DataLoaderIter, _SingleProc...\n",
       "12455    [labels = np.array(trainset.samples)[:,1], lab...\n",
       "12456    [_Equalizer, RandomSubsetSampler, torch.max, t...\n",
       "12457    [w.grad, b.grad, w[0][0].grad, def get_grads()...\n",
       "12458    [.data, .grad, clone, detach, [w, b] = model.p...\n",
       "12459    [import torchvision\\r\\n\\r\\n#  I am assuming we...\n",
       "12461    [CrossEntropyLoss, loss = nn.CrossEntropyLoss(...\n",
       "12462                                                  NaN\n",
       "12463    [higher.innerloop_ctx, model, (fmodel, diffopt...\n",
       "12464    [W^&lt;inner_i, outer_i&gt; = denotes the valu...\n",
       "12465    [_, preds = torch.max(outputs, 1)\\r\\n, Linear,...\n",
       "12466    [_, preds = torch.max(outputs, 1)\\r\\n,  a = to...\n",
       "12467                                                  NaN\n",
       "12468                                                  NaN\n",
       "12469    [no_eps = n_iterations / (len(train_loader) / ...\n",
       "12470    [torch.nn.ModuleDict, class Net3(torch.nn.Modu...\n",
       "12471    [import sklearn\\r\\nfrom sklearn.datasets impor...\n",
       "12472        [forward(), encoder_hidden_states, forward()]\n",
       "12473    [def __init__(self, inputs, labels, c):\\r\\n  s...\n",
       "12474                                      [loss.backward]\n",
       "12475    [label, label, return self.transform(img), tor...\n",
       "12476    [forward, class Autoencoder(nn.Module):\\r\\n......\n",
       "12477                                                  NaN\n",
       "12478    [torch.cuda.empty_cache()\\r\\n# start training ...\n",
       "12479    [*, @, net.fc2.weight @ (net.fc1.weight @ X[0]...\n",
       "12480    [torch.stack,  torch.stack(tmp)\\r\\n,  tmp = [t...\n",
       "12481                                                  NaN\n",
       "12482    [numpy.ndarray, torch.Tensor, torch.tensor(), ...\n",
       "12483    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "12484    [data, for (name, w) in loss_net.named_paramet...\n",
       "12485                    [out = out.view(out.size(0), -1)]\n",
       "12486    [main.py, multiprocessing, def main():\\r\\n    ...\n",
       "12488    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "12489    [transforms.Normalize, (M1,...,Mn), (S1,..,Sn)...\n",
       "12490                              [self.conv1(x.float())]\n",
       "12491    [torch.svd(), +, -, *, /, a = torch.zeros(2, 2...\n",
       "12493    [torch, torchvision, virtualenv -p python3.8 t...\n",
       "12496                                                  NaN\n",
       "12497    [transformers, pip uninstall tokenizers\\r\\npip...\n",
       "12498                   [last_hidden_state, pooler_output]\n",
       "12499                                         [Parameters]\n",
       "12500    [def mask_softmax(vec, mask):\\r\\n  leafs= vec....\n",
       "12501    [npx.sequence_mask, def sequence_mask(X, valid...\n",
       "12502    [RuntimeError: Expected object of scalar type ...\n",
       "12503    [torch.float32, torch.float, torch.float64, to...\n",
       "12504    [X_train, y_train = //read data files\\r\\n\\r\\nt...\n",
       "12505    [for (inputs, labels) in dataloader:, output_f...\n",
       "12506                                                  NaN\n",
       "12507    [!pip install torch-geometric \\\\r\\n  torch-spa...\n",
       "12508    [!pip install -q torch-scatter -f https://data...\n",
       "12509    [!pip install torch-scatter==latest+cu101 torc...\n",
       "12510    [import torch\\r\\n\\r\\ndef format_pytorch_versio...\n",
       "12511    [pip install torch-scatter -f https://pytorch-...\n",
       "12512                                [test_scripted_model]\n",
       "12513    [from transformers import pipeline\\r\\n\\r\\nqa =...\n",
       "12514    [[], ==, [],  x=torch.arange(0,10)\\r\\n x\\r\\nte...\n",
       "12515    [Pytorch Discuss, th.cholesky(..., upper=False...\n",
       "12516    [zpotrs_, magma_dpotrs_batched, def cholesky_n...\n",
       "12517    [torch.det, output = Xt.bmm(X)\\r\\ndets = torch...\n",
       "12518    ['C:\\\\Users\\\\ga2943/.cache\\\\torch\\\\sentence_tr...\n",
       "12519    [Net.cuda(), cuda(), Tensor.cuda(), torch.rand...\n",
       "12520                                         [conda, pip]\n",
       "12521                                                  NaN\n",
       "12522                                                  NaN\n",
       "12523    [RandomRotation(), fill, fill=(0,), RandomRota...\n",
       "12524    [Variable, nn.Module, nn.Parameter(), self.h, ...\n",
       "12525    [len(lengths), lengths, a = [0, 1, 2, ...., 50...\n",
       "12526    [lengths, x, container = torch.arange(0, 50 )\\...\n",
       "12527    [avggrads = [sum(grads)/len(gradslist) for gra...\n",
       "12528    [UNet, &gt;&gt; torch.nn.functional.max_pool2d...\n",
       "12529    [rows = [(row,)*len(index_tuple) for row, row_...\n",
       "12530    [     self.lstm = nn.LSTM(input_size=input_siz...\n",
       "12532                                                  NaN\n",
       "12533    [tokenizer.basic_tokenizer.tokenize(\"Kočka lez...\n",
       "12534    [tuple, __len__, int, # perhaps you can add th...\n",
       "12535                                          [forward()]\n",
       "12536    [xi = [\\r\\n# Input features at timestep 1\\r\\n[...\n",
       "12539    [softmax, import torch.nn.functional as nnf\\r\\...\n",
       "12540                                                  NaN\n",
       "12541                                                  NaN\n",
       "12542    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "12543    [torch.hub._validate_not_a_forked_repo=lambda ...\n",
       "12544                                                  NaN\n",
       "12545    [F.nll_loss(torch.log(probs), labels,reduction...\n",
       "12546    [Inputs: input, (h_0, c_0), x, (seq_length, ba...\n",
       "12547    [reshape, reshape, out[:,0,:].reshape(-1)\\r\\n,...\n",
       "12549                               [[unusedX], [unusedX]]\n",
       "12550    [split_MNIST, def split_MNIST(path2data, train...\n",
       "12551    [window_size = 100\\r\\nstride = 50\\r\\nsplits = ...\n",
       "12552    [x = torch.arange(1., 20)\\r\\nx.unfold(0,4,2)\\r...\n",
       "12554                                                  NaN\n",
       "12555    [torch.Size([1, 1219])\\r\\ntorch.Size([1, 440])...\n",
       "12557    [conda create -n myenv python=3.6\\r\\n, conda i...\n",
       "12558    [random_split, Dataset, DataLoader, DataLoader...\n",
       "12559                      [conda install cudnn=7.1.2\\r\\n]\n",
       "12560    [cudnn, RuntimeError: cuDNN version mismatch: ...\n",
       "12561           [d=[]\\r\\nwhile(1):\\r\\n  d.append('1')\\r\\n]\n",
       "12562    [nn.Linear, register_forward_hook, class FeatN...\n",
       "12570    [x = torch.tensor([1, 2])\\r\\ny = x.view(-1, 1)...\n",
       "12571    [C:\\python38\\Lib\\mimetypes.py, python -c \"impo...\n",
       "12572    [nn.TripletMarginLoss(), anchor, positive, neg...\n",
       "12573    [U, _, V = torch.svd(batch)\\r\\nS = U[:, :, :, ...\n",
       "12574                           [linalg, torch.linalg.svd]\n",
       "12575    [branch3x3dbl = self.branch3x3dbl_1(x)\\r\\nbran...\n",
       "12576    [FashionMNIST, data, targets, X, y = train.dat...\n",
       "12577    [mmap_mode='r', import numpy as np\\r\\n\\r\\nfeat...\n",
       "12578    [print('Original:')\\r\\norig_res = resnet(examp...\n",
       "12579    [torch.cat, tensor2, Tensor.unsqueeze(1), tens...\n",
       "12580    [# create a (11, 1) range array that broadcast...\n",
       "12581    [A_length = len(A)\\r\\ni = 0\\r\\nwhile i &lt; A_...\n",
       "12582    [(N, d, C) = (256, 4, 1181), (N, d) = (256, 4)...\n",
       "12583                                                  NaN\n",
       "12584    [get_linear_scheduler_with_warmup, number of b...\n",
       "12585    [examples/, if (step + 1) % args.gradient_accu...\n",
       "12586    [torch.utils.data.DataLoader, num_workers, loa...\n",
       "12587    [make_dot, grad_fn, x = torch.zeros(1, 3, 224,...\n",
       "12588    [class RNN(nn.Module):\\r\\n\\r\\n    def __init__...\n",
       "12589    [torchviz, # http://www.bnikolic.co.uk/blog/py...\n",
       "12590    [torch.cat, x = torch.randn(2, 3) # shape (2, ...\n",
       "12591                                                  NaN\n",
       "12592    [from torchvision.datasets import ImageFolder\\...\n",
       "12593    [pillow, RGB, grayscale, ImageFolder, fastai, ...\n",
       "12594    [import numpy as np\\r\\nfrom PIL import Image, ...\n",
       "12599    [torch.nonzero,  (dist &gt; 0.5).nonzero()\\r\\n...\n",
       "12600    [reshape, s, (1,2), (2,2),  s.reshape(1,2).mm(...\n",
       "12601    [ s @ x\\r\\ntensor([0.0700, 0.1000], dtype=torc...\n",
       "12602    [torch.cat, torch.max(torch.cat(outputs),1)\\r\\...\n",
       "12603                                                  NaN\n",
       "12604    [CUDA, 8.0, 10.1, CUDA, PyTorch, conda install...\n",
       "12605    [[B, C, W, H], [B, C, W * H], batch = batch.vi...\n",
       "12606    [nimages = 0\\r\\nmean = 0.0\\r\\nvar = 0.0\\r\\nfor...\n",
       "12607                                        [num workers]\n",
       "12608                                       [-- threads x]\n",
       "12609                          [if __name__ == '__main__:]\n",
       "12610                        [make_dot, Tensor, torch.cat]\n",
       "12611    [list, Tensor, dtype, import torch\\r\\n\\r\\na_li...\n",
       "12612    [dtype,  a_list = [1, 9903, 7876, 9971, 2770, ...\n",
       "12613    [dtype, torch.from_numpy, some_list = [1, 10, ...\n",
       "12614                                                  NaN\n",
       "12615    [while True:\\r\\n    with Timer('Time elapsed')...\n",
       "12616                                                  NaN\n",
       "12617    [import keras.backend as K\\r\\n\\r\\ndef coords_t...\n",
       "12619    [[nn.Conv2d(1, 2, (2, x)) for x in nchunks]\\r\\...\n",
       "12620    [@, rotMat = torch.matmul(torch.matmul(xmat, y...\n",
       "12621                                                  NaN\n",
       "12622    [import os\\r\\n\\r\\nos.environ['ARROW_PRE_0_15_I...\n",
       "12623    [torch.cat([(t == i).nonzero() for i in elemen...\n",
       "12624    [where, points, 998, [0,0], [2,0], In [34]: po...\n",
       "12626    [loss_x = self.mse_loss(x[mask], tx[mask]), ma...\n",
       "12627    [obj_mask = obj_mask.type(torch.BoolTensor)\\r\\...\n",
       "12628    [obj_mask = obj_mask.bool()\\r\\nnoobj_mask = no...\n",
       "12629    [model = BertForSequenceClassification.from_pr...\n",
       "12630    [BertForSequenceClassification, bert, classifi...\n",
       "12631    [import torch\\r\\nt = torch.tensor([1.0]) # cre...\n",
       "12632    [import torch\\r\\nfrom torchvision.ops import R...\n",
       "12633    [Collecting torch-sparse\\r\\n  Downloading http...\n",
       "12634    [namespace th = torch;\\r\\n...\\r\\n// th.set_gra...\n",
       "12636    [torch.optim.lr_scheduler.StepLR, import torch...\n",
       "12637    [torch, def adjust_learning_rate_poly(optimize...\n",
       "12638                                                  NaN\n",
       "12639    [   tensor Conv2D(X, W, B) {\\r\\n     int perm[...\n",
       "12641                                                  NaN\n",
       "12642    [torch.where, new_dist = troch.where(dist &gt;...\n",
       "12643    [import torch\\r\\nx = torch.Tensor([[1, 2, 3, 4...\n",
       "12644                          [__getattr__, __getattrt__]\n",
       "12645                                  [max_queue_size=10]\n",
       "12646    [An attempt has been made to start a new proce...\n",
       "12647    [(batch_size, 3, 3), (N, 3), (batch_size, N, 3...\n",
       "12648                    [torch.bilinear, torch.trilinear]\n",
       "12649    [pip install tensorboard\\r\\n, tensorboard --lo...\n",
       "12650    [NLLLoss, CrossEntropyLoss, t &gt;= 0 &amp;&am...\n",
       "12652    [classifier, model.parameters(), optimizer = o...\n",
       "12653    [for name, param in model.named_parameters() :...\n",
       "12655                                                  NaN\n",
       "12657    [model.eval(), .eval(), torch.no_grad(), model...\n",
       "12661    [(N, C, L), N, C, L, batch_size,  nn.Conv1d(20...\n",
       "12662                                                  NaN\n",
       "12663                                                  NaN\n",
       "12664                                                  NaN\n",
       "12665    [grad_output.cuda(), grad_output = grad_output...\n",
       "12666                                                  NaN\n",
       "12667    [class InputShapeSetter(skorch.callbacks.Callb...\n",
       "12668    [optimizer.zero_grad(), net.zero_grad(), MSELo...\n",
       "12669    [LineByLineTextDataset, --line_by_line, TextDa...\n",
       "12670                                                  NaN\n",
       "12671    [optimizer.step(), scheduler.step(), OneCycleL...\n",
       "12672    [gread_fn, out, forward, RNN_pytorch, grad_fn,...\n",
       "12673                                                  NaN\n",
       "12674    [from numba import cuda\\r\\nimport torch \\r\\nde...\n",
       "12675                      [import gc\\r\\ngc.collect()\\r\\n]\n",
       "12676    [cuda.get_current_device(), cuda.close(), gpus...\n",
       "12677    [cholesky, - func: cholesky(Tensor self, bool ...\n",
       "12678                                                  NaN\n",
       "12679    [torchtext, torch.nn.utils.rnn.pad_sequence, t...\n",
       "12680    [for i in range(num_batches):\\r\\n\\r\\n    orig_...\n",
       "12681    [self.dropout = torch.nn.Dropout(p=self.p)\\r\\n...\n",
       "12682                                                  NaN\n",
       "12683    [W_mat_directly, w, w, W, W_mat_directly = tor...\n",
       "12684    [nn.Parameter, class CustomLayer(nn.Module):  ...\n",
       "12685    [tensor, tensor1, tensor1, tensor2, bar, tenso...\n",
       "12686                                                  NaN\n",
       "12687    [TensorImageUtils.bitmapToFloat32Tensor(), Mem...\n",
       "12688    [private fun floatArrayToBitmap(floatArray: Fl...\n",
       "12689    [AttributeError: 'NoneType' object has no attr...\n",
       "12691          [\"copy_\" not implemented for \\'QInt8' \\r\\n]\n",
       "12692                                                  NaN\n",
       "12693     [$$s_{\\lambda}(z)=sign(z)*(|z|-\\lambda)_+$$\\r\\n]\n",
       "12694    [loss_flow, z_pred = net_disc(pc1[:, :, i_odds...\n",
       "12695                                                  NaN\n",
       "12696                                                  NaN\n",
       "12699    [nn.Sequential, class SimpleConvAE(nn.Module):...\n",
       "12700    [MaxPool2d, MaxUnpool2d, Sequential, class Max...\n",
       "12701                                                  NaN\n",
       "12702    [anchor_erosion_pi = anchor_erosion[positive_i...\n",
       "12703    [(tens == 101).nonzero()[:, 1], In [20]: from ...\n",
       "12704    [    test_tensor = torch.FloatTensor(2,7,7).ra...\n",
       "12705                                             [W, W.T]\n",
       "12706    [expand(), mu * foo, foo, expand().clone(), re...\n",
       "12707                                               [cp37]\n",
       "12708    [python -c \"import struct;print( 8 * struct.ca...\n",
       "12709                                                  NaN\n",
       "12710    [(N, C_in, H_in, W_in), (N, C_out, H_out, W_ou...\n",
       "12711    [result = Network(test_exp).data[0][0].item()\\...\n",
       "12712    [trainData = ImageFolder('data/in/train/', tra...\n",
       "12713                                                  NaN\n",
       "12715    [ProcessBuilder, ProcessBuilder, inheritIO(), ...\n",
       "12716    [Sequential, y = activation(W*x + b), W, b, x,...\n",
       "12717    [p(x|y), 1, x_i, x_i, 2, argmax_y p(y|x), p(x|...\n",
       "12718    [torch.cuda.device_count(), import sys\\r\\n\\r\\n...\n",
       "12719    [In [75]: x = np.ones((4,1))                  ...\n",
       "12720    [dHigh, dLow, day_of_week_n, month_n, dHigh, d...\n",
       "12721    [for param in model_conv.parameters():\\r\\n    ...\n",
       "12722    [    ...\\r\\n\\r\\nclass AutoEncoder(pl.Lightning...\n",
       "12723    [x = torch.randn(4,3)\\r\\nx -= x.mean()\\r\\nx /=...\n",
       "12724                                                  NaN\n",
       "12726    [result = c1 * c2.reshape((-1,1,1,1))\\r\\n, c2,...\n",
       "12727                     [find_package, $TORCH_LIBRARIES]\n",
       "12730    [&amp;, |, __and__, __or__, __xor__,  torch.te...\n",
       "12731    [a = torch.Tensor{0,1,1,0}\\r\\nb = torch.Tensor...\n",
       "12732    [import tensorflow as tf\\r\\nimport numpy as np...\n",
       "12733    [Datasets, Datasets, Groups, TFRecord, torch.u...\n",
       "12735    [import torch.nn.functional as nnf\\r\\n\\r\\ndef ...\n",
       "12737    [from typing import Tuple\\r\\nimport torch\\r\\n\\...\n",
       "12738    [...\\r\\nvar = x.mean((x-mean)**2, -1, keepdim ...\n",
       "12739    [x = torch.normal(0, 1, [5])\\r\\nmean = x.sum(a...\n",
       "12740    [var = x.var(-1, keepdim = True)\\r\\n, var = x....\n",
       "12741    [**, __rpow__, __pow__, 0.9 - torch.tensor(2),...\n",
       "12742    [conv, conv1, conv2, conv3, conv3, fc1, self.f...\n",
       "12743    [writer = SummaryWriter(path)\\r\\nimg_grid = to...\n",
       "12744    [F.softmax, import torch as t\\r\\n\\r\\nclass Net...\n",
       "12746    [print(model.modules), del model.my_layer_name...\n",
       "12747    [it = it.unsqueeze(0)\\r\\n, pytorch_msssim, piq...\n",
       "12748    [x = torch.rand(5, 128, 32)\\r\\npool = nn.MaxPo...\n",
       "12749    [import torch.nn.functional as F\\r\\na = torch....\n",
       "12750    [transform = transforms.Compose([\\r\\n transfor...\n",
       "12751                                               [relu]\n",
       "12752    [from torch import nn\\r\\n\\r\\nclass Model(nn.Mo...\n",
       "12754    [CrossEntropyLoss, weights = torch.tensor([0.7...\n",
       "12755                                                  NaN\n",
       "12756    [nn, nn.ModuleList, nn.ModuleDict, nn.ModuleLi...\n",
       "12757                                                  NaN\n",
       "12758                                [tf.data.Dataset\\r\\n]\n",
       "12759                                          [barrier()]\n",
       "12760    [torch.expand, t = torch.ones((1, 1000, 1000))...\n",
       "12761                [apt-get install build-essential\\r\\n]\n",
       "12762    [https://download.pytorch.org/whl/torch_stable...\n",
       "12763    [pipenv install torch --index https://download...\n",
       "12766    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "12767    [cuda, def forward(self, sentence):\\r\\n    # 6...\n",
       "12768    [indices = torch.tensor([[0, 1], [0, 2], [1, 0...\n",
       "12769    [Module.parameters(), list(d), .parameters(), ...\n",
       "12770    [with torch.no_grad():, out.cpu(), ...\\r\\nwith...\n",
       "12771                                                  NaN\n",
       "12772    [loss = Y - (X@torch.transpose(X, 1,0) * W).su...\n",
       "12774    [# your code as it is\\r\\nimport torch\\r\\nimpor...\n",
       "12775                                                  NaN\n",
       "12776                    [directory=\"resources/data/\"\\r\\n]\n",
       "12778                                                  NaN\n",
       "12779    [batch, batch, input = torch.randn(3, 5, requi...\n",
       "12780    [nn.NLLLoss(), C, C = 2, 0, 1, nn.NLLLoss, Log...\n",
       "12782                         [as_tensor, torch.as_tensor]\n",
       "12783    [torch.where((A == B).all(dim=1))[0]\\r\\n, impo...\n",
       "12784    [A[indices] == B, values, indices = torch.topk...\n",
       "12785    [m = torch.nn.LogSoftmax(dim=1), b, c, h, w, d...\n",
       "12786    [pre_train, configs, import torch\\r\\nfrom tran...\n",
       "12787                                                  NaN\n",
       "12788    [with torch.no_grad(), w11 = torch.rand((100,2...\n",
       "12789    [do/dz = 1 / 4\\r\\ndz/dy = 6y = 6 * 3 = 18\\r\\nd...\n",
       "12790    [for data in train_dataset:\\r\\n, for data in t...\n",
       "12791    [BatchNormalization, =-1, BatchNormalization, ...\n",
       "12793    [print(kneser_ney.prob('you go to'))\\r\\n, prin...\n",
       "12794                                             [argmax]\n",
       "12795       [self.tensorboard_writer = tensorboard_writer]\n",
       "12796                                                  NaN\n",
       "12797    [model = torch.nn.DataParallel(model,device_id...\n",
       "12798    [    torch::Tensor tensor = torch::empty({1000...\n",
       "12799                                                  NaN\n",
       "12800                                                  NaN\n",
       "12805    [shape:1, del spec.description.input[0].shape[...\n",
       "12806    [lab_rs = lab_rs * torch.tensor([[[100]], [[25...\n",
       "12807                                                  NaN\n",
       "12808    [from collections import namedtuple\\r\\n, def _...\n",
       "12809    [pip install -U git+https://github.com/pytorch...\n",
       "12810                                                  NaN\n",
       "12811    [permute, X_train = torch.rand(708, 256, 3)\\r\\...\n",
       "12812    [b=c, m1: [a x b], m2: [c x d]\\r\\n, m1, [a x b...\n",
       "12813    [model, trainset, transforms.CenterCrop(10), n...\n",
       "12814                                                  NaN\n",
       "12815    [forward, forward, forward, model, forward, mo...\n",
       "12816    [forward, Module, add_module(), dynamic, impor...\n",
       "12817    [W, n*k, (n1+..+nn), w_i, x, X, (n1+..+nn), m,...\n",
       "12818    [x_train, y_train = torch.rand((708, 256, 3)),...\n",
       "12819                                                  NaN\n",
       "12820    [yaxis = [cat_to_name[str(i)] for i in axes[1]...\n",
       "12821    [axes = predict(image, model)\\r\\n, axes = pred...\n",
       "12822                                                  NaN\n",
       "12823                              [TensorDataset, Subset]\n",
       "12824    [EMNIST, flipping, 8, u, n, 20, A, 0.6, 2, 0.4...\n",
       "12825    [data, n, m, k, p, torch.FloatTensor(data), (n...\n",
       "12827    [h5py.dataset, astype, astype(dtype)\\r\\nReturn...\n",
       "12828    [PyTorch, conda install pytorch torchvision cp...\n",
       "12829         [conda install -c conda-forge notebook \\r\\n]\n",
       "12830    [cd /location/to/vision\\r\\nmkdir build &amp;&a...\n",
       "12831    [# [...]\\r\\nfor i in range(batch_sz):\\r\\n    r...\n",
       "12833    [b, c, h, w, b, h, w, xy, input [b, c, h, w]\\r...\n",
       "12834    [Inputs: two [CLS]-Token, Output: Same meaning...\n",
       "12835                                              [[CLS]]\n",
       "12836    [image = Image.open(urllib.request.urlopen(URL...\n",
       "12837    [import torch\\r\\ntensor = torch.randn(84,84)\\r...\n",
       "12838    [Attention(Q, K, V) = matmul(softmax(matmul(Q,...\n",
       "12840    [get_lr(), get_last_lr(), def get_lr(self):\\r\\...\n",
       "12841    [x_train = torch.from_numpy(np.array(x_train)....\n",
       "12842    [\"out_channels=16\", nn.Linear, forward, x, x.v...\n",
       "12846    [output = model(b_x)[0]\\r\\n, [0], [100, 5], [5...\n",
       "12848    [3x3x5x5, 1x3x5x5, hz.weight.data =  horizonta...\n",
       "12849    [fun assetFilePath(context: Context, asset: St...\n",
       "12850    [amp.initialize, .half(), model = YourModel()....\n",
       "12851    [class UNetDataset(object):\\r\\n    def __init_...\n",
       "12852                                             [Module]\n",
       "12853    [model.fit, trial = Trial(model, optimizer, lo...\n",
       "12854                        [fit(...), fit(...), Trainer]\n",
       "12855                 [x_batch, x_batch = x_batch.float()]\n",
       "12856                                                  NaN\n",
       "12857    [import torch\\r\\nimport torch.nn.functional as...\n",
       "12858    [class Net(nn.Module):\\r\\n  def __init__(self,...\n",
       "12859            [vgg16(input), .cpu().numpy(), .detach()]\n",
       "12860    [Parameter containing:\\r\\ntensor([[-7.3584e-03...\n",
       "12861              [model[2*L].weight[i, j]  # w_ij^L\\r\\n]\n",
       "12862                      [format(x, '016b'), interleave]\n",
       "12863    [ldd --version, nvcc --version, conda install ...\n",
       "12864    [conda install pytorch torchvision cudatoolkit...\n",
       "12865    [mean, (25,53), mean[None, None, None, ...], (...\n",
       "12866    [nn.Module.to, # tensor a is in CPU\\r\\ndevice ...\n",
       "12868    [torch.cat((a, b.unsqueeze(1)), 1)\\r\\n tensor(...\n",
       "12869    [a = torch.tensor([[1, 2, 3],\\r\\n             ...\n",
       "12871    [np.put_along_axis, In [111]: np.put_along_axi...\n",
       "12872    [# make a copy of the inputs from numpy array\\...\n",
       "12874    [learn.lr_find()\\r\\nlearn.recorder.plot()\\r\\n,...\n",
       "12875    [import torch\\r\\nfrom PIL import Image\\r\\nimpo...\n",
       "12876                                                  NaN\n",
       "12877    [torch.nn.functional.unfold, torch.nn.function...\n",
       "12878    [ import numpy as np\\r\\n from sklearn.linear_m...\n",
       "12879    [sal_maps_hf, np.uint8, dtype, np.float, data ...\n",
       "12880    [torch.save(model.fc3),'C:\\...\\fc3.pt'), model...\n",
       "12881                          [MSELoss, CrossEntropyLoss]\n",
       "12882    [class SegLabelListCustom(SegmentationLabelLis...\n",
       "12883    [Omniglot, images, labels, MNIST, import torch...\n",
       "12885    [ii=a.argmax(0)\\r\\nmaxval = a.gather(0, ii.uns...\n",
       "12886    [min_delta, class EarlyStoppingCallback(Tracke...\n",
       "12887                                                  NaN\n",
       "12888    [__getitem__, def __getitem__(self, index):   ...\n",
       "12889    [random.seed(seed)\\r\\ntorch.manual_seed(seed)\\...\n",
       "12890    [docker run -it nvidia/cuda:10.1-cudnn7-devel-...\n",
       "12891    [deep_net, nn.Sequential, features, deep_net =...\n",
       "12892    [input @ weight.t()\\r\\n, input[0][0]*WA[0][0] ...\n",
       "12893                                               [−, -]\n",
       "12894    [void* data, Mat (int rows, int cols, int type...\n",
       "12895    [cv::Mat torchTensortoCVMat(torch::Tensor&amp;...\n",
       "12896    [500x500x3, tensor.reshape({width * height * 3...\n",
       "12897                 [batch size, channel, height, width]\n",
       "12898    [torch.zeros(1, *self.input_dim), torch.Size([...\n",
       "12899    [x = torch.randint(500,(256,), dtype=torch.flo...\n",
       "12904    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "12905                                                  NaN\n",
       "12906                                                  NaN\n",
       "12907                                                  NaN\n",
       "12908    [A = torch.eye(3)\\r\\nb = torch.tensor([1.0, 2....\n",
       "12909    [sudo -H pip3 install numpy==1.17.4\\r\\n, sudo ...\n",
       "12910    [a = torch.randn(10, 1000)\\r\\nb = torch.randn(...\n",
       "12911                                         [.zero_grad]\n",
       "12913                                                  NaN\n",
       "12914    [torch.manual_seed(seed)\\r\\nnp.random.seed(see...\n",
       "12915                                                  NaN\n",
       "12916    [data_alice = x_data[2:0]\\r\\ntarget_alice = y_...\n",
       "12917                                                  NaN\n",
       "12918    [split(...), split, import torch\\r\\nx = torch....\n",
       "12919        [split_size, x, x.split(split_size=1, dim=0)]\n",
       "12920    [from spacy.tokenizer import Tokenizer\\r\\n\\r\\n...\n",
       "12921    [%cd /content/\\r\\n!git clone https://github.co...\n",
       "12923    [torch.topk, torch.topk, y, b, h, w, torch.int...\n",
       "12925    [evaluate, object of type &lt;class 'numpy.flo...\n",
       "12926    [VisionDataset, datasets.folder, default_loade...\n",
       "12927    [torch.nn.Parameter(), model.fc1.weight = torc...\n",
       "12928    [prepend(), ${CMAKE_CURRENT_SOURCE_DIR}/, ${AR...\n",
       "12930    [N, D = 386363948, 2\\r\\nk = 190973\\r\\nvalues =...\n",
       "12931    [torch.multinomial, random.choice, # Uniform w...\n",
       "12933    [choice, randint, import torch\\r\\n\\r\\nn = 4\\r\\...\n",
       "12934    [Imagez, PIL, import torchvision\\r\\n\\r\\n\\r\\ncl...\n",
       "12935                            [show_progress_bar=False]\n",
       "12936    [show_progress_bar=False, progress_bar_refresh...\n",
       "12937    [from tqdm import tqdm\\r\\n\\r\\nclass LitProgres...\n",
       "12938    [trainer = pl.Trainer(..., progress_bar_refres...\n",
       "12939                        [enable_progress_bar = False]\n",
       "12940    [model = LinearRegression(), import torch\\r\\nf...\n",
       "12941    [torchvision, #Download the pretrained model\\r...\n",
       "12942    [evaluate_performance.py, python evaluate_perf...\n",
       "12943                 [%run /path_to_file/filename.py\\r\\n]\n",
       "12944                         [a[a==6]=2\\r\\na[a==4]=1\\r\\n]\n",
       "12946    [conda create --name my_env -c pytorch torchvi...\n",
       "12947                                                  NaN\n",
       "12948    [apply_async, multiprocessing, multiprocessing...\n",
       "12949                                                  NaN\n",
       "12950    [Keras, Pytorch, Tensorflow, np.random.randint...\n",
       "12952    [i, P(w_i|w_0, w_1... w_i-1, w_i+1, ..., w_N),...\n",
       "12953    [sentence = f\"I {tokenizer.mask_token} you\", \"...\n",
       "12954    [nvcc, wget https://developer.download.nvidia....\n",
       "12956    [imgs = torch.zeros([128, 1, 28, 28])\\r\\n\\r\\n#...\n",
       "12957    [CUDA_VISIBLE_DEVICES, CUDA_VISIBLE_DEVICES, i...\n",
       "12958                                                  NaN\n",
       "12959    [Subset, subset_train_dset = torch.utils.data....\n",
       "12960    [ONLY, CMAKE_FIND_ROOT_PATH, find_library, fin...\n",
       "12961    [def sample_image, labels = np.array([num for ...\n",
       "12962                              [avg_pool, avg_pooling]\n",
       "12963    [torch.save({'state_dict': decoder.state_dict(...\n",
       "12964    [with, def evaluation(workload):\\r\\n    jobsli...\n",
       "12965    [import torch\\r\\ninput = torch.tensor([1,0,1,0...\n",
       "12966    [roll = torch.randn(1,requires_grad=True)\\r\\ny...\n",
       "12967                                                  NaN\n",
       "12968    [train_target = torch.tensor(train_data[['Labe...\n",
       "12969    [input_dim = 16839, (batch_size, seq_len, 1683...\n",
       "12971    [x = torch.randn((1,3,20,20))\\r\\nx[(x &gt; 0) ...\n",
       "12972    [*=, k = 2\\r\\na = torch.tensor(np.array([10.,2...\n",
       "12973    [def lbp(x):\\r\\n    radius = 2\\r\\n    n_points...\n",
       "12974    [transforms.Lambda(lambda x: local_binary_patt...\n",
       "12975    [torchvision, torch, torch, torchvision, torch...\n",
       "12976    [setup.py, install_requires, torch, setup.py, ...\n",
       "12977    [install_requires, gcloud beta ai-platform ver...\n",
       "12978                                                  NaN\n",
       "12979    [path, __init__, separator, columns, columns, ...\n",
       "12981    [from skimage import io\\r\\n\\r\\n\\r\\nclass MyDat...\n",
       "12982    [    def __init__(self, root, transform=None, ...\n",
       "12985    [model_nn1.train(), model_nn2.eval(), optimize...\n",
       "12986                                              [shape]\n",
       "12987    [from torchvision.datasets import CIFAR10\\r\\nf...\n",
       "12988    [astype, df = pd.read_csv(r'dataset.csv',  low...\n",
       "12989    [x = torch.rand((1,10,2000), requires_grad=Tru...\n",
       "12990                        [detach(), grad_fn, detach()]\n",
       "12991    [model.device, self.lstm, self.char_embed, sel...\n",
       "12992    [device = torch.device('cuda:1')\\r\\nmodel = es...\n",
       "12993    [import torch\\r\\nstart = 3.197054147720337\\r\\n...\n",
       "12994    [a = torch.randn((1,3,4,4))\\r\\ndim = 2\\r\\nindi...\n",
       "12996                                                  NaN\n",
       "12997                                                  NaN\n",
       "12998      [CrossEntropyLoss, model=nn.Linear(784, 3)\\r\\n]\n",
       "12999               [value = list(), value, values, value]\n",
       "13000             [multi-class, crossEntropy, [0, C-1], C]\n",
       "13001    [C:\\Users\\User&gt;conda install PyTorch -c PyT...\n",
       "13002    [shuffle=True, DataLoader, RandomSampler, Data...\n",
       "13003    [torch.manual_seed(\"0\")\\r\\n\\r\\nfor i,elt in en...\n",
       "13004              [NeuralNet, self, NeuralNet, NeuralNet]\n",
       "13006                                                  NaN\n",
       "13007    [--bind_all, tensorboard --logdir=runs --bind_...\n",
       "13008                          [tensorboard --logdir=runs]\n",
       "13009    [pip3 install --upgrade tensorflow tensorboard...\n",
       "13010    [`venv\\Scripts\\activate`\\r\\nin your project di...\n",
       "13012                                                  NaN\n",
       "13013    [nn.Embedding.from_pretrained(), numpy.array, ...\n",
       "13014                                                  NaN\n",
       "13015    [outputVar, maskNLLLoss, # Returns padded targ...\n",
       "13016                                                  NaN\n",
       "13017                          [(-1, 1), y.reshape(-1, 1)]\n",
       "13018    [DataLoader.dataset, len(trainloader.sampler)\\...\n",
       "13019                                      [stateful=True]\n",
       "13022    [ valloader = DataLoader(train_dataset, batch_...\n",
       "13024                   [model.cuda(), model.parameters()]\n",
       "13025    [!pip install torchvision\\r\\nimport torchvisio...\n",
       "13026           [export ANDROID_HOME=/path/to/android/sdk]\n",
       "13027                 [.to(torch.float32), train_x, val_x]\n",
       "13028    [# converting the target into torch format\\r\\n...\n",
       "13029          [__init__, forward, loss, forward, pytorch]\n",
       "13030                                          [forward()]\n",
       "13031                                                  NaN\n",
       "13032    [rpn.anchor_generator._cache, dict, model.rpn....\n",
       "13033    [for param in model.parameters():\\r\\n    param...\n",
       "13034    [total_loss = net_loss + gmm_loss\\r\\ntotal_los...\n",
       "13035    [DataParallel, device_ids, model = nn.DataPara...\n",
       "13036    [model = model.toDevice(‘cuda’)\\r\\nimages = im...\n",
       "13037    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13038      [.astype(np.float32), np.float32, .astype(...)]\n",
       "13039    [data = data.astype(np.float32)\\r\\na = torch.f...\n",
       "13040    ['none', 'mean', 'sum', 'none', 'mean', 'sum',...\n",
       "13041    [number of chars + blank, 0, 1, 62, 0-61, 62, ...\n",
       "13042                                                  NaN\n",
       "13043    [        prediction_as_text = tokenizer.decode...\n",
       "13044                                  [@torch.jit.script]\n",
       "13045    [# Number of training points\\r\\nlen(self.train...\n",
       "13046    [self.register_parameter(name='bias', param=to...\n",
       "13047                                 [batch_first = True]\n",
       "13048      [root= path + 'train/', ImageFolder, ../train/]\n",
       "13050    [import os\\r\\nimport functools\\r\\nimport opera...\n",
       "13051    [torch.masked_select, torch.masked_select(valu...\n",
       "13052    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0...\n",
       "13053    [torch.argmax(nn_result, dim=1), dim,  x = np....\n",
       "13056                                                  NaN\n",
       "13057    [torch.exp(), import torch\\r\\nimport torch.nn....\n",
       "13059    [__train__, if epoch == 10 and np.mean(train_l...\n",
       "13060                                                  NaN\n",
       "13061    [BertForMultiLable, Weights from pretrained mo...\n",
       "13062                            [int16, nn.LSTM, float32]\n",
       "13063    [v, v = torch.tensor((0.5, ）, require_grad=Tru...\n",
       "13064    [import torchvision.transforms as transforms\\r...\n",
       "13065    [torch.triu, einsum, torch.einsum('...ii-&gt;....\n",
       "13067    [k[element[i], element[j]] += m[i, j] * alpha_...\n",
       "13069    [model1, model2, model2.load_state_dict(model1...\n",
       "13070                                                  NaN\n",
       "13071    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "13072    [     pip install pytorch-transformers\\r\\n,   ...\n",
       "13073                                     [0.3015, 0.3081]\n",
       "13074    [torch.std, torch.std, mean = 0.\\r\\nmean_squar...\n",
       "13078    [to, to, Uniform, class MyModule(nn.Module):\\r...\n",
       "13079    [self._apply(self, fn), def _apply(self, fn):\\...\n",
       "13080                            [pycocotools, .pyx, .pyd]\n",
       "13081    [tag_space   = self.hidden2tag(lstm_out[-1])\\r\\n]\n",
       "13082    [class DownsampleAndNoiseMap():\\r\\n    def __i...\n",
       "13083                                                  NaN\n",
       "13084    [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "13085    [torch.matmul, forward, nn.Linear, self.layer_...\n",
       "13086    [train_y = np.array(train_labels) == 'fake'\\r\\...\n",
       "13088                                                  NaN\n",
       "13089    [pip3 install --find-links https://download.py...\n",
       "13090    [requires_grad_(True), du, dv, net = Generator...\n",
       "13091    [net.predict, net.predict, # (n, 512, 512, 3)\\...\n",
       "13092    [def init_weights(net):\\r\\n    if type(net) ==...\n",
       "13093    [torch.cat, tensors = []\\r\\nfor i in range(N):...\n",
       "13094    [Runtime &gt; Change runtime type &gt; Hardwar...\n",
       "13095    [pip install torch==1.7.0+cu101 torchvision==0...\n",
       "13096    [conda install pytorch torchvision cudatoolkit...\n",
       "13097    [if torch.cuda.is_available:\\r\\n  print('GPU a...\n",
       "13098    [pip3 install torch==1.3.1+cpu torchvision==0....\n",
       "13099    [pip install -r requirements.txt, pip install ...\n",
       "13100    [     for m_batch in range(len(imageunfold)):\\...\n",
       "13101    [for batch_image in range (imageunfold.shape[0...\n",
       "13102         [tuple(map(torch.stack, zip(*x)))\\r\\n, x, x]\n",
       "13103                          [True, False, ts = ~ts\\r\\n]\n",
       "13104                                                  NaN\n",
       "13105                                                  NaN\n",
       "13106    [requires_grad = True, create_graph=True, &gt;...\n",
       "13107    [label_df.loc[:,['image_name','tags']].to_csv(...\n",
       "13108    [## Attaching label to correct file names\\r\\ni...\n",
       "13109                            [DistributedDataParallel]\n",
       "13110                                                  NaN\n",
       "13114                         [img = img.unsqueeze(0)\\r\\n]\n",
       "13115                                                  NaN\n",
       "13116    [import torch\\r\\ntorch.cuda.empty_cache()\\r\\n,...\n",
       "13117    [for e in range(epochs):\\r\\n    for images, la...\n",
       "13118    [loss =  self.criterion(pred, label)\\r\\n\\r\\nto...\n",
       "13119    [with torch.no_grad():\\r\\n  for m in self.chil...\n",
       "13120    [features, labels in batch:\\r\\n   features, la...\n",
       "13121    [import torchvision.transforms as transforms\\r...\n",
       "13122    [pip install koila\\r\\n, from koila import lazy...\n",
       "13123    [import gc\\r\\n\\r\\ndel variable #delete unneces...\n",
       "13124    [torch, dilation, dilation, dilation, pytorch,...\n",
       "13128    [ChainMap, from collections import ChainMap\\r\\...\n",
       "13129    [for, dict.items, pretrained_dict = {k: v if k...\n",
       "13130    [class CNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13131    [[B, 128, 10, 10], .flatten, [B, 128*10*10], 1...\n",
       "13132    [def flatten(w, k=3, s=1, p=0, m=True):\\r\\n   ...\n",
       "13133    [getrotation, def getrotation(self):\\r\\n    si...\n",
       "13134                                                  NaN\n",
       "13135    [nn.ConvTranspose2d, import torch \\r\\ninput = ...\n",
       "13136    [import os\\r\\nos.environ['CUDA_VISIBLE_DEVICES...\n",
       "13138    [test, def test_one_image(I, model):\\r\\n    ''...\n",
       "13139    [__getitem__, object.__getitem__(self, key), s...\n",
       "13140    [#!/usr/bin/env python3\\r\\n\\r\\nimport sys\\r\\ni...\n",
       "13142    [batch_x.shape = Batch-size, No of channels, H...\n",
       "13144    [ nn.DataParallel\\r\\n, features: (n_samples, f...\n",
       "13145    [dataloader = DataLoader(dataset, batch_size=b...\n",
       "13146    [# rewrite sklearn method to torch\\r\\ndef conf...\n",
       "13147    [# weird trick with bincount\\r\\ndef confusion_...\n",
       "13148    [def confusion_matrix_2(y_true, y_pred, sample...\n",
       "13149    [class RNN(nn.Module):\\r\\ndef __init__(self, i...\n",
       "13150    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13151    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "13152    [# rewrite sklearn method to torch\\r\\ndef conf...\n",
       "13153    [from google.colab import files\\r\\nuploaded= f...\n",
       "13154    [import torch\\r\\nimport pickle\\r\\nimport os.pa...\n",
       "13155    [valid_cols = []\\r\\nfor col_idx in range(A.siz...\n",
       "13156    [non_empty_mask = A.abs().sum(dim=0).bool(), F...\n",
       "13157                                                  NaN\n",
       "13159    [import torch\\r\\nt = torch.tensor(1)\\r\\nprint(...\n",
       "13160    [conda install pytorch torchvision -c pytorch\\...\n",
       "13161    [from __future__ import print_function\\r\\nimpo...\n",
       "13162          [/etc/sysctl.d\\r\\n, htop\\r\\n, free -m \\r\\n]\n",
       "13163    [t = transforms.Compose([transforms.RandomHori...\n",
       "13164    [sudo pip uninstall protobuf\\r\\n, conda instal...\n",
       "13165    [tolist(),  import torch\\r\\n a = torch.randn(2...\n",
       "13166    [def flair_embeddings(sentences, output_file=N...\n",
       "13167                                                  NaN\n",
       "13168    [torchvision.utils.save_image, torchvision.uti...\n",
       "13169                                        [torchvision]\n",
       "13170                                                  NaN\n",
       "13171                                 [MyServer.inference]\n",
       "13173    [SET MSSdk=1\\r\\nSET DISTUTILS_USE_SDK=1\\r\\ncal...\n",
       "13174    [mu, sigma, z = torch.randn_like(mu) * sigma +...\n",
       "13175                                                  NaN\n",
       "13176                [torch.stack, torch.cat, torch.stack]\n",
       "13177    [target,      m = nn.Sigmoid()\\r\\n     loss = ...\n",
       "13179    [prhmma, y[y == 0] = -5, torch.where, y = torc...\n",
       "13180    [pred, torch.stack, x_dt, pred, .retain_grad()...\n",
       "13181    [def embed(sentence):\\r\\n   tokens = camembert...\n",
       "13182    [&lt;s&gt;, [CLS], &lt;s&gt;, fairseq, transfo...\n",
       "13183    [from sentence_transformers import SentenceTra...\n",
       "13184                         [DataLoader, num_workers, 0]\n",
       "13185    [x, u,s,v = torch.svd(x, compute_uv=False)\\r\\n...\n",
       "13186                                                  NaN\n",
       "13187                                                  NaN\n",
       "13189        [pip install --upgrade torch torchvision\\r\\n]\n",
       "13190    [NLLLoss, CrossEntropyLoss, BCELoss, reduction...\n",
       "13191    [forward(ctx,x,INPUT), x, INPUT, backward, gra...\n",
       "13192    [torch.optim.Adam, torch.optim.CustomAdam([{'p...\n",
       "13193            [learning_rate, gradients, learning_rate]\n",
       "13195    [__getitem__, imgs_transformed = []\\r\\nfor img...\n",
       "13196                                                  NaN\n",
       "13197    [torch.nn.BCEWithLogitsLoss, LogSigmoid, NLLLo...\n",
       "13198    [self.fc1 = nn.Linear(input_size, hidden_size,...\n",
       "13199    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "13201    [pip install https://download.pytorch.org/whl/...\n",
       "13202    [pip37 install torch-1.5.1+cpu-cp37-cp37m-win_...\n",
       "13203    [inputs, labels = data                        ...\n",
       "13205    [device = args.device # \"cuda\" / \"cpu\"\\r\\nif \"...\n",
       "13206    [   * when you get this error::RuntimeError: I...\n",
       "13208    [class CNN(nn.Module):\\r\\n   def __init__(self...\n",
       "13210    [  if torch.cuda.is_available():\\r\\n      devi...\n",
       "13211                                                  NaN\n",
       "13212                                                  NaN\n",
       "13213                                                  NaN\n",
       "13214    [for i,(data,output) in validate_left_eyes:\\r\\...\n",
       "13215    [class NeuralNet(nn.Module):\\r\\n    def __init...\n",
       "13216    [features, features, torchvision, import torch...\n",
       "13217                                                  NaN\n",
       "13218    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "13220                                  [nn.Dropout(p=0.2)]\n",
       "13221    [self.drop_layer = nn.Dropout(p=p), self.dropo...\n",
       "13222    [torch.utils.data.Dataset, torchvision.transfo...\n",
       "13223    [[1x384], torch.cat((embedded[0], hidden[0]), ...\n",
       "13224    [x_train: torch.Size([45000, 784]), y_train: t...\n",
       "13225    [def train(network, epochs, save_Model = False...\n",
       "13226    [x_train = x[train_index]\\r\\nx_test = x[test_i...\n",
       "13227                                                  NaN\n",
       "13228    [for item in embeddingLists:       \\r\\n    tem...\n",
       "13229                                                  NaN\n",
       "13230    [ResNet-101, ResNet-18, torchvision, 5, 3, tor...\n",
       "13231    [from torchvision.models import resnet18\\r\\nmo...\n",
       "13232    [topk_values, linear_indices = stacked.flatten...\n",
       "13233    [maskrcnn_benchmark/modeling/backbone/resnet.p...\n",
       "13234                                                  NaN\n",
       "13235    [BertTokenizerFast, return_offsets_mapping=Tru...\n",
       "13236      [total_loss = loss_1 + loss_2\\r\\n, .backward()]\n",
       "13237    [Input-&gt;    1x32x32\\r\\nconv1-&gt;    6x30x3...\n",
       "13238    [nn.LPPool2d(3, 1)(torch.randn(1, 1, 10, 10)),...\n",
       "13239                                                  NaN\n",
       "13240                 [nn.Conv(3, 64, 3), nn.Conv(64, ...]\n",
       "13241    [tensor.numpy(), list(), images = torch.randn(...\n",
       "13242    [h, w = 7, 10\\r\\nx = torch.arange(0,h*w,dtype=...\n",
       "13243                                                  NaN\n",
       "13245    [  loss = loss_func(prediction, y.squeeze())  ...\n",
       "13246    [from multiprocessing import Process, Pipe\\r\\n...\n",
       "13247    [model(tensor([[[25.]]]), tensor([[[0., 0.]]])...\n",
       "13248    ['initial_lr', 'initial_lr', group['lr'], d = ...\n",
       "13249    [# for OS: Windows, package: pip, Language: py...\n",
       "13250    [transform = transforms.Compose([\\r\\n    trans...\n",
       "13252    [theta, nn.Parameter, import numpy as np\\r\\nim...\n",
       "13254                                                  NaN\n",
       "13255                                                  NaN\n",
       "13256                         [a = a.cuda()\\r\\n, a.cuda()]\n",
       "13258    [def __getitem__(self, idx):\\r\\n    idx_q = in...\n",
       "13259    [DataLoader, DataLoader, Dataset, DataLoader, ...\n",
       "13260    [optimizer = optim.SGD(net.parameters(), lr=0....\n",
       "13261    [ optimizer = optim.Adam(net.parameters(),0.00...\n",
       "13262    [conda create -n pytorch_env python=3 ( you ca...\n",
       "13263                                                  NaN\n",
       "13264                                                  NaN\n",
       "13265    [nn.MSELoss, nn.CrossEntropyLoss, nn.CrossEntr...\n",
       "13266    [for i, (img, label) in enumerate(dataloader):...\n",
       "13267    [a = t.tensor(1)\\r\\nb = t.tensor(2)\\r\\nc = t.t...\n",
       "13268    [PyObject *detect_device, *pArgsDevice;\\r\\ndet...\n",
       "13269    [That’s not possible. Modules can hold paramet...\n",
       "13270    [class Net(nn.Module):\\r\\n  def __init__()\\r\\n...\n",
       "13271    [class Model(nn.Module):\\r\\n    def __init__(s...\n",
       "13272                    [next(model.parameters()).device]\n",
       "13273    [directory = \"./get_preds/fail\"\\r\\n\\r\\nfor fil...\n",
       "13274    [im = Image.new('LAB',(80,80),color=(255,0,0))...\n",
       "13275    [target = torch.randint (nc, (bs,))\\r\\n, outpu...\n",
       "13276    [pip uninstall -y enum34, sudo pip uninstall -...\n",
       "13277    [loss, w2, w1, loss, w2, grad_y_pred = 2.0 * (...\n",
       "13278                                                  NaN\n",
       "13279         [single positional indexer is out-of-bounds]\n",
       "13280    [net = torchvision.models.resnet18(pretrained=...\n",
       "13281    [torch.randperm, import numpy as np\\r\\nimport ...\n",
       "13282    [python -m torch.distributed.launch test.py --...\n",
       "13285                                                  NaN\n",
       "13286    [conda create -n pytorch python=3.7\\r\\nconda a...\n",
       "13287    [pip install https://download.pytorch.org/whl/...\n",
       "13288    [pip, pip install torch, pip install torch===1...\n",
       "13289    [.view(128, 128, 3), .ToTensor(...), # ...\\r\\n...\n",
       "13290                                                  NaN\n",
       "13291    [# dnf install gcc-c++ flex bison binutils-dev...\n",
       "13292    [$ brew install 'gcc@10'\\r\\n   [... installing...\n",
       "13293    [rpm, sudo rpm -ivh --force gcc-4.4.4-2.fc13.x...\n",
       "13294    [x, f(x) = x[0][0]+x[0][1]+x[1][0]+x[1][1]\\r\\n...\n",
       "13295    [torch.tensor, requires_grad==True, nn.module,...\n",
       "13297    [test_train_split, stratify, from sklearn.mode...\n",
       "13298    [nn, F, F.binary_cross_entropy, nn, criterion ...\n",
       "13299    [w1 = tf.Variable(tf.truncated_normal(shape=[1...\n",
       "13300    [torch.utils.data.Subset, batch_size = ... # y...\n",
       "13301    [return, if, stride==1, layer1, def _layer(sel...\n",
       "13304    [nn.Conv1d, nn.Conv2d, batch_x = batch_x[..., ...\n",
       "13305    [allow_unused=True, .grad, dydx = torch.autogr...\n",
       "13306    [trainset = torchvision.datasets.CIFAR10(root=...\n",
       "13307    [sampler, batch_sampler, sampler, batch_sample...\n",
       "13308    [train_sampler = RandomSampler(train_dataset) ...\n",
       "13309    [def _setup_devices(self) -&gt; \"torch.device\"...\n",
       "13310    [def forward(...), def forward(self, x):\\r\\n  ...\n",
       "13311    [ipc=host, docker build, ipc=host, docker comm...\n",
       "13312    [docker, docker run .... --ipc=host ...\\r\\n, s...\n",
       "13313    [input_sample = input_sample.float()\\r\\n, [0, ...\n",
       "13316    [import random\\r\\nimport torch\\r\\nres = [ [ ra...\n",
       "13317    [np.expand_dims(i1r.transpose(2,0,1), axis=0) ...\n",
       "13318    [torch.stack, model = ... # Load your model\\r\\...\n",
       "13320                                                  NaN\n",
       "13321    [28x28, 28, 7, 2, 2, 13.5, 28x28, 32x32, MaxPo...\n",
       "13322                                                  NaN\n",
       "13323    [nn.LSTM, [sequence_length, batch_size, embedd...\n",
       "13324    [forward, MSE_loss, self.linear = nn.Linear(ou...\n",
       "13325    [cuda, cpu, model, cuda, model = nn.DataParall...\n",
       "13326    [net.to(device)\\r\\npre_trained_model=model_pat...\n",
       "13327    [customized_block = nn.ModuleList([]), customi...\n",
       "13328    [[bb,cc] = model.forward(test_single)\\r\\n, out...\n",
       "13329    [__init__, training_signals, training_signals,...\n",
       "13330    [(x, y), (x, y), [0, width]x[0, height], [-1, ...\n",
       "13331                                                  NaN\n",
       "13332                                                  NaN\n",
       "13333    [# [Batch size, Sequence length, Embedding siz...\n",
       "13334    [torch.sign(a) * torch.pow(torch.abs(a), 0.5)\\...\n",
       "13335    [CUDA out of memory, unet = my_unet(in_ch=5, o...\n",
       "13336    [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "13337                                                  NaN\n",
       "13338    [a = torch.LongTensor([[1, 2, 3, 4], [4, 3, 2,...\n",
       "13339                                                  NaN\n",
       "13340    [ConvTranspose2d, nn.ConvTranspose2d(in_channe...\n",
       "13341    [conda create -n deep7 -c pytorch python=3.7 p...\n",
       "13342                             [conda update conda\\r\\n]\n",
       "13343    [pytorch/pytorch:1.2-cuda10.0-cudnn7-devel, py...\n",
       "13345        [torch.nn.Softmax, torch.nn.CrossEntropyLoss]\n",
       "13347                  [NaN, inf, samples % batchsize = 0]\n",
       "13348               [sdkml3_jetpack_l4t_422_rev1_b30.json]\n",
       "13349    [model.train(), model.eval(), self.bn = nn.Bat...\n",
       "13350    [model.x.data.clamp_(min=0.0, max=1.0)\\r\\n, mo...\n",
       "13351    [tfp.distributions.Categorical(probs)\\r\\n,  tf...\n",
       "13352    [loss, pred, target_sum, nn.Parameter(), In [2...\n",
       "13353    [THCCaching, Allocator.cpp, cudaHostAlloc(), c...\n",
       "13354                                                  NaN\n",
       "13355                                                  NaN\n",
       "13356                                                  NaN\n",
       "13357        [loss.backward(), [0,1,2,3], [4,5,6,7], sinx]\n",
       "13358    [index_diff = (predictions.flatten() != target...\n",
       "13359    [conda create -n pytorch_env python=3 ( you ca...\n",
       "13360    [conda create -n conda_pytorch python=3.6\\r\\ns...\n",
       "13362    [opt.img_size, ds_size = opt.img_size // 2 ** ...\n",
       "13363                                         [father_net]\n",
       "13364    [target2.numpy().ravel(), target2.view(-1).num...\n",
       "13365    [nn.Linear, class Network(nn.Module):\\r\\n   de...\n",
       "13366    [test, X_test.to(device)\\r\\ny_test.to(device)\\...\n",
       "13367                                                  NaN\n",
       "13368    [self.word_embeddings = nn.Embedding(vocab_siz...\n",
       "13369    [transforms, cifar_train, cifar_val = torch.ut...\n",
       "13370    [ImportError: TensorBoard logging requires Ten...\n",
       "13371    [pip install tensorboard==1.14.0\\r\\n, pip inst...\n",
       "13372                   [conda install -y tensorboard\\r\\n]\n",
       "13373    [tensorboardX, tensorboard, pip install tensor...\n",
       "13374    [import matplotlib\\r\\nimport matplotlib.pyplot...\n",
       "13375                                                  NaN\n",
       "13376    [nn.DataParallel, model = nn.DataParallel(mode...\n",
       "13377    [flattening, torch.nn.Module, torch.nn.Module,...\n",
       "13378    [interpolate, nn.functional, import torch.nn.f...\n",
       "13380                                                  NaN\n",
       "13383    [nn.BCELoss, nn.CrossEntropyLoss, nn.CrossEntr...\n",
       "13384                            [net.eval(), net.train()]\n",
       "13385    [for, M, N, diff_B_C = B - C\\r\\ndiff_A_C = A[:...\n",
       "13386    [DataLoader, ToPILImage(), transform=transform...\n",
       "13387    [transforms.RandomHorizontalFlip(p=1), X, y, p...\n",
       "13388    [list, list, import torch\\r\\nimport torch.nn a...\n",
       "13389    [G.update_all(fn.copy_e(‘msg’),fn.sum(‘msg’,’c...\n",
       "13390    [forward, torch.nn.Module, eval(), Dropout, Ba...\n",
       "13391    [model(), forward, class FooBar(nn.Module):\\r\\...\n",
       "13392                                                  NaN\n",
       "13393                                                  NaN\n",
       "13394    [:8888, docker run -it ..., docker run --inter...\n",
       "13396    [from_blob, TensorOptions, double array[] = { ...\n",
       "13397    [torch::Tensor tharray = torch::tensor({1, 2, ...\n",
       "13398    [double array[5] = {1, 2, 3, 4, 5};\\r\\nauto th...\n",
       "13400    [outputs[2][0], outputs[2][1], outputs[2][0:1]...\n",
       "13401    [import torch\\r\\n\\r\\n# using small shape to ma...\n",
       "13402    [Dataset, torch.Tensor, __getitem__, __len__, ...\n",
       "13403    [jacobian, import torch\\r\\n\\r\\ntorch.manual_se...\n",
       "13404    [MNIST, 32x32, height x width, import tempfile...\n",
       "13405    [Resize, transform.Resize((32, 32))\\r\\n, Norma...\n",
       "13406    [import torch.nn as nn\\r\\n\\r\\nclass SharedMode...\n",
       "13407    [SharedModel, encoder, import torch\\r\\n\\r\\ncla...\n",
       "13408                                                  NaN\n",
       "13409    [conv2D, for, torch.sum, dim=0, cross, def con...\n",
       "13410    [np.ogrid, i, j, k = np.ogrid[:x.shape[0], :x....\n",
       "13411    [if k is 'params':\\r\\n    outputs += (k + ': '...\n",
       "13412                         [unique, return_counts=True]\n",
       "13413                                   [unique, floating]\n",
       "13417    [y, y.backward(), vector-Jacobian product, x =...\n",
       "13418    [torch.argsort, torch.argsort(sor, dim=2)\\r\\n\\...\n",
       "13419    [plt.ylim(-0.5, len(names) - 0.5)\\r\\n, len(nam...\n",
       "13420    [inplace=True, input, inplace=False, droput(in...\n",
       "13421    [query, key, value, query_ = X\\r\\nkey_ = X\\r\\n...\n",
       "13422    [nn.Linear, in_features, in_features=5, out_fe...\n",
       "13423    [Linear, in_features, out_features, (10, 3, 4)...\n",
       "13424    [nn.ModuleList, class FNNModuleVar(nn.Module):...\n",
       "13425    [running_loss, running_all, running_loss / run...\n",
       "13426                                                  NaN\n",
       "13427    [self.module_name = module, setattr(self, 'emb...\n",
       "13428         [X_batch.cuda(), y_batch.cuda(), DataLoader]\n",
       "13429    [class DeepLinear(nn.Module):\\r\\ndef __init__(...\n",
       "13430    [device = 'cuda'\\r\\nx = torch.LongTensor([0, 1...\n",
       "13431    [DataLoader, Dataset, class MyDataset(Dataset)...\n",
       "13432    [class MyDataset(Dataset):\\r\\n    def __init__...\n",
       "13433    [6x6, x, import torch\\r\\nimport torch.nn as nn...\n",
       "13434    [optimizer.step(), y, detach, targets, detach,...\n",
       "13435    [\"python.linting.pylintArgs\": [\\r\\n\"--errors-o...\n",
       "13436                                                  NaN\n",
       "13438         [.backward(), .backward( retain_graph=True)]\n",
       "13439    [nn.LSTM, nn.LSTMCell, x0 = [a,b,c]\\r\\nx1 = [c...\n",
       "13440                                                  NaN\n",
       "13441    [import torch\\r\\n\\r\\nA = [0, 3, 2, 4, 3]\\r\\nB ...\n",
       "13442    [import numpy as np\\r\\n\\r\\nA = [0, 3, 2, 4, 3]...\n",
       "13443    [bincount, def accumulate_coords(A,B):\\r\\n    ...\n",
       "13444    [x = [x1, x2], sigmoid(x1) = 1 / (1 + exp(-x1)...\n",
       "13445    [sigmoid, softmax, sigmoid, # Translate values...\n",
       "13446    [NetOne, NetTwo, # NetTwo's loss has nothing t...\n",
       "13447    [t_shape = [4, 10, 10]\\r\\ndata = torch.rand(t_...\n",
       "13448    [tf.nn.conv2d, tf.keras.layers.Conv2D, torch.n...\n",
       "13449    [nn.Transformer, EncoderLayer, d_model=512, nh...\n",
       "13450    [a = torch.Tensor(\\r\\n    [[0.2215, 0.5859, 0....\n",
       "13451    [ge, class LinearGE(nn.Module):\\r\\n    def __i...\n",
       "13452    [import random\\r\\nlabel_mapping = list(range(1...\n",
       "13453    [(25-60), sex, age, class Net(nn.Module):\\r\\n ...\n",
       "13454    [import torch\\r\\n\\r\\nw = torch.tensor([2.0, 1....\n",
       "13455    [torch.gather, a = torch.tensor([[1, 2, 3], [4...\n",
       "13456    [X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]...\n",
       "13457      [img, masked_output = img * mask.int().float()]\n",
       "13458    [img[mask==False] = 0\\r\\n, img[~mask] = 0\\r\\n,...\n",
       "13459    [import torch\\r\\n\\r\\ndef generate_masked_tenso...\n",
       "13460    [convert_tf_checkpoint_to_pytorch.py, import t...\n",
       "13461    [(seq_len, batch, input_size), seq_len, input_...\n",
       "13462    [batch_first=True, no:of_layers, seq_len, inpu...\n",
       "13464    [torch.nn.MaxPool2d, nn.Module, torch.nn.funct...\n",
       "13465                                                  NaN\n",
       "13466    [.backward, T = torch.sum(S)\\r\\nT.backward()\\r...\n",
       "13468                                                  NaN\n",
       "13469                                                  NaN\n",
       "13470    [test_image, test_image = Image.open(test_imag...\n",
       "13471                                                [img]\n",
       "13472                                                  NaN\n",
       "13473    [W.requires_grad, True, import torch \\r\\n\\r\\ni...\n",
       "13474    [imshow, origin='lower', imshow, origin=, pl.i...\n",
       "13475    [class MyLayer(Layer):\\r\\n    def __init__(sel...\n",
       "13476                                                  NaN\n",
       "13477                                                  NaN\n",
       "13478                                                  NaN\n",
       "13479    [torch.gather(fourD, 1, indices.unsqueeze(1)) ...\n",
       "13480    [from torch.utils.data import Dataset, DataLoa...\n",
       "13482    [tf.slice, def tf_index_select(input_, dim, in...\n",
       "13483                           [random seed, random seed]\n",
       "13484    [loss.backward()\\r\\nmodel.float() # add this h...\n",
       "13485                                                  NaN\n",
       "13486                  [test(epoch), with torch.no_grad()]\n",
       "13487    [with torch.no_grad(), Tensor.backward(), epoc...\n",
       "13488    [forward(), def forward(self, input_ids, atten...\n",
       "13489    [<a href=\"https://pytorch.org/docs/stable/torc...\n",
       "13490    [def u_vector(Q,parameters):\\r\\n    cols = Q.s...\n",
       "13491                 [eval(), BatchNorm, eval(), train()]\n",
       "13492    [import torch.nn as nn\\r\\nmodel = nn.Sequentia...\n",
       "13493                                                  NaN\n",
       "13494    [state_dict, OrderedDict, state_dict, state_di...\n",
       "13495                                                  NaN\n",
       "13496                                                  NaN\n",
       "13498    [X_train, numpy.ndarray, torch.Tensor, y_pred ...\n",
       "13500    [data, (1, 73, 480), MaxPool2d, data, out, ind...\n",
       "13502                                                  NaN\n",
       "13503    [import numpy as np\\r\\nfrom scipy.spatial.dist...\n",
       "13504    [import numpy as np\\r\\nimport numba as nb\\r\\nf...\n",
       "13505    [train_dataset = DatasetGenerator()\\r\\n, inps ...\n",
       "13507    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "13508    [import pandas as pd\\r\\nimport numpy as np\\r\\n...\n",
       "13510    [weights = torch.FloatTensor([.3, .7])\\r\\nloss...\n",
       "13511    [A=X[:,0]\\r\\nB=X[:,1]\\r\\n, print(B)\\r\\ntensor(...\n",
       "13512    [torch.split, A, B = X.split(1, dim=1)\\r\\n\\r\\n...\n",
       "13513    [Convnd, Linear, groups, 1, Linear, B x dim_st...\n",
       "13514    [import torch as t\\r\\n\\r\\nemb = t.nn.Embedding...\n",
       "13515               [cp27, pip3 install torch torchvision]\n",
       "13516    [numpy==1.17.0\\r\\nhttps://download.pytorch.org...\n",
       "13517    [x=x.view(-1,1), x = x.squeeze(1), forward, (b...\n",
       "13518    [ConcatDataset, torch.utils.data.Dataset, clas...\n",
       "13519                                                  NaN\n",
       "13520    [# backbone\\r\\n        if backbone_name == 're...\n",
       "13521    [.features, backbone = torchvision.models.mobi...\n",
       "13522    [def get_resnet18_backbone_model(num_classes, ...\n",
       "13523    [InstanceNorm1d, import torch\\r\\n\\r\\n\\r\\nclass...\n",
       "13524    [log_softmax(x), def log_softmax(x):\\r\\n    re...\n",
       "13525    [log_softmax, def log_softmax(x):\\r\\n    retur...\n",
       "13526    [a, import torch\\r\\na = torch.arange(9*2*2).vi...\n",
       "13528    [[100, 1, 32, 32], [1, 32, 32], num_channels =...\n",
       "13529    [y, y, X, time_series = [0, 1, 2, 3, 4, 5]\\r\\n...\n",
       "13531                [.npy, .npy, __init__(), __getitem__]\n",
       "13532                                                  NaN\n",
       "13533    [from pathlib import Path\\r\\n\\r\\ndef main(data...\n",
       "13534                                                  NaN\n",
       "13535                                                  NaN\n",
       "13536    [.to(device), conda install pytorch=1.2.0 torc...\n",
       "13537    [GeForce 30, cuda 11 =&lt;, conda install pyto...\n",
       "13538    [import numpy as np\\r\\nfrom PIL import Image\\r...\n",
       "13539                                          [torch.hub]\n",
       "13540    [state_dict = torch.hub.load_state_dict_from_u...\n",
       "13541    [import os\\r\\nlabel_paths =''\\r\\nlabels = os.l...\n",
       "13543    [forward, feedforward, class FeedForward(nn.Mo...\n",
       "13546    [set_start_method, if __name__ == '__main__':,...\n",
       "13547    [import base64\\r\\nfrom io import BytesIO\\r\\n\\r...\n",
       "13548    [requires_grad = False, loss.requires_grad = T...\n",
       "13549                    [torch.nn.ModuleList, ModuleList]\n",
       "13551                                                  NaN\n",
       "13552    [for e in range (episode):\\r\\n    state = env....\n",
       "13553    [lloss, loss, avg_train_loss, for epoch in ran...\n",
       "13554    [    conda install pytorch torchvision cudatoo...\n",
       "13555                                                  NaN\n",
       "13556    [flags, indices, mask, mask, indices = np.arra...\n",
       "13557    [torch.gather, torch.take, indices = torch.ten...\n",
       "13558                                                  NaN\n",
       "13559    [optimize_model, q_value, import torch\\r\\nimpo...\n",
       "13560    [D_loss1 = ((D(X_mb) + 1e-8).log()).mean() + (...\n",
       "13561    [a, b, b, a, b, a, out, a, np.add(), a, a = a+...\n",
       "13562                                                  NaN\n",
       "13563    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "13564    [token_embeddings, for layer in token_embeddin...\n",
       "13565    [ZeroPad2d, from functools import reduce\\r\\nfr...\n",
       "13566             [1.9.1, padding='valid', padding='same']\n",
       "13567    [padding='same', padding='valid', 'same', 'val...\n",
       "13568                                                  NaN\n",
       "13569    [conda activate myenv\\r\\nconda install -n myen...\n",
       "13571    [def get_lr(gamma, optimizer):\\r\\n    return [...\n",
       "13572    [._modules, for name,child in net.named_childr...\n",
       "13573    [nn.ReLU, F.relu, setattr, import torch\\r\\nimp...\n",
       "13574    [def replace_layers(model, old, new):\\r\\n    f...\n",
       "13575    [def replace_layer(module: nn.Module, old: nn....\n",
       "13576    [nn.modules, def replace_bn(module, name):\\r\\n...\n",
       "13578    [unsqueeze(), x = torch.zeros((4,4,4))   # Cre...\n",
       "13579                                                  NaN\n",
       "13580                       [NestedTensors, RaggedTensors]\n",
       "13581    [out, x, def mg(x, c=1.33, b=0.4, p=6.88):\\r\\n...\n",
       "13583             [X, data, X = torch.stack(X).to(device)]\n",
       "13584                                             [(0, 1]]\n",
       "13585    [from onnx_coreml import convert\\r\\nml_model =...\n",
       "13586                                 [final_model.eval()]\n",
       "13587      [pytorch, cuda, pytorch stable 1.2, 1.0.1, 1.3]\n",
       "13589                             [J, W, W, W, W, W, W, W]\n",
       "13590                                  [a, y_hat = x @  a]\n",
       "13592                                                  NaN\n",
       "13593    [batch_size=4, n_classes=3, RuntimeError: Asse...\n",
       "13594    [correct = 0\\r\\ntotal = 0\\r\\nwith torch.no_gra...\n",
       "13595                                                  NaN\n",
       "13596    [nn.Module, grad_fn, model = mymodel(channels)...\n",
       "13597                                     [shuffle = True]\n",
       "13598    [%timeit torch.randn(100, 100).to(device)\\r\\n\\...\n",
       "13599    [dict, list, setattr(x, attr, 'magic'), for i ...\n",
       "13601                                                  NaN\n",
       "13602    [self.linear = torch.nn.Linear(1, 1)\\r\\n, X_tr...\n",
       "13603    [def loss_function(output_e, outputs, imgs, la...\n",
       "13604    [torch.autograd.functional.jacobian, torch&gt;...\n",
       "13605    [def cae_loss_fcn(code, img_out, img_in, lamda...\n",
       "13606    [reset(), reset_parameters(), import torch\\r\\n...\n",
       "13607    [import torch\\r\\n\\r\\nB = 1 # num of batches\\r\\...\n",
       "13608                                                  NaN\n",
       "13609    [self.classifier = torch.nn.Sequential(torch.n...\n",
       "13610    [CUDA_LAUNCH_BLOCKING=1, b1_x1, b1_x2 = box1[:...\n",
       "13611                                                  NaN\n",
       "13612    [train = torchtext.data.TabularDataset.splits(...\n",
       "13613    [sort_key, sort_within_batch, True, BATCH_SIZE...\n",
       "13614                  [_setup, _restore, _setup, restore]\n",
       "13615                                 [training_iteration]\n",
       "13616                                                  NaN\n",
       "13617                                                  NaN\n",
       "13618    [torchvision, import torchvision\\r\\nfrom torch...\n",
       "13619    [RandomCrop, get_param, from torchvision impor...\n",
       "13620    [# Apply these to image and mask\\r\\naffine_tra...\n",
       "13621                                                  NaN\n",
       "13623    [retain_graph=True, model = Autoencoder()\\r\\nr...\n",
       "13624    [kernel_size=5, padding=2, H, W, 2^4=16, impor...\n",
       "13625                                                  NaN\n",
       "13626    [M, y_1 = (M + μ_1) * x + b\\r\\ny_2 = (M + μ_2)...\n",
       "13628    [OurModule, nn.Module, 2, num_inputs, 3, num_c...\n",
       "13629        [OurModule, nn.Module, nn.Module, init, init]\n",
       "13630    [loss += loss_fn(prediction, ratings) # instea...\n",
       "13632    [O(n m^2), n, m, import time\\r\\nimport torch\\r...\n",
       "13633    [self.vectors, return (self.vectors([i])*torch...\n",
       "13634    [x = torch.Tensor([\\r\\n        [ 0.7646,  0.55...\n",
       "13635    [', \", char, const char *, PYBIND11_MODULE('si...\n",
       "13636                                                  NaN\n",
       "13637    [ import torch\\r\\n a = torch.zeros(2)\\r\\n b = ...\n",
       "13639                                                  NaN\n",
       "13640    [hidden = torch.randn(1,5,4) # Random initiali...\n",
       "13641    [batch_first=True, # Define the model\\r\\nnet =...\n",
       "13642    [A, A.t(), Sigma_k = torch.rand(512, 512)\\r\\nS...\n",
       "13643                [tensor.add(), tensor, tensor.add_()]\n",
       "13644    [model = FFNNModel(30,5,[100,200,300,100],0.2)...\n",
       "13645    [loss = loss_fn(outputs, labels)\\r\\nl1_lambda ...\n",
       "13646    [def l1_regularizer(model, lambda_l1=0.01):\\r\\...\n",
       "13647    [import torch\\r\\n\\r\\nU = 300 # number of users...\n",
       "13648    [x_train_polynomial = torch.stack([x_train, x_...\n",
       "13649                                                  NaN\n",
       "13650                                                  NaN\n",
       "13651    [scatter, a = torch.tensor([[0, 0, 0, 0],\\r\\n ...\n",
       "13652    [3, a, b, 2 + 3, 3, b, a, num_rows, import num...\n",
       "13653    [(a + b) + c == a + (b + c), (a + b) + c, a + ...\n",
       "13654                                 [Dropout, BatchNorm]\n",
       "13655    [import os\\r\\nimport torch\\r\\nfrom torchvision...\n",
       "13656    [def calcSTD(d):\\r\\n    meanValue = 0.44531356...\n",
       "13659    [loss.backward(), optimizer.step(), # locate z...\n",
       "13661    [np.lib.stride_tricks.as_strided, scikit-image...\n",
       "13662    [b, (2,3,x1), a, (2,x2-x1+1,3,x2), x1=4, x2=6,...\n",
       "13663    [import sys\\r\\n\\r\\n# To log your outputs in a ...\n",
       "13664    [In [193]: idxs = torch.nonzero(a == 1)     \\r...\n",
       "13665    [b, batch_size x sequence_length x features, i...\n",
       "13666    [import torch\\r\\n\\r\\na = torch.Tensor([[12, 1,...\n",
       "13667           [b[torch.nonzero(a==1,as_tuple=True)]\\r\\n]\n",
       "13668    [self.layer1, nn.Conv2d(1, 16, kernel_size=5, ...\n",
       "13669    [vision, torchvision, conda create -n env_name...\n",
       "13670    [source activate env_name\\r\\nconda install -c ...\n",
       "13671    [anaconda, conda install -c anaconda cudatoolk...\n",
       "13672    [anaconda, pytorch==1.1.0\\r\\ntorchvision==0.3....\n",
       "13673    [ nvidia-smi\\r\\n nvcc -V\\r\\n,  python\\r\\n impo...\n",
       "13674    [pip3 install torch===1.2.0 torchvision===0.4....\n",
       "13675    [Anew = [{'boxes': pred[0]['boxes'][idxOfClass...\n",
       "13677    [nn.NLLLoss(), nn.CrossEntropyLoss, nn.NLLLoss...\n",
       "13678    [rebuilded_y = batched_data.transpose(0,1).vie...\n",
       "13679    [seq_len, batch, input_size, input_size, 10, 1...\n",
       "13680                                                  NaN\n",
       "13681    [mask.unique(), torch.where(mask==cls_val, tor...\n",
       "13682    [torch.var(img, dim=[0,2,3]), dim=1, torch.var...\n",
       "13683    [CUDA_LAUNCH_BLOCKING=1 python script_name arg...\n",
       "13684    [plt.figure(figsize=[width, height]), plt.imsh...\n",
       "13685    [plt.figure(figsize=[20, 20]), makegrid, plt.f...\n",
       "13686    [class myDataset(Dataset):\\r\\n    '''\\r\\n    a...\n",
       "13687    [pytorch, torchvision, ImageFolder, import tor...\n",
       "13688    [os, for d in [Good, Bad]:\\r\\n    n['all'] = t...\n",
       "13689    [from torch.utils.data.sampler import SubsetRa...\n",
       "13690    [shift, dim, def tensor_shift(t, dim, shift):\\...\n",
       "13691    [batch_size, seq_len, w2v_dim = 32, 100, 200\\r...\n",
       "13692    [ModuleList, import torch\\r\\nimport torch.nn a...\n",
       "13693    [if torch.cuda.is_available():\\r\\n   model.cud...\n",
       "13694    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "13695    [d_model, n_head, num_encoder_layers, d_model=...\n",
       "13696                   [[CLS], [SEP], spacy-transformers]\n",
       "13697    [conda install PyTorch -c PyTorch, python -m p...\n",
       "13698                                                  NaN\n",
       "13699    [final_train_loader, data, target, data, dtype...\n",
       "13700    [ConvTranspose2d, 1, width x height, import to...\n",
       "13701    [self.encoder = nn.Sequential(\\r\\n    nn.Conv2...\n",
       "13703                              [[0 1 0 0 0 1 0 0 1 0]]\n",
       "13704    [optimizer_state, state = torch.load(f, map_lo...\n",
       "13706    [torch.autograd.grad, c, d, grad_outputs, impo...\n",
       "13707    [a = torch.rand(2, requires_grad=True)\\r\\nb = ...\n",
       "13708    [loss = error(output, label)\\r\\n,     for i, (...\n",
       "13709    [torch.gather, In [1]: import torch\\r\\n\\r\\nIn ...\n",
       "13710    [nn.ConvTranspose2d, self.encoder = nn.Sequent...\n",
       "13711    [CrossEntropyLoss, Linear, ReLU, [0, inf), arg...\n",
       "13713                                                  NaN\n",
       "13714    [batch_sampler, DataLoader, class VaryingSizeB...\n",
       "13715    [optimizer = torch.optim.SGD(net.parameters(),...\n",
       "13716                 [optimizer, model, model, optimizer]\n",
       "13717    [pytorch, stack, torch.cat,  torch.cat((t_a, t...\n",
       "13718                                                  NaN\n",
       "13719    [import numpy as np\\r\\n\\r\\nA = np.array([[0.  ...\n",
       "13720    [from sklearn.base import BaseEstimator, Trans...\n",
       "13721    [import tensorly as tl\\r\\ntl.set_backend('pyto...\n",
       "13722               [y_val = y_val.cpu().data.numpy()\\r\\n]\n",
       "13723    [.squeeze(), a = np.array([[[[1.0, 1.1]]], [[[...\n",
       "13724    [a = np.array([[[[1.0, 1.1]]],[[[2.1,2.0]]]])\\...\n",
       "13725                                                  NaN\n",
       "13726                                                  NaN\n",
       "13727    [images[predicted==labels], correct = 0\\r\\ntot...\n",
       "13728                   [z[[0, 1, 1], [0, 1, 2]] += 3\\r\\n]\n",
       "13729    [z_new = z.clone() # copy the tensor\\r\\nz_new[...\n",
       "13730    [weight_ll = model.net[0].weight.clone().detac...\n",
       "13731    [conda create -n env_pytorch -c intel python=3...\n",
       "13732               [pip install pytorch-transformers\\r\\n]\n",
       "13733                 [python -m pip install transformers]\n",
       "13734    [import torch\\r\\n\\r\\nt = torch.arange(8).resha...\n",
       "13735    [torch.cat, # input tensor\\r\\nIn [98]: at = to...\n",
       "13736    [index_add_, import torch\\r\\n\\r\\nx = torch.ten...\n",
       "13738    [pip uninstall torch\\r\\npip install torch\\r\\n,...\n",
       "13739    [prob = torch.tensor([0.3,0.4,0.6,0.7])\\r\\n\\r\\...\n",
       "13740    [In [34]: output = torch.tensor([0.4481, 0.401...\n",
       "13742    [Pool, maxtasksperchild=1, pool.close(), pool ...\n",
       "13743                                      [build/, dist/]\n",
       "13744                                                  NaN\n",
       "13745    [(100,), (100, H, W, C), (100,20,20,3), (300,4...\n",
       "13746    [softmax, softmax, 0 ==&gt; [1,0,0]\\r\\n1 ==&gt...\n",
       "13747                                                  NaN\n",
       "13748    [data, target, def my_collate(batch):\\r\\n    d...\n",
       "13749    [conda install PyTorch -c PyTorch, pip3 instal...\n",
       "13750    [C:\\Users\\User&gt;conda install PyTorch -c PyT...\n",
       "13751                                             [lambda]\n",
       "13752    [conda install numpy ninja pyyaml mkl mkl-incl...\n",
       "13753    [DataLoader, Dataset, TensorDataset, import to...\n",
       "13755                                                  NaN\n",
       "13756    [X = torch.tensor([[1,2,3],[5,6,7]])          ...\n",
       "13757                           [+, a,b, c, a/10, b/10, c]\n",
       "13758    [#Step through all models in a chain to create...\n",
       "13760    [import torch\\r\\n\\r\\ninput=torch.arange(100)\\r...\n",
       "13761    [dset_train, self.transform(self.input_data[in...\n",
       "13762    [from pynvml.smi import nvidia_smi\\r\\nnvsmi = ...\n",
       "13763    [model.eval(), torch.no_grad(), model.eval(), ...\n",
       "13764    [import torch\\r\\nimport pandas as  pd\\r\\n\\r\\nx...\n",
       "13765    [astype, px = pd.DataFrame(x).astype(\"float\")\\...\n",
       "13767                                                  NaN\n",
       "13768    [import torch\\r\\n\\r\\nx = torch.tensor(3)\\r\\n\\r...\n",
       "13769    [from torchtext import vocab\\r\\ntry:\\r\\n    vo...\n",
       "13770    [pip install torchtext==0.3.1\\r\\n, pip install...\n",
       "13771     [errD = errD_real + errD_fake, optimizer.step()]\n",
       "13772                             [nn.utils.spectral_norm]\n",
       "13773    [# tensor is of shape [seq_len, batch_size, 1]...\n",
       "13774    [WA = WB, WA = WB.transpose, from time import ...\n",
       "13775    [self.decoder[0].weight = nn.Parameter(self.en...\n",
       "13776                                                  NaN\n",
       "13777                       [__getitem__, mode='L', uint8]\n",
       "13778    [import torch\\r\\nfrom torchvision import datas...\n",
       "13781                                                  NaN\n",
       "13782    [class YourSampler(torch.utils.data.sampler.Sa...\n",
       "13783    [indices = dataset.targets == 5 # if you want ...\n",
       "13784    [torch.utils.data.Subset, # For indices 5, 6 a...\n",
       "13785    [StopIteration, mask = [1 if mnist[i][1] == 5 ...\n",
       "13786    [  from parser import parameter_parser\\r\\n\\r\\n...\n",
       "13787                                              [uwsgi]\n",
       "13788    [--requirements, setup.py, REQUIRED_PACKAGES =...\n",
       "13789    [from google.cloud import storage\\r\\n\\r\\nclien...\n",
       "13790    [os.environ['GOOGLE_APPLICATION_CREDENTIALS'] ...\n",
       "13791                   [pytorch-transformers, 'gs', http]\n",
       "13792    [tensor.repeat, tensor.unsqueeze, tensor.resha...\n",
       "13794    [einops.repeat(example_tensor, 'b h w -&gt; (r...\n",
       "13796    [tensor.expand, tensor.repeat, M = N = K = 3\\r...\n",
       "13797    [from torch.utils.data import Dataset, DataLoa...\n",
       "13798    [class TimeseriesDataset(torch.utils.data.Data...\n",
       "13799                                                  NaN\n",
       "13800    [cycle(), zip(),   try:\\r\\n     data, target =...\n",
       "13801    [F.conv2d(...), forward(), nn.Conv2d, nn.ReLU,...\n",
       "13802    [torch.from_numpy, In[2]: import numpy as np\\r...\n",
       "13803    [cupy.unpackbits, import cupy\\r\\nimport torch\\...\n",
       "13804    [net, net.train(), net, net(inputs), optimizer...\n",
       "13805    [is this model equivalent to using sequential(...\n",
       "13806                                                  NaN\n",
       "13812    [moules = [list], def __init__(self, embedding...\n",
       "13813    [CUDNN_INCLUDE_DIR, /usr/lib/cuda/include, cud...\n",
       "13814    [sudo cp cuda/include/cudnn*.h /usr/local/cuda...\n",
       "13815    [prob[j], 1, 1e-6, prob /= prob.sum(axis=1) # ...\n",
       "13819    [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "13820    [normalize, (C, H, W), mean, std, tensor.sub_(...\n",
       "13821    [ torch.gt(torch.tensor([[1, 2], [3, 4]]), tor...\n",
       "13822    [all(dim), dim, all(), min_wh, pred, (number_o...\n",
       "13823    [forward, criterion(input, target), criterion....\n",
       "13824    [loss = nn.CrossEntropyLoss()(result, batch[1]...\n",
       "13825                                                  NaN\n",
       "13826    [Linear(in_features=784, out_features=256, bia...\n",
       "13827    [from torchvision.models import resnet18\\r\\nmo...\n",
       "13828    [Package wheel conflicts for:\\r\\npython=2.7 -&...\n",
       "13829    [!pip install http://download.pytorch.org/whl/...\n",
       "13830    [python    \\r\\nimport torch\\r\\nprint(torch._ _...\n",
       "13831    [import torch\\r\\n\\r\\nB,L,D = 2,4,2\\r\\n\\r\\ndef ...\n",
       "13832    [idxs = np.array(idxs)\\r\\n, idxs = idxs.cpu()....\n",
       "13833    [x.to(\"cpu\").numpy(), idxs = idxs.to(\"cpu\").nu...\n",
       "13834                                                  NaN\n",
       "13836    [fc1 = Linear(4*4*50, 500), max_pool2d(x, 2, 2...\n",
       "13837    [def my_collate(batch):\\r\\n    len_batch = len...\n",
       "13838    [def my_collate(batch):\\r\\n    len_batch = len...\n",
       "13839    [def __iter__(self):\\r\\n    return self\\r\\ndef...\n",
       "13840    [import random\\r\\nimport torch\\r\\n\\r\\n\\r\\ndef ...\n",
       "13841    [class DataSet():\\r\\n    def __getitem__(self,...\n",
       "13842    [def my_collate(batch):\\r\\n    len_batch = len...\n",
       "13843                              [libavutil-dev, -devel]\n",
       "13844    [conda create -n pytorch_env python=3.7\\r\\nsou...\n",
       "13845    [ nvcc --version\\r\\nnvcc: NVIDIA (R) Cuda comp...\n",
       "13846    [conda install pytorch torchvision cudatoolkit...\n",
       "13847    [conda install pytorch torchvision cudatoolkit...\n",
       "13848    [device = \"cuda\" if torch.cuda.is_available() ...\n",
       "13849    [conda activate &lt;name&gt;\\r\\n, nvcc --versi...\n",
       "13850    [conda remove pytorch torchvision torchaudio c...\n",
       "13851     [Mask.forward, x, indata, mask.weight == indata]\n",
       "13852                                                  NaN\n",
       "13853    [classifier, densenet121, model, model.densene...\n",
       "13854    [import torchvision.models as models\\r\\nimport...\n",
       "13855    [    from ignite.engine import Engine\\r\\n\\r\\n ...\n",
       "13856    [    for batch in loader():\\r\\n        def clo...\n",
       "13857    [def load_img(p):\\r\\n    img = Image.open(p).c...\n",
       "13859                                                  NaN\n",
       "13861    [transpose, np.swapaxes, reshape, In [12]: a\\r...\n",
       "13862                                                  NaN\n",
       "13864                                                  NaN\n",
       "13865    [from torchnlp.encoders.text import StaticToke...\n",
       "13867    [get_features_hook, torch.nn.Module, @staticme...\n",
       "13869                                                  NaN\n",
       "13870                                                  NaN\n",
       "13871    [torch, X, A, X, X, A[0,:,:], A[1,:,:], # Star...\n",
       "13872    [X, A = torch.zeros((3, 3, 3), dtype = torch.f...\n",
       "13873                                                  NaN\n",
       "13874                                                  NaN\n",
       "13876    [def __init__(self, ...):\\r\\n    ... # define ...\n",
       "13878    [sum(p.numel() for p in state_dict.values())\\r...\n",
       "13879                              [torch.gather, permute]\n",
       "13880    [image_d = torch.FloatTensor(np.asarray(A.resh...\n",
       "13881    ['np.transpose, tensor.permute, image_d  = tor...\n",
       "13882               [model.parameters(), optimizer.step()]\n",
       "13883                          [nn.GRU, PackedSequence, s]\n",
       "13884    [jupyter, pytorch, pytorch_p37, python 3.7, us...\n",
       "13885                                         [conda list]\n",
       "13886    [(pytorch)C:\\Users\\user&gt; conda install jupy...\n",
       "13887    [activate pytorch, python -m ipykernel install...\n",
       "13888    [conda install pytorch torchvision -c pytorch,...\n",
       "13889    [conda install nb_conda, conda install ipykern...\n",
       "13891    [from collections import defaultdict\\r\\n\\r\\nim...\n",
       "13892                             [DataLoader, collate_fn]\n",
       "13893       [torch.stack([x,x,x,x]).shape # (4, 2, 3)\\r\\n]\n",
       "13895    [x.item(), x = torch.tensor([3])\\r\\nx.item()\\r...\n",
       "13898    [def forward(self, tensorInput, tensorFlow):\\r...\n",
       "13899    [loss = criterion(predicted, target.type(torch...\n",
       "13900    [loss = criterion(predicted, target.type(torch...\n",
       "13901    [.size(), .size(), target = torch.from_numpy(t...\n",
       "13902    [compare = (X.method() == Y.method())\\r\\n, com...\n",
       "13903    [target, numpy, File \"train.py\", line 101, in ...\n",
       "13905                                                  NaN\n",
       "13906    [from PIL import Image\\r\\nimport cv2\\r\\nimport...\n",
       "13907    [Traceback (most recent call last):\\r\\n    A[:...\n",
       "13908    [torchvision.transforms.functional, torchvisio...\n",
       "13909    [image_name = data_dir + '/test' + '/1/' + 'im...\n",
       "13910    [X, Z, X, W_zca, class MyModule(torch.nn.Modul...\n",
       "13911                                                  NaN\n",
       "13912    [len(train_loss) == 1, train_loss = [1.6059992...\n",
       "13913    [1.2.0, torch.nn.Module, register_forward_pre_...\n",
       "13914    [def neo_genesis(self, input):\\r\\n    if self....\n",
       "13916                                                  NaN\n",
       "13917    [view, x = torch.rand(1,10) # x.shape = [1,10]...\n",
       "13918    [tf.one_hot(\\r\\n    indices,#your image with l...\n",
       "13919            [predict(w, b, X[:1])\\r\\n, predict, X, X]\n",
       "13920    [... * bs, np.expand_dims, predict(w, b, np.ex...\n",
       "13921    [__iter__, IterableDataset, yield, DataLoader,...\n",
       "13922                                                  NaN\n",
       "13923                          [libtorch, USE_OPENMP, OFF]\n",
       "13924    [RPROVIDES_${PN}, RPROVIDES_${PN} = \"libgomp-7...\n",
       "13925                                             [--help]\n",
       "13928    [requires_grad, requires_grad=True, requires_g...\n",
       "13929                                                  NaN\n",
       "13930    [result, (2, 5), a, b, 2x3, result, stride=2, ...\n",
       "13931    [RuntimeError: DataLoader worker (pid(s) 3978)...\n",
       "13932    [nn.Linear, class Linear(Module):\\r\\n\\r\\n    d...\n",
       "13933                                               [bs=2]\n",
       "13934                                                  NaN\n",
       "13936    [ImageFolder, .pth, class MyDataset(torchvisio...\n",
       "13937                                [nvidia-smi --loop=1]\n",
       "13938    [dataset, __len__, __getitem__, dataloader, da...\n",
       "13939    [seq_len, batch, num_directions * hidden_size,...\n",
       "13940    [lr = 1e-3\\r\\nfor i in range(100):\\r\\n  # 100 ...\n",
       "13941    [mask = check(rate)\\r\\nrate[mask] = reset(rate...\n",
       "13942    [torch.nn.Module, super().__init__(), __init__...\n",
       "13943                     [session.graph, SummaryWriter()]\n",
       "13944    [torch.nn.functional.one_hot,   import torch\\r...\n",
       "13945    [torch.cuda.LongTensor [128, 1], LongTensors, ...\n",
       "13946    [h = f(x)\\r\\nepsilon = torch.random()\\r\\nh+=e ...\n",
       "13947    [f, data_dir = f'{content}/competitions/dogs-v...\n",
       "13948    [np.pad, import numpy as np\\r\\na = np.random.r...\n",
       "13949    [torch.multinomial, x = torch.ones(128, 1)\\r\\n...\n",
       "13951    [x, y, with torch.no_grad():\\r\\n  x_np = x.cpu...\n",
       "13952                                                  NaN\n",
       "13953                                                  NaN\n",
       "13955    [self.model, optimizer = optim.Adam(self.model...\n",
       "13956                                                  NaN\n",
       "13957    [criterion, torch.nn.CrossEntropyLoss(), Cross...\n",
       "13958    [ # move data to GPU, if available\\r\\n    if t...\n",
       "13959                                                  NaN\n",
       "13960                                                  NaN\n",
       "13961    [requires_grad, True, Variable(tensor), Variab...\n",
       "13964    [torch.nonzero, np.where,  X = torch.tensor([0...\n",
       "13965                                [X = X[X &gt; 0]\\r\\n]\n",
       "13967                                                  NaN\n",
       "13968                                                  NaN\n",
       "13969    [myField = Field(tokenize= x_tokenize, use_voc...\n",
       "13970    [pip2 install nibabel, python2.7 -m pip instal...\n",
       "13973    [a = torch.tensor([0, 1, 2, 3, 4])\\r\\nb = torc...\n",
       "13974    [u, u /= u.norm()\\r\\n, u = u / u.norm()\\r\\n, u...\n",
       "13975    [pretrained_bert, pretrained_bert/model.ckpt*,...\n",
       "13976                                                  NaN\n",
       "13977                                     [get_transforms]\n",
       "13979    [x, import torch\\r\\nx = torch.randn(1, 1, 0)\\r...\n",
       "13980    [plt.plot, numpy, torch.tensor, .numpy(), nump...\n",
       "13981    [import matplotlib.pyplot as plt   \\r\\ntorch.T...\n",
       "13982                                                  NaN\n",
       "13983    [noise, self.embedding, noise, noise = noise.t...\n",
       "13984    [class WrapperDataset:\\r\\n    def __init__(sel...\n",
       "13986                                                  NaN\n",
       "13987    [keep_vars, state_dict, _save_to_state_dict, f...\n",
       "13988    [(3, 512, 384), ------------------------------...\n",
       "13989    [input[channel] = (input[channel] - mean[chann...\n",
       "13990                                                  NaN\n",
       "13991       [1 - 64 - 128 - 256 - 512\\r\\n, 1024, 256, 128]\n",
       "13992                                                  NaN\n",
       "13993    [__constants__, git blame, torch/nn/modules/li...\n",
       "13995    [torch.from_numpy(feature.copy()), torch.tenso...\n",
       "13996        [numpy.ascontiguousarray, torch.from_numpy()]\n",
       "13997    [torch.sum, numpy.sum, x = x + ..., x += ..., ...\n",
       "13998    [import torch\\r\\nfrom torch.nn.parameter impor...\n",
       "13999    [torch.nn.Softmax(), torch.nn.NLLLoss, torch.n...\n",
       "14000                                                  NaN\n",
       "14001    [import torch\\r\\n\\r\\n\\r\\n# partitions should b...\n",
       "14002    [data.Dataset, data.DataLoader, __init__, __ge...\n",
       "14003    [25*25*16, conv4, 16, 100/4 = 25, \\r\\nclass VA...\n",
       "14004    [global_loss_list.append(global_loss.detach_()...\n",
       "14006               [roc_curve, sklearn.metrics.roc_curve]\n",
       "14007    [python, C:\\Users\\marci&gt;python\\r\\nPython 3....\n",
       "14008    [pip install torch==1.5.0+cpu -f https://downl...\n",
       "14009    [pip3 install https://download.pytorch.org/whl...\n",
       "14010    [pip install torch==1.2.0+cpu torchvision==0.4...\n",
       "14011    [conda create -n you_env_name python=?.?.?\\r\\n...\n",
       "14012               [conda install pytorch -c pytorch\\r\\n]\n",
       "14013    [torch.cuda.empty_cache(), del, torch.cuda.emp...\n",
       "14014    [memory_allocated(), max_memory_allocated(), m...\n",
       "14015    [    \\r\\nimport gc\\r\\nimport torch\\r\\n\\r\\ndef ...\n",
       "14016                                                  NaN\n",
       "14017    [model.state_dict(), old_state_dict = {}\\r\\nfo...\n",
       "14018    [myNN.forward(), x, self.lin1, X, x, trainload...\n",
       "14019                           [BatchNorm, model1.eval()]\n",
       "14020    [N   For mini batch (or how many sequences do ...\n",
       "14021                                    [mpi4py, pytorch]\n",
       "14023    [spacy-pytorch-transformers, **kwargs, nr_clas...\n",
       "14024    [transforms.Resize((50, 50))\\r\\n, imshow, plt....\n",
       "14026                                                  NaN\n",
       "14027                                                  NaN\n",
       "14028    [backward[:, 0] = pi * obs_prob * backward[:, ...\n",
       "14029                                                  NaN\n",
       "14030    [bn_momentum, bn_momentum, model.train(), mode...\n",
       "14031                                [beta=0.01, beta=0.1]\n",
       "14032    [nn.BatchNorm2d(out_channels, track_running_st...\n",
       "14033                                           [MaskRCNN]\n",
       "14034    [weight_decay, l1_criterion = nn.L1Loss(size_a...\n",
       "14035    [criterion = torch.nn.MSELoss()\\r\\nlmbd = 1e-8...\n",
       "14036    [tensorflow-gpu, pytorch, pytorch, tensorflow-...\n",
       "14037    [decoder, BATCH_SIZE x 355008, 3 x 344 x 344, ...\n",
       "14038                                                  NaN\n",
       "14040    [dummy_input = torch.Tensor(torch.rand(2, 10, ...\n",
       "14041    [Validation, Test, test(), validation(), valid...\n",
       "14042    [def pairwise_dist(x, y,p=2, eps=1e-6):\\r\\n   ...\n",
       "14043                                                  NaN\n",
       "14044                                                  NaN\n",
       "14045    [tmp = torch.tensor([[1,2,3,2,4],[0,5,6,7,2],[...\n",
       "14046    [LogSoftMax, torch.argmax, batch_size = 5\\r\\nn...\n",
       "14047    [self.parameters, nn.ParameterList, self.param...\n",
       "14048    [model = models.__dict__[\"resnet50\"]()\\r\\nchec...\n",
       "14049    [F.pad, b= nn.ConvTranspose2d(80, 40, kernel_s...\n",
       "14051    [import torch \\r\\nlogit = torch.rand(100,10)\\r...\n",
       "14052    [from keras.layers import *\\r\\n\\r\\ndef single_...\n",
       "14053    [vars(vgg16)\\r\\n, {'_backend': &lt;torch.nn.ba...\n",
       "14054    [1.1.0a0+863818e, torch.save(model,'model.pth'...\n",
       "14055    [SWA, opt.bn_update(train_loader, model), trai...\n",
       "14056    [# using Mnist Data\\r\\n\\r\\nX_train  = X_train....\n",
       "14057    [eval, model.eval()\\r\\n, prediction, eval, mod...\n",
       "14059    [pip install horovod, horovodrun -np 4 python ...\n",
       "14060    [nn.BCELoss, nn.BCEWithLogitsLoss, nn.BCELoss,...\n",
       "14061    [nn.ModuleList(), x_trains = nn.ModuleList(x_t...\n",
       "14062    [| 1 2 3 |     | 1 | \\r\\n| 4 5   |  *  | 2 |  ...\n",
       "14063    [forward, oss = BSG_model.forward(main_word.cu...\n",
       "14064                                                  NaN\n",
       "14066    [for i in range(len(dataset)): # or i, image i...\n",
       "14068    [from torch.autograd import Variable\\r\\nimport...\n",
       "14069    [torch.bincount, v = torch.tensor([0.0811, 0.9...\n",
       "14070    [pip3 install https://download.pytorch.org/whl...\n",
       "14071              [pip install torchvision --no-deps\\r\\n]\n",
       "14072    [pip3 uninstall torch\\r\\npip3 uninstall torchv...\n",
       "14073    [torchvision, torch, pip install torch torchvi...\n",
       "14074    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14075    [pytorch, decay-rate, batch-norm, 0.9, keras, ...\n",
       "14076    [torch.autograd.grad, torch.autograd.functiona...\n",
       "14077                                             [argmax]\n",
       "14078                                             [./data]\n",
       "14079    [filter_fn, import math\\r\\n\\r\\ndef filter_fn(s...\n",
       "14080                                                  NaN\n",
       "14081    [stride, stride=2, torch.MaxUnpool2d, MaxPool2...\n",
       "14083            [self.W_di = nn.Linear(mL_n * 2, 68)\\r\\n]\n",
       "14084    [Decoder, self.list, nn.ModuleList, class Deco...\n",
       "14085                    [backwards(), d loss/d parameter]\n",
       "14086    [Y, X, Y.backward(), X.shape, torch.backward()...\n",
       "14087                                                  NaN\n",
       "14088    [volatility, Dataloader, pin_memory=False, # 1...\n",
       "14089                                                  NaN\n",
       "14090    [b = torch.IntTensor(list(zip(range(0, list(a....\n",
       "14091    [a = torch.tensor([1,2,0,1,2])\\r\\nprint(a)\\r\\n...\n",
       "14092                                                  NaN\n",
       "14093    [dynamic_axes, import torch\\r\\nimport onnx\\r\\n...\n",
       "14094                                                  NaN\n",
       "14095    [VGG, torchvision.models, make_layers, in_chan...\n",
       "14096    [class Net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "14097    [__call__, __call__(self, ...), class Foo:\\r\\n...\n",
       "14098    [__call__, self.model(...)\\r\\n, self.model.__c...\n",
       "14099    [import torch\\r\\nimport torch.nn\\r\\nclass Padd...\n",
       "14100    [def __getitem__(self, idx: int) -&gt; tuple:\\...\n",
       "14101    [dataclasses, 3.7, __init__, attrs, torch.nn.M...\n",
       "14102                                              [attrs]\n",
       "14108    [PosixPath, WindowsPath, import pathlib\\r\\ntem...\n",
       "14109    [from pathlib import Path\\r\\n\\r\\nfolder_path =...\n",
       "14110    [pathlib, + '/' +, str(path) + '/' + str(fname...\n",
       "14111    [PosixPath, WindowsPath, pickle, PosixPath, Po...\n",
       "14112    [PosixPath, WindowsPath, import pathlib\\r\\n\\r\\...\n",
       "14113    [pathlib.PosixPath, WindowsPath, try / finally...\n",
       "14114    [ __model = pickle.load(open(os.path.join('./a...\n",
       "14115                                       [y, BCELoss()]\n",
       "14116    [BCELoss(input, target), target, target.requir...\n",
       "14117    [cd, %%writefile setup.sh\\r\\n\\r\\ngit clone htt...\n",
       "14118    [%%writefile setup.sh\\r\\n\\r\\nexport CUDA_HOME=...\n",
       "14119    [setup.sh, %%writefile setup.sh\\r\\n\\r\\ngit clo...\n",
       "14120    [cd, !git clone https://github.com/NVIDIA/apex...\n",
       "14121    [try:\\r\\n  import apex\\r\\nexcept Exception:\\r\\...\n",
       "14122                                 [!cd apex, %cd apex]\n",
       "14123    [!pip install git+https://github.com/NVIDIA/ap...\n",
       "14124                                           [.float()]\n",
       "14125                                              [m, op]\n",
       "14126    [batch_size, model = MyModel(...)  # instantia...\n",
       "14127    [cuda_device, int, list, int, cuda_device, Uni...\n",
       "14128    [torch.no_grad(), def weight_init(self,x,label...\n",
       "14129                                       [x = x * mask]\n",
       "14130                          [torch.squeeze(tensor)\\r\\n]\n",
       "14131         [pip install pytorch_pretrained_bert==0.4.0]\n",
       "14132    [from pytorch_pretrained_bert.optimization imp...\n",
       "14133    [import torch\\r\\n\\r\\ndata = (data - data.min()...\n",
       "14134    [model = Model(), Model(), __init__(self, inpu...\n",
       "14135    [nn.LSTM, seq_len, out = self.fc1(out[:, -1, :...\n",
       "14136    [backward(), backward(), backward(), a = torch...\n",
       "14137                                                  NaN\n",
       "14138    [loaded_model, state_dict, for param in loaded...\n",
       "14142        [output = model(data[None, ...])  \\r\\n, data]\n",
       "14143    [Conv2d, (n_samples, channels, height, width) ...\n",
       "14144    [output = model(data[0:1]), output = model(dat...\n",
       "14145    [(4,), (1, 4), 0, (4, 1), 1, 1, 0, 1, np.squee...\n",
       "14146                          [unsqueeze, dim, unsqueeze]\n",
       "14147                                    [torch.unsqueeze]\n",
       "14148    [torch.squeeze(input, dim=None, *, out=None), ...\n",
       "14149                       [CRNN, register_buffer, .to()]\n",
       "14151    [flatten, view, view, flatten(), view(-1), fla...\n",
       "14152    [.view(), .flatten(), .flatten(), .view(), .vi...\n",
       "14153    [conda list, automl, # packages in environment...\n",
       "14154    [aws-instance, pytorch_p36, python 3.6, user@a...\n",
       "14155    [pytorch, torchvision, pytorch_p36, pytorch, $...\n",
       "14156    [target_transform, train_dataset = dsets.MNIST...\n",
       "14157    [test_loader = torch.utils.data.DataLoader(\\r\\...\n",
       "14158    [torch.nn.Sequential, block, import torch\\r\\n\\...\n",
       "14159    [BCEwithlogitsloss, logits, logits, F.sigmoid(...\n",
       "14160    [imgs.to(device)\\r\\nlabels.to(device)\\r\\n, .to...\n",
       "14161    [x, x1, x2, x, def copy(target, source):\\r\\n  ...\n",
       "14162                                                  NaN\n",
       "14163                                                  NaN\n",
       "14166    [torch.all(tensor, dim), l1 = torch.Tensor(([1...\n",
       "14167    [import torch\\r\\nlo = torch.Tensor(([1., 1., 0...\n",
       "14168                [c = a.unsqueeze(1).unsqueeze(1) * b]\n",
       "14169    [a = torch.tensor([1,2])\\r\\nb = torch.tensor([...\n",
       "14170          [b[0] *= a[0]\\r\\nb[1] *= a[1]\\r\\nc = b\\r\\n]\n",
       "14171    [torch.backends.cudnn.deterministic, torch.use...\n",
       "14172    [atomicAdd, torch.backends.cudnn.deterministic...\n",
       "14173                             [mmconvert, .onnx, .pth]\n",
       "14174    [--attn_debug, translate.py ... \\\\r\\n         ...\n",
       "14175    [import torch\\r\\n\\r\\nA = torch.tensor([[1, 2, ...\n",
       "14177    [device1 = torch.device('cuda:0')\\r\\ndevice2 =...\n",
       "14178    [is_leaf,  b = torch.rand(10, requires_grad=Tr...\n",
       "14181                                                  NaN\n",
       "14182    [state_dict(), parameters(), class Network(tor...\n",
       "14183    [torch.nn.Sequential, model = torch.nn.Sequent...\n",
       "14184    [y1.grad, y1.backward, backward, None, import ...\n",
       "14185    [(batch_size, n_channels * 2, width, height), ...\n",
       "14186    [x_data = (x_data - x_data.mean()) / x_data.st...\n",
       "14187                           [if HR &lt; 91: label = 0]\n",
       "14188    [probas = np.exp(logits)/np.sum(np.exp(logits)...\n",
       "14189    [torch.nn.functional.cross_entropy, log_softma...\n",
       "14190    [import torch\\r\\nimport torch.nn.functional as...\n",
       "14191    [pi_, pi_, 1, pi_, output \\r\\ntensor([[0.9879]...\n",
       "14192    [from pydrive.auth import GoogleAuth\\r\\nfrom p...\n",
       "14193    [\\r\\nimport os\\r\\n\\r\\ndelete_filepath = 'drive...\n",
       "14194    [if(len(batch_of_data)==BATCH_SIZE):\\r\\n    ou...\n",
       "14195    [import torch\\r\\n\\r\\n# I choose not to use ran...\n",
       "14196    [l = torch.tensor([0]), l = torch.tensor([0], ...\n",
       "14197    [torch.nn.Linear, torch.nn.functional.linear, ...\n",
       "14198    [torch.nn.functional.unfold, torch.nn.function...\n",
       "14199    [172x220x156, 32x32x32, 32x32x32, result, out_...\n",
       "14200    [unfold, batch_size, n_channels, n_rows, n_col...\n",
       "14201    [pip install torchvision==0.2.0 --no-deps --no...\n",
       "14202    [MNIST, 1, CIFAR10, 3, MNIST, transforms.Norma...\n",
       "14203    [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0...\n",
       "14204    [\\r\\nconda install pytorch torchvision cudatoo...\n",
       "14205           [pyinstaller, .exe, torchscript, libtorch]\n",
       "14206                                                  NaN\n",
       "14207    [nvidia/cuda, FROM nvidia/cuda:10.0-cudnn7-dev...\n",
       "14210                     [Transposedconv2d, UpSampling2D]\n",
       "14211    [  from torch.nn.utils.rnn import pad_sequence...\n",
       "14212    [torch.nn.Linear, input, (N, *, I), (N, *, O),...\n",
       "14213    [conda install pytorch torchvision cudatoolkit...\n",
       "14214    [output = model(input)  # raw logit output in ...\n",
       "14215    [unsqueeze, import torch\\r\\n\\r\\na = torch.rand...\n",
       "14216    [gensim, from gensim.models import KeyedVector...\n",
       "14218    [type(), built-in, 0.4.0, torch.Tensor, type()...\n",
       "14219    [train.zip, train.zip, import zipfile\\r\\nzr1 =...\n",
       "14220                                                  NaN\n",
       "14221    [[-1, 1], tanh, ReLU, class MyRnn(nn.Module):\\...\n",
       "14222                                                  NaN\n",
       "14223                                                  NaN\n",
       "14224                                                  NaN\n",
       "14225                   [optimizer.step(), optimizer.step]\n",
       "14226    [map_location=torch.device('cpu'), pickle, imp...\n",
       "14227    [    torch.load('featurs.pkl',map_location=tor...\n",
       "14228    [transforms.RandomHorizontalFlip(), PIL.Images...\n",
       "14229    [transforms.ToPILImage(), transform = transfor...\n",
       "14231      [optimizer.zero_grad()\\r\\n, nw.zero_grad()\\r\\n]\n",
       "14232    [torch.nn.LSTM, torch.nn.Module, cuda(), init_...\n",
       "14233                        [CrossEntropyLoss, forward()]\n",
       "14234    [torch.gather, out = torch.gather(A, 1, B[...,...\n",
       "14235    [pip install torch==1.0.1 -f https://download....\n",
       "14236                                 [--test-crops 1\\r\\n]\n",
       "14237                          [with torch.no_grad():\\r\\n]\n",
       "14238    [R_transpose, # define rotation angels (radian...\n",
       "14239    [docker run -ti --runtime=nvidia -e NVIDIA_DRI...\n",
       "14240    [--gpus, nvidia-docker2, --gpus, docker run --...\n",
       "14241    [ubuntu, FROM ubuntu\\r\\n, FROM nvidia/cuda:11....\n",
       "14242    [predicted = torch.tensor([[1,2,3,4]]).float()...\n",
       "14243                                                  NaN\n",
       "14244                                                  NaN\n",
       "14245                                                  NaN\n",
       "14246                                                  NaN\n",
       "14247                                                  NaN\n",
       "14248    [network.state_dict(), dictionary, for param i...\n",
       "14249    [network = Network(*args, **kwargs)\\r\\n, netwo...\n",
       "14250    [y.detach(), y, y, def forward(self, x, y=None...\n",
       "14251    [    def forward(self, x, y):\\r\\n    x = self....\n",
       "14252    [netcat, apt-get install netcat, node0, nc -vv...\n",
       "14253    [NUM_TARGETS = 4\\r\\nNUM_FEATURES = 3\\r\\nNUM_TE...\n",
       "14254    [len(dataset), pos_weights_vector, 900/100 = 9...\n",
       "14255    [train_dataset.data.y, num_positives = torch.s...\n",
       "14256    [pos_weight, 270, torch.Tensor, (270,), # 270 ...\n",
       "14257    [def calculate_pos_weights(class_counts,data):...\n",
       "14258                                                  NaN\n",
       "14259    [forward, ReLU, [0, +inf), [-1, 1], +inf, [0, ...\n",
       "14260    [self.layer1.weight = torch.nn.Parameter(torch...\n",
       "14261                                                  NaN\n",
       "14262    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "14263                                                  NaN\n",
       "14264    [uint8, float32, # Replace this\\r\\ninputs = in...\n",
       "14265    [    def weighted_mse_loss(input, target, weig...\n",
       "14266    [import sys\\r\\nfrom onnx import onnx_pb\\r\\nfro...\n",
       "14267    [import torch\\r\\nimport os\\r\\nimport torch.nn ...\n",
       "14268    [torchvision, print, GlobalAveragePooling, tor...\n",
       "14269    [class Linear(Module):\\r\\n    r\"\"\"Applies a li...\n",
       "14270    [class DoubleLinear(torch.nn.Module):\\r\\n    d...\n",
       "14271    [torchvision.models, fc, nn.Identity(), class ...\n",
       "14272    [perform_analysis, pate.perform_analysis, mome...\n",
       "14273                                            [__len__]\n",
       "14274    [In []: t[0, 0].shape\\r\\n, Out[]: torch.Size([...\n",
       "14275    [In [16]: a = torch.arange(3)\\r\\n\\r\\nIn [17]: ...\n",
       "14276                                            [Tabular]\n",
       "14277    [[x for x in data], csv, data.csv, custID name...\n",
       "14278    [import torch\\r\\nx = torch.randn(128, 32, 2, 1...\n",
       "14279    [tau, tau=2, tau=10, tau=100, tau=1000, tau=10...\n",
       "14280    [anchor_sizes = ((32,), (64,), (128,), (256,),...\n",
       "14281    [from pytorch_image_folder_with_file_paths imp...\n",
       "14282    [def gaussian_blur(img):\\r\\n   image = np.arra...\n",
       "14283    [retain_graph=True, cost.backward(), import to...\n",
       "14284    [a = torch.randn(20,3,512,512)\\r\\nprint(a.shap...\n",
       "14285    [a = torch.randn(20, 3, 512, 512)\\r\\nb = a.res...\n",
       "14286    [m, m = torch.rand(3,3)\\r\\nprint(m)\\r\\ns=1\\r\\n...\n",
       "14287                                                  NaN\n",
       "14288    [expand, repeat, repeat_interleave, import tor...\n",
       "14289                            [--no-dependencies, pip3]\n",
       "14290    [pip, torch, virtualenv, which python, which p...\n",
       "14291    [numpy.percentile, import torch as t\\r\\nimport...\n",
       "14293    [import torch\\r\\nfrom torch.utils.dlpack impor...\n",
       "14294    [n_channels = torch.max(in_tensor)+1  # maximu...\n",
       "14295                                                  NaN\n",
       "14296                                                  NaN\n",
       "14298                                                  NaN\n",
       "14299    [action = torch.max(random_values,1)[1][0]\\r\\n...\n",
       "14300    [self.l_linear, torch.nn.Linear(1024, 512), se...\n",
       "14301    [at::Tensor at::Tensor::slice(int64_t dim, int...\n",
       "14302    [Tensor::index, Tensor::index_put_, using name...\n",
       "14303    [class wrapper(torch.nn.Module):\\r\\n    def __...\n",
       "14304               [example = torch.rand(5, 3, 224, 224)]\n",
       "14305    [optimizer = optim.SGD(net.parameters(), lr=0....\n",
       "14306    [import numpy as np\\r\\n\\r\\nx= [[1,2],[3,4],[5,...\n",
       "14308    [PyTorch, torch.mm(a, b), torch.matmul(a, b), ...\n",
       "14309    [torch.equal(tensor1, tensor2), True, False, y...\n",
       "14310                                                  NaN\n",
       "14312    [TP+FN=y, TN+FP=1-y, FN_rate=1-y_pred, FP_rate...\n",
       "14313    [myconv = torch.nn.Conv2d(in_channels=2 out_ch...\n",
       "14314    [conda install pytorch torchvision cudatoolkit...\n",
       "14315              [!pip install tiny-tokenizer flair\\r\\n]\n",
       "14316                                  [pip install flair]\n",
       "14317    [pip install --upgrade pip\\r\\npip install torc...\n",
       "14318    [def sparse_dense_mul(s, d):\\r\\n  i = s._indic...\n",
       "14319    [predict, img = process_image(image)\\r\\n, proc...\n",
       "14321                     [var(x), __call__(), __call__()]\n",
       "14322    [self.conv1 = nn.Conv2d(1, 20, 5)\\r\\n, self.co...\n",
       "14323                                                  NaN\n",
       "14324    [classification_report(y_true, y_pred, target_...\n",
       "14325                                                  NaN\n",
       "14327    [a = random.choice(os.listdir(\"./dogImages/tra...\n",
       "14328    [from PIL import Image\\r\\nimport torch\\r\\n\\r\\n...\n",
       "14329    [[ W[0, feature2field[0], :],\\r\\n  W[0, featur...\n",
       "14330    [# for OS: Windows, package-manager: pip, Lang...\n",
       "14335    [https://developer.nvidia.com/cuda-downloads?t...\n",
       "14343    [import random\\r\\nimport numpy as np\\r\\nimport...\n",
       "14344    [bach_first = True\\r\\n, import random\\r\\n\\r\\ni...\n",
       "14345    [#Early stopping\\r\\nthe_last_loss = -100\\r\\npa...\n",
       "14346                                                  NaN\n",
       "14347    [import torch\\r\\n\\r\\nt = torch.tensor(1)\\r\\npr...\n",
       "14349    [tensor, pytorch, Docstring:\\r\\ntensor(data, d...\n",
       "14350    [nn.Module, model.cuda(), model.parameters(), ...\n",
       "14352    [import os, sys, shutil\\r\\nimport time\\r\\nimpo...\n",
       "14354    [LSTM, (seq_length,batch_dim,input_size), Line...\n",
       "14355    [&lt;SON&gt;, &lt;EON&gt;, &lt;EON&gt;, &lt;SO...\n",
       "14356                                                  NaN\n",
       "14357    [forwards, (loss1 + loss2).backward() \\r\\n, nn...\n",
       "14358                                                  NaN\n",
       "14359    [MTL.scoring_list[0][6].weight.grad, MTL.scori...\n",
       "14360    [num_minibatches = input_size // mb_size\\r\\n, ...\n",
       "14361    [C, shape, A, B, A, C, B, k, B, k, N1*N2*N3/2,...\n",
       "14362                        [SummaryWriter, ScriptModule]\n",
       "14363    [y = Variable(torch.tensor((0, 0, 0, 1, 1,1), ...\n",
       "14364                          [torch.cat((loss1, loss2))]\n",
       "14365    [input_transform = standard_transforms.Compose...\n",
       "14366    [DataLoader, __getitem__, torch.utils.data.Dat...\n",
       "14367    [torch.utils.data.DataLoader(), torch.utils.da...\n",
       "14368    [Bidirectional, concat, import torch\\r\\n\\r\\n\\r...\n",
       "14369                                                  NaN\n",
       "14370           [import torch\\r\\ntorch.manual_seed(0)\\r\\n]\n",
       "14371    [import sys\\r\\nimport random\\r\\nimport datetim...\n",
       "14372    [tensor.detach(), with torch.no_grad(), requir...\n",
       "14373    [detach(), detach(), from torchviz import make...\n",
       "14374    [with torch.no_grad(), requires_grad, False, t...\n",
       "14375                                                  NaN\n",
       "14376    [# Convert pyTorch model to ONNX\\r\\ninput_name...\n",
       "14377    [self.fc3(x), __init__(), forward(), self.fc2 ...\n",
       "14378    [forward, def forward(self, x):\\r\\n    x = sel...\n",
       "14379    [argmax, a = torch.randn(5, 3)\\r\\nprint(a)\\r\\n...\n",
       "14380                                                  NaN\n",
       "14381      [python -m torch.distributed.launch xxx.py\\r\\n]\n",
       "14382    [$ python -m torch.distributed.launch --use_en...\n",
       "14383    [sudo USE_ROCM=1 USE_LMDB=1 USE_OPENCV=1 MAX_J...\n",
       "14384    [CMAKE_CXX_COMPILER, build/, python setup.py i...\n",
       "14385    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "14387    [model = onnx.load(onnx_model)\\r\\ninputs = {}\\...\n",
       "14388                                                  NaN\n",
       "14389                                                  NaN\n",
       "14390    [Total parameters : 13920 float, model size : ...\n",
       "14391    [shape, 4x5000x5000x3, 4, 5000x5000, batch, he...\n",
       "14392    [loss = criterion(outputs,target)\\r\\n, mean-sq...\n",
       "14393    [nn.MSELoss(), nn.CrossEntropyLoss(), input, t...\n",
       "14394    [torch.utils.data.DataLoader, data_train_loade...\n",
       "14395    [optimizer = optim.Adam(model.parameters(), lr...\n",
       "14396    [from torch.utils.data import DataLoader\\r\\ncl...\n",
       "14397    [Dataset, from collections import Counter\\r\\ni...\n",
       "14398                                        [__getitem__]\n",
       "14399    [nn.Module, from torchvision import models\\r\\n...\n",
       "14400                              [image, target, target]\n",
       "14401    [model.eval(), traced_script_module = torch.ji...\n",
       "14403                                                  NaN\n",
       "14405    [Shape:\\r\\n\\r\\n    - Input: :math:`(N, C)` whe...\n",
       "14406    [RuntimeError: element 0 of tensors does not r...\n",
       "14407    [import torch\\r\\nimport numpy as np\\r\\nx = tor...\n",
       "14408                  [c.shape, torch.Size([]), c.item()]\n",
       "14409              [conda install -p path_to_your_dir\\r\\n]\n",
       "14412    [model.train(), dropout, batchnorm, model.trai...\n",
       "14413    [.mean, .std, keepdim, def style_noise(self, y...\n",
       "14414    [m = t.mean(); print(m) # if you don't set the...\n",
       "14416    [import torch.nn as nn\\r\\nmax_pool = nn.MaxPoo...\n",
       "14417    [max_pool = nn.MaxPool2d(3, stride=1)\\r\\na = t...\n",
       "14418    [mean, std, transform = transforms.Compose([\\r...\n",
       "14419    [def load_mnist_labels(fnlabel):\\r\\nf = gzip.o...\n",
       "14420    [model = loadmodel(), loadmodel(), defaults.de...\n",
       "14421    [nn.Module, device = torch.device(\"cuda\")\\r\\nm...\n",
       "14422    [tag_space = self.hidden2tag(outputs)\\r\\ntag_s...\n",
       "14423    [torch.optim.SGD, lr = 1.0, x = torch.tensor([...\n",
       "14424    [transforms.ToTensor(), numpy.ndarray, numpy, ...\n",
       "14425    [self.transform = transforms.Compose([transfor...\n",
       "14426                     [numpy, transforms.ToPILImage()]\n",
       "14427    [tf=transforms.Compose([\\r\\n    transforms.ToP...\n",
       "14428    [RuntimeError: Expected object of scalar type ...\n",
       "14429    [Tensor, X_train = X_train.astype(np.float32)\\...\n",
       "14430                       [torch.float32, torch.float64]\n",
       "14431    [df['target'] = df['target'].astype(np.float32...\n",
       "14432    [torch.set_default_dtype(), network.double(), ...\n",
       "14433    [from sentence_transformers import SentenceTra...\n",
       "14434                                                  NaN\n",
       "14435    [resize_(), import torch\\r\\n\\r\\ntarget_output ...\n",
       "14436    [__init__, forward, import torch\\r\\nfrom torch...\n",
       "14437    [__init__, __init__, nn.Linear(4096, 4096),\\r\\...\n",
       "14438                                                  NaN\n",
       "14439    [Pytorch, Tensorflow, SymPy, import sympy\\r\\nx...\n",
       "14440    [x = torch.tensor([5.], requires_grad=True);\\r...\n",
       "14441    [[, xdim = 240\\r\\nembed_dim = 8\\r\\nvocab_size ...\n",
       "14442    [n_classes = 20\\r\\nmodel = load_trained_model_...\n",
       "14443        [! apt install file\\r\\n! file image.jpeg\\r\\n]\n",
       "14444    [// img.save(save_dir + img_list[i], 'JPEG')\\r...\n",
       "14445    [Data/celeb_data/resized_celeb/label_name: \\r\\...\n",
       "14446    [out, (12, 10), target, (64, 10), forward(), x...\n",
       "14447    [.float(), correct, total, correct.float()/tot...\n",
       "14449    [CsvDataset, nn.CrossEntropyLoss(), torch.nn.M...\n",
       "14450    [import numpy as np\\r\\ndef numpy_xcorr(BATCH=1...\n",
       "14451    [[item.cuda_time for item in prof.function_eve...\n",
       "14452    [Power(), .grad, out, alpha_rooting = Power()\\...\n",
       "14453    [[5000:5020], bert -base-multilingual-cased, t...\n",
       "14454    [import torchvision.models as models\\r\\nalexne...\n",
       "14455    [torch.topk(x,k), k=2\\r\\nx = torch.arange(0,10...\n",
       "14456    [PySyft, import torch\\r\\ntorch.set_default_ten...\n",
       "14457    [Dataset, torchvision.datasets.MNIST(...), Dat...\n",
       "14458     [DataLoader, DataLoader, DataLoader, DataLoader]\n",
       "14459    [.narrow(), auto partial_gates = gates.narrow(...\n",
       "14460    [.slice, Tensor::slice(int64_t dim, int64_t st...\n",
       "14461                                                  NaN\n",
       "14462                                                  NaN\n",
       "14463                                                  NaN\n",
       "14464    [(300, width, height), 300*width*height != 300...\n",
       "14465    [300*30*30, [batch_size=3, channels=300, heigh...\n",
       "14466    [import torch.nn as nn\\r\\nimport torch\\r\\n\\r\\n...\n",
       "14467    [num_layers, output, h_n, h_n, output, output,...\n",
       "14468    [in_channels, out_channels, import torch\\r\\nim...\n",
       "14469    [Log1PlusExp, torch.where,  class Log1PlusExp(...\n",
       "14470    [import torch.nn.functional as F\\r\\nloss_func ...\n",
       "14471    [Fashion-MNIST, 28 x 28, 28 x 28, 5 x 5, defau...\n",
       "14472              [tensor.size(), torch.Size([12, 4, 4])]\n",
       "14473    [strides, # a 2D tensor\\r\\nIn [62]: tensor = t...\n",
       "14474    [layout=torch.strided, layout=torch.sparse_coo...\n",
       "14475    [ x = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8,...\n",
       "14477    [# update conda\\r\\nconda update -n base -c def...\n",
       "14478    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14479    [ZeroMean, -mll, lbfgs, adam, sgd, N(0,1), ten...\n",
       "14480    [MyValues = torch.tensor([0,2,4,6,8])\\r\\n, tor...\n",
       "14483    [torch.float64, torch.float32, b = torch.tenso...\n",
       "14484    [# Mapping of ignore categories and valid ones...\n",
       "14485    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "14486    [pip3 install git+https://github.com/fastai/fa...\n",
       "14487    [0, predicted_classes = torch.argmax(y_pred, d...\n",
       "14490    [mmtoir, class CIFAR(nn.Module):\\r\\ndef __init...\n",
       "14491    [import torch\\r\\nimport torch.nn as nn\\r\\n, to...\n",
       "14492                                                  NaN\n",
       "14493                                                  NaN\n",
       "14494    [p, m, p, m, def block_mul(p, m):\\r\\n   p_x, p...\n",
       "14495    [P = [ 1 1 2 2\\r\\n      1 1 2 2\\r\\n      3 3 4...\n",
       "14496    [torch.cat(), import torch\\r\\n\\r\\ndef multiply...\n",
       "14497    [cat, pad, block_mul, P_1, P_2, P_3, P_4, impo...\n",
       "14498    [import tensorflow as tf\\r\\n\\r\\ntf.enable_eage...\n",
       "14499    [4*4, 1*16, a = torch.tensor([9, 9, 9, 9, 8, 8...\n",
       "14500    [torch.split,  x\\r\\ntensor([[ 1,  2,  3,  4],\\...\n",
       "14501    [optimizator.zero_grad(), optimizator = optim....\n",
       "14502    [pip install torch==\\r\\n\\r\\nCollecting torch==...\n",
       "14503    [conda install pytorch==1.7.1 torchvision cuda...\n",
       "14504    [#tensor_name#.detach(), new_tensor = _tensor_...\n",
       "14505    [#--------------------------------------------...\n",
       "14506    [.cuda, Parameter, self.x           = torch.nn...\n",
       "14507    [def get_weights_copy(model):\\r\\n    weights_p...\n",
       "14508    [torch.utils.data.random_split(), Subset, from...\n",
       "14509    [def get_train_valid_loader(data_dir,\\r\\n     ...\n",
       "14510    [drop_last=True, batch_size, 0 &lt;class 'torc...\n",
       "14511    [Dataset, SafeDataset, bad_dataset = Dataset(....\n",
       "14512    [l = [patches[:,:,int(i/pi),i%pi,:,:] for i in...\n",
       "14514    [loss = criterion(output, target.view(-1))  # ...\n",
       "14515    [BxCxHxW : number of mini-batches, channels, h...\n",
       "14516    [a[(slice(1,None),) * len(a.shape)]\\r\\n, slice...\n",
       "14517                                                  NaN\n",
       "14518    [model.state_dict(), OrderedDict, from collect...\n",
       "14519    [def save_state(state,filename):\\r\\n    torch....\n",
       "14520    [class PAM_Module(Module):\\r\\n\"\"\" Position att...\n",
       "14521                  [    print('x_shape:',x.shape)\\r\\n]\n",
       "14522    [@app.route('/analyze', methods=['POST'])\\r\\na...\n",
       "14523    [Traceback (most recent call last):\\r\\n    Fil...\n",
       "14524    [torch.as_tensor, import torch\\r\\nimport rando...\n",
       "14525    [import torch\\r\\nimport torch.nn.functional as...\n",
       "14526    [dataset_bw, dataset_color, ImageFolder, class...\n",
       "14527    [z = x.repeat_interleave(2,dim=0).repeat_inter...\n",
       "14528    [z = einops.repeat(x, 'i j -&gt; (i 2) (j 2)')...\n",
       "14529    [user8426627, .type(torch.LongTensor), LongTen...\n",
       "14530    [INFO:tensorflow:loss = 294.3736, step = 1\\r\\n...\n",
       "14531    [import torch\\r\\nimport numpy as np\\r\\nn = np....\n",
       "14533                        [setattr, getattr, nn.Module]\n",
       "14534    [torch::constant_pad_nd, torch::Tensor source ...\n",
       "14535                                                  NaN\n",
       "14536    [NeuralNetClassifier, X, y, fit, y, torch.data...\n",
       "14537                                                  NaN\n",
       "14538                                       [VGG16.eval()]\n",
       "14539    [i = order[0] # works for PyTorch 0.4.1.\\r\\n, ...\n",
       "14540    [IndexError                                Tra...\n",
       "14541    [while order.numel() &gt; 0:\\r\\n        if ord...\n",
       "14542    [torch.autograd.functional.jacobian(func, x)\\r...\n",
       "14543    [functorch, functorch, batch_size = 64\\r\\nDin ...\n",
       "14544    [# Solution 2\\r\\ndef Jacobian(f,X):\\r\\n    X_b...\n",
       "14548    [cudatoolkit-dev, conda-forge, HCC, cudatoolki...\n",
       "14549    [/usr/local/cuda-10.2/bin, ./nvcc --version, n...\n",
       "14550    [predictor, boto3, import boto3\\r\\nruntime = b...\n",
       "14554    [None, 0, None, np.nan, np.nan, import torch\\r...\n",
       "14556    [nn.Sequential, 'generalized_rcnn.py', torchvi...\n",
       "14557    [ord, targets[i, :end] = torch.from_numpy(np.a...\n",
       "14558                                                  NaN\n",
       "14559    [import torch\\r\\nfrom torch import nn\\r\\n\\r\\ni...\n",
       "14560                                                  NaN\n",
       "14561                                                  NaN\n",
       "14562    [OrderedDict, from collections import OrderedD...\n",
       "14563    [print(model), Sequential(\\r\\n  (0): Linear(in...\n",
       "14564    [nn.Sequential(), model.layer[0].weight # for ...\n",
       "14565    [`# Build a feed-forward network\\r\\n class FFN...\n",
       "14566    [for layer in model.children():\\r\\n    if isin...\n",
       "14567    [x = torch.ones(n,3) \\r\\nx[:,1].uniform_(-1.,1...\n",
       "14568    [b, U[:, :, i, j], [10, 1], U[:, :, i, j].shap...\n",
       "14569    [reshape, import torch\\r\\n\\r\\nU = torch.zeros(...\n",
       "14570                                   [U[..., [i], [j]]]\n",
       "14571    [\\r\\n/(root)--&gt;|\\r\\n          |\\r\\n        ...\n",
       "14572                                [utils.extmath.pinvh]\n",
       "14573    [torch.multiprocessing.Queue, tensor.share_mem...\n",
       "14574                                                  NaN\n",
       "14575    [1D, 2D, 2D, 1D, import torch\\r\\n\\r\\nvar = tor...\n",
       "14577    [torch.jit.load, extra_files = torch._C.ExtraF...\n",
       "14578    [vocab, _extra_files, torch.jit.load('scriptmo...\n",
       "14579    [def forward(self, input):\\r\\n    input = inpu...\n",
       "14580    [ rnn = nn.LSTM(10, 20, 2)\\r\\n input = torch.r...\n",
       "14582    [result = rnn_utils.pad_sequence([a, b, c])\\r\\...\n",
       "14583    [a = torch.Tensor([[1,2],[3,4]])\\r\\nb = torch....\n",
       "14584    [a @ b, a = np.array([[1,2],[3,4]])\\r\\nb = np....\n",
       "14585                                   [zx = zx.pow(0.5)]\n",
       "14586                    [torch.fft, torch.fft.fft(x)\\r\\n]\n",
       "14587                                                  NaN\n",
       "14588    [class Generator(nn.Module):\\r\\n, Generator, n...\n",
       "14589                  [super(Generator, self).__init__()]\n",
       "14590    [with torch.no_grad(): # assuming it's for ini...\n",
       "14591    [ t = torch.randn(2,3)\\r\\n t\\r\\ntensor([[ 0.12...\n",
       "14592    [optimizer.zero_grad(), loss.backward(), optim...\n",
       "14593    [import torch\\r\\nimport torch.nn.functional as...\n",
       "14597    [x, y, z=f(y), None, import torch\\r\\n\\r\\nx = t...\n",
       "14598    [__init__, params[0] -&gt; self.conf1 -&gt; La...\n",
       "14599    [targets.unsqueeze(1).data.cpu(), torch.int64,...\n",
       "14600    [targets = torch.zeros(log_probs.size()).scatt...\n",
       "14601    [import torch\\r\\narr = torch.from_numpy(np.ran...\n",
       "14602    [features = torch.rand(1, 5) \\r\\nweights = tor...\n",
       "14603    [features, weights, *, view(), *, res_ij  = w_...\n",
       "14604                                         [skip_frame]\n",
       "14606                                                  NaN\n",
       "14607                   [torchtext.data.Field, fix_length]\n",
       "14608    [nn.Linear, self.fcLayers, nn.Paramters, nn.Mo...\n",
       "14609    [class NewLayer(nn.Module): \\r\\n    def __init...\n",
       "14610    [bias, bias, out = sigmoid(x * weights[:x.size...\n",
       "14611        [x = torch.tensor(train).to(torch.int64)\\r\\n]\n",
       "14612    [b_input_ids = torch.tensor(b_input_ids).to(de...\n",
       "14613             [type_as, .type_as(z), .to(self.device)]\n",
       "14614    [BCELoss, RuntimeError, nn.BCELoss, nn.BCEWith...\n",
       "14615       [input[mask]\\r\\n, sigmoid, .gt(0.5), .gt(0.0)]\n",
       "14617    [model.training = False, if model.training == ...\n",
       "14618    [import os\\r\\n\\r\\ndata_dir = '/Users'\\r\\nos.ch...\n",
       "14619                                                  NaN\n",
       "14620                                            [free(3)]\n",
       "14621    [ import torch\\r\\n a=torch.randn(2,1)\\r\\n b=to...\n",
       "14622    [transforms.ToTensor(), torch.FloatTensor, H, ...\n",
       "14623    [torch.from_numpy, ndarray, In[1]: MatA = np.r...\n",
       "14624    [map_location, torch.load, torch.load(model_we...\n",
       "14625    [scores = scores.masked_fill(scores == 0, -np....\n",
       "14626    [ mask = torch.Tensor([1,1,1,1,0,0])\\r\\n\\r\\n m...\n",
       "14627    [import math\\r\\n\\r\\nq = torch.Tensor([np.rando...\n",
       "14628    [ $ cd ~/NVIDIA_CUDA-10.0_Samples\\r\\n $ make\\r...\n",
       "14629    [map, torch.tensor, x_train, y_train, x_valid,...\n",
       "14630    [pip uninstall torchvision\\r\\npip install torc...\n",
       "14631    [def script_method(fn, _rcb=None):\\r\\n    retu...\n",
       "14632                [os.environ[\"PYTORCH_JIT\"] = \"0\"\\r\\n]\n",
       "14633    [self.seq2, prefix1=self.seq1(input1) \\r\\nsuff...\n",
       "14634                                                  NaN\n",
       "14635    [def show(img):\\r\\n   npimg = img.numpy()\\r\\n ...\n",
       "14636    [labels1,labels2 = labels[0]\\r\\n, labels1,labe...\n",
       "14637    [import torch\\r\\nimport torch.nn as nn \\r\\n\\r\\...\n",
       "14639                              [userid, nodeid, dtype]\n",
       "14640                       [requires_grad, requires_grad]\n",
       "14643    [torch.nn.utils.rnn.pad_sequence(), in_tensor ...\n",
       "14644    [def sequence_to_padding(x, length): \\r\\n    #...\n",
       "14645    [TEXT.build_vocab(train, ...), LABEL.build_voc...\n",
       "14646    [Inception3, VGG, nn.Sequantial, model = nn.Se...\n",
       "14647                                                  NaN\n",
       "14648                                   [CrossEntropyLoss]\n",
       "14649    [requires_grad, True, import torch\\r\\nts = tor...\n",
       "14650    [from collections import OrderedDict\\r\\ndef re...\n",
       "14651    [out_cls, label_org, parser.add_argument('--cu...\n",
       "14652    [with train_set, test_set, torch.utils.data.Da...\n",
       "14653    [input.requires_grad = True, loss.backward(), ...\n",
       "14654    [import cv2\\r\\nimport numpy as np\\r\\nimport to...\n",
       "14655    [pip install nnMorpho, import numpy as np\\r\\ni...\n",
       "14657    [transforms.Compose, transforms.Compose([\\r\\n ...\n",
       "14658    [base_lstm_model.save_weights('1.h5')\\r\\ncudnn...\n",
       "14659                                                  NaN\n",
       "14660    [from google.colab import files\\r\\nfiles.uploa...\n",
       "14661    [import torch\\r\\n\\r\\nclass cat_model(torch.nn....\n",
       "14663                                            [Y_train]\n",
       "14664    [astype, Y_train_class.astype(np.float32)\\r\\n,...\n",
       "14665    [DataLoader, batch_size, Dataloader, batch_siz...\n",
       "14666    [    # copied from the run_classifier.py code ...\n",
       "14667    [torch, import torch\\r\\ntorch.manual_seed(0)\\r...\n",
       "14670    [broadcasting, torch.unique(), torch.nonzero()...\n",
       "14672    [Variable, torch.from_numpy( np.asarray(list(r...\n",
       "14673                                                  NaN\n",
       "14674    [import tensorflow as tf\\r\\ndef kl_loss_comput...\n",
       "14675    [   import torch\\r\\n   # optimization by passi...\n",
       "14676    [__str__(), __repr__(), torch.Tensor, _tensor_...\n",
       "14677                                                  NaN\n",
       "14678    [# replace values greater than a certain numbe...\n",
       "14679    [pip install torch, pip, pip install https://d...\n",
       "14680    [[[0.0000, 0.0000, 0.0000, 1.0000],\\r\\n [1.000...\n",
       "14681    [labels = labels.view(labels.size(0), 1).expan...\n",
       "14682    [def groupby_mean(value:torch.Tensor, labels:t...\n",
       "14683    [labels, samples, M = torch.zeros(labels.shape...\n",
       "14684                                                  NaN\n",
       "14685    [import boto3\\r\\n\\r\\n# Convert your existing m...\n",
       "14686    [import io\\r\\nimport boto3\\r\\nimport torch\\r\\n...\n",
       "14687                                                  NaN\n",
       "14688    [MaxPool1d(), import torch\\r\\nimport torch.nn ...\n",
       "14689                                                  NaN\n",
       "14690    [.to(device), # wrong\\r\\nimgs.to(device)\\r\\n\\r...\n",
       "14691    [K x L, A, (A * B.view(len(A), -1)).view(B.sha...\n",
       "14692                                                  NaN\n",
       "14693    [``[[0, 1, 2, 3, 0, 0, 0,0],\\r\\n  [2, 3, 0, 0,...\n",
       "14694                                                  NaN\n",
       "14695    [len(labels), def to_onehot(labels, n_categori...\n",
       "14696    [def multihot_encoder(labels, dtype=torch.floa...\n",
       "14697                                                  NaN\n",
       "14698                                                  NaN\n",
       "14699    [A, C, A = torch.LongTensor([[0,1,2],[2,3,4]])...\n",
       "14700    [tanh, model = nn.Sequential(\\r\\n    nn.Linear...\n",
       "14701    [class Model1(nn.Module):\\r\\n    def __init__(...\n",
       "14702    [conda uninstall pytorch, pip install https://...\n",
       "14703    [state_dict = torch.load(args.model['state_dic...\n",
       "14704           [print(torch.load(args.model).keys())\\r\\n]\n",
       "14705    [new_theta = old_theta-learning_rate*momentum/...\n",
       "14706                                       [model.eval()]\n",
       "14707    [require_grad=False, required_grad=True, Tenso...\n",
       "14708    [torch.no_grad(), with torch.no_grad():\\r\\n   ...\n",
       "14710                                                  NaN\n",
       "14711    [foo.grad.data, bar.grad.data.copy_(foo.grad.d...\n",
       "14712    [cuda(), lstmInput, label = lstimInput.cuda(),...\n",
       "14713    [foward(), sig_out = self.sig(out) # shape: ba...\n",
       "14714    [transforms.ToTensor(), PIL Image, np.ndarray,...\n",
       "14715    [import itertools\\r\\nimport numpy as np\\r\\n\\r\\...\n",
       "14716    [app = flask.Flask(__name__)\\r\\nsegmentator = ...\n",
       "14717    [word_similarity, word_similarity = (word_1_ve...\n",
       "14718    [.norm(), .dist(), vector1 = torch.FloatTensor...\n",
       "14720    [torch.norm, torch.linalg.norm(), vector1 = to...\n",
       "14721                                                  NaN\n",
       "14722    [  tmp = torch.tensor([[0, 0, 1, 0, 1, 0, 0],\\...\n",
       "14723    [idx = torch.arange(tmp.shape[1], 0, -1)\\r\\ntm...\n",
       "14724    [argmax, tmp = torch.tensor([[0, 0, 1, 0, 1, 0...\n",
       "14725            [unhandled system error, NCCL_DEBUG=INFO]\n",
       "14726    [RuntimeError: NCCL error in: /pytorch/torch/l...\n",
       "14727    [relu, Relu, kernel_initalizer, ...\\r\\ny_pred ...\n",
       "14728    [In [14]: import torch                        ...\n",
       "14729    [for _e in range(num_epochs):\\r\\n    for batch...\n",
       "14730    [b, a = torch.Tensor([[[1,2],[1,2],[1,2]],[[3,...\n",
       "14731    [a = [[[1,2],\\r\\n      [1,2],\\r\\n      [1,2]],...\n",
       "14732    [torch.add(b.unsqueeze(1), a), import torch\\r\\...\n",
       "14733    [import torch\\r\\na = torch.FloatTensor([1,2,3,...\n",
       "14734    [a, b, a = torch.tensor([1,2,3,4,5], dtype=tor...\n",
       "14735                                                  NaN\n",
       "14736    [Backend.MPI, import pytorch_lightning as pl\\r...\n",
       "14737                                                  NaN\n",
       "14738                                                  NaN\n",
       "14739                                                  NaN\n",
       "14740    [torch.nn.Sequential, \\r\\n# test for saving ev...\n",
       "14741    [xf = x.view(x.size(0), -1)  # flatten the las...\n",
       "14742    [# input tensor \\r\\nt = tensor([[[ 0,  1,  2],...\n",
       "14743                                                  NaN\n",
       "14744    [Linear, # data.shape == (1, 4, 3)\\r\\nresults_...\n",
       "14746    [out_channels, model = BasicCNN()\\r\\nfor name,...\n",
       "14747    [import cv2\\r\\nfrom fastai.vision import *\\r\\n...\n",
       "14748    [rawids2sentence, encode, autoencode_logprobs[...\n",
       "14749                                                  NaN\n",
       "14750    [In [14]: x = np.arange(3, dtype=np.int32)\\r\\n...\n",
       "14751    [w = w - lr * w.grad\\r\\nb = b - lr * b.grad\\r\\...\n",
       "14752    [grad_input, grad_output, def backward_hook(mo...\n",
       "14753                                         [vocab_size]\n",
       "14754    [params['vocab_size'], len(vocab), params['emb...\n",
       "14755                      [nn.embedding, max(input_data)]\n",
       "14756                                           [__call__]\n",
       "14757    [    import torch\\r\\n    x = torch.tensor([1.5...\n",
       "14758    [vgg16, nn.Dropout, vgg.eval()\\r\\ntorch.all(to...\n",
       "14759    [state_dict, nn.Module, model, state_dict, mod...\n",
       "14762    [(batch, dim_ch, width, height), (width, heigh...\n",
       "14763    [[Conv2d][1], Conv2d, conv2d, import pytorch\\r...\n",
       "14764    [import torch\\r\\nzeros = torch.zeros(2, 2, 2, ...\n",
       "14765    [PyTorch &gt;= 0.4.1, o = conv(torch.autograd....\n",
       "14766    [class Wrapper(Dataset):\\r\\n    N = 16\\r\\n    ...\n",
       "14767    [torch.abs(V1[:, 1]- V1[:, 0]), torch.sum(torc...\n",
       "14768    [In [46]: torch.sum(torch.abs(V1[:, :-1] - V1[...\n",
       "14769    [cm = confusion_matrix(classes, preds)\\r\\n, co...\n",
       "14770    [def F_score(logit, label, threshold=0.5, beta...\n",
       "14771    [FloatTensor, test_tensor = torch.from_numpy(t...\n",
       "14772    [a[:, :, 0], a[:], a, a[:][:][0], a[0], a[:, :...\n",
       "14773    [# input tensor to work with\\r\\nIn [11]: a = t...\n",
       "14774    [data_dict = model.state_dict(), state_dict(),...\n",
       "14775                            [--reload_multifile True]\n",
       "14776           [writer = SummaryWriter(flush_secs=1)\\r\\n]\n",
       "14777    [img_array, np.array, normalized_input = (img_...\n",
       "14778    [img, import numpy as np\\r\\nnormalized = 2*[(i...\n",
       "14779    [In [188]: torch.einsum(\"ij, jk -&gt; ik\", x, ...\n",
       "14780    [A, normA, A, (batchSize, X, Y), normA, A, (ba...\n",
       "14781    [torch.argmax(outputs, 1).detach().cpu().squee...\n",
       "14783                                   [torch.nn.CTCLoss]\n",
       "14784                                                  NaN\n",
       "14785    [requires_grad=False, params = list(s.paramete...\n",
       "14786                          [torch.Size([3, 100, 100])]\n",
       "14787    [# loading\\r\\nsaved_params = torch.load(\\r\\n  ...\n",
       "14788                                                  NaN\n",
       "14789    [BCEWithLogitsLoss, sklearn.metrics.log_loss, ...\n",
       "14790                                                  NaN\n",
       "14791    [net_forward, nn.Module, forward, net_, net_fo...\n",
       "14792    [class BertWithCRF(BertPreTrainedModel):\\r\\n\\r...\n",
       "14794    [similar_word, import spacy\\r\\n\\r\\nnlp = spacy...\n",
       "14795    [import os\\r\\napp = Flask(__name__)\\r\\n\\r\\napp...\n",
       "14796    [Net(), Linear, Linear Regression, [x^2, x], i...\n",
       "14797                   [at::cuda::getCurrentCUDAStream()]\n",
       "14799    [import torch\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\...\n",
       "14800    [ binary = np.unpackbits(np.array([0xaa, 0xf0]...\n",
       "14801    [def decimal_to_binary_tensor(value, width=0):...\n",
       "14802    [sid_t = t[h][w][0], for loop, .item(), grad_f...\n",
       "14803    [F.nll_loss, argmax, torch.long, torch.float, ...\n",
       "14804    [43, 64, 50, argmax(), F.log_softmax, output, ...\n",
       "14805    [x, x^2, model = nn.Linear(2, 1)  # you have 2...\n",
       "14806    [nn.CrossEntropyLoss, nn.NLLLoss, log_ps, log_...\n",
       "14807    [unsqueeze, unsqueeze_(), in-place, view(), .r...\n",
       "14808    [hidden[-1], output, (h_n, c_n) = self.lstm(x_...\n",
       "14809    [output, (hidden, cell) = self.lstm(x_pack)\\r\\...\n",
       "14810    [PackedSequence, .flip(), def flipBatch(data, ...\n",
       "14811                                                  NaN\n",
       "14812    [model.eval(), state_dict = torch.load(MODEL_P...\n",
       "14813    [model=runner.load_state_dict(..., strict=Fals...\n",
       "14814            [torch.as_tensor(val.numpy()).to(device)]\n",
       "14815    [class LiTS(torch.utils.data.Dataset):\\r\\n\\r\\n...\n",
       "14816                                                  NaN\n",
       "14817    [torch.einsum(), numpy.einsum(), [a-zA-Z], [a-...\n",
       "14818    [path_on_datastore, am, create_from_data_refer...\n",
       "14819    [ds = Datastore.get(ws, datastore_name='my_ds'...\n",
       "14820    [ t1 = torch.from_numpy(a)\\r\\n t2 = torch.from...\n",
       "14821    [\\r\\na = torch.tensor([[1,2,3],[4,5,6]])\\r\\nb ...\n",
       "14822    [pad_idx = TGT.vocab.stoi[\"&lt;blank&gt;\"]\\r\\n...\n",
       "14823    [1.0.1, 0.4, torch.device, import torch\\r\\n\\r\\...\n",
       "14824    [# it's exploding\\r\\n1.01^121 = 101979  # imag...\n",
       "14826    [NESTING_FIELD = Field(batch_first=True, token...\n",
       "14827    [ids = ids.repeat(1, 255).view(-1, 1, 255)\\r\\n...\n",
       "14828    [idx = ids.flatten() + torch.arange(0,4*3,3)\\r...\n",
       "14829    [# data\\r\\nx = torch.arange(60).reshape(3, 4, ...\n",
       "14830    [conda create -n &lt;env_name&gt;python=3.6\\r\\...\n",
       "14832    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "14833    [from torchvision import models\\r\\nfrom torchs...\n",
       "14834    [def get_output_shape(model, image_dim):\\r\\n  ...\n",
       "14835    [nn.Sequential, Module, class PrintSize(nn.Mod...\n",
       "14836    [for layer in model.children():\\r\\n    if hasa...\n",
       "14837    [def get_tensor_dimensions_impl(model, layer, ...\n",
       "14838    [print(model.state_dict()['next_layer.weight']...\n",
       "14839    [nn.ReLU, F.relu, nn.ReLU(), __init__, forward...\n",
       "14840    [index_select, 1-dim, bt = b.transpose(0, 1)\\r...\n",
       "14841    [B_idx, A, A, B_idx, index_add_, A = torch.ara...\n",
       "14842                                                  NaN\n",
       "14843    [devic=cuda.device(0), devic=torch.device('cud...\n",
       "14844                                                  NaN\n",
       "14845    [storage, // _unsafe_view() differs from view(...\n",
       "14846                                                  NaN\n",
       "14847    [nn.DataParallel, nn.DataParallel, model.cuda(...\n",
       "14848                                                  NaN\n",
       "14849    [state_dict, pre-trained weights, Inception_v4...\n",
       "14850    [input, target, torch.tensor, nll = -(1/B) * s...\n",
       "14855    [index_add_(), A.index_add_(0, B, C)\\r\\n, B, t...\n",
       "14856    [O(num_types), \\r\\nnum_types = 3\\r\\nB_len = 5\\...\n",
       "14857    [torch.nn.Module, device_ids, List[int], torch...\n",
       "14858    [encoder_net = Encoder(state_dim)\\r\\nactor = A...\n",
       "14859    [self.x = torch.nn.Parameter(torch.zeros((1,M)...\n",
       "14861                                                  NaN\n",
       "14862                                                  NaN\n",
       "14863    [acc_dim, with torch.no_grad():, model.eval(),...\n",
       "14864                                                  NaN\n",
       "14865    [torch.utils.DataLoader, torch.utils.Dataset, ...\n",
       "14866    [args = parser.parse_args(), args = parser.par...\n",
       "14867    [args = easydict.EasyDict(\\r\\n{\\r\\n    \"root_p...\n",
       "14868    [image_datasets = {x: datasets.ImageFolder(os....\n",
       "14869    [{x: \"data/hymenoptera_data/\"+x for x in ['tra...\n",
       "14870    [DataParallel, nn.Parameter, nn.Module, nn.Par...\n",
       "14871    [z_proto, tensor, DataParallel, class Sequence...\n",
       "14872    [for digit in range(10):\\r\\n    similar_img = ...\n",
       "14873    [for digit in range(10):\\r\\n    similar_img = ...\n",
       "14874                             [del tensor, nvidia-smi]\n",
       "14875                                                  NaN\n",
       "14879    [In [239]: half_way = b.shape[0]//2\\r\\n\\r\\nIn ...\n",
       "14880           [forward, view, xb = xb.view(-1, 784)\\r\\n]\n",
       "14882                                                  NaN\n",
       "14883                                                  NaN\n",
       "14884                                                  NaN\n",
       "14885                                                  NaN\n",
       "14886                              [optimizer.zero_grad()]\n",
       "14888    [target, torch.LongTensor, torch.ByteTensor, n...\n",
       "14890    [orig_shape = (100, 1024, 14, 14)\\r\\nnew_shape...\n",
       "14891    [tensor.repeat(), # sample tensor for us to wo...\n",
       "14892    [a =  torch.randn(100,1024,14,14) \\r\\nb = torc...\n",
       "14893                                                  NaN\n",
       "14894    [import numpy as np\\r\\ndata = np.load('/conten...\n",
       "14895    [data, In [59]: dct = {0: np.array([5]), 1: np...\n",
       "14896    [backward(), backward(torch.Tensor([1])), torc...\n",
       "14897    ['model_state_dict', netG.load_state_dict(torc...\n",
       "14898    [z_proto_class_list.append(z_proto_class), z_p...\n",
       "14899    [C = A[..., None] + B[..., None, :]\\r\\n, b=1, ...\n",
       "14900    [nn.AvgPool2d, count_include_pad=True, True, c...\n",
       "14901    [torch.nn.functional.interpolate, torch.nn.fun...\n",
       "14903                                                  NaN\n",
       "14904    [import torch\\r\\nimport numpy as np\\r\\n\\r\\n# Y...\n",
       "14906    [B, B, C, T,  out = model(torch.tensor(X)[None...\n",
       "14908    [*, .view(), *shape, *, view, x.shape, (N, C, ...\n",
       "14911    [pip install torchvision ( this will install b...\n",
       "14913    [torch.utils.data, torch.utils.data.Dataset, t...\n",
       "14914    [pytorch_l.eval()\\r\\n, with torch.no_grad():\\r\\n]\n",
       "14915    [with torch.no_grad():\\r\\n    pytorch_l.eval()...\n",
       "14916    [def train(args, data_loader):\\r\\n    for idx,...\n",
       "14917    [kp_values, wavef, (kp_values.pow(2)).mul(wave...\n",
       "14918    [np.triu, np.triu((1, size, size), k=1).astype...\n",
       "14919    [nopeak_mask = np.triu(np.ones((1, size, size)...\n",
       "14920    [axis, dim,     |\\r\\n    v\\r\\n  dim-0  ---&gt;...\n",
       "14921    [def __init__(self, inplanes, planes, stride=1...\n",
       "14922    [if downsample:\\r\\n    self.downsample = conv1...\n",
       "14923    [resnet-50, downsample = nn.Sequential(conv1x1...\n",
       "14924                                                  NaN\n",
       "14925    [Tensorflow, PyTorch, PyTorch, one-hot, with t...\n",
       "14926    [_Loss, reduction, import torch\\r\\nfrom torch....\n",
       "14929    [import torch.nn.functional as F\\r\\n\\r\\ndef li...\n",
       "14931    [reduction='mean', if self.weight is not None:...\n",
       "14932                                                  NaN\n",
       "14933    [torch.nn.CrossEntropyLoss(), nn.LogSoftmax(),...\n",
       "14934    [    for cur_step in range(1):   \\r\\n    actio...\n",
       "14935    [ToTensor, torchvision, transform = transforms...\n",
       "14936               [docker, nvidia-docker, nvidia-docker]\n",
       "14937    [mean, normalize, sample, N x 9 x 5 x 7, mean,...\n",
       "14938         [Dataset, StopIteration, for, StopIteration]\n",
       "14939    [in_channels, out_channels, Conv1D(filters=32,...\n",
       "14940                                                  NaN\n",
       "14941    [28x28, (60000, 28, 28), y_train, x_train, x_t...\n",
       "14942                                   [x_train, y_train]\n",
       "14943    [[1, 2, 3, 4, 5, 6, 7, 8]\\r\\n, [\\r\\n  [1, 2],\\...\n",
       "14944    [source[torch.arange(source.shape[0]).unsqueez...\n",
       "14945    [index = torch.LongTensor([[0, 1, 2, 3], [1, 2...\n",
       "14949    [torch.distributed, torch.nn.DataParallel, tor...\n",
       "14950    [import matplotlib.pyplot as plt\\r\\nimport tor...\n",
       "14951            [tae_runner, kmnist_from_cfg, total_loss]\n",
       "14952    [nn.functional.sigmoid, torch.sigmoid, sigmoid...\n",
       "14954    [z = torch.linspace(-1, 1, steps=5, requires_g...\n",
       "14955    [z = torch.linspace(1, 5, steps=5, requires_gr...\n",
       "14956                                                  NaN\n",
       "14957    [/,   path = f'content/gdrive/My Drive/Machine...\n",
       "14958                                   [PyDrive, PyDrive]\n",
       "14959    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "14960    [    import numpy as np\\r\\n    import matplotl...\n",
       "14961    [self.conv1 = nn.Conv2d(in_channels=3, out_cha...\n",
       "14962    [def imshow_filter(img,row,col):\\r\\n    print(...\n",
       "14963    [+------+--------------+------------+---------...\n",
       "14964                                                  NaN\n",
       "14965    [TensorDataset, PIL.Image, import numpy as np\\...\n",
       "14966    [b[b.nonzero()[i]] = 2\\r\\n, import torch as t\\...\n",
       "14967    [import torch.nn as nn\\r\\n\\r\\nclass TestModel(...\n",
       "14968                                                  NaN\n",
       "14969    [torch.nn.CrossEntropyLoss(), # define loss fu...\n",
       "14970    [nn.Conv1d, nn.Linear, MaxPool1d, def count_pa...\n",
       "14971    [Yann Dubois, import torch, timeit, torch.nn a...\n",
       "14972    [idx, In [55]: x = np.array([[1,2,3,4,5,6],[10...\n",
       "14973    [x = [x[:,i].narrow(2,index,2) for i,index in ...\n",
       "14974    [# example\\r\\na = np.arange(60).reshape(2, 3, ...\n",
       "14975    [x = np.array([[1,2,3,4,5,6,7,8,9,10],[10,20,3...\n",
       "14976    [index_add_, # inputs\\r\\nsizes = torch.tensor(...\n",
       "14977    [labels, [N, 1], N, .size(...), torch.Size, .s...\n",
       "14978    [tensor.size(), images, labels = data\\r\\n, ima...\n",
       "14979    [Lang, pairs[0][0], pairs[1][1], Lang('s'), La...\n",
       "14980          [td_loss.backward(retain_graph = True)\\r\\n]\n",
       "14981    [x.cuda(), x.cuda(non_blocking=True), x.cuda(n...\n",
       "14983    [def timeseries_to_supervised(data, seq_length...\n",
       "14984    [prints, SGD(...), Adam(...), Net, import torc...\n",
       "14985    [List, Dict, Dict[str, Any], torchtext, prepro...\n",
       "14986    [LABEL = Field(sequential=True, use_vocab=Fals...\n",
       "14987    [CrossEntropyLoss, to_one_hot_vector, CEL, CEL...\n",
       "14988    [import torch\\r\\nbatch_size=10\\r\\nn_classes=5\\...\n",
       "14989    [torch.argmax(one_hot, dim=1), nn.LogSoftmax, ...\n",
       "14990    [import torch.nn.functional as F\\r\\nclass_labe...\n",
       "14991    [torch.flatten(), torch.flatten(),  t = torch....\n",
       "14993    [flatten(), reshape(), flatten(), import torch...\n",
       "14995    [torch.argmax(), import torch\\r\\n\\r\\nx = torch...\n",
       "14998    [d (out1) / d (out1) = 1, backward, a = torch....\n",
       "14999                                                  NaN\n",
       "15000    [pytorch 1.5.0, 1.4.0, torch::TensorOptions, t...\n",
       "15001    [(batch, classes, height, width), classes, 1, ...\n",
       "15002    [torch.split, tensor = torch.rand(12, 512, 768...\n",
       "15003    [torch.unsqueeze(), # inputs\\r\\nIn [6]: tensor...\n",
       "15004    [tensor.gather(), tensor = torch.rand(12, 512,...\n",
       "15005                                                  NaN\n",
       "15006                                                  NaN\n",
       "15007                                                  NaN\n",
       "15008    [torch.load('/path/to/saved/model', map_locati...\n",
       "15009    [print(outputs.shape, labels.shape)\\r\\n#out: t...\n",
       "15010    [dis = dis.clamp(min=0)\\r\\n, import torch\\r\\nd...\n",
       "15011                           [torch.sum(ts, dim=0)\\r\\n]\n",
       "15012    [torch.conv2d, [batch, channel, height, width]...\n",
       "15013                                                  NaN\n",
       "15014    [torch.save(model,'model.pt'), '__main__', __n...\n",
       "15015    [Net(nn.Module), import torch\\r\\nfrom torch im...\n",
       "15016    [dill,     # - path to files\\r\\n    path = Pat...\n",
       "15017    [ import torch\\r\\n t1 = torch.ones(3)\\r\\n t2 =...\n",
       "15019    [torch.stack, dim=1, t1 = torch.tensor([1, 2, ...\n",
       "15021    [import torch\\r\\nimport torch.nn.functional as...\n",
       "15022    [einsum, import torch\\r\\n\\r\\nT = torch.randn(1...\n",
       "15023    [pip uninstall torch\\r\\npip uninstall torch\\r\\...\n",
       "15024    [pytorch, pytorch, pip install -U torch==1.5\\r...\n",
       "15025    [pytorch, pytorch, pytorch, conda-forge, pytor...\n",
       "15026                                                  NaN\n",
       "15027                             [f['group/subroup'][()]]\n",
       "15030    [In [18]: t = torch.randn((1, 3, 256, 256, 3))...\n",
       "15031    [conda create -n my_env python=3.6, source act...\n",
       "15032    [import torch\\r\\n\\r\\ntensor1 = torch.tensor([1...\n",
       "15035    [final_losses.append(loss)\\r\\n, plt.plot(range...\n",
       "15037    [reduction='none', kl_div, log(x_n), y_n, kl_d...\n",
       "15038    [def forward(self, x):\\r\\n    out = self.featu...\n",
       "15039                    [images, labels = next(dataiter)]\n",
       "15040                                                  NaN\n",
       "15043    [Model, self, forward, model, optimizer, w, b,...\n",
       "15044                       [sudo find / -iname torch\\r\\n]\n",
       "15045                                                  NaN\n",
       "15046    [ImageFolder, root, data/\\r\\n├── train/\\r\\n|  ...\n",
       "15047    [data_dir = '/content/data/oxford-102-flowers/...\n",
       "15048                                                  NaN\n",
       "15049                                                  NaN\n",
       "15050    [nn.Embeddings, f = [[0,0,1], [1,0,0]]\\r\\n, nn...\n",
       "15051                                                  NaN\n",
       "15053    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15055    [last_seq_idxs, last_seq_items, last_seq_items...\n",
       "15056    [# ...\\r\\noutput, input_sizes = pad_packed_seq...\n",
       "15058                                                  NaN\n",
       "15059                                                  NaN\n",
       "15060    [Embedding, import torch\\r\\nfrom pytorch_pretr...\n",
       "15061    [T, theta, backward, def phaseOptimize(n, s = ...\n",
       "15062    [theta.grad = None, backward, T, T = t + theta...\n",
       "15063    [to(), rnn.to(device), rnn = RNN(n_letters, n_...\n",
       "15064                        [loss, mean, reduction, mean]\n",
       "15065    [loss.backward(), optimizer.step(), loss.backw...\n",
       "15066    [torchvision.utils.save_image, 255, normalize=...\n",
       "15067                                                  NaN\n",
       "15068    [acc, total_train_acc, total_train_acc += acc,...\n",
       "15069    [pip3, pip, python3, which pip3, less $(which ...\n",
       "15070    [import torch                                 ...\n",
       "15072    [net = nn.DataParallel(model.cuda(), device_id...\n",
       "15073    [input_tokens, hidden, forward(), hidden, forw...\n",
       "15074    [model.forward, __call__, nn.Module, __call__,...\n",
       "15076                                                  NaN\n",
       "15077                                                  NaN\n",
       "15079    [predictated, predicted, _, predictated = torc...\n",
       "15080    [&lt;head&gt;&lt;title&gt;&lt;title&gt;&lt;tit...\n",
       "15081    [with torch.no_grad():\\r\\n    correct = 0\\r\\n ...\n",
       "15082    [tensor_to_image, image *= np.random.random([5...\n",
       "15083    [torch.manual_seed(3)\\r\\nemb1 = nn.Embedding(5...\n",
       "15085    [from math import floor\\r\\n\\r\\nstride = 2\\r\\np...\n",
       "15086                               [n_in = 12, n_out = 6]\n",
       "15087    [tensor.to(),  images = images.to(device)\\r\\n ...\n",
       "15088                                                  NaN\n",
       "15089    [batch_size, target, view(-1, 1), loss = crite...\n",
       "15090    [loss.backward(retain_graph=True), out = self(...\n",
       "15091    [nn.Parameter, requires_grad=True, nn.Paramete...\n",
       "15092    [optim = torch.optim.SGD(model.convL2.paramete...\n",
       "15093    [# this will be inside your class mostly\\r\\nse...\n",
       "15094    [import torch.nn as nn\\r\\n\\r\\nclass Net(nn.Mod...\n",
       "15095    [.clone().detach(), .detach().clone(), .detach...\n",
       "15096    [y = x.clone().detach()\\r\\n, .clone(), .clone(...\n",
       "15097    [import torch\\r\\ndef samestorage(x,y):\\r\\n    ...\n",
       "15098                       [y_fill_, y_vec_, y_, scatter]\n",
       "15099    [test_loader_subset, img = img.numpy(), batch_...\n",
       "15100    [mask_fc1/2/3, self.mask_fc1 = nn.Parameter(to...\n",
       "15101    [ReLU, ftn = fitness(str(output.data[0][0]).tr...\n",
       "15103    [ConvTranspose3d(64, 3, kernel_size=4, stride=...\n",
       "15104    [&lt;torch_install&gt;/torch/nn/modules/contai...\n",
       "15105    [git clone https://github.com/tbepler/protein-...\n",
       "15108    [pytorch_bias_1 = torch.from_numpy(alpha * tf_...\n",
       "15109                                                  NaN\n",
       "15110     [conda list python\\r\\n, conda update python\\r\\n]\n",
       "15111    [for i in range(0, data_amount, batch_size):\\r...\n",
       "15114                                                  NaN\n",
       "15115                                                  NaN\n",
       "15116    [transforms.Normalize, transforms.ToTensor, in...\n",
       "15117    [model.zero_grad()                            ...\n",
       "15118    [requires_grad, a, a = torch.arange(1,13,dtype...\n",
       "15119    [import torch\\r\\nimport torch\\r\\nimport pycuda...\n",
       "15120    [flat_list = [item for sublist in c for item i...\n",
       "15121    [Module, Module, Modules, backward, Module, Mo...\n",
       "15123    [list, dict, set, list, nn.ModuleList, __init_...\n",
       "15124    [# Undo transforms.Normalize\\r\\ndef denormalis...\n",
       "15125    [    import cv2\\r\\n    import numpy as np\\r\\n ...\n",
       "15127                                                  NaN\n",
       "15129                                          [nn.Linear]\n",
       "15131    [nn.Module, __init__(), model.eval(), class Ne...\n",
       "15132    [fit_params, fit_params, X_dict = {'X': X, 'le...\n",
       "15133                                                  NaN\n",
       "15134    [.numpy(), prediction = prediction.cpu().numpy...\n",
       "15135    [ import torchfile\\r\\n model = torchfile.load(...\n",
       "15136    [OMP_NUM_THREADS=1, from torch import jit\\r\\n#...\n",
       "15137    [workspace.GlobalInit([\"caffe2\", \"--caffe2_omp...\n",
       "15138    [ import torch\\r\\n model = models.vgg16(pretra...\n",
       "15140    [target, target.view_as(pred), target, pred, t...\n",
       "15141    [class autoencoder(nn.Module):\\r\\n    def __in...\n",
       "15142    [glob.glob, transform_images, current_image, c...\n",
       "15143    [torch.argmax, torch.max(x, dim=k), condition,...\n",
       "15144    [    # Put the embedded inputs into the GRU.\\r...\n",
       "15145    [train(), output, hidden = model(x, use_softma...\n",
       "15146                                         [bias=False]\n",
       "15147                                     [kaiming_normal]\n",
       "15148    [import numpy as np\\r\\nimport torch\\r\\n# user_...\n",
       "15149    [from scipy.stats import truncnorm #extra impo...\n",
       "15151    [padding_mode, padding_mode, F.grid_sample(can...\n",
       "15152    [import *\\r\\n, from ..utils.parse_config impor...\n",
       "15153                                                  NaN\n",
       "15154                       [BxMxN, torch.cdist(Y, X)\\r\\n]\n",
       "15155    [transform = transforms.Compose([transforms.To...\n",
       "15156    [nn.Conv2d, floor(c_out / c_in), 1x1, groups=1...\n",
       "15157    [img = Variable(img).cuda(), cuda(), nn.Module...\n",
       "15158    [tarfile, getmember, getmembers(), __getitem__...\n",
       "15159                                                  NaN\n",
       "15160    [array, UMat, img_array = cv2.UMat.get(umat_im...\n",
       "15161       [import cv2\\r\\nimg_array = umat_img.get()\\r\\n]\n",
       "15162                                                  NaN\n",
       "15163                                                  NaN\n",
       "15164                                                  NaN\n",
       "15165    [torch.einsum, torch.einsum('bp,bqr-&gt;bpqr',...\n",
       "15166    [v = torch.arange(3)\\r\\nM = torch.arange(8).vi...\n",
       "15167    [# input matrices\\r\\nbatch_size = 2\\r\\nx1 = to...\n",
       "15168    [cat, import torch\\r\\n\\r\\na = torch.arange(8)....\n",
       "15169    [Tensor, List,  torch.Tensor([[1, 2], [3, 4]])...\n",
       "15170    [stage-2.pth, learner.model.load_state_dict(\\r...\n",
       "15171    [_, target = torch.max(target.data, 1)\\r\\n, [e...\n",
       "15173    [long, float, input_seq = input_seq.float().cu...\n",
       "15174    [torch.utils.data.DataLoader, collate_fn, coll...\n",
       "15175    [def collate_fn_padd(batch):\\r\\n    '''\\r\\n   ...\n",
       "15176    [def get_max_length(x):\\r\\n    return len(max(...\n",
       "15177          [torch.max, batch_size, 64, x[0], 13504, 1]\n",
       "15178    [torch.max, torch.nn.functional.max_pool2d, [h...\n",
       "15179    [  x = x.squeeze(2)\\r\\n,   x = x.view(-1, 64) ...\n",
       "15180    [import numpy as np\\r\\na = np.ones(5)\\r\\nb = a...\n",
       "15181    [b = torch.from_numpy(a)\\r\\n, Converting a tor...\n",
       "15182    [cross_vec = (feature_emb[:, None, ...] * feat...\n",
       "15183    [mse_loss = loss(torch.tensor(decoded_x, dtype...\n",
       "15184    [tf.keras.applications, tensorflow/models, pyt...\n",
       "15186    [argmax, argmax, 0, MB_Size x num_classes -1, ...\n",
       "15187    [import random\\r\\nrandom.shuffle(list)  // shu...\n",
       "15188    [sklearn.model_selection.train_test_split, fro...\n",
       "15189    [import glob\\r\\nimport pandas as pd\\r\\nimport ...\n",
       "15190                                                  NaN\n",
       "15191    [predicted, labels, predicted, np.array, label...\n",
       "15192                                          [ipdb, pdb]\n",
       "15193    [nn.module, __setattr__, def __setattr__(self,...\n",
       "15194    [nn.Module, Module._modules, __construct, def ...\n",
       "15195                                                  NaN\n",
       "15196    [class_object(fn params), __call__, nn.Module,...\n",
       "15197    [pytorch, sklearn, CountVectorizer, from io im...\n",
       "15199    [argmax, argmax, [C1, C2, C3, ...], CN, [C1', ...\n",
       "15200    [t = torch.tensor([-0.0627,  0.1373,  0.0616, ...\n",
       "15203                                                  NaN\n",
       "15204                                                  NaN\n",
       "15205                                                  NaN\n",
       "15207    [with SummaryWriter() as writer:\\r\\n   writer....\n",
       "15208     [A, B, R, dtype, float64, float32, R_gpu, R_gpu]\n",
       "15209    [max_length = max([len(l) for l in index])\\r\\n...\n",
       "15210    [features, classifier, VGG16.features, VGG16.c...\n",
       "15211    [C, import numpy as np\\r\\nimport torch.nn as n...\n",
       "15212    [DataParallel, C_gpu, import torch\\r\\nimport t...\n",
       "15213                                                  [C]\n",
       "15214    [# Input data\\r\\ntorch.Size([64, 1, 96, 96])\\r...\n",
       "15215    [from PIL import Image\\r\\n\\r\\nimg = Image.from...\n",
       "15216                                                  NaN\n",
       "15217    [CLASS torch.nn.Linear(in_features, out_featur...\n",
       "15218                                            [Network]\n",
       "15219    [cnn_learner, Pytorch, FastAI, breaking change...\n",
       "15220    [weights_init, def weights_init(m):\\r\\n    if ...\n",
       "15221    [def __init__(self, features, num_classes=1000...\n",
       "15222    [torch.load('alexnet_places365.pth.tar'), feat...\n",
       "15223    [group = 1, in_channels = 1, out_channels = 64...\n",
       "15224                                                  NaN\n",
       "15225    [import cv2\\r\\n\\r\\nimg = []\\r\\nfor i in range(...\n",
       "15226    [pathlib, from pathlib import Path\\r\\n# *.png\\...\n",
       "15227    [from torch.utils.data import Dataset, DataLoa...\n",
       "15228    [from torchvision import datasets, transforms\\...\n",
       "15229    [torch.utils.data.DataLoader, from torchvision...\n",
       "15230                        [x[:, 0, :] = y[:, 0, :]\\r\\n]\n",
       "15231    [x = torch.arange(0, 8).reshape((2,2,2))\\r\\ny ...\n",
       "15233                                                  NaN\n",
       "15234    [ToPILImage, ToPILImage, c, img = transforms.T...\n",
       "15235                                                  NaN\n",
       "15236                                                  NaN\n",
       "15237    [CrossEntropyLoss, Softmax, forward, CrossEntr...\n",
       "15238                                                  NaN\n",
       "15239    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15240    [opt = {\\r\\n  'model': 'models/beach/iter63000...\n",
       "15241                                          [action, a]\n",
       "15242    [Sequential, modules(),  model = nn.Sequential...\n",
       "15243    [def get_children(model: torch.nn.Module):\\r\\n...\n",
       "15244    [dict, named_layers = dict(model.named_modules...\n",
       "15245    [def flatten(el):\\r\\n    flattened = [flatten(...\n",
       "15246    [{'conv1': Conv2d(...),\\r\\n 'bn1': BatchNorm2d...\n",
       "15247    [def flatten_model(modules):\\r\\n    def flatte...\n",
       "15248    [target_layers =[]\\r\\nmodule_list =[module for...\n",
       "15265    [conda create -n env_pytorch python=3.6\\r\\n, c...\n",
       "15266    [forward, run, images = images.resize_((100,61...\n",
       "15267              [conda install -c pytorch pytorch, pip]\n",
       "15268    [#for valid set \\r\\n\\r\\nv = valid.reshape(1515...\n",
       "15269                                                  NaN\n",
       "15270    [tup = (2,3)\\r\\nfor dim in tup:\\r\\n    X = tor...\n",
       "15271    [dim = (2,3)\\r\\nx     = torch.rand(2,3,4,4)\\r\\...\n",
       "15272    [pytorch-0.4.0, pytorch-1.0.1, # 1. do not ins...\n",
       "15274    [TextLMDataBunch.from_df, TextClasDataBunch.fr...\n",
       "15275    [permute, view, from_pretrained, self.w2v_rnod...\n",
       "15277    [nn.LSTM, nn.RNNBase, import torch\\r\\ntorch.ma...\n",
       "15278               ['0', lstm.weight_ih_l0, weight_ih_l1]\n",
       "15279    [class Model(nn.Module):\\r\\n  def __init__(sel...\n",
       "15280    [bb = trainMyNet(thisCNN, train, test), thisCN...\n",
       "15281    [thisCNN, trainMyNet, thisCNN, for x in range(...\n",
       "15282    [torch.save, torch.save({\\r\\n            'epoc...\n",
       "15283    [import torch\\r\\n\\r\\nt = torch.tensor([[1,2,3]...\n",
       "15284                                                  NaN\n",
       "15285    [folder.py, hymenoptera_data\\\\train, classes =...\n",
       "15287                                                  NaN\n",
       "15288    [def time_backward(do_detach):\\r\\n    x = torc...\n",
       "15290    [partial, functools, ExplicitFactorizationMode...\n",
       "15291    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "15292     [MLModelConfiguration, computeUnits, .cpuAndGPU]\n",
       "15293    [dataloader, dataset, sample_idx, for i, _ in ...\n",
       "15294    [train_set = torchvision.datasets.CIFAR10(root...\n",
       "15295    [print(net), __repr__, __repr__, nn.Module, My...\n",
       "15296    [nn.Parameter, ~torch.Tensor, Module, ~Module....\n",
       "15297    [X, X[i], grad(), import torch\\r\\nimport torch...\n",
       "15299    [import torch\\r\\nfrom torch.autograd import gr...\n",
       "15300    [torch.autograd.grad, dy/dx, (batch_size, inpu...\n",
       "15301    [.npz, key = filename, data = np.savez_compres...\n",
       "15302    [super().forward(...), super(), __call__, regi...\n",
       "15303    [M0, forward(), m0(), import torch\\r\\nimport t...\n",
       "15304    [np.clip, torch.max, torch.min, In [1]: x\\r\\nO...\n",
       "15305                                                  NaN\n",
       "15306    [.backward(), v = model(s)\\r\\nv.backward()\\r\\n...\n",
       "15307    [    image_path_list = sort([os.path.join(self...\n",
       "15309    [new_torch_tensor = torch.tensor(numpy_array)\\...\n",
       "15310    [orig = torch.randint(low=0, high=10, size=(2,...\n",
       "15311    [torch.cat, a = torch.rand(128, 4, 150, 150)\\r...\n",
       "15312                       [num_workers=8, num_workers=1]\n",
       "15313    [        while True:\\r\\n            #keep loop...\n",
       "15314    [x.backward(), x, retain_grad(), .grad, autogr...\n",
       "15315    [conda install python==3.6.7, conda update pyt...\n",
       "15316    [import coremltools\\r\\nspec = coremltools.util...\n",
       "15317    [def weak_script_method(fn):\\r\\n    weak_scrip...\n",
       "15319                                                  NaN\n",
       "15321    [dataset.train_data, transform, DataLoader(dat...\n",
       "15322    [_apply, to, net.cuda(), net.float(), _apply, ...\n",
       "15323    [self._train_noise = torch.randn(batch_size, e...\n",
       "15324    [def to(self, **kwargs):\\r\\n    module = super...\n",
       "15325    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "15326    [nn.Module, .to(device), device, requires_grad...\n",
       "15327    [.size(), import torch\\r\\nimport torch.utils.d...\n",
       "15328    [def make_A(Rs, Js):\\r\\n    R_homo = torch.cat...\n",
       "15329    [std::optional&lt;at::Tensor&gt; optional_cons...\n",
       "15330    [noArray(), void xyz_forward(\\r\\n    const at:...\n",
       "15331    [torch.no_grad(), requires_grad, True, import ...\n",
       "15332    [argmax, dim, a = tensor(\\r\\n    [[0.3232, -0....\n",
       "15333    [nn.CrossEntropyLoss, out, nn.CrossEntropyLoss...\n",
       "15334                                                  NaN\n",
       "15336    [NetActor, nn.Parameter, forward, self.nn_laye...\n",
       "15337    [optim2, model2, optim2.step(), loss2.backward...\n",
       "15338    [state_dict, if os.path.exists(checkpoint_file...\n",
       "15340    [// cat 2 or more images to make a batch\\r\\ncv...\n",
       "15341    [torch::TensorList, ArrayRef, TensorList, // t...\n",
       "15342    [prediction, ground_truth, reduction, BCEWithL...\n",
       "15343    [class BCEWithLogitsLoss(_Loss):\\r\\n    def __...\n",
       "15344    [vgg.classifer=nn.Sequential(vgg.classifier, n...\n",
       "15345    [pytorch, torch, pip3 install torch  # or with...\n",
       "15346    [img = images[1]\\r\\n\\r\\n# TODO: Calculate the ...\n",
       "15347    [LongTensor of, nn.Embedding, test_voc = [\"ok\"...\n",
       "15348    [nn.Module.zero_grad(), optim.zero_grad(), nn....\n",
       "15349    [torch.cat, nn.Conv2d, forward, p = self.point...\n",
       "15350    [torch.tensor([1, 84, 84]), torch.tensor([1, 8...\n",
       "15351    [KeyError, Dataset, __iter__(), 0, __getitem__...\n",
       "15352    [ipython, python3.6, conda, which ipython, ipy...\n",
       "15354    [class CustomDataset(Dataset):\\r\\n    def __in...\n",
       "15358    [logprob = dist.log_prob(sample), logprob, sam...\n",
       "15359    [data, type(data), DataLoader, mean(), DataLoa...\n",
       "15360                          [torch.mean(), torch.std()]\n",
       "15361    [N = input.shape[0] #know the total size/sampl...\n",
       "15362    [img_dir\\r\\n|_class1\\r\\n  |_a.jpg\\r\\n  |_b.jpg...\n",
       "15363                   ['./Dataset/images/', './Dataset']\n",
       "15364    [class ImageFolder(Dataset):\\r\\n    def __init...\n",
       "15365                                        [ImageFolder]\n",
       "15367    [nn.Linear, Linear, nn.functional.linear, torc...\n",
       "15368    [torch.bool, torch.BoolTensor,  a = torch.Bool...\n",
       "15370    [torch.nn.functional.max_pool1d, torch.autogra...\n",
       "15371    [output, with no_grad, torch.autograd.Function...\n",
       "15372                           [model.named_parameters()]\n",
       "15374    [60000, mnist, batch = 100, len(encoded_images...\n",
       "15375    [LSTM, batch_first, self.lstm = nn.LSTM(input_...\n",
       "15376    [it doesn't work, torch.autograd.grad(outputs,...\n",
       "15378                              [dataloader, .to(cuda)]\n",
       "15379    [import torch\\r\\n\\r\\n# unroll the one-liner to...\n",
       "15380    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "15381                           [torch.manual_seed(0)\\r\\n]\n",
       "15382      [torchvision.datasets.ImageFolder, __getitem__]\n",
       "15383                                          [Long, Int]\n",
       "15384                                                  NaN\n",
       "15385    [@weak_script_method, embedding(input), __call...\n",
       "15386                                                  NaN\n",
       "15387                                                  NaN\n",
       "15388    [.cuda(), from torch.nn.utils.rnn import pack_...\n",
       "15389    [np.einsum, torch.einsum, grad_y_K = (X[:, Non...\n",
       "15390    [import torch\\r\\na = torch.tensor([[3,2,2,3], ...\n",
       "15391    [    a = #1D Array of  your choice\\r\\n    wind...\n",
       "15392     [torch.where, torch.nonzero, for, scipy, argmax]\n",
       "15393                                                  NaN\n",
       "15394                                                  NaN\n",
       "15395    [device = torch.device('cuda:0' if torch.cuda....\n",
       "15396                                    [.cpu(), .cuda()]\n",
       "15397    [1., conv1a, 0.5, fast_parameters = []\\r\\nslow...\n",
       "15398    [conda install pytorch torchvision -c pytorch\\...\n",
       "15399                                                  NaN\n",
       "15400    [torch.zeros, device=x.device, import torch\\r\\...\n",
       "15401    [dia_matrix, from scipy.sparse import dia_matr...\n",
       "15403    [tempTens[20,:] = SomeMatrix * A[20,:], tempTe...\n",
       "15405    [ ans = torch.einsum('nhwc,nc-&gt;nhw', img, a...\n",
       "15407                                                  NaN\n",
       "15408    [.zero_grad(), optimizer.zero_grad(), gradient...\n",
       "15409    [optimizer.zero_grad(), for epoch in range(epo...\n",
       "15411    [in_features * out_features, linear.weight, ou...\n",
       "15412    [a.storage()\\r\\n, a.storage().data_ptr()\\r\\n, ...\n",
       "15413    [torch.load(), map_location, cpu, load, # Load...\n",
       "15414    [transforms.Compose, train_data = datasets.Ima...\n",
       "15415                                                  NaN\n",
       "15417                         [Patch=img[0:100,0:100]\\r\\n]\n",
       "15418    [print, en6add, [1, 512, 5, 5], en7, [1, 512, ...\n",
       "15419    [TensorDataset, print(dataset[0]), (tensor([ 0...\n",
       "15420    [SSLError...sslv3 alert handshake failure, 1.0...\n",
       "15421    [init_hidden_encoder, init_hidden_decoder, cla...\n",
       "15422    [pip3 install Cython\\r\\n, _C.cpython-37m-x86_6...\n",
       "15423    [k, torch.int32, P, d_k, torch.float32, cat, k...\n",
       "15424    [# Here you increase the size of the matrix wi...\n",
       "15425    [c,         x = torch.tensor([\\r\\n        [5, ...\n",
       "15426    [CIFAR10, numpy, class SubLoader(torchvision.d...\n",
       "15428                            [.show(), plt.show()\\r\\n]\n",
       "15429           [/content/drive, open(log_loss_path, 'w')]\n",
       "15430    [sys.getsizeof, __sizeof__, torch.Tensor, sys....\n",
       "15431    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "15432    [DataLoader, len(dataset), DataLoader, batch_s...\n",
       "15433    [cycle, itertools, from itertools import cycle...\n",
       "15434    [mu-manylinux1, $ python -c \"import sys; print...\n",
       "15435    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "15436        [torch.ger(), np.outer(), umath, torch.ger()]\n",
       "15437    [class LazyFrames(object):\\r\\n    def __init__...\n",
       "15439    [model.add(layers.Conv1D(60, 3, strides=1, act...\n",
       "15440    [from torchvision import datasets\\r\\n\\r\\n# con...\n",
       "15441    [batch_size, num_workers, nsamples = 10000\\r\\n...\n",
       "15442    [z, r, import torch\\r\\n\\r\\nclass GridDataset:\\...\n",
       "15443    [class GridDataset:\\r\\n    def __init__(self):...\n",
       "15444                                [0, 1, 0, 1, 0, 7, 1]\n",
       "15445                                                  NaN\n",
       "15446    [im2arr = im2arr[np.newaxis, np.newaxis, :, :]...\n",
       "15447    [seq_len, batch_size, embedding_size, seq_len,...\n",
       "15448         [x=, x=x.view(-1,self.num_flat_features(x))]\n",
       "15449    [# initial guess\\r\\nguess = torch.tensor([1], ...\n",
       "15450    [running_loss += loss, running_loss += loss.it...\n",
       "15451    [import torch\\r\\nimport numpy as np\\r\\ny =[1, ...\n",
       "15452                               [batch_size, [64, 36]]\n",
       "15453    [train_batch = next(iter(train_iter))\\r\\nprint...\n",
       "15456    [import torch\\r\\n\\r\\n# stack vs cat\\r\\n\\r\\n# c...\n",
       "15457    [import torch\\r\\ntorch.__version__ # 1.10.2\\r\\...\n",
       "15458                                                  NaN\n",
       "15459                                                  NaN\n",
       "15460                                                  NaN\n",
       "15461    [Softmax, a, soft_a = softmax(a, dim=0) # othe...\n",
       "15462    [softmax, NLLLoss, softmax, log_softmax, NLLLo...\n",
       "15463    [$ conda install -c conda-forge torchvision\\r\\...\n",
       "15464    [pip, Collecting pytorch\\r\\n  Using cached htt...\n",
       "15465                                [2x+5, 2x+5, sklearn]\n",
       "15466                                                  NaN\n",
       "15467    [def postprocessing(arr,vocab,pad_token):\\r\\n ...\n",
       "15468                                                  NaN\n",
       "15469                        [CUDA_VISIBLE_DEVICES=GPU_ID]\n",
       "15470    [version: '3.5'\\r\\n\\r\\nservices:\\r\\n  training...\n",
       "15471    [from torch.utils.data import DataLoader\\r\\n\\r...\n",
       "15472    [...\\r\\nvoid Start()\\r\\n{\\r\\n    ...\\r\\n    da...\n",
       "15473    [unique, dim, dim=0, dim=1, dim=1, unique, 11,...\n",
       "15474         [dim, n x m x k, dim=2, unique, k, n x m, 2]\n",
       "15476                                                  NaN\n",
       "15477    [conda update pytorch\\r\\n, conda install pytor...\n",
       "15478                                                  NaN\n",
       "15479    [x = torch.rand(1, 64, 256, 1600, requires_gra...\n",
       "15480    [torch.utils.data.Subset(), Dataset, import to...\n",
       "15481    [Dataset, __len__, __getitem__, 0, len(self), ...\n",
       "15482    [print(\"\\nFirst...\")\\r\\nst = time()\\r\\nx_all_t...\n",
       "15483                                                  NaN\n",
       "15484    [backward, requires_grad == True, backward, .g...\n",
       "15485    [def mse_loss_with_nans(input, target):\\r\\n\\r\\...\n",
       "15487    [model.weight, model.bias, # clone and detach ...\n",
       "15488                                                  NaN\n",
       "15489    [torch.nn.Linear, 3x5, 6x1, 2x5, 5x1, 0, 2, la...\n",
       "15490    [pyro.clear_param_store(), latent_dim=5, laten...\n",
       "15492                                                  NaN\n",
       "15493    [input_size = 784\\r\\nhidden_sizes = [128, 64]\\...\n",
       "15495    [# Here's how to save the model.\\r\\nwith open(...\n",
       "15496                                                  NaN\n",
       "15497    [    dataset_transform = transforms.Compose([ ...\n",
       "15498    [matrix-multiplication, c = A.sum(1,keepdims=T...\n",
       "15499                                                  NaN\n",
       "15500                                              [sigma]\n",
       "15501    [[256, 1, 28, 28], [B, C, H, W], Linear(784, 1...\n",
       "15502    [device = torch.device(\"cuda\" if torch.cuda.is...\n",
       "15505    [CUDA_VISIBLE_DEVICES=2,3 python lstm_demo_exa...\n",
       "15506     [prob = output.probs.detach().cpu().numpy()\\r\\n]\n",
       "15508    [at::isnan, int main() {\\r\\n  torch::Tensor te...\n",
       "15509    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15512    [model.named_parameters(), In [106]: resnet = ...\n",
       "15513    [for name, m in mdl.named_children():\\r\\n    p...\n",
       "15514    [item&lt;dtype&gt;(), int main() {\\r\\n  torch:...\n",
       "15515    [Variable, from ... import *, Variable, Variab...\n",
       "15516                                                  NaN\n",
       "15518    [\\r\\nimport torch\\r\\nimport torch.nn as nn\\r\\n...\n",
       "15519    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15520    [model = torch.load(check_point), model.load_s...\n",
       "15521    [import torch \\r\\nimport torch.nn as nn\\r\\nimp...\n",
       "15522    [with torch.no_grad():\\r\\n    predFeats = self...\n",
       "15523                                                  NaN\n",
       "15524    [output[target == 0] = 0      # I get error at...\n",
       "15525                                                  NaN\n",
       "15526    [X, Model, class Model(nn.Module):\\r\\n   def _...\n",
       "15527    [# if m is a Module, you do:\\r\\nm.cuda()\\r\\n\\r...\n",
       "15528                                       [torch.Tensor]\n",
       "15529    [.backward, out, autograd.backward, autograd.g...\n",
       "15530                                      [register_hook]\n",
       "15531                                                  NaN\n",
       "15532    [print(FeedForwardNetModel([1,2,3]), Attribute...\n",
       "15533    [import torch\\r\\n\\r\\nactor = torch.nn.Sequenti...\n",
       "15534    [transforms.ToTensor(), PIL.Image, torchvision...\n",
       "15535    [np.random.binomial([np.ones((len(input),np.ar...\n",
       "15536    [def forward(self, x):\\r\\n    output = x @ sel...\n",
       "15537    [class sillyExample(torch.nn.Module):\\r\\n   de...\n",
       "15538                                                  NaN\n",
       "15539    [import torch\\r\\n\\r\\nt = torch.randn(10, 10)\\r...\n",
       "15540    [contiguous memory, contiguous, x = torch.tens...\n",
       "15542    [piqa, torch, torchvision, pip install piqa\\r\\...\n",
       "15544    [target, NLLLoss, [4., 2., 2., 8., ...], targe...\n",
       "15546    [torch.no_grad(), requires_grad == False, w, b...\n",
       "15547    [netz(), netz =Net(), nn.Sequential, *args, ne...\n",
       "15548    [five_sentences_of_twenty_words.to(cuda)\\r\\nfi...\n",
       "15549    [cpuTensor = cpuTensor.cuda()\\r\\n, cpuTensor =...\n",
       "15550    [def test_model_works_on_gpu():\\r\\n    device_...\n",
       "15551    [model_conv.fc = nn.Linear(4096, 2)\\r\\n, model...\n",
       "15552    [torch.as_tensor, torch.load, torch.tensor(arr...\n",
       "15553    [torch.load, numpy.ndarray, torch.Tensor, torc...\n",
       "15554    [model.load_state_dict(checkpoint['state_dict'...\n",
       "15555    [final_value = 1e-3 # Small number because don...\n",
       "15556    [l = lambda r: 1 if r &lt; 10 else 1.0-(r-9)/1...\n",
       "15557    [idx, import torch\\r\\ntorch.manual_seed(0)\\r\\n...\n",
       "15558    [torch.meshgrid,  index_tuple = torch.meshgrid...\n",
       "15559    [ import torch\\r\\n a = torch.randn(4,2,3)\\r\\n ...\n",
       "15560    [import torch\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\...\n",
       "15561    [super().__init__(), ColorizationCycleGAN, sup...\n",
       "15562    [def loss (other params, decay params, initial...\n",
       "15564                                                  NaN\n",
       "15567    [Dataset, boto3, class ImageDataset(Dataset):\\...\n",
       "15568                     [os.environ['SM_CHANNEL_TRAIN']]\n",
       "15571    [AlexNet = alexnet(pretrained=True)\\r\\n, repea...\n",
       "15573                                         [ToTensor()]\n",
       "15574    [all_data = np.load('training_data.npy')\\r\\nin...\n",
       "15575                                                  NaN\n",
       "15576    [backward(), backward() + step(), backward(), ...\n",
       "15584                           [torch.empty, torch.zeros]\n",
       "15587    [torch.gather, unsqueeze, repeat_interleave, #...\n",
       "15588    [sequences = torch.randn(8,12,2)\\r\\n# defining...\n",
       "15589    [    # the number of tokens is the sum of elem...\n",
       "15590                                [PyTorch, TensorFlow]\n",
       "15591    [import torch \\r\\n\\r\\ndef my_custom_loss(outpu...\n",
       "15594    [loss.backward, optim.step, # Our \"model\"\\r\\nx...\n",
       "15595    [model, criterion, pred = model(input)\\r\\nloss...\n",
       "15596    [x = torch.tensor([1.0], requires_grad=True)\\r...\n",
       "15598    [expand, expand, size, one_hot = torch.zeros(1...\n",
       "15599    [DataLoader, num_workers=2, num_workers=0, if ...\n",
       "15600    [loss = - criterion(inputs, outputs), loss = 1...\n",
       "15601    [1 - similarity(x, y), def ssim_loss(x, y):\\r\\...\n",
       "15602    [pip install openvino-dev[pytorch,onnx]\\r\\n, d...\n",
       "15604    [flatten, torch.flatten(input, start_dim=0, en...\n",
       "15606    [Go to Menu &gt; Runtime &gt; Change runtime.,...\n",
       "15607                                                  NaN\n",
       "15608    [F1 __call__, preds, targs, pytorch, pytorch, ...\n",
       "15609    [nn.CrossEntropyLoss(), outputs.shape\\r\\n torc...\n",
       "15610    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "15611    [output[a, b, c, d] == img[a, x[a, b, c], y[a,...\n",
       "15612                                                  NaN\n",
       "15613    [BatchNorm, BatchNorm, x, conv, conv, bn, ReLU...\n",
       "15614    [cat, a = torch.randn([2])\\r\\nb = torch.randn(...\n",
       "15616    [.tolist(), indices, def random_split(dataset,...\n",
       "15617    [random_split, index, torch.Tensor, int, __get...\n",
       "15618    [self.len = len(self.x_data)\\r\\n, len, pandas,...\n",
       "15619    [[int(len(data)*0.8),int(len(data)*0.2)]\\r\\n, ...\n",
       "15620    [dataset = TensorDataset(data_x, data_y), trai...\n",
       "15621    [from sklearn.model_selection import train_tes...\n",
       "15622    [/, dataroot = \"Users/user1/Downloads/DCGANs/c...\n",
       "15624    [Network, classifier, AlexNet, AlexNet, state_...\n",
       "15625    [History, History, model.fit(), History, Histo...\n",
       "15626    [Tensor.tolist(),  import torch\\r\\n a = torch....\n",
       "15628    [in[]\\r\\n#bbox predictions\\r\\nboxes = predicti...\n",
       "15629    [state_dict, pretrained_dict = {k: v for k, v ...\n",
       "15630                                                  NaN\n",
       "15631    [index = output.data.numpy().argmax()\\r\\n, ind...\n",
       "15632                                [output.argmax()\\r\\n]\n",
       "15633    [torch.max, value, index = torch.max(output,1)...\n",
       "15634    [!pip uninstall -y Pillow\\r\\n!pip install Pill...\n",
       "15635                                                  NaN\n",
       "15636    [NameError: name 'set_trace' is not defined, i...\n",
       "15638    [resnet152, from torchvision import models\\r\\n...\n",
       "15639                                                  NaN\n",
       "15640    [nn.Dropout, __init__, eval(), class mylstm(nn...\n",
       "15641    [def predict_class(model, test_instance, activ...\n",
       "15642       [__init__, model.eval(), __init__, nn.Dropout]\n",
       "15643    [(batch, 128, 2, 2), output = output.view(-1,1...\n",
       "15644    [def find_continguous_max_sum(t): \\r\\n    max_...\n",
       "15645    [A, [ [1.3], [0], [0.6, 0.7, 0.8] ], def split...\n",
       "15646    [Conv2d(1, 6, 5), output dim = (input_dim - fi...\n",
       "15647                                                  NaN\n",
       "15648                     [loss.backwards(), optim.step()]\n",
       "15649    [return_indices=True, class ConvDAE(nn.Module)...\n",
       "15652    [torch.nn, (batch_size, channels, height, widt...\n",
       "15653    [model, torch.load(\"iNat_2018_InceptionV3.pth....\n",
       "15654    [outputs, retain_graph=True, outputs, labels, ...\n",
       "15655    [labels, lables, print(output.shape, labels.sh...\n",
       "15656    [(input_size//output_size), input_size - (outp...\n",
       "15657    [start_index, end_index, from typing import Li...\n",
       "15658                                                  NaN\n",
       "15659                                                  NaN\n",
       "15660                                                  NaN\n",
       "15661                                             [v0.4.1]\n",
       "15662    [torchvision.models, sq = torchvision.models.s...\n",
       "15663    [data, data, data, data, weight.data, bias.dat...\n",
       "15664    [b, uint8, bool, uint8, a[b], a, a[i], b, b[i]...\n",
       "15665    [nn.softmax, m = nn.Softmax()\\r\\nout = vgg16(f...\n",
       "15666    [data.Dataset.__len__, len(dataloader.dataset)...\n",
       "15667    [width, heigth, nb_channels, f=kernel_size, f=...\n",
       "15668    [advantages, returns, advantage_list.insert(0,...\n",
       "15669    [Linear, Conv2d, [batch_size, n_features_conv,...\n",
       "15670                                                  NaN\n",
       "15671    [self.fc1 = nn.Sequential(\\r\\n        nn.Linea...\n",
       "15672                                                  NaN\n",
       "15673    [my_img_tensor = my_img_tensor.type('torch.Dou...\n",
       "15674    [transforms.ToTensor(), TenCrop, [batch, featu...\n",
       "15675    [ToTensor, TenCrop, TenCrop, transform = Compo...\n",
       "15676          [ import sys\\r\\n print(sys.executable)\\r\\n]\n",
       "15677    [classes, img, lbl = image_datasets['val'][0]\\...\n",
       "15678                       [ReLU, Sigmoid, nn.Sequential]\n",
       "15679                                                  NaN\n",
       "15680    [TEXT.preprocess(\"Hello, how are you today?\")\\...\n",
       "15681    [import torch\\r\\nimport torchvision.models as ...\n",
       "15682    [transform = transforms.Compose([\\r\\n    trans...\n",
       "15683    [44/2=22, x = self.pool(F.relu(self.conv1(x)))...\n",
       "15684               [image_datasets['train'].class_to_idx]\n",
       "15685    [A generic data loader where the images are ar...\n",
       "15686    [import numpy as np\\r\\nimport torch\\r\\nimport ...\n",
       "15689                                     [sum, criterion]\n",
       "15690                                        [num_workers]\n",
       "15691                                             [smooth]\n",
       "15693    [[h, w, 3], [b, 3, h, w], b, reshaped = img.pe...\n",
       "15694    [for, x, x, v1, v2, import torch\\r\\nimport tor...\n",
       "15695    [import torch\\r\\nt = torch.rand(5, 5)\\r\\n# ori...\n",
       "15697    [.prod, x = torch.prod(x, dim=1), x = x.prod(d...\n",
       "15698    [relu1[relu1 &gt; self.act_max] = self.act_max...\n",
       "15700    [gather(), torch.Tensor().gather(dim, input_te...\n",
       "15701    [conda create -n pytorch_env  python=3  \\r\\nso...\n",
       "15702    [model.to(device), device, inputs, labels, to,...\n",
       "15703    [dataloader, Dataloader, DataLoader, torch.aut...\n",
       "15705    [grad_output.zero_(), grad_output[:, i-1] = 0,...\n",
       "15706                       [set_detect_anomaly, autograd]\n",
       "15707    [            inputs_reg = Variable(data, requi...\n",
       "15708                                    [clone(), step()]\n",
       "15709    [torch.nn.functional.pad, mode='replicate', pa...\n",
       "15710    [import torch.nn as nn\\r\\nimport torch.nn.func...\n",
       "15711    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "15712                                                  NaN\n",
       "15713    [torch.cat, from typing import List\\r\\nimport ...\n",
       "15715    [Variable, import torch\\r\\nprint(torch.__versi...\n",
       "15716    [num_batches_tracked, model_dict = checkpoint[...\n",
       "15717                                                  NaN\n",
       "15718    [import torch\\r\\nimport numpy as np\\r\\n\\r\\nt =...\n",
       "15719                                                  NaN\n",
       "15720               [__getitem__, __len__, __getitem__, i]\n",
       "15721                                                  NaN\n",
       "15722                                                  NaN\n",
       "15723                                     [num_workers=0?]\n",
       "15724    [nn.Module, __call__, def __call__(self, *inpu...\n",
       "15725    [item = self.X[idx], item = self.X[idx].copy()...\n",
       "15727                                                  NaN\n",
       "15728    [num_samples, multinomial, def select_action(s...\n",
       "15729                                                  NaN\n",
       "15730    [torch.Tensor, torch.cuda.Tensor, torch.Tensor...\n",
       "15731    [self.outputs = nn.Linear(NETWORK_WIDTH, 1)\\r\\...\n",
       "15733    [matplotlib, numpy, matplotlib, from scipy.mis...\n",
       "15737    [plt.imshow(white_torch.permute(1, 2, 0))\\r\\n,...\n",
       "15739    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "15740      ['if', sign(), [-1,1], Tanh(), sign(), clamp()]\n",
       "15741                        [image, (image, _), image, _]\n",
       "15742    [_, 2, 2, features = torch.tensor(np.array([ [...\n",
       "15743    [//define the deleter ...\\r\\nvoid deleter(void...\n",
       "15744                                                  NaN\n",
       "15745    [resnet18, model_ft = models.resnet18(pretrain...\n",
       "15746           [nn.PairWiseDistance, N, D, N, eps = 1e-6]\n",
       "15747    [Computes the p-norm distance between every pa...\n",
       "15748                                                  NaN\n",
       "15749                                                  NaN\n",
       "15750                                             [mpirun]\n",
       "15751    [__len__, shape, import torch\\r\\nclass Foo:\\r\\...\n",
       "15752    [torch.nn.Linear(in_features, out_features), 7...\n",
       "15753    [loss = criterion(output, batch['mask'])\\r\\n, ...\n",
       "15754    [from tensorboardX import SummaryWriter\\r\\n, w...\n",
       "15755    [nn.CrossEntropyLoss(), v, loss = criterion(ou...\n",
       "15756    [y, z, Y, Z, Y, Z, y, z, y, z, Y, Z, x = torch...\n",
       "15757    [l1 = nn.L1Loss(reduction='sum')\\r\\nloss = l1(...\n",
       "15758                                   [CrossEntropyLoss]\n",
       "15759    [Subset, testset = ImageFolderWithPaths(root=\"...\n",
       "15760    [DataLoader, test_loader = DataLoader(image_da...\n",
       "15761    [dataset, # Recovers the original `dataset` fr...\n",
       "15762    [DataLoader, list = [ x[0] for x in iter(train...\n",
       "15764    [shuffle=True, DataLoader, from torch.utils.da...\n",
       "15765    [.to, In [10]: a = torch.rand(10)\\r\\n\\r\\nIn [1...\n",
       "15767        [Tensor.view, answer(x.data).view(-1, 1)\\r\\n]\n",
       "15768         [net.load_state_dict(copy_net.state_dict())]\n",
       "15769    [&gt;, torch.gt(), # input tensor\\r\\nIn [76]: ...\n",
       "15771    [a = torch.tensor([0,4,0,0,5,0.12,0.34,0,0])\\r...\n",
       "15774        [self.fc1, 32 * 28 * 28, 32 * 3 * 3, 32 * 32]\n",
       "15775                                        [__getitem__]\n",
       "15776    [cuda, cpu, device = torch.device(\"cpu\"), sigm...\n",
       "15777    [ # get all the image and mask path and number...\n",
       "15778                                                  NaN\n",
       "15779    [Sizes of tensors must match except in dimensi...\n",
       "15780    [     a = torch.tensor([[1,1],[2,2]], dtype=to...\n",
       "15781    [with torch.enable_grad():, with, torch.enable...\n",
       "15782    [parameter_current, parameter_current, backwar...\n",
       "15784    [gather, index, torch::gather, auto x = torch:...\n",
       "15785                                                  NaN\n",
       "15786    [def make_covariance_matrix(sigma, rho):\\r\\n  ...\n",
       "15787    [nn.Linear, num_flat_features, x, self.fc1, x,...\n",
       "15788    [nn.Module, X, x_sample, z_mu, z_var = vae(X[N...\n",
       "15789    [x = torch.tensor([[10, 2], [3,5]])\\r\\ny = tor...\n",
       "15790    [features = torch.rand(1, 5) \\r\\nweights = tor...\n",
       "15791                                              [256*x]\n",
       "15792    [permute, transpose, view, C, B, H, B, C*H, si...\n",
       "15793    [from einops import rearrange\\r\\nimport torch\\...\n",
       "15794    [DataLoader, Dataset, 'json', Dataset, 'json',...\n",
       "15795    [aux_logits=False, output, aux = model(input_v...\n",
       "15796    [F, import torch.nn.functional as F\\r\\n, F, F=...\n",
       "15797    [x,_ = self.blstm(x), torch.nn.CrossEntropyLos...\n",
       "15798    [model, fc1, model.fc1.in_features\\r\\n, .forwa...\n",
       "15799                                                  NaN\n",
       "15800    [t = torch.rand(32, 10, 64).permute(0, 2, 1)[:...\n",
       "15801    [torch.gather, expand, I, eI = I[..., None, No...\n",
       "15804                       [objmask, requires_grad=False]\n",
       "15808    [tensor([-0.0000, -1.8421, -3.6841, -5.5262, -...\n",
       "15810                                                  NaN\n",
       "15811    [test = (1,2,3)\\r\\ntester = iter(test)\\r\\n\\r\\n...\n",
       "15812    [return x*self.my_registered_parameter[0], nn....\n",
       "15813    [nn.ParameterList, return x*self.my_registered...\n",
       "15814    [print(model), RNN(\\r\\n  (dense1): Linear(in_f...\n",
       "15815    [print(unet.conv1.state_dict()[\"weight\"]), pri...\n",
       "15816    [squeeze(), output, sequence_length   = 75\\r\\n...\n",
       "15817                                                  NaN\n",
       "15818    [torchvision.dataset.ImageFolder, transform, _...\n",
       "15819                                                  NaN\n",
       "15821    [no_grad, torch.set_grad_enabled, class no_gra...\n",
       "15822    [torch.autograd.enable_grad, no_grad, no_grad,...\n",
       "15823    [print(model) # print network architecture\\r\\n...\n",
       "15824    [str(), caption_str = str(caption_all_for_a_im...\n",
       "15825    [sum(), M = ((X[:, None, :] - X_[:, None, :] *...\n",
       "15826    [# setup\\r\\nbatch, step, vec_size = 64, 10, 12...\n",
       "15829    [TransformationFunction, requires_grad, False,...\n",
       "15830    [TEXT = data.Field(sequential=True, tokenize=t...\n",
       "15831    [import dill\\r\\nfrom pathlib import Path\\r\\n\\r...\n",
       "15832    [def save_to_pickle(dataSetObject,PATH):\\r\\n  ...\n",
       "15833    [def save_examples(dataset, savepath):\\r\\n    ...\n",
       "15834    [nn.Dropout, import torch\\r\\nimport torch.nn a...\n",
       "15835    [Functional, nn, nn, from .. import functional...\n",
       "15836    [torch.nn.functional,  if p &lt; 0. or p &gt; ...\n",
       "15837    [test_data, test_target = image_datasets['trai...\n",
       "15838    [self.optimizer.state, dict_with_acc_delta = [...\n",
       "15839    [torch.arange(max_len).expand(len(lens), max_l...\n",
       "15840    [torch.arange(max_len)[None, :] &lt; lens[:, N...\n",
       "15841    [torch.arange(max_len)[None, :] &lt; lens[:, N...\n",
       "15842    [m, m, p(z), Diters, p(z), niter, Diters, # tr...\n",
       "15843    [random_split, DataLoader, Dataset, torch.util...\n",
       "15844    [sklearn.preprocessing.StandardScaler, from sk...\n",
       "15845    [    net = NeuralNetClassifier(\\r\\n        ......\n",
       "15846    [!pip3 install https://download.pytorch.org/wh...\n",
       "15847                                             [module]\n",
       "15849    [__matmul__, def __matmul__(self, other):\\r\\n ...\n",
       "15850                                                  NaN\n",
       "15851    [in_channels, self.fc1, self.fc1 = nn.Linear(1...\n",
       "15852                                                  NaN\n",
       "15853    [a = torch.randn(2, 2, 3)\\r\\nb = torch.eye(2, ...\n",
       "15854                                                  NaN\n",
       "15856    [param, name, name, param, for name, param in ...\n",
       "15857                          [functools.partial, lambda]\n",
       "15858    [_, add -&gt; add_  # in-place equivalent\\r\\nd...\n",
       "15859                                                  NaN\n",
       "15861    [torch.utils.data.DataLoader, trainTransform  ...\n",
       "15862    [import torchvision as tv\\r\\nimport numpy as n...\n",
       "15864                                 [accumulation_steps]\n",
       "15865       [loss.backward(), predictions = model(inputs)]\n",
       "15866    [.to(device), .cuda(), .to(device), device=tor...\n",
       "15867    [zeros_tensor_gpu = torch.zeros((50, 50), devi...\n",
       "15868    [b = torch.ones(4,4).cuda()\\r\\nfor _ in range(...\n",
       "15869    [import torch\\r\\n\\r\\nvec = torch.zeros(4, dtyp...\n",
       "15871                                                  NaN\n",
       "15872    [optimizer.step(), for input, target in datase...\n",
       "15873                                  [num_workers=0\\r\\n]\n",
       "15874      [python3 --version, sudo apt install python3.6]\n",
       "15875                          [pip install python==3.6.1]\n",
       "15876                                                  NaN\n",
       "15877    [ptrblck, nb_classes = 9\\r\\n\\r\\nconfusion_matr...\n",
       "15878    [from sklearn.metrics import confusion_matrix\\...\n",
       "15879    [nb_classes = 9\\r\\nconfusion_matrix = np.zeros...\n",
       "15880    [from sklearn.metrics import accuracy_score\\r\\...\n",
       "15881    [x = [torch.max(tensor).item() for tensor in x...\n",
       "15882    [x, y = next(iter(training_loader))\\r\\n, train...\n",
       "15884    [a = torch.tensor(np.random.randn(), requires_...\n",
       "15885    [y.backward(), y.backward(torch.tensor(1.0)), ...\n",
       "15886    [!export FOO=blah, !, !, %%writefile foo.py\\r\\...\n",
       "15887                    [Runtime-&gt;Change Runtime Type]\n",
       "15888    [os, import os\\r\\nos.environ['CUDA_LAUNCH_BLOC...\n",
       "15889                                                  NaN\n",
       "15891        [f'{path}/*.*'\\r\\n, SyntaxError, SyntaxError]\n",
       "15892    [import PIL\\r\\nprint(PIL.PILLOW_VERSION)\\r\\n, ...\n",
       "15893             [!pip install -U pillow\\r\\n, -U, pillow]\n",
       "15894    [!pip uninstall -y Pillow\\r\\n# install the new...\n",
       "15895    [fc1, fc2, forward(), def forward(self, x):\\r\\...\n",
       "15897    [flatten_parameters, _cudnn_rnn_flatten_weight...\n",
       "15898                                                  NaN\n",
       "15900                                                  NaN\n",
       "15901    [requires_grad, True, X, requires_grad, True, ...\n",
       "15902     [retain_grad(), Z.retain_grad()\\r\\n, backward()]\n",
       "15903    [T_dec = torch.tensor([0, 1])\\r\\nX = torch.ten...\n",
       "15904    [y_true=1, [loss(y_pred) for y_pred in np.lins...\n",
       "15905    [argmax(), n = torch.tensor(4)\\r\\nd = torch.te...\n",
       "15907    [unravel_index, torch, def unravel_index(\\r\\n ...\n",
       "15908    [argmax, argmax, batch_argmax, def batch_argma...\n",
       "15910                                                  NaN\n",
       "15912    [*, torch.mm, a = torch.rand(2,5)\\r\\nb = torch...\n",
       "15913    [x, torch.Tensor, requires_grad, torch.tensor(...\n",
       "15914    [async, SyntaxError, cuda(), async, async, non...\n",
       "15915                         [async, async, non_blocking]\n",
       "15916    [import torch \\r\\nimport torch.nn.utils.rnn as...\n",
       "15917    [ loaded_state = torch.load(model_path+seq_to_...\n",
       "15918                                                  NaN\n",
       "15919    [model.onnx, \\r\\n# Export the model from PyTor...\n",
       "15920    [# Export the model from PyTorch to ONNX\\r\\nto...\n",
       "15921    [!pip install onnx2keras\\r\\n, import onnx\\r\\nf...\n",
       "15922                                                  NaN\n",
       "15923    [import torch, import PyTorch,  import torch\\r...\n",
       "15924    [optimizer, Parameters, optimizer, requires_gr...\n",
       "15925    [rois = rois.data.float()\\r\\nnum_rois = rois.s...\n",
       "15926    [torch.FloatTensor, torch.cuda.FloatTensor, te...\n",
       "15927    [b_x.cuda(), b_x, b_x = b_x.cuda()\\r\\nb_y = b_...\n",
       "15928    [forward, x, def forward(self, x):\\r\\n    x1 =...\n",
       "15929                                                  NaN\n",
       "15930    [input = torch.randn(3, 10)\\r\\nresult = torch....\n",
       "15931    [nn.functional.one_hot, from torch.nn.function...\n",
       "15932    [VGG, vgg.classifier[0]: Linear(in_features=25...\n",
       "15933                                  [AdaptiveAvgPool2d]\n",
       "15934    [inputs, labels, for i, data in enumerate(trai...\n",
       "15935    [conda install pytorch torchvision cudatoolkit...\n",
       "15936    [torch.cuda.is_available(), device = torch.dev...\n",
       "15937                                                  NaN\n",
       "15938    [tf.distributions.Bernoulli, import numpy as n...\n",
       "15939                                                  NaN\n",
       "15940                                                  NaN\n",
       "15941                                                  NaN\n",
       "15942        [torch.set_default_dtype(torch.float64) \\r\\n]\n",
       "15943    [GRU, torch.manual_seed(42)\\r\\nbilstm.eval()  ...\n",
       "15944    [double, weights, self.fully_connected, float,...\n",
       "15945    [DoubleTensor, .from_numpy(), print(type(zvec)...\n",
       "15946    [myTensor[0,0]*=5\\r\\n, requires_grad, True, re...\n",
       "15947    [%matplotlib auto, import torch, import torch,...\n",
       "15948    [torchtext.data.TabularDataset, class TabularD...\n",
       "15949    [model, model = FeatureExtractor().cuda()\\r\\nm...\n",
       "15951    [self.hidden2tag, out = self.lstm(x)\\r\\n, out,...\n",
       "15952            [state = np.array(state)\\r\\n, np.asarray]\n",
       "15954                                                  NaN\n",
       "15955    [# so these are your original hidden states fo...\n",
       "15956    [output, h_n, In [1]: import torch\\r\\n   ...: ...\n",
       "15957    [x = torch.cat((xLeft, xRight)), x = torch.cat...\n",
       "15958    [pytorchviz, pytorchviz, grad_fn, import torch...\n",
       "15959    [stride=2, import tensorflow as tf\\r\\nimport n...\n",
       "15960             [torch.onnx, repeat, repeat, torch.onnx]\n",
       "15961    [*args, **kwargs, =, File \"/home/pc/anaconda3/...\n",
       "15962    [y, ndarray, import torch\\r\\nimport numpy as n...\n",
       "15966    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "15967    [loss(input, target)\\r\\n, loss = CrossEntropyL...\n",
       "15968    [CrossEntropyLoss, loss = CrossEntropyLoss(Pip...\n",
       "15969    [L = CrossEntropyLoss()\\r\\n, L(y_pred, y_true)...\n",
       "15970    [plt.imshow(), plt.show(), plt.show(images[0]....\n",
       "15971    [x, x_mapped, from collections import defaultd...\n",
       "15972    [state_dict, parameters, nn.Modules, state_dic...\n",
       "15973    [model.state_dict()[\"your_weight_names_here\"][...\n",
       "15974    [state_dict, state_dict, state_dict, BasicMode...\n",
       "15976    [&gt; TypeError: Traceback (most recent call l...\n",
       "15978                                    [x.retain_grad()]\n",
       "15979    [torch.arange, position = torch.arange(0, max_...\n",
       "15983                      [a[idx[:,0], idx[:,1]] = 1\\r\\n]\n",
       "15984    [self.saved_tensors, import torch\\r\\na = torch...\n",
       "15985    [In [2]: a = torch.tensor([2, 4, 6])\\r\\n, In [...\n",
       "15986                                                  NaN\n",
       "15987                                                  NaN\n",
       "15989    [grad_h = grad_h_relu.clone()\\r\\n, grad_h_relu...\n",
       "15990    [def set_deterministic(seed=42):\\r\\n    random...\n",
       "15992    [it, it &gt; 0, it, True, False, True, False, ...\n",
       "15993                                                  NaN\n",
       "15995    [# defining the tensor along with device to ru...\n",
       "15996    [import torch\\r\\nimport numpy, math\\r\\nimport ...\n",
       "15997                                                  NaN\n",
       "15999    [focal_loss_fixed(), focal_loss_fixed(), loss,...\n",
       "16000                                          [x, x, 1.0]\n",
       "16001    [import torch.nn as nn\\r\\n, num_ftrs = model_f...\n",
       "16002                                                  NaN\n",
       "16004    [torch.utils.data.DataLoader, collate_fn, torc...\n",
       "16006    [os.environ['CUDA_VISIBLE_DEVICES']='0'\\r\\n......\n",
       "16007    [PIL.Image, io.imread, io, PIL.Image, PIL.Imag...\n",
       "16010                                                  NaN\n",
       "16011                                                  NaN\n",
       "16012    [conv, weights = ch.Tensor([[0, 0, 0], [0, 1, ...\n",
       "16014                                                  NaN\n",
       "16015    [empty, Tensor&amp; empty_out(Tensor&amp; resu...\n",
       "16016    [F.normalize, ux, # I modified the input to ma...\n",
       "16017    [PyTorch, requirements.txt, flask\\r\\nflask-cor...\n",
       "16018                                                  NaN\n",
       "16019    [x = torch.Tensor([6, 5, 4])\\r\\ny = torch.Tens...\n",
       "16020    [a.size(-1), import torch\\r\\na= torch.zeros((2...\n",
       "16021    [from itertools import groupby\\r\\nfrom operato...\n",
       "16022    [Out = float(((W−F+2P)/S)+1)\\r\\n, W = (55 - 1)...\n",
       "16023           [out_size= floor((in_size + 2p -f)/s + 1)]\n",
       "16024                                                  NaN\n",
       "16025    [_renamed_operators = {\\r\\n    'Caffe2ConvTran...\n",
       "16026                                                  NaN\n",
       "16027    [DataParallel, args.gpus, None, None, DataPara...\n",
       "16028                             [y = x * (2^7), 2^7 * x]\n",
       "16030    [lr_scheduler, lr_scheduler.get_lr(), my_optim...\n",
       "16031            [import pdb\\r\\npdb.set_trace()\\r\\n, n, s]\n",
       "16032                [import pdb; \\r\\npdb.set_trace()\\r\\n]\n",
       "16033    [import sys; sys.breakpoint()\\r\\n, Command  De...\n",
       "16034    [for p in net.named_parameters():\\r\\n    print...\n",
       "16035                                                  NaN\n",
       "16036    [modules(), from torch import nn\\r\\n\\r\\nfor mo...\n",
       "16039    [ma = torch.cuda.memory_allocated()\\r\\nprint(m...\n",
       "16040    [nn.Conv2d, torch.nn.functional.conv2d, out = ...\n",
       "16041               [pip --version, No module named torch]\n",
       "16042    [if torch.cuda.device_count() &gt; 1:\\r\\n    m...\n",
       "16043    [Dataset, Example, torchtext.data,     from to...\n",
       "16044    [import torch\\r\\n\\r\\n# downloading the model f...\n",
       "16045                                              [model]\n",
       "16046    [import torch.nn as nn\\r\\n\\r\\nclass NNet(nn.Mo...\n",
       "16047                                                  NaN\n",
       "16048    [model = models.resnet152(pretrained=True)\\r\\n...\n",
       "16049    [Model.fc = nn.Sequential()\\r\\n\\r\\n, class Ide...\n",
       "16050    [import torch.nn as nn\\r\\nfrom collections imp...\n",
       "16051    [(fc): Linear(in_features=512, out_features=10...\n",
       "16052    [grad_seq = [torch.ones(1).cuda(gpu) for _ in ...\n",
       "16055                                               [CUDA]\n",
       "16056                                                  NaN\n",
       "16057    [loss.backward(), loss.backward(), optimiser.z...\n",
       "16059    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "16060                                                  NaN\n",
       "16061    [class PR(torch.nn.Module):\\r\\n    def __init_...\n",
       "16062    [class PR(nn.Module):\\r\\n        def __init__(...\n",
       "16063    [s1 = torch.cuda.Stream()\\r\\ns2 = torch.cuda.S...\n",
       "16065    [weight = torch.nn.Parameter(torch.ones(1, 3, ...\n",
       "16066    [retain_graph, import numpy as np\\r\\nimport to...\n",
       "16067    [class Flatten(nn.Module):\\r\\n    def forward(...\n",
       "16068    [nn.Flatten(), def get_flat_fts(self, input_sh...\n",
       "16069    [__getitem__, class CancerDataset(Dataset):\\r\\...\n",
       "16070                                                  NaN\n",
       "16073    [grad_h, grad_h = derivative of ReLu(x) * inco...\n",
       "16074    [retain_graph=True, retain_graph=True, x = tor...\n",
       "16075    [$ conda update anaconda-navigator, $ conda up...\n",
       "16077    [N, D_in, H, D_out = 128, 1000, 500, 10\\r\\ndty...\n",
       "16079    [def forward(self, x):\\r\\n    print ('input', ...\n",
       "16080                                                  NaN\n",
       "16081    [[1,1,28,28], [1,3,28,28], images = images[:,0...\n",
       "16082    [ImageFolder, def pil_loader(path):\\r\\n    wit...\n",
       "16083      [__getitem__, Y = 0.299 R + 0.587 G + 0.114 B.]\n",
       "16084    [sudo apt-get purge nvidia., $ sudo add-apt-re...\n",
       "16085    [import torch\\r\\ninput = torch.randn(64, 22, 9...\n",
       "16086      [iloc, self.landmarks_frame.iloc[index, 0]\\r\\n]\n",
       "16087    [batch_size=1, import torch\\r\\nimport pandas a...\n",
       "16088    [def forward(self, x):\\r\\n     x = self.conv1(...\n",
       "16090    [class ConvNet(nn.Module):\\r\\n    def __init__...\n",
       "16091    [stride=2, kernel_size, stride=2, kernel_size=...\n",
       "16092                                                  NaN\n",
       "16094    [=, a + 1, a = a + 1, a + 1, a, a += 1, a, __i...\n",
       "16095    [[[[0.86471446, 0.26302726],\\r\\n  [0.04137454,...\n",
       "16096                                                  NaN\n",
       "16097    [bxy,iyk-&gt;bxik, einsum, torch.einsum('bxy,i...\n",
       "16099    [## TODO: Rescale the detected face to be the ...\n",
       "16100                                                  NaN\n",
       "16101                                   [np.vstack(a)\\r\\n]\n",
       "16102    [sudo apt-get update\\r\\nsudo apt-get dist-upgr...\n",
       "16103    [W, def baseline_als(y, lam=100000, p=1e-3, ni...\n",
       "16104    [x2 = torch.tensor(np.transpose(npo, [0, 3, 2,...\n",
       "16105                                                  NaN\n",
       "16107    [# Prerequisites\\r\\nAnaconda, manages Python e...\n",
       "16108                                                  NaN\n",
       "16109                                                  NaN\n",
       "16110    [# for pytorch, the right format for image is ...\n",
       "16111    [torch.Tensor, torch.nn.functional.pad, import...\n",
       "16112    [torch.nn.utils.rnn.pad_sequence, import torch...\n",
       "16113    [PNASNetLarge, ResNets, UNet, ResNets, __init_...\n",
       "16114                                                  NaN\n",
       "16115                                                  NaN\n",
       "16117                                  [tensor = var.data]\n",
       "16118    [model.to('cuda')\\r\\nmodel.eval()\\r\\naccuracy ...\n",
       "16119    [torch.save(model.state_dict(), 'checkpoint.pt...\n",
       "16120    [import torch\\r\\ntorch.manual_seed(0)\\r\\nN = 1...\n",
       "16121                      [del, torch.cuda.empty_cache()]\n",
       "16122    [batch_size, [batch_size, sequence_length, inp...\n",
       "16123    [torch.cat, center, conv5, conv5, pool, center...\n",
       "16124    [data.Sampler, data.DataLoader, Dataset, data....\n",
       "16125    [def validation(model, testloader, criterion):...\n",
       "16127    [if torch.cuda.is_available():\\r\\n        inpu...\n",
       "16128    [def validation(model, testloader, criterion):...\n",
       "16129    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16130    [preprocessing_args= {'image_scale' : (1.0/255...\n",
       "16131    [__hash__, id, class Foo:\\r\\n    pass\\r\\n\\r\\ni...\n",
       "16132                                                  NaN\n",
       "16133    [.repeat(), In [1]: torch.Tensor([1, 2, 3]).re...\n",
       "16134                                            [forward]\n",
       "16136    [layer1, layer2, model1, mode2, feature_ex = n...\n",
       "16137    [# a.shape (16L, 10L)\\r\\n# idx.shape (16L,1)\\r...\n",
       "16138    [def torch_gather(x, indices, gather_axis):\\r\\...\n",
       "16139    [        # last-axis gathering only - use 2D-r...\n",
       "16140    [def original_order(ordered, indices):\\r\\n    ...\n",
       "16141    [tf.nn.top_k, dist, idx = tf.nn.top_k(inputs, ...\n",
       "16142    [__getitem__, Dataset, __getitem__, MNIST, def...\n",
       "16143                                       [tf.gather_nd]\n",
       "16145    [self.hidden2tag(lstm_out.view(len(sentence), ...\n",
       "16146    [if self.y_vars is not None:\\r\\n    y = torch....\n",
       "16148    [b, chunk, b, &gt;&gt; a = torch.arange(3*3*3*...\n",
       "16149    [with-device, device, .cuda(), # allocates a t...\n",
       "16150    [size(), numpy(), &gt;&gt; [t.size() for t in ...\n",
       "16151    [nparray = tensor.numpy()\\r\\n, tensor_size = t...\n",
       "16152    [with torch.no_grad():\\r\\n    probs = [t.numpy...\n",
       "16153           [pytorch, loss.backward()\\r\\n, alpha, nan]\n",
       "16154    [backwards(), w_r = w_r.type(torch.LongTensor)...\n",
       "16155    [   rank_loss = torch.mean([torch.max(0,alpha ...\n",
       "16156                                                  NaN\n",
       "16157                            [conv1, conv2, nn.Linear]\n",
       "16161    [G_loss, .detach(), .clone(), train(), D_loss,...\n",
       "16162    [a, [a00, a01], [a10, a11], b, norm, n1, n2 = ...\n",
       "16164    [nn.Conv2d, nn.Linear, num_classes, self.layer...\n",
       "16165    [torch.Tensor, import matplotlib.pyplot as plt...\n",
       "16167    [torch.Tensor, torch.Tensor, torch.Tensor(), d...\n",
       "16170    [torch.Tensor, nn.Linear, nn._ConvNd, torch.em...\n",
       "16171    [im.transpose(0, 3, 1, 2), im, im.shape, (224,...\n",
       "16172    [.transpose, im.permute(), im.permute(0, 3, 1,...\n",
       "16173    [dtype=torch.float, import torch\\r\\n\\r\\nx = to...\n",
       "16174                                                  NaN\n",
       "16175      [class_to_idx, data.classes, data.class_to_idx]\n",
       "16177    [&lt;absolute path to python.exe&gt; -m pip in...\n",
       "16178    [class QandA(nn.Module):\\r\\n    def __init__(s...\n",
       "16179                                                  NaN\n",
       "16180                                                  NaN\n",
       "16181    [self.fc = nn.Linear(7*7*32, num_classes), (10...\n",
       "16183    [Pipfile, pytorch, whl, [packages]\\r\\npyfoo = ...\n",
       "16184    [AC, import torch\\r\\n\\r\\ndef get_points_from_l...\n",
       "16185                                                  NaN\n",
       "16186                                                  NaN\n",
       "16187    [allennlp, torch&gt;=0.4.0,&lt;0.5.0, torch==0...\n",
       "16188    [optimizer.zero_grad() #RMSprop on net\\r\\nif e...\n",
       "16189        [test_tensor = torch.Tensor(test.values)\\r\\n]\n",
       "16190    [.values, import torch\\r\\nimport pandas as pd\\...\n",
       "16191    [to_numpy, values, train_tensor = torch.tensor...\n",
       "16192    [import numpy as np\\r\\nimport torch\\r\\n\\r\\nten...\n",
       "16193    [.pth.tar, nn.Module, torch.save, nn.Module, t...\n",
       "16194    [list, tensor_list, tensor_list =[]\\r\\nfor i,c...\n",
       "16195    [h, output, states, dynamic_rnn, grad_fn, impo...\n",
       "16196                                                  NaN\n",
       "16197    [data, tmp = torch.ones(3, 2, 2, requires_grad...\n",
       "16198    [import torch\\r\\nimport torch.nn.functional as...\n",
       "16199                 [y, torch.int64, CrossEntropyLoss()]\n",
       "16200    [from torch import nn\\r\\nnet = nn.Linear(input...\n",
       "16201                       [targets, logits, torch.int64]\n",
       "16202    [a = torch.rand((2), requires_grad=True)\\r\\npr...\n",
       "16203    [is_leaf, a = torch.tensor([3.,2.,7.], require...\n",
       "16204       [c[i] = i, __setitem__, __setitem__, c[i] = i]\n",
       "16205    [import torch\\r\\nfrom modelfolder import yourm...\n",
       "16206    [ToTensor, Normalize, Resize, train_transforms...\n",
       "16207    [t_ = transforms.Compose([transforms.ToPILImag...\n",
       "16208    [transforms.Normalize, # imagenet normalize\\r\\...\n",
       "16209        [torchvision.transforms.functional.normalize]\n",
       "16212    [module.parameters(), module.zero_grad(), requ...\n",
       "16213    [class tree:\\r\\n    def __init__(self, value, ...\n",
       "16214    [import torch\\r\\nfrom torchvision.transforms i...\n",
       "16215    [    TEXT = data.Field(sequential=True,tokeniz...\n",
       "16216    [nn.Bilinear, B(x1, x2) = x1*A*x2 + b, A, nn.B...\n",
       "16217    [from copy import copy\\r\\n\\r\\ntrain_dataset, t...\n",
       "16218    [class Subset(Dataset):\\r\\n    r\"\"\"\\r\\n    Sub...\n",
       "16219    [import torch\\r\\nfrom torch.utils.data import ...\n",
       "16220    [collate_fn, def collate_fn_transform(transfor...\n",
       "16221                                                  NaN\n",
       "16222    [Residual, Residual, class Residual(nn.Module)...\n",
       "16223    [UnetSkipConnectionBlock.forward(), UnetSkipCo...\n",
       "16225    [3, 32, 32, 32, 32, 3, image, image = image.tr...\n",
       "16226    [def push_to_tensor_alternative(tensor, x):\\r\\...\n",
       "16227    [n, n, collections.deque, import time\\r\\nimpor...\n",
       "16228    [add_param_group, param_group, dict, import to...\n",
       "16229    [dataloader, [batch, channel, height, width], ...\n",
       "16230      [train_np = np.array(train_loader.dataset)\\r\\n]\n",
       "16231    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16232    [export LD_LIBRARY_PATH= \"/usr/local/cuda-9.1/...\n",
       "16233    [pip3 uninstall torch\\r\\npip3 install https://...\n",
       "16234    [conda install pytorch torchvision cudatoolkit...\n",
       "16235    [import torch\\r\\nparameter_vector = torch.tens...\n",
       "16236    [requires_grad, False, model = torchvision.mod...\n",
       "16239    [requires_grad=True, l = nn.Linear(1, 1)\\r\\np ...\n",
       "16241                                                  NaN\n",
       "16242    [.data, Variable, Tensor, Tensor, .data, Varia...\n",
       "16243    [model = nn.Sequential(nn.Linear(10, 1))\\r\\n, ...\n",
       "16245                                                  NaN\n",
       "16246    [$ pip install --upgrade git+https://github.co...\n",
       "16247    [N, N, D_in, # -*- coding: utf-8 -*-\\r\\nimport...\n",
       "16248    [torch.utils.data.DataLoader, torch.utils.data...\n",
       "16249                                                  NaN\n",
       "16250    [module, module__, NeuralNet, initialize_model...\n",
       "16251    [clone, weights = []\\r\\n\\r\\nfor param in model...\n",
       "16252                                                  NaN\n",
       "16253    [pytorch, pip install torchvision, None, pip3 ...\n",
       "16254    [In [1]: torch.nonzero((t == q).sum(dim=1) == ...\n",
       "16255    [import torch\\r\\n\\r\\nt = torch.tensor([[1, 0, ...\n",
       "16256    [torch.all(q.repeat((t.shape[1],1))==t, dim=1)...\n",
       "16257    [nn.Sequential, Sequential, torch.legacy.nn.Se...\n",
       "16259         [cuda runtine error, CUDA_LAUNCH_BLOCKING=1]\n",
       "16260    [target = [1,2,3,4,5]\\r\\n, 1, target = [0,1,2,...\n",
       "16261    [RuntimeError, torch.Tensor, list, IndexError,...\n",
       "16262    [max(train_labels)\\r\\nmin(train_labels)\\r\\n, t...\n",
       "16263    [batch_data = batch_data[batch_data != batch_d...\n",
       "16264    [transforms.ToTensor(), lighting(), PIL, light...\n",
       "16265    [batch['doc_tok'], index, Embedding, batch['do...\n",
       "16266    [batch['doc_tok']=batch['doc_tok'].long().cpu(...\n",
       "16267                                                  NaN\n",
       "16268    [f, long_tensor = f.long(), cuda, cuda_tensor....\n",
       "16269    [.cuda(), .cpu(), .to(torch.device(\"cpu\")), A ...\n",
       "16270           [t, t = t.cpu() \\r\\n, t = t.to(\"cpu\")\\r\\n]\n",
       "16271    [x, [-1, 1], [0, 1], [-1, 1], torchvision.tran...\n",
       "16272    [params.require_grad = False, params.requires_...\n",
       "16273    [torch.nn, torch.nn.functional, nn.Sequential(...\n",
       "16274                                                  NaN\n",
       "16275    [AssertionError: nn criterions don't compute t...\n",
       "16276                 [pip3 install torchvision --no-deps]\n",
       "16277                                                  NaN\n",
       "16278                                                  NaN\n",
       "16279                                                  NaN\n",
       "16280                                                  NaN\n",
       "16281                                                  NaN\n",
       "16282    [tensors, variable length in dimension 0, impo...\n",
       "16283                                          [set_epoch]\n",
       "16284    [DNetwork, # Set up batch size, image size, an...\n",
       "16285    [create_graph, backward, loss = get_loss()\\r\\n...\n",
       "16286    [ImageFolder, train/daisy, train/dandelion, te...\n",
       "16287    [import splitfolders\\r\\nsplitfolders.ratio(ima...\n",
       "16288                                                  NaN\n",
       "16289                                                  NaN\n",
       "16290                                                  NaN\n",
       "16291     [x, correct/x.shape[0], correct/output.shape[0]]\n",
       "16292    [for epoch in range(num_epochs):\\r\\n\\r\\n    co...\n",
       "16293    [total = 0\\r\\nwith torch.no_grad():\\r\\n    net...\n",
       "16294    [def evaluate(model, validation_loader, use_cu...\n",
       "16295    [  Accuracy = Total Correct Observations / Tot...\n",
       "16296    [def train(model, train_loader):\\r\\nmodel.trai...\n",
       "16297    [acc == (true == mdl(x).max(1).item() / true.s...\n",
       "16298    [#%%\\r\\n\\r\\n# refs:\\r\\n# https://stackoverflow...\n",
       "16299    [2022-08-08 12:26:48,472 Epoch [20/20], Step [...\n",
       "16300    [from torchmetrics import Accuracy\\r\\n\\r\\naccu...\n",
       "16301    [alexnet, new_model = models.alexnet(pretraine...\n",
       "16303    [x_data, self.linear2.weight = torch.nn.Parame...\n",
       "16304    [conda create -n py_env python=3.5, source act...\n",
       "16305                  [pip install torch torchvision\\r\\n]\n",
       "16306    [conda create -n pytorch_env python=3, source ...\n",
       "16307                 [CrossEntropyLoss, [0..n_classes-1]]\n",
       "16308                                                  NaN\n",
       "16309                                                  NaN\n",
       "16310    [embeds = nn.Embedding(2, 5), lookup_tensor = ...\n",
       "16311    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16312    [class Siamese(Dataset):\\r\\n\\r\\n\\r\\n    def __...\n",
       "16313    [dataset = torch.utils.data.TensorDataset(data...\n",
       "16314    [cycle(), zip(), dataloaders1 = DataLoader(Dum...\n",
       "16315    [zip(), DataLoader(), FileNotFoundError, Datas...\n",
       "16316    [cycle(), itertools, from torch.utils.data imp...\n",
       "16317    [class Holder(PointerHolderBase):\\r\\n\\r\\n    d...\n",
       "16318    [Tensor.scatter_(), sort(), torch.zeros(ch,h,w...\n",
       "16320    [nn.Module.train(), def train(self, mode=True)...\n",
       "16323    [import torch\\r\\nimport torch.nn.functional as...\n",
       "16325                                                  NaN\n",
       "16326    [sim_preds = converter.decode(preds.data, pred...\n",
       "16327    [cov(), cov(), M, HxW, H, W, cov(M), HxH, H, M...\n",
       "16328                                                  NaN\n",
       "16329    [torch.distributions.Bernoulli(), 1, 0, In [14...\n",
       "16330                                                  NaN\n",
       "16331    [pytorch, pickle, checkpoint = torch.load(\"xxx...\n",
       "16333    [Parameters, Tensor, Module, Module, parameter...\n",
       "16334    [def l_cross_entropy2d(input, target, weight=N...\n",
       "16335    [C, M, I, M(i,j) = c, I(i,j), c, c, [0; C[, i,...\n",
       "16336    [broadcasting, numpy broadcasting rules, In [2...\n",
       "16337    [a + b, a.shape = (2, 3, 4, 5, 1, 1, 1)\\r\\nb.s...\n",
       "16338         [model = models.vgg16_bn(pretrained = True)]\n",
       "16340    [qvalues, qvalues = torch.rand((5, 5), require...\n",
       "16341             [py:class:, :class:, dict, torch.Tensor]\n",
       "16342    [replay_buffer,     # get batches\\r\\n    batch...\n",
       "16343    [zero_grad(), self.actor_target, self.critic_t...\n",
       "16344    [i_batch, print(i_batch.shape), i_batch, [N], ...\n",
       "16347    [Dataset, def get_same_index(target, label):\\r...\n",
       "16348    [3x3, [3, 3], 1x128x32x32, import torch\\r\\n\\r\\...\n",
       "16349    [In [107]: import torchvision\\r\\n\\r\\n# sample ...\n",
       "16350    [import numpy as np\\r\\n\\r\\ndef show(img):\\r\\n ...\n",
       "16351    [torch.nn.DataParallel, import torch\\r\\nimport...\n",
       "16352                                                  NaN\n",
       "16355    [torch.index_select(), import torch\\r\\nimport ...\n",
       "16356    [y_true, y_pred, K.eval(K.binary_crossentropy(...\n",
       "16357    [model, logit = model(x)\\r\\nloss = torch.nn.fu...\n",
       "16358                                         [backward()]\n",
       "16359    [torch.einsum(), import torch\\r\\nimport numpy ...\n",
       "16360    [tensordot, axes, dims, import torch\\r\\nimport...\n",
       "16361            [det(D) = det(P)det(L)det(U)\\r\\n, (-1)^t]\n",
       "16362     [torch.linalg, torch.linalg.cholesky(input)\\r\\n]\n",
       "16363    [FILTER_SIZES = [3,4,5]\\r\\nspacy_en = spacy.lo...\n",
       "16364    [preprocessing, postprocessing, postprocessing...\n",
       "16365    [sth., [Anaconda PATH]\\Lib\\site-packages\\torch...\n",
       "16366    [acc += torch.sum(predClass == labels.data), a...\n",
       "16367    [for i in train_iter:\\r\\n    print i.Tweet\\r\\n...\n",
       "16368    [pad_packed_sequence, def forward(self, inputs...\n",
       "16369    [import torch\\r\\n\\r\\nD_in = 100\\r\\nD_out = 100...\n",
       "16370    [yr = (-1 / weights[1].item()) * (weights[0].i...\n",
       "16371    [labels = torch.tensor([-1,-1,-1,1], dtype=tor...\n",
       "16372    [Affect Dimension, Affect_Dimension, for i in ...\n",
       "16373    [3, R, G, B, 64, 11x11, 64, 96, One weird tric...\n",
       "16374    [startTime = datetime.now()\\r\\n# Create random...\n",
       "16375    [torch.tensor(), torch.Tensor(), torch.tensor(...\n",
       "16376                                                  NaN\n",
       "16377    [loss_fn = nn.MSELoss()\\r\\n\\r\\nbatch_size = 10...\n",
       "16378    [self, copy_, sent_states.data, =, .copy(), =,...\n",
       "16379                                                  NaN\n",
       "16380    [In [12]: aten = torch.tensor([[1, 2, 3], [4, ...\n",
       "16381    [a, a, In [7]: import torch\\r\\n\\r\\nIn [8]: a =...\n",
       "16384    [torch.empty(), torch.empty(), # a block of me...\n",
       "16385    [mt_train = datasets.SequenceTaggingDataset(pa...\n",
       "16386    [def weighted_logsumexp(x,w, dim=None, keepdim...\n",
       "16387    [def weights_init(m):\\r\\n    classname = m.__c...\n",
       "16388    [weight_dict = net.state_dict()\\r\\nnew_weight_...\n",
       "16389           [checkpoint, torch.cudnn.benchmark = True]\n",
       "16392    [pytorch, image_d = torch.FloatTensor(np.asarr...\n",
       "16393                             [neuralnet.parameters()]\n",
       "16394    [torch.nn.Parameter(), torch.autograd.Variable...\n",
       "16395    [b, a, In [43]: a\\r\\nOut[43]: \\r\\ntensor([[ 0....\n",
       "16396    [a = torch.rand(2,3)\\r\\nprint(a)\\r\\n\"\"\"Output ...\n",
       "16397    [In [2]: a = torch.rand(2,3)\\r\\n   ...: \\r\\n\\r...\n",
       "16398    [padding='SAME', num_channels, tf.tile, tf.nn....\n",
       "16399    [ def foo():\\r\\n       print(\"function\")\\r\\n\\r...\n",
       "16400    [# Forward and backward passes\\r\\noutput = mod...\n",
       "16401    [pre-trained model, criterion, classifier, inp...\n",
       "16402    [data = torch.Tensor([[1,2,3,4],[1,2,3,4]]), t...\n",
       "16403                                                  NaN\n",
       "16405    [model_ft = models.inception_v3(pretrained=Tru...\n",
       "16406    [model_ft.aux_logits=False\\r\\n\\r\\nmodel_ft.fc ...\n",
       "16407              [_, preds = torch.max(outputs.data, 1)]\n",
       "16408                     [output, aux = model(input_var)]\n",
       "16409    [torch.nn.Module, __init__, forward, # Code in...\n",
       "16410    [import torch\\r\\nimport math\\r\\nimport matplot...\n",
       "16411                                      [nan, nan, nan]\n",
       "16412    [ a = [torch.tensor([1,2,3]), torch.tensor([3,...\n",
       "16413    [pack_padded_sequence(), 6, 6, batch_size, bat...\n",
       "16414    [pack_padded_sequence, pack_padded_sequence, i...\n",
       "16418    [criterion = torch.nn.CrossEntropyLoss().cuda(...\n",
       "16419    [torch.bmm(), torch.squeeze(), torch.unsqueeze...\n",
       "16420    [torch.gather, torch.Tensor.gather, t = torch....\n",
       "16421    [torch.gather, dim, torch.LongTensor, index, r...\n",
       "16422    [source, torch.Size([4, 3]), source = torch.te...\n",
       "16423    [torch.gather, torch.gather(input, dim, index,...\n",
       "16424    [Tensor.view(), import torch\\r\\n\\r\\ndef magic_...\n",
       "16425    [a = torch.zeros(1, 2, 3, 4, 5, 6)\\r\\nb = a.vi...\n",
       "16426    [&gt; pip install einops\\r\\n, from einops impo...\n",
       "16427    [flatten, start_dim, end_dim, magic_combine, e...\n",
       "16428                         [if __name__ == '__main__':]\n",
       "16429                                                  NaN\n",
       "16430    [RandomSampler, SubsetRandomSampler, A, B, ind...\n",
       "16431    [torch.einsum, torch.reshape, AB = torch.einsu...\n",
       "16432    [parameters = list(Model1.parameters())+ list(...\n",
       "16433    [Class CNN(nn.Module):...\\r\\n\\r\\nhparams1=[......\n",
       "16434    [1..N, N = 4, (N,), label(img1) = [0, 0, 0, 1]...\n",
       "16435                                                  NaN\n",
       "16436    [m = nn.Linear(20, 30)\\r\\ninput = Variable(tor...\n",
       "16437    [(sequence, batch, feature), (batch, sequence,...\n",
       "16438                                     [model.to(cuda)]\n",
       "16439    [RandomResizedCrop, ...ResizedCrop, Random...,...\n",
       "16440    [conda install pytorch-cpu -c pytorch \\r\\npip ...\n",
       "16441           [conda install torchvision -c pytorch\\r\\n]\n",
       "16444                                [b_y = b_y.squeeze()]\n",
       "16445                                                  NaN\n",
       "16446                   [loss.backward(retain_graph=True)]\n",
       "16447    [torch.nn.CrossEntropy(), torch.nn.CrossEntrop...\n",
       "16448    [torch.nn.CrossEntropyLoss, torch.nn.functiona...\n",
       "16449    [enumerate(), (x, y), \"image\", \"labels\", for i...\n",
       "16450    [torch.onnx.export(model,dummy_input , 'model....\n",
       "16451    [bidirectional=True, u_emb_batch = (lasthidden...\n",
       "16452    [output, (seq_len, batch, num_directions * hid...\n",
       "16453    [# shape of x is size(batch_size, time_steps, ...\n",
       "16455    [torch.nn.Module, model.__call__(...), model(x...\n",
       "16456    [if __name__ == '__main__', # required imports...\n",
       "16457    [multiprocessing, if __name__ == '__main__':\\r\\n]\n",
       "16458                                                  NaN\n",
       "16459                                                  NaN\n",
       "16462    [%%timeit\\r\\nx = torch.rand([1,1,1000,1000])\\r...\n",
       "16463    [B x S x d, B x S x h, B x 1 x d, B x 1 x h, T...\n",
       "16465    [bmm, matmul,         attn_applied = torch.bmm...\n",
       "16466    [if len_grad == 2: grad_bias = -1 * grad_out \\...\n",
       "16467    [default_loader(), torchvision/datasets/folder...\n",
       "16468    [class SelectItem(nn.Module):\\r\\n    def __ini...\n",
       "16469    [pip3 install http://download.pytorch.org/whl/...\n",
       "16470    [pip install torchvision\\r\\n, pip install --no...\n",
       "16471    [pip install torch===1.5.0 torchvision===0.6.0...\n",
       "16472    [backward, step, def d(y, x):\\r\\n    return to...\n",
       "16474    [DatasetFolder, class LimitDataset(data.Datase...\n",
       "16475    [zeros[rows, raw_target] = 1., import numpy as...\n",
       "16476                   [%timeit, zeros[rows, target] = 1]\n",
       "16477    [-1, numpy.reshape(), import torch\\r\\n\\r\\nx = ...\n",
       "16478    [tensor.view(-1), tensor.view(-1, Dnew), (D1, ...\n",
       "16479    [np.reshape, a = torch.arange(1, 18), a.view(-...\n",
       "16480    [ x = torch.randn(4, 4)\\r\\n x.size()\\r\\ntorch....\n",
       "16481    [ a = torch.rand(4,4)\\r\\n a.size()\\r\\ntorch.si...\n",
       "16482    [-1, numpy.reshape(), t.view(1,17), t.view(1,-...\n",
       "16483    [Tensor.reshape(), torch.mm(), torch.einsum(),...\n",
       "16484    [#WAS\\r\\nmodel.load_state_dict(torch.load(fina...\n",
       "16485    [import torch\\r\\nprint(torch.cuda.is_available...\n",
       "16486    [torch.cuda.device(), torch.cuda.set_device(0)...\n",
       "16488    [I, K, I, K, K, I, W x H x 3, ConvLayer, 3 by ...\n",
       "16489    [import torch\\r\\n\\r\\nx = torch.mm(torch.randn(...\n",
       "16490                    [torch.bmm, torch.bmm, torch.bmm]\n",
       "16491                                                  NaN\n",
       "16492    [accuracy += (correct/total)\\r\\n, avg_accuracy...\n",
       "16493    [[1,2,3,4,5,....,100], inputs, [1,2,3,4,5,.......\n",
       "16494    [image = trainset[1][0]\\r\\n\\r\\nprint(image)\\r\\...\n",
       "16495    [Tanh(), -1, 1, train_discriminator(), # train...\n",
       "16496                                     [python_version]\n",
       "16497                                                  NaN\n",
       "16498    [In [15]: x = torch.randn(3, requires_grad=Tru...\n",
       "16499    [y.data.norm() \\r\\n, torch.sqrt(torch.sum(torc...\n",
       "16500    [x = torch.ones(3, requires_grad=True)\\r\\nprin...\n",
       "16502    [loss.backward(), loss.backward(), net, nn.Mod...\n",
       "16503    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "16505    [nn.Embedding, import torch.nn as nn \\r\\n\\r\\n#...\n",
       "16506    [torch.nn.Embedding, from collections import C...\n",
       "16507    [nn.Embedding.from_pretrained(weight), import ...\n",
       "16508    [retain_graph, x, y1, import torch\\r\\n\\r\\nw = ...\n",
       "16509    [mask_weights.register_hook(print)\\r\\n\\r\\nz = ...\n",
       "16510                                                  NaN\n",
       "16511    [import torch.multiprocessing as mp\\r\\nimport ...\n",
       "16512    [RuntimeError: CUDA error: initialization erro...\n",
       "16513                                                  NaN\n",
       "16514    [tensor.reshape(new_shape), torch.reshape(tens...\n",
       "16517    [numpy.moveaxis(), In [90]: aa\\r\\nOut[90]: \\r\\...\n",
       "16518    [(Pdb) torch.transpose(aa, 0, 2).t()\\r\\ntensor...\n",
       "16519                                                  NaN\n",
       "16520    [torch.onnx.export, export_params=False, Weigh...\n",
       "16522    [files.upload(), pytorch type/model, a = files...\n",
       "16523    [ht[-1], ht[-1], # feed to rnn\\r\\npacked_outpu...\n",
       "16524    [torch.eq(), torch.unique(), torch.sort(), (le...\n",
       "16525    [def slice_torch_sparse_coo_tensor(t, slices):...\n",
       "16526    [coo_matrix, import torch\\r\\nimport numpy as n...\n",
       "16527    [import torch\\r\\nimport numpy as np\\r\\nfrom sc...\n",
       "16528                                     [custom_sampler]\n",
       "16529    [CustomSampler, mx.gluon.data.DataLoader, batc...\n",
       "16530    [torch.index_select(), Z = np.random.rand(100,...\n",
       "16531    [_image = np.array(_image)\\r\\nimage = torch.fr...\n",
       "16532    [torch.nn.CrossEntropyLoss, input, (30, C, 96,...\n",
       "16533                                                  NaN\n",
       "16534    [AttributeError, AttributeError: module 'torch...\n",
       "16535    [pip uninstall pytorch\\r\\n, pip install pytorc...\n",
       "16536    [conda install -c soumith pytorch\\r\\n, conda i...\n",
       "16537    [torch.nn.conv2d(), torch.nn.functional.conv2d...\n",
       "16538               [x = torch.rand(5, 3)\\r\\nprint(x)\\r\\n]\n",
       "16539                   [conda install pytorch -c pytorch]\n",
       "16540        [conda install -c peterjc123 pytorch-cpu\\r\\n]\n",
       "16543                        [BCE, size_average=True, KLD]\n",
       "16544    [def index_max(child, idx, num_partitions): \\r...\n",
       "16545    [retain_graph=True, opt.zero_grad(), opt.zero_...\n",
       "16546                                                  NaN\n",
       "16547    [import copy\\r\\nforward(self, input)\\r\\n    x ...\n",
       "16549    [embedding_size, hidden_size, class EncoderRNN...\n",
       "16550    [torch.bmm(), import torch\\r\\nfrom torch.autog...\n",
       "16551    [pytorch, torch.einsum('ijk,abk-&gt;abc', (rnn...\n",
       "16552                                                  NaN\n",
       "16553    [torch.nn.Linear, torch.nn.LSTM, torch.nn.Line...\n",
       "16554    [lstm = nn.LSTM(3, 3)  # Input dim is 3, outpu...\n",
       "16555    [SubsetRandomSampler, import torch\\r\\nimport n...\n",
       "16556    [random_split, train_size = int(0.8 * len(full...\n",
       "16557    [ds, k, def sampleFromClass(ds, k):\\r\\n    cla...\n",
       "16558    [train_test_split, sklearn, data, from torch.u...\n",
       "16559    [Subset, random_split, SubsetRandomSampler, ra...\n",
       "16560    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16561    [def stratify_split(dataset: Dataset, train_sa...\n",
       "16562    [sudo -S env RELEASE_UPGRADER_NO_SCREEN=1 do-r...\n",
       "16563                                                  NaN\n",
       "16564    [device = torch.device(\"cuda:0\" if torch.cuda....\n",
       "16565    [class Net(nn.Module):\\r\\n\\r\\n  def __init__(s...\n",
       "16566    [[2000, 1, 2000], import torch\\r\\nimport numpy...\n",
       "16567    [[\"the\",\"fox\",\"jumped\", \"over\",\"the\",\"lazy\"] \\...\n",
       "16568                                                  NaN\n",
       "16569    [dtype = torch.cuda.float if torch.cuda.is_ava...\n",
       "16571    [torch.tensor, 'cpu', torch.FloatTensor()     ...\n",
       "16574    [pip install --upgrade pip\\r\\n, pip install to...\n",
       "16575    [ sudo apt-get update\\r\\n,  pip install torch=...\n",
       "16576    [trainloader = torch.utils.data.DataLoader(tra...\n",
       "16577    [def run():\\r\\n   # code goes here\\r\\n\\r\\nif _...\n",
       "16578    [**NOTE:** These examples have been update for...\n",
       "16579    [conda list | grep pytorch \\r\\nconda upgrade c...\n",
       "16580                                                  NaN\n",
       "16581                                                  NaN\n",
       "16582                                                  NaN\n",
       "16583    [torch.stack([torch.from_numpy(b) for b in bat...\n",
       "16584                                                  NaN\n",
       "16585    [requires_grad = True, requires_grad = False, ...\n",
       "16586    [DataParallel, module, for epoch in range(EPOC...\n",
       "16587    [self.model = model \\r\\n# Since if the model i...\n",
       "16589    [[700, 2] (batch x data), [1, 700] (data x bat...\n",
       "16590    [device = torch.device('cuda')\\r\\nmodel = ResN...\n",
       "16591    [mkdir test_torch\\r\\ncd test_torch\\r\\npython3 ...\n",
       "16592                            [brew install libomp\\r\\n]\n",
       "16593    [conv2d, img = img/255, __getitem__, float, by...\n",
       "16594    [inputs = inputs.type(torch.FloatTensor)\\r\\n, ...\n",
       "16595    [[block_1 x1; block_2 x1] xN, block_1, block_2...\n",
       "16596    [import torch\\r\\nfrom scipy import spatial\\r\\n...\n",
       "16597    [eps, def sim_matrix(a, b, eps=1e-8):\\r\\n    \"...\n",
       "16598    [def sim_matrix(a, b, eps=1e-8):\\r\\n    \"\"\"\\r\\...\n",
       "16599    [import torch as t\\r\\na = t.randn(2,4)\\r\\nprin...\n",
       "16600                       [torch.nn.functional.upsample]\n",
       "16601    [def custom_loss(tensor1, tensor2):\\r\\n    # c...\n",
       "16602    [# Test the model\\r\\nwith torch.no_grad():\\r\\n...\n",
       "16603               [self.gru(input, h_0)\\r\\n, input, h_0]\n",
       "16604                                       [GRUCell, GRU]\n",
       "16605    [torch.cat(), torch.stack(), import torch\\r\\n\\...\n",
       "16606    [torch.argmax(), prediction = torch.argmax(ten...\n",
       "16609    [C:\\Users\\Saeed\\AppData\\Local\\Programs\\Python\\...\n",
       "16610    [f = x + y + z, w = torch.cat([x, y, z])\\r\\nf ...\n",
       "16611    [for data in dataloaders['val']:\\r\\n    images...\n",
       "16612                [requires_grad, False, requires_grad]\n",
       "16613                              [sudo rm -rf ~/.nv\\r\\n]\n",
       "16614                        [gt = gt.repeat(2, 1, 1)\\r\\n]\n",
       "16615    [grad, import torch\\r\\nfrom torch.autograd imp...\n",
       "16616    [hessian, torch.autograd.functional.hessian()\\...\n",
       "16617    [rand, .pylintrc, [TYPECHECK]\\r\\n\\r\\n# List of...\n",
       "16618    [Press: CTRL + Shift + P\\r\\n\\r\\nClick on \"Pref...\n",
       "16620                                                  NaN\n",
       "16621            [Dropout, p=0.5, net.train(), net.eval()]\n",
       "16622    [ImageFolder, DataSetFolder, ImageFolder, ['.f...\n",
       "16623    [from astropy.io import fits\\r\\nimport matplot...\n",
       "16624    [labels = []\\r\\ntransform = transforms.Compose...\n",
       "16627    [import numpy as np\\r\\nimport torch\\r\\nfrom to...\n",
       "16629    [input = torch.LongTensor([[1,2,4,5],[4,3,2,9]...\n",
       "16630    [conda install pytorch-cpu torchvision-cpu -c ...\n",
       "16631    [Anaconda, conda install pytorch -c pytorch\\r\\...\n",
       "16632    [torchtext, PyTorch, torchtext, PyTorch 0.4.0,...\n",
       "16634                                                  NaN\n",
       "16635                                [backwards(vec), vec]\n",
       "16636    [torch.autograd.functional.jacobian(func, inpu...\n",
       "16637    [LongTensor, import random\\r\\n\\r\\ndef add_unk(...\n",
       "16638    [def softmax(x):\\r\\n    return np.exp(x) / np....\n",
       "16639    [import math\\r\\nimport torch as th\\r\\nimport t...\n",
       "16640    [LSTMFrame, LayerNormLSTM, # snippet from rnn_...\n",
       "16641    [torch.autograd.variable.Variable\\r\\n, 0.3.1, ...\n",
       "16642    [torch.autograd.variable.Variable, torch.autog...\n",
       "16643    [reg = 0\\r\\nfor param in CNN.parameters():\\r\\n...\n",
       "16644    [train.py, num_classes, input_size, train.py, ...\n",
       "16645    [class LayerNormLSTMCell(nn.LSTMCell):\\r\\n\\r\\n...\n",
       "16646                                             [eval()]\n",
       "16647    [ trainable = torch.ones(1, requires_grad=True...\n",
       "16648    [combine_nets, def combine_nets(net_train, net...\n",
       "16650    [__len__, def __len__(self):\\r\\n    return len...\n",
       "16651    [torch.unbind, In [1]: import torch\\r\\n\\r\\nIn ...\n",
       "16652    [stack, unbind, def batch_stripe(a):\\r\\n    b,...\n",
       "16654    [x, torch.tensor(x, requires_grad=True)\\r\\n, i...\n",
       "16655    [item(), 0.4.0, item(), item(), item(), def f(...\n",
       "16656    [self.features=nn.Sequential(*list(original_mo...\n",
       "16657    [self.conv1 = nn.Conv2d(in_channels=1,...), im...\n",
       "16658            [input, input, torch.unsqueeze(input, 0)]\n",
       "16659                                                  NaN\n",
       "16661    [ResNet152, def image_loader(loader, image_nam...\n",
       "16662    [in_features, out_features, weight1, bias, def...\n",
       "16664                           [layer.weight.data, .data]\n",
       "16665    [def load_dataset():\\r\\n    data_path = 'data/...\n",
       "16666    [import torch\\r\\nimport torchvision\\r\\nimport ...\n",
       "16667    [# abs_cosine should be a Tensor of shape (m, ...\n",
       "16668    [import numba as nb\\r\\n@nb.njit(fastmath=True)...\n",
       "16669         [torch.set_printoptions(sci_mode=False)\\r\\n]\n",
       "16670    [def ReLU(x):\\r\\n    if(x &gt; 0):\\r\\n        ...\n",
       "16671    [batch_size = 8\\r\\nsequence_length = 10\\r\\ninp...\n",
       "16672    [from torch.autograd import Variable\\r\\n\\r\\nim...\n",
       "16673    [import torch\\r\\nimport torchvision.models as ...\n",
       "16674    [transforms.Compose, transforms.Compose, trans...\n",
       "16675    [(3*224*224), (3, 224, 224), classifier = nn.S...\n",
       "16677    [1, n_classes, 0, n_classes-1, one_hot_target ...\n",
       "16678    [stride_tricks,  import numpy as np\\r\\n \\r\\n d...\n",
       "16679    [offset, numpy.diagonal(), a = np.array([[0, 1...\n",
       "16680    [import torch\\r\\n\\r\\ndef stripe(a):\\r\\n    i, ...\n",
       "16681    [200x200px, size, height x width, nn.Conv2d, c...\n",
       "16682                                                  NaN\n",
       "16683                                                  NaN\n",
       "16686    [pytorch_env, conda create -n pytorch_env -c p...\n",
       "16687    [Verify the installation with import torch not...\n",
       "16688    [#!/usr/bin/env python3\\r\\n# -*- coding: utf-8...\n",
       "16689      [                        x_t = x_(t-1) + r\\r\\n]\n",
       "16690    [OrderedDict, import torch\\r\\nimport torch.nn ...\n",
       "16691    [torch.save(model_conv,'cnn.pt')\\r\\nthe_model ...\n",
       "16692    [x = np.transpose(np.array([[1, 2, 3, 4]]))\\r\\...\n",
       "16693    [# Assuming that input.size() is (N, D, W, H) ...\n",
       "16694    [torch.where, import torch\\r\\nfrom torch.autog...\n",
       "16695    [switch, torch.autograd.Function, class switch...\n",
       "16696    [MKL, conda install -c anaconda mkl\\r\\n, conda...\n",
       "16697    [conda install pytorch-cpu torchvision-cpu -c ...\n",
       "16698    [pip install torch==1.2.0+cpu torchvision==0.4...\n",
       "16699    [conda create -n pytorch_env python=3.5, sourc...\n",
       "16700    [python3 -m pip install torch torchvision \\r\\n...\n",
       "16701           [conda install -c pytorch torchvision\\r\\n]\n",
       "16702               [conda install -c pytorch pytorch\\r\\n]\n",
       "16704            [--network host, docker run, MASTER_ADDR]\n",
       "16705    [   normalize = transforms.Normalize(\\r\\n     ...\n",
       "16706    [!pip install torch\\r\\n!pip install torchvisio...\n",
       "16707    [import torch\\r\\nimport torch.nn as nn\\r\\nn, d...\n",
       "16708    [Keep_prop, keep_prob = 1 - drop_prob, tf.nn.d...\n",
       "16712    [nn.Module, loss.backward(), cust_loss, criter...\n",
       "16714    [layer, torch.norm, torch Tensor, .data, Param...\n",
       "16715                                                  NaN\n",
       "16716    [(max_indices == labels).sum()\\r\\n(max_indices...\n",
       "16717    [def error_criterion(outputs,labels):\\r\\n    m...\n",
       "16718    [x.view, x.view(batch_size, -1), Flatten, __re...\n",
       "16719    [volatile, x, y, x = Variable(torch.FloatTenso...\n",
       "16720                                                  NaN\n",
       "16722    [.detach(), # this is just my embedding matrix...\n",
       "16724    [na, import torch\\r\\na = torch.ones((1,2))\\r\\n...\n",
       "16726    [x.numpy(), RuntimeError: Can't call numpy() o...\n",
       "16727    [labels, outputs, label = label.squeeze_(), la...\n",
       "16730    [np.diagonal(a, axis1=1, axis2=2)\\r\\n, In [10]...\n",
       "16731    [a.reshape(a.shape[0],-1)[:,::a.shape[-1]+1]\\r...\n",
       "16734                      [cnn = CNN()\\r\\ncnn.eval()\\r\\n]\n",
       "16735    [def __getitem__(self, idx):\\r\\n        if tor...\n",
       "16736    [state_dict(), torch.save(), model.load_state_...\n",
       "16737    [!, !ls -l\\r\\n, {}, # Supposing you have epoch...\n",
       "16739    [conda install -c conda-forge ffmpeg \\r\\nconda...\n",
       "16740    [    self.conv = torch.nn.ModuleList()\\r\\n    ...\n",
       "16741    [module.parameter(), module.cuda(), class Mode...\n",
       "16743                                                  NaN\n",
       "16745    [torch.view, torch.reshape, torch.view,  z = t...\n",
       "16747    [a = torch.arange(8).reshape(2, 4)\\r\\n, a.stri...\n",
       "16749                                        [tokenize.py]\n",
       "16750    [import torch, import numpy, pip uninstall num...\n",
       "16751    [pipenv install git+https://github.com/pytorch...\n",
       "16752                      [torch.cuda.is_available()\\r\\n]\n",
       "16754    [3 x 256 x 256, B x N, nn.Linear(3*256*256, 12...\n",
       "16755    [RuntimeError: size mismatch, m1: [a x b], m2:...\n",
       "16756    [[76800 x 256], m2: [784 x 128] # Incorrect!\\r...\n",
       "16757                  [optimizer.step(), loss.backward()]\n",
       "16758    [\"super(rnn,self).__init__()\", \"super().__init...\n",
       "16759    [#!/usr/bin/env python\\r\\n# encoding: utf-8\\r\\...\n",
       "16760    [#!/usr/bin/env python\\r\\n# encoding: utf-8\\r\\...\n",
       "16761                                                  NaN\n",
       "16763    [enumerate, enumerate, X, y, X, y, __getitem__...\n",
       "16764    [for batch_index, batch in enumerate(dataloade...\n",
       "16765    [numpy.int64, int, numpy.int64, int, torch.ran...\n",
       "16766    [export PATH=/home/$USER/cuda-9.0/bin:\"$PATH\"\\...\n",
       "16767                                   [l = loss(tY)\\r\\n]\n",
       "16768    [@staticmethod, LinearFunction.backward(x, y)\\...\n",
       "16769    [@staticmethod, ctx, torch.nn.Module, forward(...\n",
       "16771    [ import torch\\r\\n n = 3\\r\\n t = torch.zeros((...\n",
       "16772    [for var_name in model.state_dict():\\r\\n    pr...\n",
       "16773                                          [LSTM, GRU]\n",
       "16774    [output = net(input)\\r\\ntarget = torch.randn(1...\n",
       "16776                                                  NaN\n",
       "16777    [(batch_size, seq_len, embedding_size), LSTM, ...\n",
       "16780                                                  NaN\n",
       "16781                                 [learner.eval()\\r\\n]\n",
       "16782    [[0, 0, 0, 1], 1, H(p, q), H(p, softmax(output...\n",
       "16783    [loss(x, class) = -log(exp(x[class]) / (\\sum_j...\n",
       "16784    [nn.LogSoftmax, nn.NLLLoss, nn.CrossEntropyLos...\n",
       "16785    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "16786    [import numpy as np\\r\\nfrom keras.model import...\n",
       "16787    [def save_checkpoint(state, filename='./checkp...\n",
       "16788    [print(self.conv1.state_dict()[\"weight\"][0])\\r...\n",
       "16789    [def sparse_mx_to_torch_sparse_tensor(sparse_m...\n",
       "16790                                                  [x]\n",
       "16791    [1, encoder_hidden = torch.randn(1, 4, 256)\\r\\...\n",
       "16792    [view(), decoder_hidden_new = decoder_hidden.v...\n",
       "16793    [# random tensor\\r\\nIn [53]: t.shape\\r\\nOut[53...\n",
       "16794                                                  NaN\n",
       "16795    [CE, xm  = torch.mean(x)\\r\\nym  = functionFit(...\n",
       "16796    [dd = cc, dd, cc, bb = aa, bb = bb * 2, *, bb,...\n",
       "16797    [aa = Variable(torch.FloatTensor([[1,2],[3,4]]...\n",
       "16798                          [model, x, x, model.cuda()]\n",
       "16799    [28 * 28, # compute loss of real_img\\r\\nreal_o...\n",
       "16800                                                  NaN\n",
       "16801                [pytorch, numpy, j, tensor[:, j]\\r\\n]\n",
       "16802    [class Seq2Seq(nn.Module):\\r\\n    \"\"\"A Seq2seq...\n",
       "16804    [ntokens = 8000\\r\\noutput = Variable(torch.ran...\n",
       "16805    [new_*, new, t = torch.randn((3, 4)), t = torc...\n",
       "16807                                                  NaN\n",
       "16808    [mu  = alpha * torch.mean(x[I[(1-rho)*N:N]]) +...\n",
       "16809    [torch.log, ln([0.5611,0.4389])=[-0.5778,-0.82...\n",
       "16810                             [torch.log, torch.log10]\n",
       "16811    [do_something, def do_something(gpu_device, on...\n",
       "16812    [print(str(fileDataSet[0], encoding='utf-8', e...\n",
       "16814    [nn.LSTM(input_size, hidden_size, 2)\\r\\n, nn.S...\n",
       "16816    [torch.cuda.FloatTensor(10, 10).uniform_() &gt...\n",
       "16817    [import numpy as np\\r\\nimport cudamat as cm\\r\\...\n",
       "16818    [import torch\\r\\n\\r\\ntensor = torch.rand((3, 5...\n",
       "16819    [CrossEntropyLoss(), criterion(), batchSize x ...\n",
       "16820    [a = (([0,1,2], [3,4], [5,6,7,8]), 1)\\r\\n\\r\\n#...\n",
       "16821    [def batch_to_sequence(x, len_x, batch_first):...\n",
       "16822               [encoder.cuda()\\r\\ndecoder.cuda()\\r\\n]\n",
       "16824    [model.named_paramters(), from prettytable imp...\n",
       "16825    [torch.Tensor.data_ptr, sum(dict((p.data_ptr()...\n",
       "16826    [collections.OrderedDict, import torch\\r\\n\\r\\n...\n",
       "16829    [def model_summary(model):\\r\\n  print(\"model_s...\n",
       "16832    [if p.grad is not None:, def clip_gradient(mod...\n",
       "16835                       [ht.data[idx], ht[idx], .data]\n",
       "16836    [ht, ht = Variable(torch.from_numpy(np.random....\n",
       "16837    [ht.data[idx], torch.no_grad(), with torch.no_...\n",
       "16838    [x.grad, import torch\\r\\nimport numpy as np\\r\\...\n",
       "16839    [torch.autograd.grad, tf.gradients, from torch...\n",
       "16840                                                  NaN\n",
       "16841    [torch.FloatTensor([[0.0, 1.0, 0.0]])\\r\\n, sel...\n",
       "16842    [for name in varList:\\r\\n    caffe_params = si...\n",
       "16843    [Variable(torch.from_numpy(X).type(torch.Float...\n",
       "16844    [main, img_pil = transforms.ToPILImage()(img.s...\n",
       "16845    [for item in emb:, 16 x 10, 16, batch_size, 10...\n",
       "16846    [input, MBxninp, hidden, MBxnhid, h, MBxnhid, ...\n",
       "16847    [B x S, S, embeddings = self.embed(captions)\\r...\n",
       "16848    [ImageFolder, train/dog, train/cat, test/dog, ...\n",
       "16849    [    train_dataset=datasets.ImageFolder(root=\"...\n",
       "16851                  [Network#__init__, Network#forward]\n",
       "16852                                                  NaN\n",
       "16854    [(s1, s2, s3, s4), sum = torch.sum(input, dim ...\n",
       "16855    [ x = torch.tensor([[1,2],[3,4]],dtype=torch.f...\n",
       "16856    [x = [[1,2],\\r\\n    [3,4]]\\r\\n, y = [[0.27,0.7...\n",
       "16857    [dim, m0 = nn.Softmax(dim=0)\\r\\n, m0, b, (d0,d...\n",
       "16858    [import torch\\r\\nimport torch.nn.functional as...\n",
       "16859    [import numpy as np\\r\\nimport matplotlib.pyplo...\n",
       "16860    [# Open Image from dataset:\\r\\nmy_img, _ = tra...\n",
       "16861    [states = detach(states)\\r\\nout, states, z = m...\n",
       "16862    [out_channels, x = x.view(x.size(0),  -1), sel...\n",
       "16863         [torch.nn.functional.log_softmax(x, -1)\\r\\n]\n",
       "16864    [log_softmax, torch.nn.functional.log_softmax(...\n",
       "16865    [X_batch = Variable(torch.from_numpy(X[slice_]...\n",
       "16867    [self.wxh=Parameter, self.wxh=Variable, Variab...\n",
       "16868    [packed_in= pack_padded_sequence(embedded, seq...\n",
       "16869    [criterion = Custom_Loss()\\r\\n, class Custom_L...\n",
       "16870    [p, [1,0], p[cd[0], cd[1]] = v[0], cd = torch....\n",
       "16871    [import torch\\r\\n\\r\\nx1 = torch.rand(5, 3, 6)\\...\n",
       "16872    [narrow(), view(), expand(), transpose(), tran...\n",
       "16874    [aaa = torch.Tensor( [[1,2,3],[4,5,6]] )\\r\\npr...\n",
       "16875    [ t = torch.tensor([[0, 1, 2, 3], [4, 5, 6, 7]...\n",
       "16876    [transpose(), samestorage(), contiguous, def s...\n",
       "16877    [contiguous, view, contiguous, [[1, 2]\\r\\n [3,...\n",
       "16878    [.view,         # normal lstm([loss, grad_prep...\n",
       "16879                [conda install -c peterjc123 pytorch]\n",
       "16880    [MiniBatch x Dim, MB = 1, 0, _,preds = t.max(o...\n",
       "16881                                                  NaN\n",
       "16882    [cmake, cmake3, alternatives, $ sudo alternati...\n",
       "16883      [sudo ln -s /usr/bin/cmake3 /usr/bin/cmake\\r\\n]\n",
       "16884              [ln -s /usr/bin/cmake3 ~/bin/cmake\\r\\n]\n",
       "16885      [cmake3, cmake3, cmake, cmake, /usr/bin/cmake3]\n",
       "16886    [BuildRequires:  cmake3\\r\\n\\r\\nmkdir ~/bin\\r\\n...\n",
       "16888                                                  NaN\n",
       "16889    [torch.multiprocessing, multiprocessing, spawn...\n",
       "16890    [set_start_method, import multiprocessing as m...\n",
       "16891    [traindata = datasets.ImageFolder(data_dir + '...\n",
       "16892    [torch~=1.8.0\\r\\ntorchvision~=0.9.0\\r\\n, impor...\n",
       "16893    [def get_mean_std(loader):\\r\\n    mean = 0.\\r\\...\n",
       "16895    [trainIters, trainIters(encoder1, decoder1, ab...\n",
       "16896                                                  NaN\n",
       "16897    [classifier, class newModel(nn.Module):\\r\\n   ...\n",
       "16898    [for e in range(epochs):\\r\\n    sequences = sh...\n",
       "16899    [nn.Conv2d(512, 512, kernel_size=3, padding=1)...\n",
       "16900              [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
       "16901    [http://download.pytorch.org/whl/cpu/torch-0.3...\n",
       "16902    [nn.Linear(25088, 4096), x = x.view(x.size(0),...\n",
       "16903    [output = model(data)\\r\\n, output = model.forw...\n",
       "16904    [kernel_product(w1, x, s), w1, x, s, kernel_pr...\n",
       "16905    [ImageNet, VGG16, Keras, PyTorch, VGG16, from ...\n",
       "16906    [weights='imagenet', vgg_16 = keras.applicatio...\n",
       "16907        [embedding_matrix.float(), float(), double()]\n",
       "16908                                                  NaN\n",
       "16909    [np.meshgrid, i, k, l = np.meshgrid(range(n), ...\n",
       "16910    [torch.diag(), torch.diagonal(), diagonal, U =...\n",
       "16911    [s, words = s.split()\\r\\n, LSTMc, encoded_word...\n",
       "16912                                         [MAX_LENGTH]\n",
       "16913    [torch.nn.functional.pad, torch.ones(*sizes)*p...\n",
       "16916    [import torch.nn.functional as F\\r\\ndata = tor...\n",
       "16917    [In [1]: import torch\\r\\n\\r\\nIn [2]: a = torch...\n",
       "16919    [ t[:,:,1].T\\r\\narray([[ 0.25631294,  0.917762...\n",
       "16920                  [t[:, :, 1:].reshape((2, 2)).T\\r\\n]\n",
       "16921    [training_samples = utils_data.TensorDataset(t...\n",
       "16922    [net.register_forward_hook(your_print_blobs_fu...\n",
       "16923    [nn.Linear, model = nn.Sequential(nn.Linear(in...\n",
       "16924    [import torch as pt\\r\\nfrom torch.nn.functiona...\n",
       "16925    [model = nn.Sequential(nn.Linear(input_dim, hi...\n",
       "16926                                                  NaN\n",
       "16928    [def rle_encode(image):\\r\\n    \"\"\"\\r\\n    rece...\n",
       "16929    [from keras.callbacks import Callback\\r\\nfrom ...\n",
       "16930    [x, x[0], x[i,j], x[i,j:j+1], x[i,j].view(1,4)...\n",
       "16931                        [torch.unsqueeze(x[i, j], 0)]\n",
       "16932      [None, x[:, j][:, None]\\r\\n, x[:, j, None]\\r\\n]\n",
       "16933                                                  NaN\n",
       "16935    [beta = 0.5 #The interpolation parameter    \\r...\n",
       "16936                                                  [0]\n",
       "16937    [range(N), pytorch, 0:N, hyp = torch.exp(score...\n",
       "16938    [scattered, .collect(), model.grad, None, .col...\n",
       "16939    [enumerate, ix, _ = min(enumerate(li), key=lam...\n",
       "16940    [from setuptools import find_packages\\r\\nfrom ...\n",
       "16941    [from_numpy(), dtype, torch.Tensor, torch.Floa...\n",
       "16942    [torch.tensor, torch.as_tensor, torch.tensor, ...\n",
       "16943    [_torch_docs.py, def from_numpy(ndarray): # re...\n",
       "16944    [x = np.arange(8, dtype=np.float64).reshape(2,...\n",
       "16945    [device = \"cuda\" if torch.cuda.is_available() ...\n",
       "16946         [load_data(), x /= 255\\r\\nx_test /= 255\\r\\n]\n",
       "16947    [bs=1, del, ps -elf | grep python, kill -9 [pid]]\n",
       "16948                    [transforms.Resize((64, 64))\\r\\n]\n",
       "16950    [.whl, gs://bucketname/directory/torch-0.3.0.p...\n",
       "16951    [dependency_links, from setuptools import find...\n",
       "16952    [datasets.MNIST('../data', train=True, downloa...\n",
       "16953                                           [Variable]\n",
       "16954    [torch.save(model.state_dict(), 'model_state.p...\n",
       "16955    [score_detector.pkl, cnn = MyModel()\\r\\ncnn.lo...\n",
       "16956                [labels = model_conv(new_images)\\r\\n]\n",
       "16957    [hidden, Variables, 1 x 1 x 3, (0 ,.,.), 1 x 1...\n",
       "16958                                                [1x1]\n",
       "16959            [nn.MaxPool2d(), kernel_size, input_size]\n",
       "16960    [self.fc1, 16 * 5 * 5 * 120 = 48000, len(params)]\n",
       "16961    [def count_parameters(model):\\r\\n    total_par...\n",
       "16962    [probs_flat = probs.view(-1)\\r\\ntargets_flat =...\n",
       "16963    [---&gt; 18         loss = criterion(outputs, ...\n",
       "16964    [forward(), x, return F.log_softmax(self.last(...\n",
       "16965    [a = a + 1\\r\\n, a, a, a, b, a, a, In [75]: a =...\n",
       "16966                                                  NaN\n",
       "16967    [T = torch.from_numpy(np.arange(10))\\r\\n, T[to...\n",
       "16968    [i, h, LSTMCell,         x_i = K.dot(inputs_i,...\n",
       "16969       [nn.Squential(*(make_foo() + make_bar()))\\r\\n]\n",
       "16970    [y = (x - mean(x)) / (std(x) + eps)\\r\\n, mean(...\n",
       "16972    [optim.param_groups[i]['lr'], optim.param_grou...\n",
       "16974                                                  NaN\n",
       "16979    [import torch.nn as nn\\r\\ntorch.manual_seed(1)...\n",
       "16980    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "16981                                            [.cuda()]\n",
       "16982    [loss.backward(),  hidden.detach_()\\r\\n hidden...\n",
       "16983                                                  NaN\n",
       "16984    [volatile, with torch.no_grad():\\r\\n    # Your...\n",
       "16985    [cpu(), numpy(), # evaluate on Variable x with...\n",
       "16986    [def evaluate(model, batches, dictionary, outf...\n",
       "16987    [tensor_data.detach().cpu().numpy()\\r\\n, detac...\n",
       "16988    [numpy.array, json.loads, list, float, torch.u...\n",
       "16993    [y', x, 2x3, y'*x, y'+x, tile, y = tf.tile(tf....\n",
       "16994                            [expand, tf.broadcast_to]\n",
       "16995    [def mse_loss(input, target, size_average=True...\n",
       "16996    [nan != nan,  x = torch.tensor([1, 2, np.nan])...\n",
       "17001                                                  NaN\n",
       "17002    [ import torch\\r\\n\\r\\n torch.cuda.is_available...\n",
       "17003    [torch.device, device, # setting device on GPU...\n",
       "17004    [watch, $ watch -n 2 nvidia-smi\\r\\n, nvidia-sm...\n",
       "17005    [import torch\\r\\ndev = torch.device(\"cuda\") if...\n",
       "17008    [torch.cuda.is_available()\\r\\n, False, CUDA_VI...\n",
       "17010    [python -c 'import torch; print(torch.cuda.is_...\n",
       "17013    [import torch\\r\\n, tensor = torch.tensor([5, 6...\n",
       "17018    [self.embedding.weight.data.copy_(torch.from_n...\n",
       "17019                                                  NaN\n",
       "17020                                                  NaN\n",
       "17021    [transform = transforms.Compose(\\r\\n          ...\n",
       "17022                                           [self.fc1]\n",
       "17023    [lists, In [35]: X = torch.Tensor([[3, 4, 5, 6...\n",
       "17024    [PyTorch, loss.backward(), zero out the gradie...\n",
       "17026    [zero_grad(), zero_grad(), zero_grad(), model ...\n",
       "17027    [optimizer = some_pytorch_optimizer\\r\\n# decay...\n",
       "17028    [# let us write a training loop\\r\\ntorch.manua...\n",
       "17029    [torch.cuda.synchronize()\\r\\nt = Variable(torc...\n",
       "17030    [optim, nn, optim, nn, optimizer = optim.Adam(...\n",
       "17031    [MKL, MKL, MKL, $ conda install -c anaconda mk...\n",
       "17032                                 [conda update conda]\n",
       "17033    [lstm = nn.LSTM(3, 3)  # Input dim is 3, outpu...\n",
       "17034    [self.lstm = nn.LSTM(input_size, hidden_size, ...\n",
       "17035    [__getitem__, data = self.tensor_data[:, :, in...\n",
       "17036    [__getitem__, transform = transforms.Compose(\\...\n",
       "17037                                                  NaN\n",
       "17038                                                  NaN\n",
       "17039    [dilation, nn.Linear,  a = torch.zeros((1, 3, ...\n",
       "17040    [xtrain = [[ 1.0721,  0.7327, -0.3655,  1.0686...\n",
       "17042    [wmin, wmax, w = wmax - (wmax - wmin) * (iter ...\n",
       "17043    [torch.mv(a,b)\\r\\n, torch.matmul(), torch.matm...\n",
       "17044    [ b = torch.rand(4)\\r\\n,  b = torch.rand((4,1)...\n",
       "17046    [(tensor == target_value).nonzero(as_tuple=Tru...\n",
       "17049    [def index(tensor: Tensor, value, ith_match:in...\n",
       "17050    [import torch\\r\\nx = torch.range(1,4)\\r\\nprint...\n",
       "17052    [mat=torch.tensor([1,8,5,3])\\r\\n, five=5\\r\\n\\r...\n",
       "17054    [transform_label(label), 255.0, datatype, tran...\n",
       "17055    [loss, # optimizer = optim.Adam(net.parameters...\n",
       "17056    [weight_decay, 0.1, weight_decay, weight_decay...\n",
       "17057                  [torch.exp(output_from_logsoftmax)]\n",
       "17058                  [&lt;anaconda root&gt;/envs/my_env]\n",
       "17059    [__init__, forward, forward, forward, loss = Y...\n",
       "17060    [que.close(), que.close(), time.sleep(2), que....\n",
       "17062    [\\r\\nconda update conda\\r\\nconda update pytorc...\n",
       "17063       [mkl, 2018, conda install mkl -c anaconda\\r\\n]\n",
       "17064    [ class LinearWithInputBias(nn.Linear):\\r\\n   ...\n",
       "17065                         [--input_nc 1 --output_nc 1]\n",
       "17066    [ import torch\\r\\n import torch.nn.functional ...\n",
       "17067    [Input: (N,C), where C = number of classes\\r\\n...\n",
       "17068    [# main training loop\\r\\n    generator = iter(...\n",
       "17071    [for batch_index, (x, y) in enumerate(itertool...\n",
       "17072    [python caffe2pth_convertor.py \\\\r\\n--prototxt...\n",
       "17073    [def create_mask(input_column):\\r\\n    r = 10\\...\n",
       "17074    [error.backward()\\r\\nopt.step()\\r\\n, .backward...\n",
       "17075    [net_b = torch.nn.Sequential()\\r\\n, [nn.Identi...\n",
       "17076             [nn.Identity, net_b = nn.Identity()\\r\\n]\n",
       "17078                            [output = vgg_net(input)]\n",
       "17079    [type, if use_cuda:\\r\\n    dtype = torch.cuda....\n",
       "17080    [np.swapaxes, np.transpose, 2D, a.swapaxes(-2,...\n",
       "17081                     [np.reshape(a,(3,9), order='F')]\n",
       "17082    [order='F', In [35]: arr\\r\\nOut[35]: \\r\\narray...\n",
       "17083                                 [torch.nn, Upsample]\n",
       "17084    [def forward (self, inputs):\\r\\n        inputs...\n",
       "17085    [nn.BCELoss(), o, t, i, nn.BCELoss(), o, i, N ...\n",
       "17088    [torch.autograd.Variable, .grad_fn, total_loss...\n",
       "17089    [class myLSTM(nn.Module):\\r\\n    def __init__(...\n",
       "17090    [print len(dset)\\r\\n, dset[0], dset[0][0], dse...\n",
       "17091    [Tensor, x = Variable(torch.rand(2, 2))\\r\\ny =...\n",
       "17093    [ModuleList, add_module, import torch.nn as nn...\n",
       "17094    [Variable, i = Variable(torch.from_numpy(index...\n",
       "17095    [...\\r\\ny_pred = torch.nn.functional.F.relu(se...\n",
       "17097    [dataset, main.py, sudo -H pip install dataset...\n",
       "17098    [labels, 0th, loss = criterion(outputs, labels...\n",
       "17099              [criterion = nn.CrossEntropyLoss()\\r\\n]\n",
       "17100    [l = loss(net(X), y), l.backward(), loss.backw...\n",
       "17101                                                  NaN\n",
       "17102                                                  NaN\n",
       "17103    [pow, import torch\\r\\nfrom torch.autograd impo...\n",
       "17104    [0.9477  1.0090  0.8348 -1.3513\\r\\n-0.4861  1....\n",
       "17105    [def mask_fill_inf(matrix, mask):\\r\\n    negma...\n",
       "17106    [masked_fill, def mask_fill_inf(matrix, mask):...\n",
       "17108    [class YourSampler(Sampler):\\r\\n    def __init...\n",
       "17109    [torch.utils.data.Subset, shuffle, import torc...\n",
       "17110              [for i in range(T):, G_i, alpha_i, for]\n",
       "17111                             [torchvision transforms]\n",
       "17112    [import torch\\r\\n\\r\\na = torch.randn(3, 2, 4, ...\n",
       "17113                  [out = out.view(x.size(0), -1)\\r\\n]\n",
       "17114    [import torch\\r\\n\\r\\na = torch.rand(2, 3)\\r\\np...\n",
       "17115    [torch.diag_embed,  a = torch.randn(2, 3)\\r\\n ...\n",
       "17116    [import torch\\r\\n\\r\\na = torch.rand(2, 3)\\r\\np...\n",
       "17117                                                  NaN\n",
       "17118    [roll, numpy.roll, x, DxN, roll, axis=0, x_1[i...\n",
       "17119    [RuntimeError: save_for_backward can only save...\n",
       "17120    [Net, self.sub_module = nn.Linear(10, 5), __se...\n",
       "17121    [x, x = x.cpu()  # get the CPU copy\\r\\n# do yo...\n",
       "17122                     [new = (1/(2*2.25)) * old + 0.5]\n",
       "17123    [torch, torch, $ pwd\\r\\n/some/path\\r\\n$ python...\n",
       "17124    [python2, metadata,  \"metadata\": {\\r\\n  \"kerne...\n",
       "17125    [import torch\\r\\nprint(torch.__path__)\\r\\nIf (...\n",
       "17126    [def get_iterator(data, batch_size=32, max_len...\n",
       "17127                                            [.cuda()]\n",
       "17128    [net = nn.Sequential(\\r\\n    nn.Linear(28*28, ...\n",
       "17129                       [cfg.MODEL.DEVICE = \"cpu\"\\r\\n]\n",
       "17130    [models.resnet50, num_classes=num_breeds, 2048...\n",
       "17131                                                  NaN\n",
       "17132    [import torch\\r\\n\\r\\na = torch.LongTensor([1])...\n",
       "17133    [ByteTensor, if, if (minynext[0] &lt; miny[0])...\n",
       "17134    [idx = (x1 &gt; x2)\\r\\nx2[idx] = x1[idx]\\r\\n, ...\n",
       "17135                                                  NaN\n",
       "17136    [e = z - h\\r\\n, z, Nx1, h, NxP, h, z, e = z.ex...\n",
       "17137    [.... same as your code\\r\\nprint(\"# Starting g...\n",
       "17138    [W, data, hid_dim = 32\\r\\ndata = torch.randn(1...\n",
       "17139    [import torch\\r\\n\\r\\na = torch.randn(30)\\r\\nb ...\n",
       "17140    [# wrap them in Variable\\r\\nimages_batch, labe...\n",
       "17141    [import torch\\r\\ndtype = torch.cuda.FloatTenso...\n",
       "17142                                                  NaN\n",
       "17144    [0.2, x= (xmax-xmin)*torch.rand(pop, 1).type(d...\n",
       "17145    [A, B, AxE, BxE, AxBxE, A, B, import torch\\r\\n...\n",
       "17146    [one_hot_target = autograd.Variable(torch.Tens...\n",
       "17147    [BxSxW, B = Batch size\\r\\nS = Sentence length\\...\n",
       "17148    [from allennlp.modules.time_distributed import...\n",
       "17149    [BatchNorm1d, BatchNorm1d, import torch.nn as ...\n",
       "17150    [import torch.nn as nn\\r\\n\\r\\nclass Policy(nn....\n",
       "17151    [numpy, .tolist(), a=[1,2,3];\\r\\ncontext_var =...\n",
       "17152    [a=[1,2,3]\\r\\nprint(torch.autograd.Variable(to...\n",
       "17153    [torchvision.transforms.Compose(), torchvision...\n",
       "17154    [trans = transforms.Compose([transforms.Resize...\n",
       "17155    [rnn_output, rnn_hidden = rnn(Variable(input_t...\n",
       "17156    [(3,1), (3,), (3,3), (1,3), (3,), def check_ve...\n",
       "17157    [__init__, self.conv1, out = self.conv2(out), ...\n",
       "17159    [image_files, pd.read_csv(), image_files = pd....\n",
       "17160    [inputs, labels = Variable(inputs), Variable(l...\n",
       "17161    [def find_settings(shape_in, shape_out, kernel...\n",
       "17162    [inputs = inputs.view(4, 3, 32, 32), inputs, l...\n",
       "17163    [class Net(nn.Module):\\r\\n    def __init__(sel...\n",
       "17164    [loss_total = Variable(torch.zeros(1).cuda(), ...\n",
       "17166    [In [24]: import os\\r\\n\\r\\n# select `GPU 0` fo...\n",
       "17167    [optimizer.zero_grad(), detach, # evaluate\\r\\n...\n",
       "17168    [    story = Variable(story, volatile=True)\\r\\...\n",
       "17169                                                  NaN\n",
       "17170    [import torch\\r\\nimport torch.nn as nn\\r\\nfrom...\n",
       "17171                                                  NaN\n",
       "17172    [.from_numpy(), numpy==1.13.0\\r\\ntorch==0.1.12...\n",
       "17173          [http://pytorch.org/, pip install -U numpy]\n",
       "17174                                                  NaN\n",
       "17175    [loss = 0\\r\\nloss += loss_function(pred_A, lab...\n",
       "17176                           [torch.cuda.empty_cache()]\n",
       "17177    [model = Sequential()\\r\\nmodel.add(Dense(30, i...\n",
       "17178    [model = Sequential()\\r\\nmodel.add(InputLayer(...\n",
       "17179    [  model = Sequential()\\r\\n  model.add(Dense(3...\n",
       "17180    [int n[k] = 0\\r\\nint sx[k] = 0\\r\\nint sy[k] = ...\n",
       "17181    [bincount, m,n = a.shape\\r\\nr,c = np.mgrid[:m,...\n",
       "17182    [import numpy as np\\r\\nfrom skimage import mea...\n",
       "17183    [ import torch\\r\\n var = torch.tensor([[1,0], ...\n",
       "17184    [NumPy, tensor.shape, In [3]: ar = torch.rand(...\n",
       "17187    [net, def l1_loss(x):\\r\\n    return torch.abs(...\n",
       "17188    [activations_to_regularise = upconv(input)\\r\\n...\n",
       "17190    [retain_graph=True, d, e, a, import torch\\r\\nf...\n",
       "17191    [                    -- FC - FC - FC - cat?\\r\\...\n",
       "17192    [cur_img.reshape((28, 28)).astype('uint8') * 2...\n",
       "17193    [output = loss(data, target)\\r\\n, output = net...\n",
       "17194    [out, hidden = net(Variable(tensor), Variable(...\n",
       "17195    [net = YouNetworkClass()\\r\\ndevice = torch.dev...\n",
       "17196    [decoder_test, .cuda(), encoder_hidden = encod...\n",
       "17197    [torch.set_default_tensor_type('torch.cuda.Flo...\n",
       "17198    [dataset = torchvision.datasets.ImageFolder(.....\n",
       "17199    [# Turn string into list of longs\\r\\ndef char_...\n",
       "17200    [In[2]: import torch\\r\\nIn[3]: torch.__version...\n",
       "17203    [transforms.ToPILImage(), data_transforms = {\\...\n",
       "17204    [conv1d, Conv1d, conv1.double(), model.double(...\n",
       "17205    [out-channel, in-channel, import torch\\r\\nimpo...\n",
       "17206    [1x1x42x42, nn.Conv2D, nn.Linear, input = inpu...\n",
       "17208    [inp.grad.data.zero_()\\r\\n, Variable, import t...\n",
       "17209    [autograd.Variable(torch.from_numpy(embeds[0])...\n",
       "17210    [Tensor, numpy.ndarray, Tensor, Variable, Tens...\n",
       "17211    [torch.Variable, v=torch.Variable(mytensor)\\r\\...\n",
       "17212    [import torch as pt\\r\\nimport torch.nn as nn\\r...\n",
       "17214    [with, with, # For python 2/3 compatibility, d...\n",
       "17215    [transforms.RandomSizedCrop.get_params(), img....\n",
       "17216    [view_as_windows, scikit-image, advanced-index...\n",
       "17219    [myseed=args.seed\\r\\nnp.random.seed(myseed)\\r\\...\n",
       "17220    [def mse_loss(input, target):\\r\\n            r...\n",
       "17221                                      [net.cpu()\\r\\n]\n",
       "17222    [last_timestep, class BaselineRNN(nn.Module):\\...\n",
       "17223    [[batch size, sequence length, features], unpa...\n",
       "17224                          [torch.view, torch.squeeze]\n",
       "17225    [random.seed(opt.manualSeed)\\r\\ntorch.manual_s...\n",
       "17227    [nn.Module, torch.nn.optim.Optimizer, encoder_...\n",
       "17228    [text_batch = torch.stack(batch['text'], 0)[:,...\n",
       "17229                                                  NaN\n",
       "17230    [unet = UnetGenerator(512,512,4)\\r\\nlayers = l...\n",
       "17231    [pytorch, tensorflow, pytorch, forward, class ...\n",
       "17232    [from torchvision import models    \\r\\nmodel_v...\n",
       "17233    [w.grad\\r\\n, w.data -= learning_rate * w.grad....\n",
       "17234    [loss.backward()\\r\\n, optimizer = torch.optim....\n",
       "17235                                                  NaN\n",
       "17236    [d, training_data, d, d = x[0:10000].clone()\\r...\n",
       "17237    [softmax_cross_entropy_with_logits, torch.nn.f...\n",
       "17238    [from thexp.calculate.tensor import onehot\\r\\n...\n",
       "17239    [# pred is the prediction with shape [C, H*W]\\...\n",
       "17240    [import torch\\r\\nimport torch.nn as nn\\r\\nimpo...\n",
       "17241    [.cuda(), device = torch.device('cuda:0' if to...\n",
       "17242    [Dataset, Dataset, Dataset, Dataloader, Datase...\n",
       "17244                                                  NaN\n",
       "17245                                                  NaN\n",
       "17246                                                  NaN\n",
       "17247                                       [model.eval()]\n",
       "17248    [model.eval(), ('prediction:', u'Egyptian cat'...\n",
       "17249    [cuda, x, .cuda(), x = V(centre_crop(img).unsq...\n",
       "17250    [model, x, model.cuda(), x.cuda(), model.cuda(...\n",
       "17251                                                  NaN\n",
       "17252    [pip install openvino-dev[pytorch,onnx]\\r\\n, d...\n",
       "17253                                                  NaN\n",
       "17254    [from torch import nn\\r\\nimport torchvision\\r\\...\n",
       "17255    [conda install -c peterjc123 pytorch cuda80\\r\\...\n",
       "17256    [conda install -c pytorch pytorch, conda insta...\n",
       "17257    [import torch\\r\\nimport torch.nn.functional as...\n",
       "17258                                   [torch.nn.BCELoss]\n",
       "17259    [net.cpu(), net.cuda(), vision/torchvision/mod...\n",
       "17260    [DataParallel, DistributedDataParallel, if not...\n",
       "17261    [DataParallel, my_model = model.module.to(devi...\n",
       "17262    [Variable, Variable, a = b + c, b, c, .grad, o...\n",
       "17263    [unfold, batch_size, n_channels, n_rows, n_col...\n",
       "17264    [import math\\r\\nimport torch.nn.functional as ...\n",
       "17265                              [sudo rm -rf ~/.nv\\r\\n]\n",
       "17266                [torch.fft, torch.fft.fft(input)\\r\\n]\n",
       "17268    [        sub_patch[i:(i + filter_sz), j:(j + f...\n",
       "17269                                     [ngpus_per_node]\n",
       "17270    [pip install http://download.pytorch.org/whl/t...\n",
       "17271                          [pip install -U numpy \\r\\n]\n",
       "17272                                                  NaN\n",
       "17274    [FloatTensor, DoubleTensor, ByteTensor, model(...\n",
       "17275    [data_transforms, data_transforms, torch.utils...\n",
       "17276    [nn.Module, nn.Sequential(), class Flatten(nn....\n",
       "17277    [main.add_module('flatten', Flatten()), class ...\n",
       "17278    [ import numpy as np\\r\\n a=np.random.rand(5)\\r...\n",
       "17279    [nn.Module, self.opt, self.my_var, .cuda(), -u...\n",
       "17280    [torch.device, #Assuming you have a cuda boole...\n",
       "17281    [nn.Linear(...), __init__, .cuda(), net.forwar...\n",
       "17282    [Variable, Variable, numpy array, Variable, Va...\n",
       "17284    [self.input_layer, forward(), self.network.cud...\n",
       "17285    [dtype=torch.cuda.FloatTensor\\r\\nx=torch.autog...\n",
       "17286    [batch_size = 8\\r\\nimg_size = 224\\r\\n\\r\\ntrans...\n",
       "17287    [dim=0, dim=0, dim=1, def custom_imshow(tensor...\n",
       "17288    [import torch\\r\\nimport numpy as np\\r\\nfrom to...\n",
       "17289    [np.resize, M = 3 # number of rows for output\\...\n",
       "17290                                                  NaN\n",
       "17291    [DataParallel, encoderchar, DataParallel, dim=...\n",
       "17292                                                  NaN\n",
       "17293    [print([trainset[i] for i in range(10)])\\r\\n, ...\n",
       "17294    [train_size = int(0.8*len(dataset))\\r\\ntest_si...\n",
       "17295    [nn.Module, .cuda(), encoder, decoder, train()...\n",
       "17296    [ i = [2, 1, 0, 3]\\r\\n a = np.array([[5, 2, 11...\n",
       "17297    [get_batch2, torch.randperm(N), n_epochs = 100...\n",
       "17298    [torchvision.datasets, ImageFolder, trainset=t...\n",
       "17299    [for epoch in range(500):\\r\\n    k=0\\r\\n    lo...\n",
       "17300    [torch.utils.data, torch.utils.data.Dataset, c...\n",
       "17301    [torch.utils.data.Dataset, torch.utils.data.Da...\n",
       "17302    [pd.DataFrame.sample, train = pd.read_csv(Trai...\n",
       "17303    [class UnlabeledTensorDataset(TensorDataset):\\...\n",
       "17304    [class ImageLoader(torch.utils.data.Dataset):\\...\n",
       "17305    [hidden_size, input_size, num_layers, hidden_s...\n",
       "17306    [output1 = self.Batch1(self.ReLu1(self.Lin1(in...\n",
       "17307    [Variable, input = Variable(letterToTensor('A'...\n",
       "17309    [add_, sub_, w.data.sub_(f.grad.data * alpha)\\...\n",
       "17311    [class RNNBase(Module):\\r\\n    ...\\r\\n    def ...\n",
       "17312    [requires_grad, # Load your model\\r\\nmodel = t...\n",
       "17313    [pack_padded_sequence, from torch.nn.utils.rnn...\n",
       "17314    [ var = [[0, 1, -4, 8],\\r\\n       [2, -3, 2, 1...\n",
       "17315    [index_select,  idx = torch.LongTensor([1,0,2]...\n",
       "17316    [ var\\r\\ntensor([[ 0,  1, -4,  8],\\r\\n        ...\n",
       "17317    [index = torch.LongTensor([1,0,2])\\r\\n, var[in...\n",
       "17318    [view, training=True, batch_norm, batch_norm, ...\n",
       "17319    [p = torch.exp(vector.dot(ht))\\r\\n, vector, ht...\n",
       "17320    [Tensor * Tensor, Variable * Variable, Tensor ...\n",
       "17321                                                  NaN\n",
       "17323    [DataLoader, DataLoader, nsamples = 10000\\r\\nf...\n",
       "17324    [torch.utils.data.Subset(), import torch.utils...\n",
       "17325    [torch.utils.data.random_split(), tr = dataset...\n",
       "17326                               [/lib64/tls/libc.so.6]\n",
       "17327    [ img_nhwc = torch.randn(10, 480, 640, 3)\\r\\n ...\n",
       "17328    [Einops, from einops import rearrange\\r\\nx  = ...\n",
       "17329                                                  NaN\n",
       "17330    [append, results, result = []\\r\\n...\\r\\n\\r\\nre...\n",
       "17331    [args = parser.parse_args(), sys.argv[1:], $:p...\n",
       "17332                 [Run &gt; Edit configurations..., \"]\n",
       "17333    [i = torch.LongTensor([[0, 1, 2], [5, 5, 5], [...\n",
       "17334                                                  NaN\n",
       "17335    [loss, import torch\\r\\nfrom torch.autograd imp...\n",
       "17336    [OutputHook, import torch\\r\\n\\r\\n\\r\\nclass Out...\n",
       "17337    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "17338    [my_layer, def l1_penalty(params, l1_lambda=0....\n",
       "17339    [target, Y_train[k] = 5, np.array(Y_train[k], ...\n",
       "17340    [float(), torch.FloatTensor of size 1, mean, m...\n",
       "17341                                                  NaN\n",
       "17342    [from sklearn import preprocessing\\r\\nimport t...\n",
       "17343    [In[]\\r\\nimport torch\\r\\n\\r\\nwords = ['שלום', ...\n",
       "17344    [labels = ['cat', 'dog', 'mouse']\\r\\nsentence_...\n",
       "17345    [torch.svd(), TypeError, import torch\\r\\nfrom ...\n",
       "17346    [net = torch.nn.DataParallel(RNN(n_chars, hidd...\n",
       "17347    [\\r\\nclass PEncoder(nn.Module):\\r\\n    def __i...\n",
       "17348    [expand(), repeat(), expand(), repeat(), impor...\n",
       "17349    [np.repeat(), np.tile(), np.repeat([1, 2], 2) ...\n",
       "17352                                     [SIGKILL, dmesg]\n",
       "17353    [torch.mm, torch.mm(a, b)\\r\\n, torch.dot(), np...\n",
       "17354    [AB = A.mm(B)\\r\\n\\r\\nAB = torch.mm(A, B)\\r\\n\\r...\n",
       "17355    [torch.mm(a, b), torch.matmul(a, b),  torch.mm...\n",
       "17356    [a = torch.tensor([[1,2],\\r\\n                 ...\n",
       "17357    [torch.LongTensor, __init__, Tensor, new, init...\n",
       "17359    [one_hot, torch.nn.functional, indices, n, n =...\n",
       "17360    [def one_hot(x, class_count):\\r\\n    return to...\n",
       "17361    [PyTorch, scatter_, Tensor, labels = torch.Lon...\n",
       "17362    [Dataset, Dataset, TensorDataset, import torch...\n",
       "17363    [TensorDataset, Dataset, import torch\\r\\nfrom ...\n",
       "17364    [DataLoader, DataSet, torch.utils.data.TensorD...\n",
       "17365    [torch.autograd.Function, Variables, Function,...\n",
       "17366            [spmm, torch, torch.sparse, torch.sparse]\n",
       "17367                           [layers += [Testme()]\\r\\n]\n",
       "17368    [del_W, del_H = grad_cost(W, H)\\r\\n, grad=f_gr...\n",
       "17369    [from libcpp.memory cimport shared_ptr\\r\\n\\r\\n...\n",
       "17370    [s1 = torch.cuda.Stream()\\r\\ns2 = torch.cuda.S...\n",
       "17374    [Tensor, autograd.Variable, a.data, a.data.num...\n",
       "17375    [$ docker build -t oz123/alpine-test-mycoolapp...\n",
       "17376    [U, (r1 - r2) * U + r2, (r1 - r2) * torch.rand...\n",
       "17378    [torch.distributions, [a,b], range(low, high),...\n",
       "17383    [# generating uniform variables\\r\\n\\r\\nimport ...\n",
       "17385                        [model_2.layer[0].weight\\r\\n]\n",
       "17386    [state_dict(), for k, v in model_2.state_dict(...\n",
       "17387    [_modules, class Net(nn.Module):\\r\\n    def __...\n",
       "17388    [tf.space_to_depth(), norm = tf.random_normal(...\n",
       "17389    [def pixel_shuffle_down(input, downscale_facto...\n",
       "17390    [def space_to_depth(input, block_size)\\r\\n    ...\n",
       "17391           [sudo apt install nvidia-cuda-toolkit\\r\\n]\n",
       "17392    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "17393    [nn.DataParallel, DataParallel, nn.DataParalle...\n",
       "17394    [discuss.pytorch.org, adam.py, bias_correction...\n",
       "17395    [self.learning_rate = (self.learning_rate_init...\n",
       "17396    [nn.Conv1d, m = nn.Conv1d(200, 10, 2) # in-cha...\n",
       "17397                                               [view]\n",
       "17398    [# LSTM() returns tuple of (tensor, (recurrent...\n",
       "17399    [rnn = nn.LSTM(10, 20, 2)\\r\\ninput = Variable(...\n",
       "17400    [SplitTable, SelectTable, class, nn.Module, cl...\n",
       "17401    [index_select, import torch\\r\\n\\r\\nA_idx = tor...\n",
       "17402    [import torch\\r\\n\\r\\nB = torch.LongTensor([[1,...\n",
       "17403    [import torch\\r\\n\\r\\narr = torch.tensor([[0,1,...\n",
       "17404    [numpy, def accuracy_score(y_true, y_pred):\\r\\...\n",
       "17405    [values, target = torch.max(tag_scores, -1)\\r\\...\n",
       "17406    [inf, (torch.nn.utils.clip_grad_norm(model.par...\n",
       "17407    [m = tf.Variable( [width,height] , dtype=tf.fl...\n",
       "17411    [class Network(torch.nn.Module):\\r\\n    def __...\n",
       "17412    [Network.parameters(), parameters, parameters,...\n",
       "17413    [Network, Network, optimizer = optim.SGD(Netwo...\n",
       "17414    [class Net(nn.Module):\\r\\ndef __init__(self):\\...\n",
       "17415    [optimizer = torch.optim.SGD(net.parameters(),...\n",
       "17416    [torch.FloatTensor, torch.cuda.FloatTensor, .c...\n",
       "17417    [conda uninstall, conda uninstall pytorch torc...\n",
       "17420    [    conda clean --yes --packages --dry-run\\r\\...\n",
       "17422    [pip install pip-autoremove\\r\\n, Usage: pip-au...\n",
       "17423    [HTTPSConnectionPool(host='binstar-cio-package...\n",
       "17424    [NO_CUDA=1 MACOSX_DEPLOYMENT_TARGET=10.9 CC=cl...\n",
       "17425    [/tmp, export TMPDIR=/where/you/have/enough/sp...\n",
       "17426                               [pip uninstall pipenv]\n",
       "17427    [y_train = np.array([[152.],[185.],[180.],[196...\n",
       "17429     [H_out, W_out, dilation=n, 1x1, nxn, dilation=1]\n",
       "17430    [gradients = torch.FloatTensor([0.1, 1.0, 0.00...\n",
       "17431    [loss, loss, loss, leaf node, loss, loss, grad...\n",
       "17434    [transform.Compose, .ToTensor(), .Scale(), Pyt...\n",
       "17435    [transforms.ToTensor(), transform.Scale((32, 3...\n",
       "17436    [targetnp=targets.numpy()\\r\\nidxs=np.where(tar...\n",
       "17437    [CrossEntropyLoss, tf.nn.softmax_cross_entropy...\n",
       "17439    [torch.unsqueeze(input, dim, out=None),  impor...\n",
       "17440    [a.view(1,5)\\r\\nOut: \\r\\n\\r\\n 1  2  3  4  5\\r\\...\n",
       "17441    [2 x 3, x = torch.Tensor(2, 3)\\r\\nprint(x.shap...\n",
       "17442    [tensor.resize_(), In [23]: a = torch.Tensor([...\n",
       "17443    [In [3]: a.view(1,-1)\\r\\nOut[3]:\\r\\n\\r\\n 1  2 ...\n",
       "17444    [*, view(), img = Variable(tensor.randn(20,30,...\n",
       "17445    [dir(torch), import torch\\r\\nx=torch.arange(24...\n",
       "17446    [einops, from einops import rearrange\\r\\nans =...\n",
       "17447    [import torch\\r\\na = torch.Tensor([1,2,3,4,5])...\n",
       "17448    [import torch\\r\\nimport numpy as np\\r\\na = tor...\n",
       "17449    [import torch\\r\\nt = torch.ones((2, 3, 4))\\r\\n...\n",
       "17450                                                  NaN\n",
       "17451     [1x1 convolution, x, F(x), y=F(x)+x, 1x1 convs.]\n",
       "17452                                                  NaN\n",
       "17453    [conda install pytorch=0.1.10 torchvision -c s...\n",
       "17454    [\\r\\nconda install pytorch torchvision -c soum...\n",
       "17455    [pytorch, Module, Module,  class Model(nn.Modu...\n",
       "17456    [conv1, conv2, _modules, nn.Module.__init__, n...\n",
       "17457    [class QuestionClassifier(nn.Module):\\r\\n    d...\n",
       "17458    [torch.nn.fuctional.conv2d, torch.nn.Conv2d, t...\n",
       "17459    [torch, flip(i), flip(2), flip(3), def convolu...\n",
       "17460    [from torchvision import models\\r\\nmodel = mod...\n",
       "17461    [from torchvision import models\\r\\nfrom torchs...\n",
       "17462    [from torchsummary import summary\\r\\n, pip ins...\n",
       "17463    [torchinfo, torchsummary, from torchinfo impor...\n",
       "17464    [from torch.nn.modules.module import _addinden...\n",
       "17465    [print(model)\\r\\n, repr(model)\\r\\n, sum([param...\n",
       "17466    [from torchsummary import summary\\r\\n, device ...\n",
       "17467    [net = model\\r\\nmodules = [module for module i...\n",
       "17468    [from torchsummary import summary\\r\\nsummary(m...\n",
       "17469    [class RNN(nn.Module):\\r\\n    def __init__(sel...\n",
       "17470    [summary(my_model, (3, 224, 224), device = 'cp...\n",
       "17471    [from torchvision.models import resnet18\\r\\nfr...\n",
       "17472    [view(), reshape(), a, import torch\\r\\na = tor...\n",
       "17473    [view, self, a = torch.arange(1, 17)  # a's sh...\n",
       "17474    [view(), view(), storage, t2 = t1.view(3,2), s...\n",
       "17475    [torch.Tensor.view(), torch.Tensor.view(), num...\n",
       "17477    [    a=torch.range(1,16)\\r\\n\\r\\nprint(a)\\r\\n\\r...\n",
       "17478    [-1, -1, view(), x.view(-1,1), [anything, 1], ...\n",
       "17480    [import torch.utils.data as data_utils\\r\\n\\r\\n...\n",
       "17482    [from torch.utils.data import TensorDataset, D...\n",
       "17483    [DataLoader, Dataset, __getitem__, __len__, Da...\n",
       "17484    [torch.topk, &gt; t = torch.Tensor{9, 1, 8, 2,...\n",
       "17485    [import torch\\r\\n\\r\\nt = torch.tensor([5.7, 1....\n",
       "17486    [require 'torch'\\r\\n\\r\\ndata = torch.Tensor({1...\n",
       "17487                                                  NaN\n",
       "17488                                                  NaN\n",
       "17489    [to, struct Critic_Net : torch::nn::Module {\\r...\n",
       "17490    [torchaudio.functional.resample, torchaudio.tr...\n",
       "17493                                                  NaN\n",
       "17494                                                  NaN\n",
       "17495                                                  NaN\n",
       "17496       [pip uninstall torch\\r\\npip install torch\\r\\n]\n",
       "17497    [(H,W), img[mask.squeeze()==0] = 0\\r\\n, img[ma...\n",
       "17498    [np.where, import numpy as np\\r\\n\\r\\nH, W, C =...\n",
       "17500    [for epoch in range(max_epocks):\\r\\n    for i,...\n",
       "17501    [   If you did intend to build this package fr...\n",
       "17502    [In [70]: z=torch.randn(5)[None,None,:]\\r\\n\\r\\...\n",
       "17503    [np.expand_dims, [0][0], tensor.tensor(\\r\\ntor...\n",
       "17504                                                  NaN\n",
       "17505                                                  NaN\n",
       "17506                                                  NaN\n",
       "17507                                                  NaN\n",
       "17508    [dataset1: Any = ...\\r\\n# subsample original_d...\n",
       "17509    [StopIteration, Dataloader, class SubDataset(D...\n",
       "17510    [import subprocess\\r\\n\\r\\nd = list(range(20))\\...\n",
       "17511                                                  NaN\n",
       "17512                                                  NaN\n",
       "17513    [cuda::memcpy_async, cub::BlockLoad, cub::Bloc...\n",
       "17514                                                  NaN\n",
       "17515                                                  NaN\n",
       "17516                                                  NaN\n",
       "17517    [torch.matrix_rank, torch.linalg.matrix_rank, ...\n",
       "17519                                                  NaN\n",
       "17520    [.index_select, from einops import rearrange  ...\n",
       "17521                                                  NaN\n",
       "17522                                                  NaN\n",
       "17523    [Dict, _task_head_models, if-else, import torc...\n",
       "17524    [/torch/install/bin/torch-activate, bashrc, te...\n",
       "17525    [torch, pytorch, conda create -n pytorch -c py...\n",
       "17526                                                  NaN\n",
       "17527                                                  NaN\n",
       "17528                                                  NaN\n",
       "17529    [RUN, RUN, # all within a single RUN line\\r\\nR...\n",
       "17530                                                  NaN\n",
       "17531    [multiprocessing, os.environ[\"CUDA_VISIBLE_DEV...\n",
       "17532                                                  NaN\n",
       "17533    [    cond_w, cond_b = rearrange(b_t, \"b (split...\n",
       "17534    [import torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n...\n",
       "17535                                                  NaN\n",
       "17536                                                  NaN\n",
       "17537    [diffs_from_one = torch.abs(tensor - 1)\\r\\nind...\n",
       "17538                                                  NaN\n",
       "17539    [torch.save(model.state_dict(), PATH)\\r\\n, mod...\n",
       "17540                                                  NaN\n",
       "17541                                                  NaN\n",
       "17542                                                  NaN\n",
       "17543                                                  NaN\n",
       "17544                                                  NaN\n",
       "17545    [conda create -n venv python==3.6.13\\r\\n, pip ...\n",
       "17546    [model_children[i].weight, OverlapPatchEmbed, ...\n",
       "17547                                                  NaN\n",
       "17548    [torch.cidst, p=2, import faiss\\r\\nimport nump...\n",
       "17549    [ai.StackExchange, def cumsum_3d(test, train):...\n",
       "17551                                                  NaN\n",
       "17552    [torch::Tensor, torch::jit::IValue, network.fo...\n",
       "17553                                                  NaN\n",
       "17554                                                  NaN\n",
       "17555    [def postprocess(self, data):\\r\\n    output_da...\n",
       "17556    [a.T\\r\\n, tensor([[  101, 14812, 10337,  7257]...\n",
       "17558                                                  NaN\n",
       "17559                                                  NaN\n",
       "17560    [average=None, from torchmetrics import Jaccar...\n",
       "17561                                                  NaN\n",
       "17562                                                  NaN\n",
       "17563    [def replace_zeros_with_prev_nonzero(tensor):\\...\n",
       "17564                                                  NaN\n",
       "17565                                                  NaN\n",
       "17566                                                  NaN\n",
       "17567    [_upsample_like, F.upsample(src,size=tar.shape...\n",
       "17568                                                  NaN\n",
       "17569                                            [.cuda()]\n",
       "17570                                                  NaN\n",
       "17571                                                  NaN\n",
       "17572    [from torchdata.datapipes.iter import FileOpen...\n",
       "17573                                                  NaN\n",
       "17574    [import torch\\r\\npoints = torch.randint(1,5,(4...\n",
       "17575                                                  NaN\n",
       "17577    [id_movies=data[:,1]data[:,0]==id_users]\\r\\n, ...\n",
       "17578    [library(torch)\\r\\nx &lt;- torch_tensor(1)\\r\\n...\n",
       "17579                                                  NaN\n",
       "17580    [d_input   = torch.nn.Conv1d(1, 33, 10, stride...\n",
       "17581                                                  NaN\n",
       "17582                                                  NaN\n",
       "17583                                                  NaN\n",
       "17584                                                  NaN\n",
       "17585                                                  NaN\n",
       "17586                      [resampler.to(self.device)\\r\\n]\n",
       "17587                                                  NaN\n",
       "17589                                                  NaN\n",
       "17590                                                  NaN\n",
       "17591                                                  NaN\n",
       "17592    [3717974 INFO: Analyzing hidden import 'pytorc...\n",
       "17593                                                  NaN\n",
       "17594                                                  NaN\n",
       "17595    [  # SuperFastPython.com\\r\\n  # example of lim...\n",
       "17596                                                  NaN\n",
       "17597                                                  NaN\n",
       "17598    [load_checkpoint, optimizer, ckpt_path, classi...\n",
       "17599                                                  NaN\n",
       "17600    [r = torch.tensor([0,1])\\r\\nL[r[:,None], r]\\r\\...\n",
       "17601                                                  NaN\n",
       "17602                                                  NaN\n",
       "17603                                                  NaN\n",
       "17604                                                  NaN\n",
       "17605    [(512, 2), X, y, (2,), y_val.shape, (2600,), (...\n",
       "17606                                                  NaN\n",
       "17608    [arr_3d, ax_0 = np.arange(arr_3d.shape[0])[:,N...\n",
       "17609    [In [107]: arr_3d = np.arange(2*3*4).reshape(2...\n",
       "17610    [numpy.ogrid, import numpy as np\\r\\n\\r\\n# exam...\n",
       "17611    [torch.save(net.state_dict(), '1.chkpt')\\r\\n, ...\n",
       "17612            [pip install --default-timeout=900 torch]\n",
       "17613                                                  NaN\n",
       "17614                                                  NaN\n",
       "17615                                                  NaN\n",
       "17616                                                  NaN\n",
       "17617                                                  NaN\n",
       "17619                                                  NaN\n",
       "17620    [os.system, subprocess.Popen, import os       ...\n",
       "17621    [device = input_data.get_device(), get_device(...\n",
       "17623                    [!python3.6 -m pip install scipy]\n",
       "17624    [load(), &gt; _VERSION\\r\\nLua 5.4\\r\\n&gt; tab ...\n",
       "17625                                                  NaN\n",
       "17626    [label_encoder.txt, label_encoder.ckpt, hyperp...\n",
       "17627    [masks, dtype=np.int8, :mask_size//2, In [244]...\n",
       "17628                                                  NaN\n",
       "17629                                                  NaN\n",
       "17631    [t[torch.arange(N),indices]\\r\\n, import torch\\...\n",
       "17633                       [conda install python=3.9\\r\\n]\n",
       "17634         [conda update -n base -c defaults conda\\r\\n]\n",
       "17635                 [conda install -n py310 python=3.10]\n",
       "17636    [conda-forge, conda install -c conda-forge pyt...\n",
       "17637                                                  NaN\n",
       "17638    [a = a.unsqueeze(-1)   # a.shape == (2, 1)\\r\\n...\n",
       "17639                                         [set.seed()]\n",
       "17640    [torch.nn.modules.loss, criterion = nn.NLLLoss...\n",
       "17641         [def forword(self, x), def forward(self, x)]\n",
       "17642    [index = random.sample(range(index[0]), 1000)\\...\n",
       "17644    [ pred + torch.tensor([val1, val2]).reshape((1...\n",
       "17645                                                  NaN\n",
       "17646                            [w -= dw, w, w - dw, w =]\n",
       "17647    [export LD_PRELOAD=/usr/lib/aarch64-linux-gnu/...\n",
       "17649                                                  NaN\n",
       "17651    [╔══════════════════════════╦═════════════════...\n",
       "17652    [preds, loss_fn, preds = torch.argmax(preds, d...\n",
       "17653                                                  NaN\n",
       "17654        [train_data.pop(index), .remove(), .remove()]\n",
       "17655                                                  NaN\n",
       "17656                                                  NaN\n",
       "17658                                                  NaN\n",
       "17659               [X_train = X_train.permute(1,0,2)\\r\\n]\n",
       "17660    [if __name__ == '__main__':\\r\\n    import code...\n",
       "17661                                                  NaN\n",
       "17662                                                  NaN\n",
       "17663    [z[1:] -= z[:-1].copy()\\r\\n, z[1:], z[:-1], copy]\n",
       "17664                          [np.diff(z, prepend=0)\\r\\n]\n",
       "17665    [np.diff, 1...N, cumsum, diff, cumsum, orig = ...\n",
       "17666    [z, np.ediff1d, x = np.ediff1d(z, to_begin=z[0...\n",
       "17667                 [orig = np.r_[z[0], np.diff(z)]\\r\\n]\n",
       "17668    [chmod +x ~/Downloads/Miniforge3-MacOSX-arm64....\n",
       "17669                                                  NaN\n",
       "17670    [class NEO(torch.nn.Module):\\r\\n    def __init...\n",
       "17672                                                  NaN\n",
       "17673    [a = np.array((1e-30, 2e-30), dtype='f4')\\r\\nn...\n",
       "17676                                                  NaN\n",
       "17677    [git lfs install\\r\\ngit clone https://huggingf...\n",
       "17678    [from transformers import BertTokenizer, BertF...\n",
       "17679    [function_parabola, def function_parabola(vari...\n",
       "17680    [torch.tensor_split, a = tensor([1., 1., 1., 1...\n",
       "17681    [mCameraDevice.createCaptureRequest(CameraDevi...\n",
       "17682    [x@w.t(), inputs = torch.tensor([[ 73,  67,  4...\n",
       "17683    [rearrange(mat, '(h n) w -&gt; (n h) w', n = 2...\n",
       "17684                                                  NaN\n",
       "17685                                                  NaN\n",
       "17687                                                  NaN\n",
       "17688                                [!nvcc --version\\r\\n]\n",
       "17689    [torchvision.io.read_image, import PIL\\r\\nimpo...\n",
       "17691                                                  NaN\n",
       "17692    [python3 -c \"import torch;print(torch.__versio...\n",
       "17693                                                  NaN\n",
       "17694    [# A -&gt; tensor of shape (8, 20, 256, 256)\\r...\n",
       "17695    [Target, Label, Label, import networkx as nx\\r...\n",
       "17696    [Weight, Label, Weight, Label, ID, node_label,...\n",
       "17697    [gcloud dataproc clusters create ${CLUSTER_NAM...\n",
       "17698    [def denormalize(x):\\r\\n  # Denormalizeing \\r\\...\n",
       "17699    [torch_image, numpy_image = torch_image.permut...\n",
       "17700    [print(loaded_model.device)\\r\\n, model = model...\n",
       "17701                                                  NaN\n",
       "17703                                                  NaN\n",
       "17704    [line_graph, original_edge_attrs = data.edge_a...\n",
       "17706    [!pip install torch-geometric \\\\r\\n  torch-spa...\n",
       "17707    [import torch\\r\\nprint(torch.__version__)\\r\\n!...\n",
       "17708    [import torch\\r\\n\\r\\n!pip uninstall torch-scat...\n",
       "17709    [!pip install -q torch-scatter -f https://data...\n",
       "17710    [import torch print(torch.__version__), !pip u...\n",
       "17711                                                  NaN\n",
       "17712                                                  NaN\n",
       "17713    [def save_checkpoint(epoch, model, best_top5, ...\n",
       "17714    [nvcc --version, conda install pytorch torchvi...\n",
       "17715    [torch.cat([a[:2], b, a[2:]])\\r\\n, tensor([ 1....\n",
       "17716                                                  NaN\n",
       "17717                                                  NaN\n",
       "17718                                                  NaN\n",
       "17719    [Sys.setenv(\"CUDA_HOME\" = \"C:/Program Files/NV...\n",
       "17720                                                  NaN\n",
       "17721    [&lt;!DOCTYPE html&gt;\\r\\n&lt;html lang=\"en\"&g...\n",
       "17727    [#created a random tensor like you mention  \\r...\n",
       "17728    [for, torch, import numpy as np\\r\\nimport torc...\n",
       "17729    [torch::from_blob, tuple&lt;float, float...&gt...\n",
       "17730                                                  NaN\n",
       "17731                                                  NaN\n",
       "17733    [Data/, Data/, path/to/lua/project/\\r\\n└── Dat...\n",
       "17734    [from transformers import AlbertTokenizer, Alb...\n",
       "17735    [upconv2 = self.upconv2(torch.cat([upconv1,con...\n",
       "17736                          [pip install torchtext\\r\\n]\n",
       "17737    [np.printoptions, __enter__,  from contextlib ...\n",
       "17738    [requirements.txt, git add .\\r\\ngit commit -m ...\n",
       "17739    [  output = module.forward(inputs);\\r\\n\\r\\n  a...\n",
       "17740    [import torch\\r\\n\\r\\na = torch.arange(12)\\r\\nm...\n",
       "17741    [import tensorflow as tf\\r\\nfrom tensorflow.ke...\n",
       "17743                                                  NaN\n",
       "17745    [np.bincount, indexs = np.array([1, 4, 3, 0, 0...\n",
       "17746    [n = len(train_ds)\\r\\n\\r\\n# I'm not sure if th...\n",
       "17747    [c = torch.tensor([\\r\\n    image.reshape(1,1,2...\n",
       "17752                        [use_cuda, fp16, True, False]\n",
       "17753                                [use_cuda= False\\r\\n]\n",
       "17754                                     [use_cuda=False]\n",
       "17755    [conda install pytorch torchvision torchaudio ...\n",
       "17756    [python3 -c \"import torch; print(torch.__versi...\n",
       "17757    [# python symlink\\r\\npython -m pip freeze\\r\\n#...\n",
       "17758    [user@debian:~/..$ pip3 show torch\\r\\nName: to...\n",
       "17759    [set_seed(42)\\r\\nt5model = T5ForConditionalGen...\n",
       "17760    [_, (hidden, _) = self.rnn1(packed_embedded)\\r...\n",
       "17761                                                  NaN\n",
       "17762                                                  NaN\n",
       "17763                                                  NaN\n",
       "17765    [!pip install urllib3==1.25.10\\r\\n!git clone h...\n",
       "17766    [a, # No need to squeeze\\r\\nc = torch.roll(a, ...\n",
       "17767    [matplotlib.pyplot, imshow, # Fake batch dimen...\n",
       "17768    [N=100 #For example\\r\\nk=10 #For example\\r\\nst...\n",
       "17769    [Pre-cxx11, cxx11, Pre-cxx11, cxx11, Pre-cxx11...\n",
       "17770                                                  NaN\n",
       "17771    [torch.save(model), torch.save('path_to_the_mo...\n",
       "17772    [model.save_pretrained(output_dir), model = *....\n",
       "17773    [Q, Q, torch.conj(Q).t(), *, @, torch.mm, torc...\n",
       "17774                                                  NaN\n",
       "17775    [seek, import torch \\r\\nimport io\\r\\nx = torch...\n",
       "17776                                       [int, int64_t]\n",
       "17777    [fatal: not a git repository (or any of the pa...\n",
       "17779    [import pickle\\r\\n\\r\\nimport tarfile\\r\\n\\r\\nfr...\n",
       "17780    [static void printScale(std::ostream &amp; str...\n",
       "17781    [PIL.Image.open, numpy, OpenCV, cv::Mat, torch...\n",
       "17783    [from numpy.core._multiarray_umath import (\\r\\...\n",
       "17785    [torch::stack, view, auto tfm = torch::stack( ...\n",
       "17786                                                  NaN\n",
       "17788    [static, static PyObject* THPFInfo_eps(THPFInf...\n",
       "17789    [cv::Mat, cv::Mat input_array (3, 1, CV_32FC1)...\n",
       "17790    [from_blob(), vector&lt;float&gt; linearize(co...\n",
       "17791                                                  NaN\n",
       "17792    [ids = np.delete(ids, np.concatenate([[last], ...\n",
       "17794    [y, torch::unsqueeze, cat, stack, torch::Tenso...\n",
       "17795    [pip install torch===1.6.0 torchvision===0.7.0...\n",
       "17796    [std::vector&lt;double&gt;, torch::from_blob, ...\n",
       "17797    [std::vector&lt;std::vector&lt;double&gt;&gt;,...\n",
       "17798    [answers[np.arange(size), pos] = c\\r\\n, answer...\n",
       "17799    [torchvision.models.resnet50(), conv1 = {Conv2...\n",
       "17800    [luarocks install luaossl OPENSSL_DIR=/usr/loc...\n",
       "17801                                                  NaN\n",
       "17802    [python3 -c 'import torch; print(torch.cuda.is...\n",
       "17803                                                  NaN\n",
       "17805    [def fill_ones(arr, idxs):\\r\\n    x = np.where...\n",
       "17806    [/etc/dphys-swapfile, CONF_SWAPFILE=2048M\\r\\n,...\n",
       "17807    [-D_GLIBCXX_USE_CXX11_ABI=0, TORCH_CXX_FLAGS, ...\n",
       "17808    [x.view(x.size(0), -1), x.view(), x.shape(0), ...\n",
       "17809                                                  NaN\n",
       "17810    [pip install torch==1.5.0 torchvision==0.6.0 -...\n",
       "17811    [features = MyConvolutions(x)\\r\\npooled_featur...\n",
       "17812                                          [nn.Module]\n",
       "17813    [class MyModel(nn.Module):\\r\\n    def __init__...\n",
       "17814    [cp /usr/lib/libc++.1.dylib /Library/Framework...\n",
       "17815    [!pip3 install transformers\\r\\nfrom transforme...\n",
       "17816    [pyi-bindepend caffe2_nvrtc.dll\\r\\n, MISSING_L...\n",
       "17817              [[], {}, [1, 2, 3], [, ], {1, 2, 3}, []\n",
       "17819    [torch==1.3, pip install torch===1.3.1 -f http...\n",
       "17820                                     [%PATH%, %PATH%]\n",
       "17821               [6a35cd9, pkg/torch, 89ede3b, 2186e41]\n",
       "17823    [labels = [0,1]\\r\\nlogits = np.asarray([[0.9,0...\n",
       "17825                                                  NaN\n",
       "17826    [replicate(x,batch_size), -- Stacks replicated...\n",
       "17827                                                  NaN\n",
       "17828                                                  NaN\n",
       "17829    [Timer(Duration(milliseconds: 450), () {\\r\\n  ...\n",
       "17830    [Go to Menu &gt; Runtime &gt; Change runtime.,...\n",
       "17831    [init, import torch, def init():\\r\\n    if __n...\n",
       "17832                                                  NaN\n",
       "17833    [def sample(self, sentences: List[str], beam: ...\n",
       "17834                                                  NaN\n",
       "17835    [tensorflow-tensorboard,  pip uninstall tensor...\n",
       "17836                      [pip install tensorflow-io\\r\\n]\n",
       "17837    [diff, def reduce(x): return np.r_[x[:,:-1].su...\n",
       "17838                [pytorch, C++, C++, C++, torchscript]\n",
       "17839    [torch.multiprocessing.Queue, data_item.share_...\n",
       "17840    [import sys\\r\\nimport time\\r\\n\\r\\nimport torch...\n",
       "17841                                                  NaN\n",
       "17842    [filep= os.path.join(root, splitp)\\r\\n\\r\\nwith...\n",
       "17843                                    [../utils/net.pt]\n",
       "17844    [V, entities, utterance, Named Entity Recognit...\n",
       "17845          [scikit-learn, Doc2Vec, gensim, GoogleNews]\n",
       "17846    [librosa, conda-forge, conda config --remove c...\n",
       "17847                      [(N, C, H, W), (1, 1, 500, 13)]\n",
       "17848                                                  NaN\n",
       "17849                                                  NaN\n",
       "17851                                    [torch, luarocks]\n",
       "17852    [bsg = sgs.data\\r\\ndevice = sgs.device\\r\\nbs, ...\n",
       "17853                                                  NaN\n",
       "17854    [.png, import torch\\r\\nfrom kymatio import Sca...\n",
       "17855                                                  NaN\n",
       "17857    [brew tap caskroom/fonts\\r\\nError: caskroom/fo...\n",
       "17859    [brew cask, MyMacBook-Pro:homebrew-core adam$ ...\n",
       "17863    [ x = torch.tensor([[1, 2, 3]])\\r\\n print(x)\\r...\n",
       "17865    [C:\\Anaconda3\\lib\\site-packages, \\\\nsq025ps\\p1...\n",
       "17866                                                  NaN\n",
       "17867    [&lt;permission android:name=\"android.permissi...\n",
       "17868    [private void turnOffLight() {\\r\\n\\r\\n        ...\n",
       "17869    [from torch.utils.cpp import ....\\r\\n#or\\r\\nfr...\n",
       "17871    [cd \"D:\\Program Files (x86)\\IntelSWTools\\compi...\n",
       "17872    [__str__, __repr__, __repr__, def __repr__(sel...\n",
       "17874    [nn.MSELoss(), loss = nn.MSELoss()\\r\\ninput = ...\n",
       "17875                                                  NaN\n",
       "17876    [&lt;, import torch\\r\\nimport heapq\\r\\n\\r\\ncla...\n",
       "17877    [    [...]\\r\\n    torchvision.transforms.ToTen...\n",
       "17878    [out = out[:,-1,:] # batch_size x 480\\r\\nout =...\n",
       "17879            [sigma = 0.3\\*((ksize-1)\\*0.5 - 1) + 0.8]\n",
       "17880    [gaussian_kernel = cv2.getGaussianKernel(kerne...\n",
       "17881    [matplotlib, indices = []\\r\\nlosses = []\\r\\n\\r...\n",
       "17882                                                  NaN\n",
       "17883    [lua-science, conda install -c alexbw lua-cudn...\n",
       "17884                                                  NaN\n",
       "17885          [import nn as n, import nn.functional as F]\n",
       "17886                                       [torch, torch]\n",
       "17887                                                  NaN\n",
       "17888       [export PATH=$PATH:/bin/python/:/bin/bash\\r\\n]\n",
       "17889                                                  NaN\n",
       "17890    [model, torch::nn::Sequential, torch::NoGradGu...\n",
       "17891    [void set_weights(fc_model &amp;src_net) {\\r\\n...\n",
       "17892    [model.forward()[0,:,:,:], 3x256x256, np.trans...\n",
       "17893    [!git clone https://github.com/nagadomi/distro...\n",
       "17894    [CMakeLists.txt, cmake_minimum_required(VERSIO...\n",
       "17895    [CMakeLists.txt, TorchConfig.cmake, vcpkg, vcp...\n",
       "17896                                                  NaN\n",
       "17898    [numpy, all, np.sum((A == B).all(1))\\r\\n#1\\r\\n...\n",
       "17900    [encoder_clones.forward, encoder_clones, encod...\n",
       "17901                                      [cublas_device]\n",
       "17902    [git clone https://github.com/nagadomi/distro....\n",
       "17903    [sudo apt remove cmake\\r\\nwget https://cmake.o...\n",
       "17904    [local myValue = someTable.theIndex\\r\\n-- or\\r...\n",
       "17905    [t[k], k, fea_img[i], {k,{}}, nil, {k,{}}, fea...\n",
       "17907                                                  NaN\n",
       "17908    [inspect.getmembers, ('bmm', torch.bmm), torch...\n",
       "17909    [somevariable.icgnn.someproperty, somevariable...\n",
       "17911             [tonumber, tonumber(\"10\"), tonumber(10)]\n",
       "17912    [git clone https://github.com/torch/distro.git...\n",
       "17913                                               [cunn]\n",
       "17914    [#for Torch with Lua 5.3:\\r\\nimport os\\r\\nos.e...\n",
       "17915    [from os import path\\r\\nfrom wheel.pep425tags ...\n",
       "17916    [torch.nn.DataParallel, RNN_ENCODER, CNN_ENCOD...\n",
       "17918    [class Region private () {\\r\\n  private val re...\n",
       "17919                                    [th and luarocks]\n",
       "17920                                                  NaN\n",
       "17921                                           [g++, g++]\n",
       "17923    [a = createSomeTable()\\r\\n...\\r\\nb = a -- now ...\n",
       "17924                                                  NaN\n",
       "17925                                                  NaN\n",
       "17926    [cudnn, cunn, if currentModule is cuda, then c...\n",
       "17927    [ResNet, block, # Residual Block\\r\\nclass Resi...\n",
       "17929    [C:\\Program Files\\NVIDIA GPU Computing Toolkit...\n",
       "17930    [conda create -n envName python=3.6 anaconda, ...\n",
       "17931    [.whl, pip install numpy‑1.14.5+mkl‑cp36‑cp36m...\n",
       "17932        [conda install -c peterjc123 pytorch-cpu\\r\\n]\n",
       "17933                         [import torch, import torch]\n",
       "17934    [import torch\\r\\n  File \"C:\\Program Files\\Pyth...\n",
       "17935    [virtualenv --python=3.6 pytorch_test, cd D:\\p...\n",
       "17936        [colorize, output, input, colormap, init.lua]\n",
       "17937                                    [--enable-shared]\n",
       "17938    [newFile:write('images', input_images_caffe[i]...\n",
       "17941    [  local depth_wise_conv = nn.Concat(2)\\r\\n  f...\n",
       "17943                                                  NaN\n",
       "17946    [make NO_AFFINITY=1 USE_OPENMP=0 USE_THREAD=0\\...\n",
       "17948                                                  NaN\n",
       "17949     [audio.load, python, import, audio.load, README]\n",
       "17950    [audio.load, /Users/.../fullyMerged.mp3, audio...\n",
       "17951                                                  NaN\n",
       "17952    [model = nn.Sequential()\\r\\nmodel:add(nn.Linea...\n",
       "17953                                                  NaN\n",
       "17954                                                  NaN\n",
       "17955    [-DCMAKE_INSTALL_PREFIX=\"/home/tex/torch/insta...\n",
       "17956    [IF (CUDA_FOUND)\\r\\n   LIST(APPEND CUDA_NVCC_F...\n",
       "17957    [torch-opencv, opencv-3.1.0, opencv-3.3.0, ope...\n",
       "17958                                                  NaN\n",
       "17962    [local aaa = {1, 2, 3, 4}\\r\\nlocal bbb = {0, 0...\n",
       "17963    [t = torch.Tensor([[1,2],[3,4]])\\r\\nindex = to...\n",
       "17964    [gather, y, torch.manual_seed(0)\\r\\n\\r\\nnum_ex...\n",
       "17965                                                  NaN\n",
       "17966    [layer {\\r\\n  name: \"input-data\"\\r\\n  type: \"D...\n",
       "17967    [@Override\\r\\nprotected void onStart() {\\r\\n  ...\n",
       "17973                                                  NaN\n",
       "17974    [backward(), repeat\\r\\n  local output = model:...\n",
       "17975                                                  NaN\n",
       "17976    [nn.Normalize, PartialNormalize.lua, local Par...\n",
       "17977    [concat, require\"torch\"\\r\\nnn=require\"nn\"\\r\\nl...\n",
       "17978    [running_std, running_var, ptb:add(some_model:...\n",
       "17979    [git clone https://github.com/deepmind/torch-t...\n",
       "17980    [net = nn.Sequential()\\r\\ntriple = nn.Parallel...\n",
       "17981    [scores, &gt; scores=torch.floor(torch.rand(4,...\n",
       "17982    [ sr=scores:view(-1,scores:size(1)*scores:size...\n",
       "17983                                                  NaN\n",
       "17984                                                  NaN\n",
       "17985    [t = nn.Sequential()\\r\\nt:add(nn.Linear(3,2))\\...\n",
       "17986    [o:f(x, y)\\r\\n, o.f(self, x, y)\\r\\n, init, sel...\n",
       "17987    [foo:bar, foo.bar, self, function Foo:bar( ......\n",
       "17988         [    local gesture_int = gesture:uint()\\r\\n]\n",
       "17989    [print(type(gesture)) -&gt; prints `userdata`\\...\n",
       "17990            [include, nil, include, include, include]\n",
       "17994    [:threads(function()\\r\\n            require 'm...\n",
       "17995    [torch[cpuType], torch.cpuType, cpuType, Doubl...\n",
       "17996    [self.transfer, transfer, mlp, output, gradInp...\n",
       "17997    [TORCH_LUA_VERSION, LUAXX, LUA53, git clone ht...\n",
       "17998    [# Mac users\\r\\nbrew install graphviz\\r\\n\\r\\n#...\n",
       "17999    [EMDCriterion, torch.histc, for i=1,#images do...\n",
       "18000    [import caffe\\r\\nimport numpy as np\\r\\n\\r\\ncla...\n",
       "18001                                                  NaN\n",
       "18003    [net:add(nn.JoinTable(1,8)), net:add(nn.JoinTa...\n",
       "18004    [torch.randperm,  a=torch.rand(3,5)\\r\\n print(...\n",
       "18005    [dim = 0\\r\\nidx = torch.randperm(t.shape[dim])...\n",
       "18006    [data=torch.floor(torch.rand(5,3,2)*100):float...\n",
       "18007    [x = torch.rand(4, 4)\\r\\np = torch.randperm(4)...\n",
       "18008                                                  NaN\n",
       "18009                                                  NaN\n",
       "18010    [numpy, 64-bit floating point, torch.DoubleTen...\n",
       "18011    [data, DoubleTensor, FloatTensor, data, FloatT...\n",
       "18013                        [state, config, beta1, beta2]\n",
       "18014    [w[t+1] = w[t] - learning_rate * dw - weight_d...\n",
       "18015    [tf.train.Optimizer, class AdamWeightDecayOpti...\n",
       "18016    [nngraph, __call__, (), __unm__, -, __sub__, -...\n",
       "18018    [y_i = x_i, if x_i &gt;= min_value or x_i &lt;...\n",
       "18019                                                  NaN\n",
       "18020                                                  NaN\n",
       "18021                           [cuda(), cudnn, nn, cudnn]\n",
       "18022                          [:cuda(), cudnn.xxx, cudnn]\n",
       "18023    [brew install hdf5@1.8\\r\\n, hdf5._config = {\\r...\n",
       "18025    [L, loss(input, target) = ClassNLLCriterion(in...\n",
       "18026    [tmp, TMPDIR, mkdir $HOME/tmp\\r\\nexport TMPDIR...\n",
       "18027                  [tmp, tmp, mount, /etc/fstab, /tmp]\n",
       "18030                              [sudo rm /usr/bin/nvcc]\n",
       "18032                                    [/usr/local/coda]\n",
       "18033    [luarocks install torch, luarocks install cuto...\n",
       "18034    [forward, output, charFeatures[i], charFeature...\n",
       "18035    [CDivTable, null, 2x3, SplitTable(dim), dim, r...\n",
       "18036                   [224 x 224, 660 x 1045, 224 x 224]\n",
       "18037                                                  NaN\n",
       "18038    [n, x_at_i, X = torch.Tensor(n, n):zero()\\r\\nf...\n",
       "18039    [netR:evaluate()\\r\\n, training(), evaluate(), ...\n",
       "18041    [ x=torch.Tensor{{1,2,3,4,},{5,6,7,8,}}\\r\\n y=...\n",
       "18042    [X = torch.rand(10000, 3, 50, 50)\\r\\ninds = to...\n",
       "18043    [train = torch.range(1,10)\\r\\np = torch.randpe...\n",
       "18044    [torcy.save('mynet.t7',net, params, grad_param...\n",
       "18045    [. ~/torch/install/bin/torch-activate, ~/.bash...\n",
       "18047    [findFile, wc -L 'findFile' | cut -f1 -d, 53, ...\n",
       "18052    [libpq-dev, /usr/include/postgresql/libpq-fe.h...\n",
       "18053    [libpq-dev, libpq-fe.h, /usr/include/postgresql/]\n",
       "18054    [nn.View, nn.View(−1, out_channels * out_heigh...\n",
       "18055    [yum install postgresql-devel\\r\\n, yum install...\n",
       "18056    [setmetatable(train_set, \\r\\n{\\r\\n  __index = ...\n",
       "18057    [t, __index, train_set, __index, train_set, k,...\n",
       "18058    [h_desired, h_desired - h_current, delta_i=(y_...\n",
       "18060    [tf.GraphKeys.UPDATE_OPS, name_scope, UPDATE_O...\n",
       "18061                                                  NaN\n",
       "18062    [cmul, mul, import torch\\r\\n\\r\\nx = torch.Tens...\n",
       "18063                                    [torch.legacy.nn]\n",
       "18064                    [z = x.cmul(y)\\r\\n, cmul, Tensor]\n",
       "18065               [view(), -1, A, A:view(2, 1, 3, 4), A]\n",
       "18066    [unsqueeze(), view(), view(), unsqueeze(), uns...\n",
       "18067                                [a, and, b, or, a, b]\n",
       "18068    [model:evaluate();\\r\\n\\r\\n-- We assume that th...\n",
       "18069    [minibatch = torch.Tensor(5, 2, 3,5)\\r\\nm = nn...\n",
       "18071    [tensor_a = torch.Tensor(n, 2A, B,C)\\r\\n-- Ini...\n",
       "18075    [MobileBarcodeScanner, FlashButtonText, &lt;Bo...\n",
       "18076                                                  NaN\n",
       "18077    [require 'dpnn'\\r\\n\\r\\naaa = torch.DoubleTenso...\n",
       "18078    [require 'image'\\r\\nrequire 'nn'\\r\\nrequire 't...\n",
       "18079    [-- First get the maximum element and indices ...\n",
       "18081    [  public Camera getCameraObject (CameraSource...\n",
       "18082    [print model, model = torch.load(path_to_model...\n",
       "18084    [apply, repeatTensor, cmul, rPr = r:view(1, N)...\n",
       "18085    [denominator[1][1], -- W and P are of size NxN...\n",
       "18087                          [org.eclipse.dltk.debug.ui]\n",
       "18088    [nn.ClassNLLCriterion, for k,v in pairs(criter...\n",
       "18089                                             [-model]\n",
       "18090    [require 'nn'\\r\\n\\r\\n-- the input\\r\\nlocal bat...\n",
       "18091    [k, for k = 1,nScales do, for scale = -3,2,.25...\n",
       "18092                                                  NaN\n",
       "18093                                             [iTorch]\n",
       "18094                   [./clean.sh, ~/torch, ./update.sh]\n",
       "18095                                  [random, nil, rand]\n",
       "18096    [rm -rf ~/torch, cutorch, cunn, luarocks, luar...\n",
       "18097               [sudo apt-get install libopenblas-dev]\n",
       "18098                                                  NaN\n",
       "18102    [nn.Container():add(enc):add(dec):getParameter...\n",
       "18103    [params = cmd:parse()\\r\\nlocal tmptab = {}\\r\\n...\n",
       "18105    [package.loadlib, require, require, package.lo...\n",
       "18106                                                  NaN\n",
       "18107                                                  NaN\n",
       "18108    [tf.fused_batch_norm, fused=True, feed_dict, f...\n",
       "18109                         [cudnn.benchmark = true\\r\\n]\n",
       "18110                                                  NaN\n",
       "18111    [model:add(nn.Reshape(28*28)), ……./torch/insta...\n",
       "18112    [this.ReleaseCapture();\\r\\nthis.InitCapture();...\n",
       "18113                     [nn.utils.addSingletonDimension]\n",
       "18114                                                  NaN\n",
       "18119    [boundingRect, import numpy as np\\r\\nimport cv...\n",
       "18120     [image.save('train100.jpg', trainData[100])\\r\\n]\n",
       "18121                       [torchvision.utils.save_image]\n",
       "18122                                                  NaN\n",
       "18123                                                  NaN\n",
       "18125                                                  NaN\n",
       "18126    [result = storage_res-&gt;data;, `for(size_t i...\n",
       "18127    [__index, __index__, __index__, __index, type(...\n",
       "18128    [-- Function that builds a gModule\\r\\nfunction...\n",
       "18130    [$ lspci  | grep -i 'vga\\|3d\\|2d'\\r\\n, $ expor...\n",
       "18131    [getParameters, getParameters, getParameters, ...\n",
       "18133    [f:lines(), line:split(' '), tonumber(val), &l...\n",
       "18134                                                  NaN\n",
       "18135    [m = nn.ClassNLLCriterion()\\r\\nnClasses = 3\\r\\...\n",
       "18136        [in_1, in_2, in_1, in_2, nil, collectgarbage]\n",
       "18137    [function train()\\r\\n  do\\r\\n    local in = lo...\n",
       "18138                                                  NaN\n",
       "18139    [require 'torch'\\r\\nrequire 'nn'\\r\\nrequire 'o...\n",
       "18140    [local loss_x = criterion:forward(model:forwar...\n",
       "18142    [nIputPlane, nOutputPlane, nInputPlane  = 3, n...\n",
       "18143    [public class fragment_qrscan extends myFragme...\n",
       "18145    [&lt;ctrl - \\ &gt;, /setTestArgs, map &lt;C-\\&...\n",
       "18146                                                  NaN\n",
       "18147        [undefined symbol: luaL_setfuncs, ./clean.sh]\n",
       "18148    [torch.manualSeed(0), 2000, 50, MOMENTUM, ITER...\n",
       "18149    [LEARN_RATE = 0.001, 1e-1, 1e-8, hiddenUnitVec...\n",
       "18151    [                   gradParameters:div(inputs:...\n",
       "18152                                                  NaN\n",
       "18154    [if nArgs == 1 and input == nil then\\r\\n   err...\n",
       "18155                   [-help, th MyScript.lua -help\\r\\n]\n",
       "18156    [require(), \"./?.so;./?.dll;/usr/local/?/init....\n",
       "18157    [LUA_PATH, LUA_CPATH, LUA_CPATH=/path/to/?.so,...\n",
       "18159    [:type(), cutorch = require('cutorch')\\r\\n\\r\\n...\n",
       "18160    [local myFile = hdf5.open('/path/to/write.h5',...\n",
       "18161    [vector&lt;int&gt;, malloc, int, free, vector&...\n",
       "18163    [gradInput, self.gradInput = torch.CudaTensor(...\n",
       "18166    [def depthconcat(inputs):\\r\\n    concat_dim = ...\n",
       "18167    [torch, app.lua, require 'torch'\\r\\nrequire 'n...\n",
       "18168                                                  NaN\n",
       "18169    [nobody, chown -R nobody:nogroup openresty_pro...\n",
       "18170    [require 'nn'\\r\\nN = 4\\r\\naaaTensor = torch.ra...\n",
       "18171    [z = {}\\r\\n\\r\\nfor i=1,10 do\\r\\n\\r\\n  z[i] = {...\n",
       "18172    [local function makeMatrix(initialVal, ...)\\r\\...\n",
       "18174    [nn.Container, container = nn.Container()\\r\\nc...\n",
       "18175    [net2, input = nn.Identity()()\\r\\nnet1 = nn.Se...\n",
       "18176    [net1.updateGradInput = function(self, inp, ou...\n",
       "18177                                                  NaN\n",
       "18178    [Torch_DIR, export Torch_DIR=/home/my/pyenv/py...\n",
       "18179    [input = nn.Identity()()\\r\\nL1 = nn.ReLU(true)...\n",
       "18180                                                  NaN\n",
       "18181                                                  NaN\n",
       "18182    [CudaTensor, conv = conv:float(), local tensor...\n",
       "18183    [for i = 1, n do\\r\\nthreads:addjob(\\r\\n       ...\n",
       "18184    [seqlen x batchsize, 0 0\\r\\n1 2\\r\\n1 2\\r\\n2 3\\...\n",
       "18185    [function feval(x)\\r\\nif x ~= params then\\r\\n ...\n",
       "18186    [permute(x, y, z), itorch.image(your_image), x...\n",
       "18188    [torch.serialize, serialized_batch = nil\\r\\nco...\n",
       "18189                                                  NaN\n",
       "18190    [x = torch.Tensor(2, 2):fill(2)\\r\\n\\r\\nz = tor...\n",
       "18191    [local z= torch.cinv(x) -- to make a copy\\r\\nx...\n",
       "18193    [CrossEntropyCriterion(), LogSoftMax, ClassNLL...\n",
       "18195                   [http-data, bash, dash, sh, $PATH]\n",
       "18198                                                  NaN\n",
       "18199    [X_py = {X_py_1, X_py_2, X_py_3, X_py_4, X_py_...\n",
       "18200    [X_py = {}\\r\\nfor s, scale in ipairs(scales) d...\n",
       "18201    [cd /usr/bin/\\r\\nmv gcc gcc-6.1-back\\r\\nmv g++...\n",
       "18204                                                  NaN\n",
       "18205    [max_size, self:get_max_size()\\r\\n, myClass:ge...\n",
       "18207                                                  NaN\n",
       "18209    [function rmdir(p)\\r\\n  path.each(path.join(p,...\n",
       "18210    [local lfs = require('lfs')\\r\\n\\r\\nlocal delet...\n",
       "18212                            [luarocks install cv\\r\\n]\n",
       "18214                                                  NaN\n",
       "18215    [require 'nn'\\r\\n\\r\\nx = {torch.Tensor{{1,1},{...\n",
       "18216    [nclasses = 2, y[1] = values[#values] + 1, y, ...\n",
       "18217                                                  NaN\n",
       "18219    [m = nn.Linear(100,200)\\r\\n-- copy your weight...\n",
       "18223    [qlua, luajit, torch, luarocks, qlua, $ luaroc...\n",
       "18224    [CUDA_VISIBLE_DEVICES=0 th [torch script]\\r\\nC...\n",
       "18225    [cd ~/torch\\r\\n./clean.sh\\r\\nTORCH_LUA_VERSION...\n",
       "18226    [buff = buff..line..\"\\n\"\\r\\n, local buff = \"\" ...\n",
       "18227    [pairs, ipairs, pairs (t)\\r\\n, t, __pairs, t, ...\n",
       "18231    [for i = 1,niter do\\r\\n  -- k-means computatio...\n",
       "18236    [if __name__ == '__main__':\\r\\n    app.run(hos...\n",
       "18237    [CameraManager camManager = (CameraManager) ge...\n",
       "18238                                                  NaN\n",
       "18239                                                  NaN\n",
       "18240    [x, x, dl_dx = model:getParameters(), model:fo...\n",
       "18241    [x, function foo(a, b)\\r\\n    local a = a or 0...\n",
       "18242    [{...},  {...}              -- creates a list ...\n",
       "18243    [nn.SplitTable, ParallelCriterion, M = 100\\r\\n...\n",
       "18244    [t = torch.Tensor({1, 2, 3, 1, 4, 2, 2, 2, 3, ...\n",
       "18245    [local Bar, parent = torch.class('torch.Bar', ...\n",
       "18246    [cdata, ffi.copy, require 'torch'\\r\\nffi = req...\n",
       "18247    [require 'torch';\\r\\nrequire 'nn';\\r\\nrequire ...\n",
       "18248                       [optim, optim.sgd, nil, optim]\n",
       "18250    [brew, sudo ~/torch/install/bin/luarocks insta...\n",
       "18251                     [ffi, luarocks install torchffi]\n",
       "18252    [3D or 4D (batch mode) tensor, t.data[i]\\r\\n, ...\n",
       "18253    [luarocks install https://raw.github.com/jucor...\n",
       "18254    [rpnnode.Foo(rpnnode, input), rpnnode:Foo(input)]\n",
       "18255    [narrow, narrow, select, sub, Storage, th&gt; ...\n",
       "18256    [t2h_d.data.module:share(shared_weights[1], 'w...\n",
       "18258                                                  NaN\n",
       "18259                                                  NaN\n",
       "18260                                                  NaN\n",
       "18261    [import numpy\\r\\nimport Image\\r\\n\\r\\n## boot s...\n",
       "18262                           [x:view(x:nElement())\\r\\n]\n",
       "18263    [local my_vector = nn.reshape(vector_size, ori...\n",
       "18264    [mnist.train.next_batch(50), correct_predictio...\n",
       "18265    [eval(), correct_prediction, print correct_pre...\n",
       "18266    [correct_prediction.eval(), tf.session.run(cor...\n",
       "18267    [require \"torch\"\\r\\nrequire \"nn\"\\r\\nrequire \"r...\n",
       "18268                     [x, (-1, 1), |x|, 0.5x + 0.5, y]\n",
       "18269    [HDF5Group:_writeData, ffi.lua, label = {'a', ...\n",
       "18270              [score = model:forward(input_case)\\r\\n]\n",
       "18271    [torch.serialization, File:writeObject, elseif...\n",
       "18273    [\\init.lua\\r\\n\\main.lua\\r\\n\\test-0.1-1.rockspe...\n",
       "18274      [m:forward({y, x:view(4,1,5):expandAs(y)})\\r\\n]\n",
       "18275    [sudo git config --global url.\"https://\".inste...\n",
       "18276                                                  NaN\n",
       "18277    [print, __tostring, tostring, tostring, &gt; t...\n",
       "18278                                                  NaN\n",
       "18280    [source ~/.profile\\r\\n, # On Linux with bash\\r...\n",
       "18281                                                  NaN\n",
       "18283    [sudo apt-get --purge remove ipython\\r\\nsudo p...\n",
       "18284         [a = a:repeatTensor(1, 3):reshape(9, 3)\\r\\n]\n",
       "18285    [./pkg/torch/lib/TH/cmake/FindMKL.cmake, ./cle...\n",
       "18289        [os.execute(\"th test.lua -visiualize 0\")\\r\\n]\n",
       "18290    [p.getOutputStream(),     Process p = Runtime....\n",
       "18291    [sudo apt-get install libhdf5-serial-dev hdf5-...\n",
       "18292    [t = require 'torch'\\r\\nrequire 'cunn'\\r\\nrequ...\n",
       "18293    [set, unique(), function vector_unique(input_t...\n",
       "18294    [gradInput, gradOutput, d_C/d_input_L, d_C/d_o...\n",
       "18295    [cd ~/torch-android;, git submodule update --i...\n",
       "18296                   [ a[b:ne(1)]\\r\\n,  a[b:eq(0)]\\r\\n]\n",
       "18297    [net = nil\\r\\ntrainset = nil\\r\\ntestset = nil\\...\n",
       "18298    [local matio = require \"matio\"\\r\\nmatio.save(\"...\n",
       "18299    [==, a = torch.Tensor(3, 5):fill(1)\\r\\nb = tor...\n",
       "18300                           [luarocks install sys\\r\\n]\n",
       "18301                                  [net:get(6).output]\n",
       "18302    [sel = S:ge(5):expandAs(A)   -- now you can us...\n",
       "18303    [maskedSelect, result=A:maskedSelect(your_byte...\n",
       "18304    [nn.BatchNormalization, image:reshape(1,3,32,3...\n",
       "18305    [sudo python, import theano, make, ./[name_of_...\n",
       "18306                         [sudo bash /torch/update.sh]\n",
       "18307    [sliced_dataset = dataset:index(1, positive_ma...\n",
       "18308    [local dump = function(vec)\\r\\n    vec = vec:v...\n",
       "18309    [narrow, narrow, ten[{{1,2},1}], 2, ten[{{1,2}...\n",
       "18310    [require 'torch'\\r\\n\\r\\nmatrix = torch.Tensor(...\n",
       "18311    [import pytorch as torch\\r\\nimport numpy as np...\n",
       "18312        [install-deps, easy_install, pip, install.sh]\n",
       "18313         [permission denied, root, sudo, chown, root]\n",
       "18314                                                  NaN\n",
       "18315                   [sudo apt-get install libjpeg-dev]\n",
       "18317                                                  NaN\n",
       "18318    [seq.zip, seq.zip, zip, local zip\\r\\ndo\\r\\n  l...\n",
       "18319    [---------------------------------------------...\n",
       "18320    [local zipgen = function(args)\\r\\n    -- find ...\n",
       "18321    [torch.updateerrorhandlers(), hi from Lua func...\n",
       "18322    [function repeatNoCopy(tensor, k)\\r\\n    local...\n",
       "18323    [The weights and biases in the network model w...\n",
       "18324    [new, self._getFromThreads, self._pushResult, ...\n",
       "18325    [libcufft.so, SET(PROJECT_LINK_LIBS libcufft.s...\n",
       "18326    [function fill_0normal(t,sigma) do\\r\\n  t:norm...\n",
       "18327    [sub = ls:index(1, torch.LongTensor{2, 7, 9})\\...\n",
       "18328    [&gt; a = torch.ByteTensor{1,0,1,0,1}\\r\\n&gt; ...\n",
       "18329                      [updateOutput, updateGradInput]\n",
       "18330    [subprocess.check_output(['th', 'sample.lua', ...\n",
       "18331    [[jalal@goku scratch]$ sudo /usr/bin/pip insta...\n",
       "18332    [opts.lua, donkey.lua, th&gt; dofile(\"opts.lua...\n",
       "18333                                                  NaN\n",
       "18334    [model:add(nn.LogSoftMax()), log, model = nn.S...\n",
       "18335    [(7,1,1,1,1,1,1) &lt;--First class representat...\n",
       "18336    [t = torch.rand(2, 3, 6)\\r\\n-- (1,.,.) = \\r\\n-...\n",
       "18337    [nn, cunn, luarocks install nn\\r\\nluarocks ins...\n",
       "18339    [lc, lt, set terminal x11 0 position 1200,20 p...\n",
       "18340    [jupyter kernelspec list, /usr/local/share/jup...\n",
       "18342    [import lutorpy as lua\\r\\nimport numpy as np\\r...\n",
       "18343    [th&gt; require 'nngraph'\\r\\nth&gt; conv1 = nn...\n",
       "18345                              [bash install-deps\\r\\n]\n",
       "18346                                               [body]\n",
       "18347    [local gm = require 'graphicsmagick'\\r\\nlocal ...\n",
       "18348    [debug.getinfo(3), debug.getinfo(3).name, nil,...\n",
       "18349       [net:parameters(), net:getParameters(), sgd()]\n",
       "18350    [luarocks-5.1 path, $ luarocks-5.1 path\\r\\nexp...\n",
       "18351    [local softMaxLayer = cudnn.LogSoftMax():cuda(...\n",
       "18352    [require 'nn'\\r\\ntorch.getmetatable('nn.Module...\n",
       "18353    [printTry, perceptron, Module, Module.lua, nn....\n",
       "18354    [nn, (Spatial)BatchNormalization, nn.Linear, f...\n",
       "18355                                                  NaN\n",
       "18358    [yi = f(xi)\\r\\n   = log( exp(xi) / sum_j(exp(x...\n",
       "18359    [function get_elems_simple(tensor, indices)\\r\\...\n",
       "18360                                              [torch]\n",
       "18361    [import torch\\r\\n\\r\\na = torch.rand(1,10)\\r\\nb...\n",
       "18362    [bb:resize(2,1)\\r\\n, th&gt; bb:t()\\r\\n 1  2\\r\\...\n",
       "18363    [th&gt; torch.cmul(q,w)\\r\\n  1   4   9\\r\\n  4 ...\n",
       "18364    [:sub, x = torch.Tensor(5, 6):zero()\\r\\n&gt; x...\n",
       "18368    [z = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9...\n",
       "18369    [a = torch.Tensor([1,2,3,4])\\r\\n, [1., 2., 3.,...\n",
       "18370    [def repeat(tensor, dims):\\r\\n    if len(dims)...\n",
       "18371    [from einops import repeat\\r\\n\\r\\nrepeat(x, 'i...\n",
       "18372    [import torch as pt\\r\\n\\r\\n#1 work as numpy ti...\n",
       "18374    [    dataSize = Data.data:size()[1]\\r\\n    shu...\n",
       "18375    [# in a terminal, run the commands\\r\\ncurl -s ...\n",
       "18376    [dataset[i] = {input[i], output}, output[1], o...\n",
       "18377    [$ luarocks install graphicsmagick, require 'i...\n",
       "18378    [number, nn.ClassNLLCriterion, nn.LogSoftMax()...\n",
       "18379                                                  NaN\n",
       "18380    [n = 100\\r\\ns = 20\\r\\nx = torch.randn(1, n, n,...\n",
       "18381                                                  NaN\n",
       "18383                                                  NaN\n",
       "18384    [SpatialConvolutionMM, model:add(nn.SpatialCon...\n",
       "18386    [THGeneral.c, THAllocInternal, THAllocInternal...\n",
       "18387    [function split(str)\\r\\n    tbl = {}\\r\\n    fo...\n",
       "18389    [torch_activate, .bash_profile, source /Users/...\n",
       "18390    [t = torch.Tensor({{0, -1, -3}, {6, 5, 0}, {0....\n",
       "18391    [t = { 0,  -1,  -3,\\r\\n      6,   5,   0,\\r\\n ...\n",
       "18392    [t = { 0,  -1,  -3,\\r\\n      6,   5,   0,\\r\\n ...\n",
       "18393    [Lua, type(), type('Hello world')             ...\n",
       "18394                                               [type]\n",
       "18395    [require 'torch'\\r\\ncmd = torch.CmdLine()\\r\\nc...\n",
       "18396    [B,  1  1  1\\r\\n 2  2  2\\r\\n 3  3  3\\r\\n[torch...\n",
       "18397    [subfolders = {}\\r\\ncounter = 0\\r\\n\\r\\nlocal d...\n",
       "18398    [.., ., 447, function isSubdir(path)\\r\\n    no...\n",
       "18399    [sudo, sudo source ~/.bashrc, source, sudo, .b...\n",
       "18400    [$ qlua\\r\\n&gt; require 'image'\\r\\n&gt; w = im...\n",
       "18401    [optim, optimState = { \\r\\nlearningRate = 0.00...\n",
       "18404    [x = torch.Tensor(2, 4, 4)\\r\\nx[1]:fill(0)\\r\\n...\n",
       "18405    [y = x[{{1, 1}, {}, {}}]\\r\\n, y = x[{{1, 1}}]\\...\n",
       "18406    [match, local str = \"0.001 0.002 0.003\"\\r\\ntor...\n",
       "18412    [Torch, function apply_to_slices(tensor, dimen...\n",
       "18414    [matrix\\r\\n\\r\\nmatrix:sub(2,3,2,3)\\r\\n\\r\\nz = ...\n",
       "18415    [array = torch.zeros(5) -- array = [0 0 0 0 0]...\n",
       "18416    [torch.IndexCopy, array:indexCopy(1, indices, ...\n",
       "18417    [array = np.zeros(5) # array = [0 0 0 0 0]\\r\\n...\n",
       "18418    [require 'nn'\\r\\nrequire 'torch'\\r\\nrequire 'r...\n",
       "18419    [torch.Tensor, :sub, :select, __index, torch.m...\n",
       "18420                                                  NaN\n",
       "18422    [nn, nn.Concat, nn.Select, local net = nn.Conc...\n",
       "18423    [CUDA_VISIBLE_DEVICES, export CUDA_VISIBLE_DEV...\n",
       "18424    [CUDA_VISIBLE_DEVICES, cutorch.setDevice(), CU...\n",
       "18425    [sudo apt-get install -y libreadline-dev\\r\\n, ...\n",
       "18426    [mydata = torch.class('something')\\r\\nmydata =...\n",
       "18428    [gnuplot\\r\\nset title \"Mean accuracy\"\\r\\nset x...\n",
       "18431    [gModule, gradInput, nn.Module, input, nngraph...\n",
       "18432    [import numpy\\r\\nimport Image\\r\\nimport lutorp...\n",
       "18433                                                  NaN\n",
       "18435    [-v, arg, local exe, i = arg[ 0 ], -1\\r\\nwhile...\n",
       "18436    [/opt/zbstudio/bin/linux/x64/lua version is Lu...\n",
       "18437                                                  NaN\n",
       "18438    [/usr/local/Cellar/lua/5.3.5_1/include/lua, #i...\n",
       "18439                                                  NaN\n",
       "18440    [do\\r\\n local Blah = torch.class('Blah')\\r\\n f...\n",
       "18441    [local Blah = torch.class('Blah'), do \\r\\nend ...\n",
       "18442    [nvcc -o im2col -I/deep/u/ibello/torch/include...\n",
       "18443                                                [m[]]\n",
       "18444    [local a = 5\\r\\nlocal b = a\\r\\n, b, do local i...\n",
       "18445    [data[5],  -- matrix-matrix operation: result ...\n",
       "18446    [debug.getlocal, repl(), require \"trepl\"\\r\\n\\r...\n",
       "18447                                    [getParameters()]\n",
       "18448    [torch.mm, prod = torch.mm(a,b), /* this is th...\n",
       "18451    [torch.eq, torch.eq(torch.tensor([[1., 2.], [3...\n",
       "18454    [external_command.lua, -- args has been set by...\n",
       "18455    [loadfile, local TempFunc = loadfile \"torch_sc...\n",
       "18456    [function runfile(&lt;scriptName&gt;, ...)\\r\\n...\n",
       "18459    [classes = {1}\\r\\n, confusion = optim.Confusio...\n",
       "18460                                                  NaN\n",
       "18461                                                  NaN\n",
       "18464    [local parallel = nn.ParallelTable()\\r\\nparall...\n",
       "18465    [df_do, nn.Criterion, nn.MSECriterion, df_do, ...\n",
       "18466    [nn.ClassNLLCriterion, batch_size, class, batc...\n",
       "18467    [local command = table.concat(arg, ' ', -1, #a...\n",
       "18468    [l3 = nn.Linear(params.x3_size1, params.x3_siz...\n",
       "18469    [torch.nn, nn.Parallel, gradOutput, local firs...\n",
       "18470                        [model.modules[2].weight\\r\\n]\n",
       "18471    [model.modules[1].weight, model:get(1).weight,...\n",
       "18472    [indices = torch.LongTensor{1,7,5}:view(-1,1)\\...\n",
       "18473    [indicies = torch.LongTensor{1,7,5}\\r\\none_hot...\n",
       "18474                                                  NaN\n",
       "18475       [nn.gModule, idx, sentence_idx, node_idx, nil]\n",
       "18476    [nn_, \"#define nn_\", init.c, #define nn_(NAME)...\n",
       "18477    [[{ ... }], n, n, {start,end}, start, end, {},...\n",
       "18478                                                 [cl]\n",
       "18480    [perceptron_general, gradOutput, gradOutput, g...\n",
       "18482                                                  NaN\n",
       "18483    [ firstHalf = torch.Tensor(firstHalf)\\r\\n seco...\n",
       "18484    [[-1,1], [0.9], threshold, [-0.35], -0.35, thr...\n",
       "18486    [{}, {}, &gt; a = torch.Tensor(3, 3):fill(0)\\r...\n",
       "18488    [mean = data:mean(1)\\r\\ndata:add(-1, mean:expa...\n",
       "18489                                                  NaN\n",
       "18490    [nn.Identity(), (), nn.Module, __call__, __cal...\n",
       "18491    [()(), (), call, function foo()\\r\\n  return fu...\n",
       "18492    [require 'torch'\\r\\n\\r\\n-- define some dummy A...\n",
       "18493    [-- nstates[2]*filtsize*filtsize = 64x5x5 = 1,...\n",
       "18494             [require, local torch = require \"torch\"]\n",
       "18495    [predictionValue*targetValue &lt; 1, targetVal...\n",
       "18497    [gdb64 /bin/bash    # check your gdb configura...\n",
       "18498          [lldb, gdb, sudo apt-get install lldb, yum]\n",
       "18500    [maxSize = 480\\r\\n-- find the smaller dimensio...\n",
       "18501    [Tensor:apply, require 'torch'\\r\\n\\r\\nA = torc...\n",
       "18502    [lib/TH/THTensor.h:\\r\\n#define THTensor_(NAME)...\n",
       "18503    [require \"nn\", init.lua, require('libnn'), ini...\n",
       "18504    [torch.setnumthreads, torch.getnumthreads, loc...\n",
       "18505    [nn.Tanh(), act_function = nn.Tanh\\r\\nperceptr...\n",
       "18506    [act_function = nn.Tanh();\\r\\n, act_function, ...\n",
       "18507                                 [x[x:gt(5)] = 0\\r\\n]\n",
       "18508    [/Users/you/torch/install/bin, $ cd\\r\\n, $ ema...\n",
       "18510    [printT = function(t)\\r\\n   t = t:view(-1)\\r\\n...\n",
       "18512    [sudo port -f deactivate jpeg\\r\\nsudo port ins...\n",
       "18514                                                  NaN\n",
       "18516    [luarocks install inspect, local inspect = req...\n",
       "18517    [local z = {\\r\\n  {27, 0.0001}, {29, 0.001}, {...\n",
       "18518    [Not updating your shell profile.\\r\\nYou might...\n",
       "18519    [which ipython, echo $PATH, .bashrc, cd, .bash...\n",
       "18520    [net:add(nn.Transpose({1,2},{2,3},{3,4}))\\r\\nc...\n",
       "18521                                                  NaN\n",
       "18522    [string.match, io.lines, -- script.lua\\r\\nloca...\n",
       "18523    [mlp:add(nn.Linear(inputs:size(2), HUs))\\r\\nml...\n",
       "18524    [images:resize(...)\\r\\n, images.resize(...)\\r\\...\n",
       "18525                                                  NaN\n",
       "18526    [mlp = model:toModule(datasource:trainSet():su...\n",
       "18527    [dataset[i] = {dnaseIsignals[i-1], dnaseIsigna...\n",
       "18528    [input, output, Tensor, input, dim, Tensor, x0...\n",
       "18529    [local, data, points, unsup.kmeans, -- batch s...\n",
       "18530    [mlp2 = mlp:toModule(datasource:trainSet():sub...\n",
       "18531    [torch.DoubleTensor.nn.L1Cost_updateOutput\\r\\n...\n",
       "18532    [require 'caffe', caffe::Net, nn, nn.Sequentia...\n",
       "18533    [image.lena(), size(dim), require 'image'\\r\\n\\...\n",
       "18534                                [-G \"MSYS Makefiles\"]\n",
       "18535    [\"c:\\Program Files (x86)\\Microsoft Visual Stud...\n",
       "18536    [libcunn.so, git clone https://github.com/torc...\n",
       "18538    [C:\\Program Files\\Torch, path.lua=[[C:\\Program...\n",
       "18539    [-- This assumes `t1` is a 2-dimensional tenso...\n",
       "18541                                                  NaN\n",
       "18542                                                  NaN\n",
       "18543                                                  NaN\n",
       "18545    [    boxes1 (Array[N, 4])\\r\\n    boxes2 (Array...\n",
       "18547                                                  NaN\n",
       "18549                                                  NaN\n",
       "18550                                                  NaN\n",
       "18551    [import pandas as pd\\r\\nmy_dataframe = pd.read...\n",
       "18552    [antialias, antialias=True, InterpolationMode....\n",
       "18553                                                  NaN\n",
       "18554                                                  NaN\n",
       "18555    [model_urls, # change from your model_urls to ...\n",
       "18556    [pip install --upgrade medcat -f https://downl...\n",
       "18559                                                  NaN\n",
       "18560                    [transform, transfrom, transform]\n",
       "18561                                                  NaN\n",
       "18562    [if __name__ == \"__main__\":\\r\\n        main()\\...\n",
       "18563                      [DataLoader(num_workers=0)\\r\\n]\n",
       "18564    [pickle, transformations = transforms.Compose(...\n",
       "18565           [from collections import OrderedDict \\r\\n]\n",
       "18566               [WSGIApplicationGroup %{GLOBAL}  \\r\\n]\n",
       "18567                                                  NaN\n",
       "18568    [torchvision, 0.4.0, pip uninstall torchvision...\n",
       "18569    [conda create --name test5 python=3.6\\r\\nconda...\n",
       "18570                           [pip3 install torchvision]\n",
       "18571    [inputs,labels=next(iter(trainset))\\r\\n, input...\n",
       "18572    [import glfw\\r\\ndef f():\\r\\n   ....\\r\\n   some...\n",
       "18573    [https://github.com/python-pillow/Pillow/blob/...\n",
       "18574    [RandomRotation, Image, core.fill(), return im...\n",
       "18575                                                  NaN\n",
       "18576    [classifier, classifier, output, classifier, f...\n",
       "18578    [from torchvision.datasets.vision import Visio...\n",
       "18580    [pip, pip install torchvision\\r\\n, conda insta...\n",
       "18581    [torch.nn.CrossEntropyLoss, torch.nn.BCELoss()...\n",
       "18583    [train_input = mnist_train_set.train_data.view...\n",
       "18584                              [root, download = True]\n",
       "18586    [class MNIST01(MNIST):\\r\\n    def __getitem__(...\n",
       "18587      [print(VGG16(normalize(img).unsqueeze(0)))\\r\\n]\n",
       "18588                                                  NaN\n",
       "18589                                                  NaN\n",
       "18590    [!python3 -m pip install torchvision==0.11.1\\r...\n",
       "18592                                         [lit_models]\n",
       "18593                                                  NaN\n",
       "18594    [F.binary_cross_entropy_with_logits, training_...\n",
       "18595    [on_epoch, log, from torchmetrics import Accur...\n",
       "18596    [LightningModule, class MNISTModel(LightningMo...\n",
       "18597    [.step(), optimizer.step(training_step_closure...\n",
       "18598                                                  NaN\n",
       "18599    [from pytorch_lightning.utilities import rank_...\n",
       "18600    [TQDMProgressBar, on_train_epoch_start, from p...\n",
       "18601                                                  NaN\n",
       "18602    [log_dict, log, metrics = {\\r\\n    'val_loss':...\n",
       "18603    [{epoch}, {step}, ModelCheckpoint, LightningMo...\n",
       "18604                                                  NaN\n",
       "18605                                                  NaN\n",
       "18608    [return_dict=False, output = self.classifier(o...\n",
       "18609    [x = x.view(b, -1), x = x.view(b, -1, 28, 28),...\n",
       "18610                                                  NaN\n",
       "18611    [dm = DataModule()\\r\\n# write your weights get...\n",
       "18613    [from torch.autograd import Variable\\r\\n\\r\\nim...\n",
       "18614    [import logging\\r\\nfrom pycave import set_logg...\n",
       "18616    [test_epoch_end, rank==0, torch.distributed.re...\n",
       "18617                                                  NaN\n",
       "18618    [from pytorch_lightning.loggers import CSVLogg...\n",
       "18619    [1.9.0+cu111, +cu111, !pip install cloud-tpu-c...\n",
       "18620    [import torch\\r\\ntorch.version.cuda\\r\\n\\r\\n10....\n",
       "18621            [trainer.fit(model), trainer.tune(model)]\n",
       "18622                                                  NaN\n",
       "18623                                                  NaN\n",
       "18624                                                  NaN\n",
       "18625                                                  NaN\n",
       "18626                                                  NaN\n",
       "18627                                                  NaN\n",
       "18628    [Trainer, .fit(), .test(), .fit(), .test(), li...\n",
       "18629    [metric_acc = torchmetrics.Accuracy(average='m...\n",
       "18630                                                  NaN\n",
       "18631    [LightningModule, .training_step(), Trainer, L...\n",
       "18632    [  | Name | Type   | Params\\r\\n---------------...\n",
       "18634    [.log(), def validation_step(self, batch, _):\\...\n",
       "18635    [--limit_val_batches, --val_check_interval, de...\n",
       "18636    [pl.LightningModule, nn.Module, \\r\\nclass Wrap...\n",
       "18637    [azureml-core==1.30.0\\r\\nazureml-mlflow==1.30....\n",
       "18638                                                  NaN\n",
       "18639                [.to(device), device = cuda(), cpu()]\n",
       "18640    [prepare_data(), setup(), def prepare_data(sel...\n",
       "18641    [import torch\\r\\nfrom torch.autograd import Va...\n",
       "18642    [import numpy as np \\r\\nimport pytorch_lightni...\n",
       "18644    [torch.nn.parameter.Parameter, too_big_for_GPU...\n",
       "18645                                                  NaN\n",
       "18646          [pl.LightingModule, pl.LightningDataModule]\n",
       "18647    [logger = TensorBoardLogger(\"tb_logs\", name=\"m...\n",
       "18648    [self.logger.experiment.some_tensorboard_funct...\n",
       "18649    [def training_step(self, batch: Tuple[Tensor, ...\n",
       "18650    [ def training_step_end(self, training_step_ou...\n",
       "18651    [Parallel, Split, class Parallel(torch.nn.Modu...\n",
       "18652    [class Split(torch.nn.Module):\\r\\n    \"\"\"\\r\\n ...\n",
       "18653    [\\r\\nclass IntHandler:\\r\\n    def legend_artis...\n",
       "18654    [self.logger.experiment.add_figure(*tag*, *fig...\n",
       "18655    [import pytorch_lightning as pl\\r\\nimport seab...\n",
       "18660    [class EncoderLayer(nn.Module):\\r\\n\"\"\"Encoder ...\n",
       "18661    [wandb, #!/usr/bin/env python\\r\\nimport wandb\\...\n",
       "18662                                    [python, python3]\n",
       "18663    [experiment.load_state_dict(checkpoint['state_...\n",
       "18666                                                  NaN\n",
       "18667                                                  NaN\n",
       "18668                                                  NaN\n",
       "18669                                                  NaN\n",
       "18671                                                  NaN\n",
       "18672                                                  NaN\n",
       "18673                                                  NaN\n",
       "18674    [mode=\"raw\", max_prediction, max_prediction, t...\n",
       "18675    [TimeSeriesDataSet, predict=True, TimeSeriesDa...\n",
       "18676    [import pandas as pd\\r\\nfrom torch.utils.data ...\n",
       "18677                                                  NaN\n",
       "18678    [torchtext.legacy.datasets.SequenceTaggingData...\n",
       "18679                                                  NaN\n",
       "18680    [# Load image file\\r\\n# def load_image(path):\\...\n",
       "18681    [WeightedRandomSampler, weights = [1./(S*j) fo...\n",
       "18682           [pin_memory = True\\r\\nnum_workers = 4\\r\\n]\n",
       "18683                                                  NaN\n",
       "18684                                                  NaN\n",
       "18685    [64, 3, W, H, batchsize, channels, width, heig...\n",
       "18686    [(4), b, (3), 0, sample = self.transform(sampl...\n",
       "18688    [.ipynb_checkpoints, /content/drive/MyDrive/Da...\n",
       "18689    [datasets.ImageFolder, img1, img2, Dataset, Da...\n",
       "18690                                                  NaN\n",
       "18691    [class SignMNISTDataset(Dataset):\\r\\n, def Sig...\n",
       "18692    [examples = enumerate(train_loader)\\r\\nbatch_i...\n",
       "18693    [labelsdec = trainset.class_to_idx, def getLis...\n",
       "18694    [import torch\\r\\n\\r\\nclass mnist(torch.utils.d...\n",
       "18695    [input = train_set(image)\\r\\ninput = input.uns...\n",
       "18696    [#input_var = input_var.view(1, 3, 32,32), inp...\n",
       "18697                                                  NaN\n",
       "18698    [CPUFloatType, auto options = torch::TensorOpt...\n",
       "18700                                                  NaN\n",
       "18701    [void get_tensors(torch::Tensor* out) {\\r\\n   ...\n",
       "18702    [operator[], data_ptr, std::cout &lt;&lt; frog...\n",
       "18703    [.data_ptr, float* temp_arr = frogs.data_ptr&l...\n",
       "18704                                                  NaN\n",
       "18705                              [one_T.transpose(0, 1)]\n",
       "18706    [cv::Mat resultImg(448, 448, CV_8UC3);\\r\\n, cv...\n",
       "18707    [torch::jit::IValue::from, IValue, auto my_arr...\n",
       "18708                                                  NaN\n",
       "18709    [void save_tensor_map(const std::map&lt;std::s...\n",
       "18710    [#include &lt;torch/torch.h&gt;\\r\\n\\r\\nusing n...\n",
       "18711                                                  NaN\n",
       "18712                                                  NaN\n",
       "18714    [using namespace someLibrary;, someLibrary::so...\n",
       "18715                                                  NaN\n",
       "18716                                                  NaN\n",
       "18717                                                  NaN\n",
       "18718    [auto dims = torch::IntArrayRef{1, 10, 512, 51...\n",
       "18719                                                  NaN\n",
       "18720                                                  NaN\n",
       "18721                                              [links]\n",
       "18722    [...\\r\\nfor (int i = 0; i &lt; 255; i++)\\r\\n  ...\n",
       "18723                                                  NaN\n",
       "18724    [std::__cxx11::basic_string, std::string, D_GL...\n",
       "18725                                                  NaN\n",
       "18727                                                  NaN\n",
       "18728                                                  NaN\n",
       "18729                                                  NaN\n",
       "18730    [// forgot to add these both lines\\r\\n// the y...\n",
       "18732                                                  NaN\n",
       "18733    [torch::nn::AdaptiveMaxPool2d, AdaptiveMaxPool...\n",
       "18734                                                  NaN\n",
       "18735                                                  NaN\n",
       "18736             [torch::jit::Module, torch::jit::Module]\n",
       "18737                                                  NaN\n",
       "18738                                                  NaN\n",
       "18739    [QT_NO_KEYWORDS, slots, QT_NO_KEYWORDS, #undef...\n",
       "18740    [PS &gt; $env:DEBUG=1\\r\\nPS &gt; $env:CMAKE_IN...\n",
       "18741                                                  NaN\n",
       "18742                                                  NaN\n",
       "18744    [tensor_image_cpy = tensor_image.reshape({ wid...\n",
       "18745                                                  NaN\n",
       "18746                                                  NaN\n",
       "18747    [% git clone -b master --recurse-submodule htt...\n",
       "18748    [ten2,   int main{\\r\\n    auto ten=torch::rand...\n",
       "18750                                                  NaN\n",
       "18751    [torch::from_blob, torch::from_blob, from_blob...\n",
       "18752                                                  NaN\n",
       "18753    [cmake_minimum_required(VERSION 3.17)\\r\\nproje...\n",
       "18754    [cmake .. -G Ninja -DTorch_DIR=\"path_to_your_l...\n",
       "18757    [string, torch::Tensor, syntax = \"proto3\";\\r\\n...\n",
       "18758    [torch::TensorOptions, torch::Tensor::slice, /...\n",
       "18759    [using namespace torch::indexing; //for using ...\n",
       "18760    [c10::kByte, uchar, char, uint, uchar, int, au...\n",
       "18761    [torch::from_blob, void*, IntArrayRef, Eigen::...\n",
       "18762                                                  NaN\n",
       "18764    [cmake_minimum_required(VERSION 3.14 FATAL_ERR...\n",
       "18765    [cmake_minimum_required(VERSION 3.8 FATAL_ERRO...\n",
       "18767    [tensor.to(torch::kLong), Long, Tensor, to, in...\n",
       "18768    [inline Tensor Tensor::to(ScalarType dtype, bo...\n",
       "18769    [make, make, cmake build ., mkdir build\\r\\ncd ...\n",
       "18770    [set_target_properties(torch PROPERTIES\\r\\n  I...\n",
       "18771    [cmake -DCMAKE_PREFIX_PATH=path\\to\\libtorch -A...\n",
       "18772    [typedef Eigen::Matrix&lt;float, Eigen::Dynami...\n",
       "18773    [if (MSVC)\\r\\n    file(GLOB TORCH_DLLS \"${TORC...\n",
       "18774    [torch::jit::load, std::shared_ptr&lt;torch::j...\n",
       "18775    [module, torch::jit::script::Module, using mod...\n",
       "18776                                                  NaN\n",
       "18777    [_GLIBCXX_USE_CXX11_ABI=0, _GLIBCXX_USE_CXX11_...\n",
       "18778                                                  NaN\n",
       "18779    [for (auto&amp; p : net-&gt;named_parameters()...\n",
       "18780    [g++, g++-4.9, sudo apt-get install g++-4.9, ....\n",
       "18781    [throw std::runtime_error(\"hi this is my error...\n",
       "18782    [[nikita@x1c build]$ objdump -C -t CMakeFiles/...\n",
       "18783                                                  NaN\n",
       "18784    [Modifygraph_byAdding, Modifygraph_byDeleting,...\n",
       "18785                                                  NaN\n",
       "18786                                                  NaN\n",
       "18787    [import random\\r\\nimport networkx as nx\\r\\n\\r\\...\n",
       "18790                                                  NaN\n",
       "18792                                                  NaN\n",
       "18793    [!pip install torch==1.10.0+cu111 torchvision=...\n",
       "18794                                                  NaN\n",
       "18795                                                  NaN\n",
       "18796                                                  NaN\n",
       "18797                                                  NaN\n",
       "18798                                                  NaN\n",
       "18799                                                  NaN\n",
       "18800    [get_idx_split, def get_idx_split(self):\\r\\n  ...\n",
       "18801    [to_networkx(&lt;PyTorchGeometricDataObject&gt...\n",
       "18802                                                  NaN\n",
       "18803                                                  NaN\n",
       "18805    [from torchtext.datasets import IMDB\\r\\nfrom c...\n",
       "18806    [from torchtext.datasets import IMDB\\r\\nfrom c...\n",
       "18807                                                  NaN\n",
       "18808    [__getitem__, string, token, vocab['cat'], vocab]\n",
       "18809    [str, int, KeyError, {}[1], {}.get(1, \"I don't...\n",
       "18810    [english, Field, english.build_vocab(...), bui...\n",
       "18811    [build_vocab, min_freq, build_vocab, use_vocab...\n",
       "18813    [train.replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t...\n",
       "18814                                                  NaN\n",
       "18815    [from torchtext.data import TabularDataset, Fi...\n",
       "18816    [ReversibleField, class ReversibleField(Field)...\n",
       "18818    [itos[4], stoi[\"the\"], ('the', &lt;count&gt;),...\n",
       "18820                                                  NaN\n",
       "18821                                                  NaN\n",
       "18822    [prev_mask, bool, True, False, prev_generated_...\n",
       "18823    [TEXT, load_data, load_data_but_error, train=T...\n",
       "18824    [TEXT, TEXT, TEXT.build_vocab(examples, min_fr...\n",
       "18825    [torchtext\\utils.py, csv.field_size_limit(sys....\n",
       "18826                                                  NaN\n",
       "18827    [def inference(model, inputs):\\r\\n    # use do...\n",
       "18828                                                  NaN\n",
       "18829                                                  NaN\n",
       "18830    [t5, onnx, fastT5, traced_model = torch.jit.tr...\n",
       "18831                                [1.4.0, 1.8.1, 1.8.0]\n",
       "18832                                                  NaN\n",
       "18834                                                  NaN\n",
       "18835    [# If you get an error in the next cell, you c...\n",
       "18838       [torch.from_numpy(array), torch.tensor(array)]\n",
       "18839                                                  NaN\n",
       "18840    [K += noise  * np.eye(n_datapoints), K += nois...\n",
       "18841                                                  NaN\n",
       "Name: ansCode, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['ansCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f6d808e81b650dd36485f963f47376e57ef3663dba705673e3634328daadeaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
